{"id":{"0":"http:\/\/arxiv.org\/abs\/2201.00075v1","1":"http:\/\/arxiv.org\/abs\/2201.02735v1","2":"http:\/\/arxiv.org\/abs\/1907.09358v3","3":"http:\/\/arxiv.org\/abs\/2103.10415v3","4":"http:\/\/arxiv.org\/abs\/2112.15545v1","5":"http:\/\/arxiv.org\/abs\/2103.12360v3","6":"http:\/\/arxiv.org\/abs\/2112.15356v1","7":"http:\/\/arxiv.org\/abs\/2105.04976v2","8":"http:\/\/arxiv.org\/abs\/2112.15324v1","9":"http:\/\/arxiv.org\/abs\/2112.15290v1","10":"http:\/\/arxiv.org\/abs\/2112.15283v1","11":"http:\/\/arxiv.org\/abs\/2112.15280v1","12":"http:\/\/arxiv.org\/abs\/2112.11632v2","13":"http:\/\/arxiv.org\/abs\/2112.15253v1","14":"http:\/\/arxiv.org\/abs\/2112.15124v1","15":"http:\/\/arxiv.org\/abs\/2112.15099v1","16":"http:\/\/arxiv.org\/abs\/2112.15060v1","17":"http:\/\/arxiv.org\/abs\/2112.15051v1","18":"http:\/\/arxiv.org\/abs\/2112.15043v1","19":"http:\/\/arxiv.org\/abs\/2112.15011v1","20":"http:\/\/arxiv.org\/abs\/2112.15009v1","21":"http:\/\/arxiv.org\/abs\/2112.14938v1","22":"http:\/\/arxiv.org\/abs\/2112.14933v1","23":"http:\/\/arxiv.org\/abs\/2112.02498v2","24":"http:\/\/arxiv.org\/abs\/2105.01893v2","25":"http:\/\/arxiv.org\/abs\/2112.14890v1","26":"http:\/\/arxiv.org\/abs\/2106.05642v3","27":"http:\/\/arxiv.org\/abs\/2112.14820v1","28":"http:\/\/arxiv.org\/abs\/1907.00457v2","29":"http:\/\/arxiv.org\/abs\/2112.14789v1","30":"http:\/\/arxiv.org\/abs\/2112.14731v1","31":"http:\/\/arxiv.org\/abs\/2103.15330v2","32":"http:\/\/arxiv.org\/abs\/2111.10269v2","33":"http:\/\/arxiv.org\/abs\/2109.02325v2","34":"http:\/\/arxiv.org\/abs\/2112.14569v1","35":"http:\/\/arxiv.org\/abs\/2009.09708v3","36":"http:\/\/arxiv.org\/abs\/2012.05481v2","37":"http:\/\/arxiv.org\/abs\/2102.01547v5","38":"http:\/\/arxiv.org\/abs\/2112.14484v1","39":"http:\/\/arxiv.org\/abs\/2110.00031v2","40":"http:\/\/arxiv.org\/abs\/2201.02504v1","41":"http:\/\/arxiv.org\/abs\/2112.14375v1","42":"http:\/\/arxiv.org\/abs\/2110.00534v3","43":"http:\/\/arxiv.org\/abs\/2112.14343v1","44":"http:\/\/arxiv.org\/abs\/2112.14330v1","45":"http:\/\/arxiv.org\/abs\/2112.14318v1","46":"http:\/\/arxiv.org\/abs\/1809.04128v3","47":"http:\/\/arxiv.org\/abs\/2104.08646v3","48":"http:\/\/arxiv.org\/abs\/2112.13572v2","49":"http:\/\/arxiv.org\/abs\/2110.01529v2","50":"http:\/\/arxiv.org\/abs\/2109.00527v2","51":"http:\/\/arxiv.org\/abs\/2112.14192v1","52":"http:\/\/arxiv.org\/abs\/2112.14168v1","53":"http:\/\/arxiv.org\/abs\/2112.14153v1","54":"http:\/\/arxiv.org\/abs\/2201.02737v1","55":"http:\/\/arxiv.org\/abs\/2109.05837v3","56":"http:\/\/arxiv.org\/abs\/2112.13808v2","57":"http:\/\/arxiv.org\/abs\/1906.08487v3","58":"http:\/\/arxiv.org\/abs\/2112.13969v1","59":"http:\/\/arxiv.org\/abs\/2112.13960v1","60":"http:\/\/arxiv.org\/abs\/2112.13946v1","61":"http:\/\/arxiv.org\/abs\/2112.13906v1","62":"http:\/\/arxiv.org\/abs\/2112.13870v1","63":"http:\/\/arxiv.org\/abs\/2112.13834v1","64":"http:\/\/arxiv.org\/abs\/2112.13833v1","65":"http:\/\/arxiv.org\/abs\/2112.13800v1","66":"http:\/\/arxiv.org\/abs\/2008.00097v3","67":"http:\/\/arxiv.org\/abs\/2112.13790v1","68":"http:\/\/arxiv.org\/abs\/2112.13776v1","69":"http:\/\/arxiv.org\/abs\/2112.13758v1","70":"http:\/\/arxiv.org\/abs\/2112.13756v1","71":"http:\/\/arxiv.org\/abs\/2112.13742v1","72":"http:\/\/arxiv.org\/abs\/1911.01208v4","73":"http:\/\/arxiv.org\/abs\/2112.13634v1","74":"http:\/\/arxiv.org\/abs\/2112.13619v1","75":"http:\/\/arxiv.org\/abs\/2112.13610v1","76":"http:\/\/arxiv.org\/abs\/2008.11841v3","77":"http:\/\/arxiv.org\/abs\/2112.13597v1","78":"http:\/\/arxiv.org\/abs\/2112.13556v1","79":"http:\/\/arxiv.org\/abs\/2112.13512v1","80":"http:\/\/arxiv.org\/abs\/2112.13432v1","81":"http:\/\/arxiv.org\/abs\/2112.13428v1","82":"http:\/\/arxiv.org\/abs\/2111.03963v2","83":"http:\/\/arxiv.org\/abs\/2105.10909v2","84":"http:\/\/arxiv.org\/abs\/2109.06935v2","85":"http:\/\/arxiv.org\/abs\/2105.07148v3","86":"http:\/\/arxiv.org\/abs\/2106.01598v2","87":"http:\/\/arxiv.org\/abs\/2112.13372v1","88":"http:\/\/arxiv.org\/abs\/2112.13352v1","89":"http:\/\/arxiv.org\/abs\/2112.03719v2","90":"http:\/\/arxiv.org\/abs\/2112.13320v1","91":"http:\/\/arxiv.org\/abs\/2112.13319v1","92":"http:\/\/arxiv.org\/abs\/2104.07396v3","93":"http:\/\/arxiv.org\/abs\/2108.12928v2","94":"http:\/\/arxiv.org\/abs\/2112.13288v1","95":"http:\/\/arxiv.org\/abs\/2112.13259v1","96":"http:\/\/arxiv.org\/abs\/2112.13241v1","97":"http:\/\/arxiv.org\/abs\/2112.13238v1","98":"http:\/\/arxiv.org\/abs\/2112.13237v1","99":"http:\/\/arxiv.org\/abs\/2009.06206v5","100":"http:\/\/arxiv.org\/abs\/2112.13179v1","101":"http:\/\/arxiv.org\/abs\/2010.08566v4","102":"http:\/\/arxiv.org\/abs\/1909.13302v4","103":"http:\/\/arxiv.org\/abs\/2112.12996v1","104":"http:\/\/arxiv.org\/abs\/2112.12940v1","105":"http:\/\/arxiv.org\/abs\/2112.12938v1","106":"http:\/\/arxiv.org\/abs\/2112.12913v1","107":"http:\/\/arxiv.org\/abs\/2111.02110v3","108":"http:\/\/arxiv.org\/abs\/2112.12870v1","109":"http:\/\/arxiv.org\/abs\/2112.12809v1","110":"http:\/\/arxiv.org\/abs\/2112.12731v1","111":"http:\/\/arxiv.org\/abs\/2112.12672v1","112":"http:\/\/arxiv.org\/abs\/2112.12489v1","113":"http:\/\/arxiv.org\/abs\/2112.12444v1","114":"http:\/\/arxiv.org\/abs\/2112.12441v1","115":"http:\/\/arxiv.org\/abs\/2112.12433v1","116":"http:\/\/arxiv.org\/abs\/2107.00676v2","117":"http:\/\/arxiv.org\/abs\/2107.08408v2","118":"http:\/\/arxiv.org\/abs\/2112.12389v1","119":"http:\/\/arxiv.org\/abs\/2201.02738v1","120":"http:\/\/arxiv.org\/abs\/2112.12356v1","121":"http:\/\/arxiv.org\/abs\/2112.12318v1","122":"http:\/\/arxiv.org\/abs\/2106.00400v2","123":"http:\/\/arxiv.org\/abs\/2112.12224v1","124":"http:\/\/arxiv.org\/abs\/2112.12028v1","125":"http:\/\/arxiv.org\/abs\/2201.02739v1","126":"http:\/\/arxiv.org\/abs\/2112.12014v1","127":"http:\/\/arxiv.org\/abs\/2107.11414v3","128":"http:\/\/arxiv.org\/abs\/2112.08914v2","129":"http:\/\/arxiv.org\/abs\/2112.11973v1","130":"http:\/\/arxiv.org\/abs\/2112.11941v1","131":"http:\/\/arxiv.org\/abs\/2112.11850v1","132":"http:\/\/arxiv.org\/abs\/2008.00364v6","133":"http:\/\/arxiv.org\/abs\/2106.12384v2","134":"http:\/\/arxiv.org\/abs\/2112.11800v1","135":"http:\/\/arxiv.org\/abs\/2112.11776v1","136":"http:\/\/arxiv.org\/abs\/2106.02382v3","137":"http:\/\/arxiv.org\/abs\/2112.11769v1","138":"http:\/\/arxiv.org\/abs\/2107.02126v5","139":"http:\/\/arxiv.org\/abs\/2112.11740v1","140":"http:\/\/arxiv.org\/abs\/2112.11739v1","141":"http:\/\/arxiv.org\/abs\/2110.13715v2","142":"http:\/\/arxiv.org\/abs\/2106.08785v2","143":"http:\/\/arxiv.org\/abs\/2111.03945v3","144":"http:\/\/arxiv.org\/abs\/2112.11670v1","145":"http:\/\/arxiv.org\/abs\/2112.11668v1","146":"http:\/\/arxiv.org\/abs\/2112.11642v1","147":"http:\/\/arxiv.org\/abs\/2112.11640v1","148":"http:\/\/arxiv.org\/abs\/2004.14174v3","149":"http:\/\/arxiv.org\/abs\/2105.10396v2","150":"http:\/\/arxiv.org\/abs\/2112.11494v1","151":"http:\/\/arxiv.org\/abs\/2112.11471v1","152":"http:\/\/arxiv.org\/abs\/2112.11391v1","153":"http:\/\/arxiv.org\/abs\/2112.11389v1","154":"http:\/\/arxiv.org\/abs\/2112.12262v1","155":"http:\/\/arxiv.org\/abs\/2010.08197v2","156":"http:\/\/arxiv.org\/abs\/2201.00693v1","157":"http:\/\/arxiv.org\/abs\/2110.04217v2","158":"http:\/\/arxiv.org\/abs\/2112.11241v1","159":"http:\/\/arxiv.org\/abs\/2112.11176v1","160":"http:\/\/arxiv.org\/abs\/2112.11070v1","161":"http:\/\/arxiv.org\/abs\/2109.06050v2","162":"http:\/\/arxiv.org\/abs\/2112.11031v1","163":"http:\/\/arxiv.org\/abs\/2112.10991v1","164":"http:\/\/arxiv.org\/abs\/2110.04913v2","165":"http:\/\/arxiv.org\/abs\/2104.03934v2","166":"http:\/\/arxiv.org\/abs\/2112.10936v1","167":"http:\/\/arxiv.org\/abs\/2110.14207v2","168":"http:\/\/arxiv.org\/abs\/2112.10925v1","169":"http:\/\/arxiv.org\/abs\/2105.02486v2","170":"http:\/\/arxiv.org\/abs\/2112.10746v1","171":"http:\/\/arxiv.org\/abs\/2112.10684v1","172":"http:\/\/arxiv.org\/abs\/2112.10668v1","173":"http:\/\/arxiv.org\/abs\/2112.00712v2","174":"http:\/\/arxiv.org\/abs\/2012.07499v4","175":"http:\/\/arxiv.org\/abs\/2109.13510v2","176":"http:\/\/arxiv.org\/abs\/2112.10553v1","177":"http:\/\/arxiv.org\/abs\/2112.10543v1","178":"http:\/\/arxiv.org\/abs\/2112.10508v1","179":"http:\/\/arxiv.org\/abs\/2008.09943v3","180":"http:\/\/arxiv.org\/abs\/2112.10424v1","181":"http:\/\/arxiv.org\/abs\/2112.10360v1","182":"http:\/\/arxiv.org\/abs\/2112.10322v1","183":"http:\/\/arxiv.org\/abs\/2112.10202v1","184":"http:\/\/arxiv.org\/abs\/2112.10189v1","185":"http:\/\/arxiv.org\/abs\/2112.10123v1","186":"http:\/\/arxiv.org\/abs\/2112.10108v1","187":"http:\/\/arxiv.org\/abs\/2112.10070v1","188":"http:\/\/arxiv.org\/abs\/2112.10064v1","189":"http:\/\/arxiv.org\/abs\/2201.02510v1","190":"http:\/\/arxiv.org\/abs\/2110.02950v2","191":"http:\/\/arxiv.org\/abs\/2112.10021v1","192":"http:\/\/arxiv.org\/abs\/2112.09986v1","193":"http:\/\/arxiv.org\/abs\/2112.09939v1","194":"http:\/\/arxiv.org\/abs\/2112.09925v1","195":"http:\/\/arxiv.org\/abs\/2112.09924v1","196":"http:\/\/arxiv.org\/abs\/2112.05328v3","197":"http:\/\/arxiv.org\/abs\/2112.09866v1","198":"http:\/\/arxiv.org\/abs\/2112.09860v1","199":"http:\/\/arxiv.org\/abs\/2109.07140v2","200":"http:\/\/arxiv.org\/abs\/2105.11905v2","201":"http:\/\/arxiv.org\/abs\/2112.09841v1","202":"http:\/\/arxiv.org\/abs\/2201.02740v1","203":"http:\/\/arxiv.org\/abs\/2106.07176v3","204":"http:\/\/arxiv.org\/abs\/2112.09742v1","205":"http:\/\/arxiv.org\/abs\/2112.09669v1","206":"http:\/\/arxiv.org\/abs\/2009.02835v3","207":"http:\/\/arxiv.org\/abs\/2112.09658v1","208":"http:\/\/arxiv.org\/abs\/2106.07340v4","209":"http:\/\/arxiv.org\/abs\/2112.09628v1","210":"http:\/\/arxiv.org\/abs\/2201.03445v1","211":"http:\/\/arxiv.org\/abs\/2112.09600v1","212":"http:\/\/arxiv.org\/abs\/2112.10609v1","213":"http:\/\/arxiv.org\/abs\/2108.13327v3","214":"http:\/\/arxiv.org\/abs\/2112.09526v1","215":"http:\/\/arxiv.org\/abs\/2112.09488v1","216":"http:\/\/arxiv.org\/abs\/2112.09467v1","217":"http:\/\/arxiv.org\/abs\/2112.08754v2","218":"http:\/\/arxiv.org\/abs\/2112.07421v2","219":"http:\/\/arxiv.org\/abs\/2112.08098v2","220":"http:\/\/arxiv.org\/abs\/2111.05068v2","221":"http:\/\/arxiv.org\/abs\/2112.09348v1","222":"http:\/\/arxiv.org\/abs\/2010.16143v3","223":"http:\/\/arxiv.org\/abs\/2112.09340v1","224":"http:\/\/arxiv.org\/abs\/2012.00893v2","225":"http:\/\/arxiv.org\/abs\/2112.09301v1","226":"http:\/\/arxiv.org\/abs\/2102.04081v3","227":"http:\/\/arxiv.org\/abs\/2112.09288v1","228":"http:\/\/arxiv.org\/abs\/2112.09231v1","229":"http:\/\/arxiv.org\/abs\/2011.00416v5","230":"http:\/\/arxiv.org\/abs\/2112.09215v1","231":"http:\/\/arxiv.org\/abs\/2104.08444v2","232":"http:\/\/arxiv.org\/abs\/1902.06689v2","233":"http:\/\/arxiv.org\/abs\/2112.07392v2","234":"http:\/\/arxiv.org\/abs\/2112.07391v2","235":"http:\/\/arxiv.org\/abs\/2112.09153v1","236":"http:\/\/arxiv.org\/abs\/2112.09118v1","237":"http:\/\/arxiv.org\/abs\/2010.05953v2","238":"http:\/\/arxiv.org\/abs\/2111.09296v3","239":"http:\/\/arxiv.org\/abs\/2112.09097v1","240":"http:\/\/arxiv.org\/abs\/2101.04255v6","241":"http:\/\/arxiv.org\/abs\/2112.09062v1","242":"http:\/\/arxiv.org\/abs\/2112.09054v1","243":"http:\/\/arxiv.org\/abs\/2108.00946v2","244":"http:\/\/arxiv.org\/abs\/2112.08918v1","245":"http:\/\/arxiv.org\/abs\/2112.08910v1","246":"http:\/\/arxiv.org\/abs\/2112.08907v1","247":"http:\/\/arxiv.org\/abs\/2107.13377v3","248":"http:\/\/arxiv.org\/abs\/2111.09749v2","249":"http:\/\/arxiv.org\/abs\/2112.08844v1","250":"http:\/\/arxiv.org\/abs\/2112.08808v1","251":"http:\/\/arxiv.org\/abs\/2112.08804v1","252":"http:\/\/arxiv.org\/abs\/2112.08789v1","253":"http:\/\/arxiv.org\/abs\/2112.08778v1","254":"http:\/\/arxiv.org\/abs\/2112.08770v1","255":"http:\/\/arxiv.org\/abs\/2112.11916v1","256":"http:\/\/arxiv.org\/abs\/2112.08735v1","257":"http:\/\/arxiv.org\/abs\/2112.08726v1","258":"http:\/\/arxiv.org\/abs\/2112.08723v1","259":"http:\/\/arxiv.org\/abs\/2112.08713v1","260":"http:\/\/arxiv.org\/abs\/2112.08696v1","261":"http:\/\/arxiv.org\/abs\/2112.08692v1","262":"http:\/\/arxiv.org\/abs\/2112.08688v1","263":"http:\/\/arxiv.org\/abs\/2112.08670v1","264":"http:\/\/arxiv.org\/abs\/2112.08663v1","265":"http:\/\/arxiv.org\/abs\/2112.08657v1","266":"http:\/\/arxiv.org\/abs\/2112.08653v1","267":"http:\/\/arxiv.org\/abs\/2112.08652v1","268":"http:\/\/arxiv.org\/abs\/2112.01488v2","269":"http:\/\/arxiv.org\/abs\/2112.08634v1","270":"http:\/\/arxiv.org\/abs\/2010.12723v2","271":"http:\/\/arxiv.org\/abs\/2112.08616v1","272":"http:\/\/arxiv.org\/abs\/2112.08609v1","273":"http:\/\/arxiv.org\/abs\/2112.08608v1","274":"http:\/\/arxiv.org\/abs\/2112.08596v1","275":"http:\/\/arxiv.org\/abs\/2012.05395v5","276":"http:\/\/arxiv.org\/abs\/2112.08593v1","277":"http:\/\/arxiv.org\/abs\/2112.08592v1","278":"http:\/\/arxiv.org\/abs\/2112.09738v1","279":"http:\/\/arxiv.org\/abs\/2112.08587v1","280":"http:\/\/arxiv.org\/abs\/2112.08583v1","281":"http:\/\/arxiv.org\/abs\/2112.08578v1","282":"http:\/\/arxiv.org\/abs\/2112.08570v1","283":"http:\/\/arxiv.org\/abs\/2112.12072v1","284":"http:\/\/arxiv.org\/abs\/2112.08560v1","285":"http:\/\/arxiv.org\/abs\/2112.08554v1","286":"http:\/\/arxiv.org\/abs\/2112.08550v1","287":"http:\/\/arxiv.org\/abs\/2112.08548v1","288":"http:\/\/arxiv.org\/abs\/2112.08547v1","289":"http:\/\/arxiv.org\/abs\/2103.10918v2","290":"http:\/\/arxiv.org\/abs\/2112.10613v1","291":"http:\/\/arxiv.org\/abs\/2112.11913v1","292":"http:\/\/arxiv.org\/abs\/2112.08532v1","293":"http:\/\/arxiv.org\/abs\/2112.08491v1","294":"http:\/\/arxiv.org\/abs\/2111.14709v2","295":"http:\/\/arxiv.org\/abs\/2102.01223v2","296":"http:\/\/arxiv.org\/abs\/2004.14120v2","297":"http:\/\/arxiv.org\/abs\/2112.08470v1","298":"http:\/\/arxiv.org\/abs\/2112.08462v1","299":"http:\/\/arxiv.org\/abs\/2112.11915v1","300":"http:\/\/arxiv.org\/abs\/2112.08414v1","301":"http:\/\/arxiv.org\/abs\/2112.08357v1","302":"http:\/\/arxiv.org\/abs\/2112.08351v1","303":"http:\/\/arxiv.org\/abs\/2112.08346v1","304":"http:\/\/arxiv.org\/abs\/2112.08342v1","305":"http:\/\/arxiv.org\/abs\/2109.01156v2","306":"http:\/\/arxiv.org\/abs\/2112.08333v1","307":"http:\/\/arxiv.org\/abs\/2112.08327v1","308":"http:\/\/arxiv.org\/abs\/2112.08321v1","309":"http:\/\/arxiv.org\/abs\/2112.08289v1","310":"http:\/\/arxiv.org\/abs\/2112.08266v1","311":"http:\/\/arxiv.org\/abs\/2111.10776v2","312":"http:\/\/arxiv.org\/abs\/2112.08261v1","313":"http:\/\/arxiv.org\/abs\/2112.08256v1","314":"http:\/\/arxiv.org\/abs\/2107.02794v2","315":"http:\/\/arxiv.org\/abs\/2008.05449v3","316":"http:\/\/arxiv.org\/abs\/2107.10941v2","317":"http:\/\/arxiv.org\/abs\/2112.08191v1","318":"http:\/\/arxiv.org\/abs\/2111.03470v2","319":"http:\/\/arxiv.org\/abs\/2112.08159v1","320":"http:\/\/arxiv.org\/abs\/2112.08152v1","321":"http:\/\/arxiv.org\/abs\/2112.08140v1","322":"http:\/\/arxiv.org\/abs\/2112.11914v1","323":"http:\/\/arxiv.org\/abs\/2111.00086v4","324":"http:\/\/arxiv.org\/abs\/2111.00107v3","325":"http:\/\/arxiv.org\/abs\/2112.08087v1","326":"http:\/\/arxiv.org\/abs\/2107.01275v2","327":"http:\/\/arxiv.org\/abs\/2112.08033v1","328":"http:\/\/arxiv.org\/abs\/2112.07985v1","329":"http:\/\/arxiv.org\/abs\/2112.07940v1","330":"http:\/\/arxiv.org\/abs\/2104.08728v2","331":"http:\/\/arxiv.org\/abs\/2112.07924v1","332":"http:\/\/arxiv.org\/abs\/2112.05587v2","333":"http:\/\/arxiv.org\/abs\/2112.07899v1","334":"http:\/\/arxiv.org\/abs\/2112.07888v1","335":"http:\/\/arxiv.org\/abs\/2112.07887v1","336":"http:\/\/arxiv.org\/abs\/2112.07882v1","337":"http:\/\/arxiv.org\/abs\/2112.07877v1","338":"http:\/\/arxiv.org\/abs\/2112.07874v1","339":"http:\/\/arxiv.org\/abs\/2112.07873v1","340":"http:\/\/arxiv.org\/abs\/2112.07870v1","341":"http:\/\/arxiv.org\/abs\/2112.07869v1","342":"http:\/\/arxiv.org\/abs\/2112.07783v1","343":"http:\/\/arxiv.org\/abs\/2104.11832v2","344":"http:\/\/arxiv.org\/abs\/2112.07772v1","345":"http:\/\/arxiv.org\/abs\/2112.07771v1","346":"http:\/\/arxiv.org\/abs\/2112.11207v1","347":"http:\/\/arxiv.org\/abs\/2112.07742v1","348":"http:\/\/arxiv.org\/abs\/2112.07711v1","349":"http:\/\/arxiv.org\/abs\/2112.07708v1","350":"http:\/\/arxiv.org\/abs\/2109.06827v2","351":"http:\/\/arxiv.org\/abs\/2104.05240v2","352":"http:\/\/arxiv.org\/abs\/2112.07648v1","353":"http:\/\/arxiv.org\/abs\/2112.11911v1","354":"http:\/\/arxiv.org\/abs\/1910.09909v5","355":"http:\/\/arxiv.org\/abs\/2105.06813v4","356":"http:\/\/arxiv.org\/abs\/2112.07536v1","357":"http:\/\/arxiv.org\/abs\/2108.10949v2","358":"http:\/\/arxiv.org\/abs\/2112.07515v1","359":"http:\/\/arxiv.org\/abs\/2112.07497v1","360":"http:\/\/arxiv.org\/abs\/2112.07447v1","361":"http:\/\/arxiv.org\/abs\/2112.07443v1","362":"http:\/\/arxiv.org\/abs\/2112.07434v1","363":"http:\/\/arxiv.org\/abs\/2112.07384v1","364":"http:\/\/arxiv.org\/abs\/2112.07381v1","365":"http:\/\/arxiv.org\/abs\/2112.01922v2","366":"http:\/\/arxiv.org\/abs\/2112.07337v1","367":"http:\/\/arxiv.org\/abs\/2112.07327v1","368":"http:\/\/arxiv.org\/abs\/2112.07308v1","369":"http:\/\/arxiv.org\/abs\/2112.07259v1","370":"http:\/\/arxiv.org\/abs\/2112.07254v1","371":"http:\/\/arxiv.org\/abs\/2112.07198v1","372":"http:\/\/arxiv.org\/abs\/2108.08877v3","373":"http:\/\/arxiv.org\/abs\/2011.08772v3","374":"http:\/\/arxiv.org\/abs\/2112.07165v1","375":"http:\/\/arxiv.org\/abs\/2112.06494v2","376":"http:\/\/arxiv.org\/abs\/2109.11136v3","377":"http:\/\/arxiv.org\/abs\/2104.12114v2","378":"http:\/\/arxiv.org\/abs\/2103.12248v3","379":"http:\/\/arxiv.org\/abs\/2112.07089v1","380":"http:\/\/arxiv.org\/abs\/2104.14781v2","381":"http:\/\/arxiv.org\/abs\/2112.11483v1","382":"http:\/\/arxiv.org\/abs\/2112.07055v1","383":"http:\/\/arxiv.org\/abs\/2112.07035v1","384":"http:\/\/arxiv.org\/abs\/2112.07011v1","385":"http:\/\/arxiv.org\/abs\/2112.06953v1","386":"http:\/\/arxiv.org\/abs\/2112.06905v1","387":"http:\/\/arxiv.org\/abs\/2112.06888v1","388":"http:\/\/arxiv.org\/abs\/2104.01791v2","389":"http:\/\/arxiv.org\/abs\/2112.06837v1","390":"http:\/\/arxiv.org\/abs\/2112.06776v1","391":"http:\/\/arxiv.org\/abs\/2112.06748v1","392":"http:\/\/arxiv.org\/abs\/2112.06743v1","393":"http:\/\/arxiv.org\/abs\/2112.06736v1","394":"http:\/\/arxiv.org\/abs\/2112.06924v1","395":"http:\/\/arxiv.org\/abs\/2112.06724v1","396":"http:\/\/arxiv.org\/abs\/2112.06723v1","397":"http:\/\/arxiv.org\/abs\/2109.07943v2","398":"http:\/\/arxiv.org\/abs\/2112.06603v1","399":"http:\/\/arxiv.org\/abs\/2112.11482v1","400":"http:\/\/arxiv.org\/abs\/2112.06540v1","401":"http:\/\/arxiv.org\/abs\/2112.11481v1","402":"http:\/\/arxiv.org\/abs\/2112.06507v1","403":"http:\/\/arxiv.org\/abs\/2110.02001v2","404":"http:\/\/arxiv.org\/abs\/2112.05662v2","405":"http:\/\/arxiv.org\/abs\/2112.11480v1","406":"http:\/\/arxiv.org\/abs\/2112.06462v1","407":"http:\/\/arxiv.org\/abs\/2112.06448v1","408":"http:\/\/arxiv.org\/abs\/2111.02643v5","409":"http:\/\/arxiv.org\/abs\/2012.01775v2","410":"http:\/\/arxiv.org\/abs\/2112.06412v1","411":"http:\/\/arxiv.org\/abs\/2112.07622v1","412":"http:\/\/arxiv.org\/abs\/2112.06370v1","413":"http:\/\/arxiv.org\/abs\/2112.06346v1","414":"http:\/\/arxiv.org\/abs\/2112.06331v1","415":"http:\/\/arxiv.org\/abs\/2112.06327v1","416":"http:\/\/arxiv.org\/abs\/2112.06310v1","417":"http:\/\/arxiv.org\/abs\/2112.06309v1","418":"http:\/\/arxiv.org\/abs\/2112.06295v1","419":"http:\/\/arxiv.org\/abs\/2112.06240v1","420":"http:\/\/arxiv.org\/abs\/2112.06204v1","421":"http:\/\/arxiv.org\/abs\/2112.06199v1","422":"http:\/\/arxiv.org\/abs\/2112.06196v1","423":"http:\/\/arxiv.org\/abs\/2112.06166v1","424":"http:\/\/arxiv.org\/abs\/2112.06135v1","425":"http:\/\/arxiv.org\/abs\/2112.06109v1","426":"http:\/\/arxiv.org\/abs\/2106.13876v2","427":"http:\/\/arxiv.org\/abs\/2006.11405v2","428":"http:\/\/arxiv.org\/abs\/2111.12783v2","429":"http:\/\/arxiv.org\/abs\/2111.14192v2","430":"http:\/\/arxiv.org\/abs\/2112.06013v1","431":"http:\/\/arxiv.org\/abs\/2010.16021v3","432":"http:\/\/arxiv.org\/abs\/2112.05973v1","433":"http:\/\/arxiv.org\/abs\/2112.04796v2","434":"http:\/\/arxiv.org\/abs\/2112.05910v1","435":"http:\/\/arxiv.org\/abs\/2106.09898v2","436":"http:\/\/arxiv.org\/abs\/2112.05785v1","437":"http:\/\/arxiv.org\/abs\/2112.05843v1","438":"http:\/\/arxiv.org\/abs\/2112.05842v1","439":"http:\/\/arxiv.org\/abs\/2104.15135v3","440":"http:\/\/arxiv.org\/abs\/2112.05826v1","441":"http:\/\/arxiv.org\/abs\/2112.11479v1","442":"http:\/\/arxiv.org\/abs\/2112.11478v1","443":"http:\/\/arxiv.org\/abs\/2112.05807v1","444":"http:\/\/arxiv.org\/abs\/2110.06961v2","445":"http:\/\/arxiv.org\/abs\/2112.05717v1","446":"http:\/\/arxiv.org\/abs\/2112.05705v1","447":"http:\/\/arxiv.org\/abs\/2112.05702v1","448":"http:\/\/arxiv.org\/abs\/2109.12104v2","449":"http:\/\/arxiv.org\/abs\/2112.05647v1","450":"http:\/\/arxiv.org\/abs\/2112.05596v1","451":"http:\/\/arxiv.org\/abs\/2112.05555v1","452":"http:\/\/arxiv.org\/abs\/2112.05459v1","453":"http:\/\/arxiv.org\/abs\/2112.05452v1","454":"http:\/\/arxiv.org\/abs\/2112.05438v1","455":"http:\/\/arxiv.org\/abs\/2112.05419v1","456":"http:\/\/arxiv.org\/abs\/2112.05364v1","457":"http:\/\/arxiv.org\/abs\/2112.05359v1","458":"http:\/\/arxiv.org\/abs\/2103.04399v2","459":"http:\/\/arxiv.org\/abs\/2112.05346v1","460":"http:\/\/arxiv.org\/abs\/2112.05256v1","461":"http:\/\/arxiv.org\/abs\/2112.05253v1","462":"http:\/\/arxiv.org\/abs\/2110.07096v2","463":"http:\/\/arxiv.org\/abs\/2010.12675v3","464":"http:\/\/arxiv.org\/abs\/2104.08211v3","465":"http:\/\/arxiv.org\/abs\/2112.00861v3","466":"http:\/\/arxiv.org\/abs\/2112.05209v1","467":"http:\/\/arxiv.org\/abs\/2110.04169v2","468":"http:\/\/arxiv.org\/abs\/2112.05197v1","469":"http:\/\/arxiv.org\/abs\/2112.05194v1","470":"http:\/\/arxiv.org\/abs\/2112.05136v1","471":"http:\/\/arxiv.org\/abs\/2112.05125v1","472":"http:\/\/arxiv.org\/abs\/2112.05056v1","473":"http:\/\/arxiv.org\/abs\/2112.04999v1","474":"http:\/\/arxiv.org\/abs\/2112.04971v1","475":"http:\/\/arxiv.org\/abs\/2112.04928v1","476":"http:\/\/arxiv.org\/abs\/2112.01332v2","477":"http:\/\/arxiv.org\/abs\/2112.04888v1","478":"http:\/\/arxiv.org\/abs\/2112.04886v1","479":"http:\/\/arxiv.org\/abs\/2112.04873v1","480":"http:\/\/arxiv.org\/abs\/2112.04871v1","481":"http:\/\/arxiv.org\/abs\/2108.01204v2","482":"http:\/\/arxiv.org\/abs\/2112.04831v1","483":"http:\/\/arxiv.org\/abs\/2012.13577v2","484":"http:\/\/arxiv.org\/abs\/2106.01040v3","485":"http:\/\/arxiv.org\/abs\/2103.02895v2","486":"http:\/\/arxiv.org\/abs\/2112.04803v1","487":"http:\/\/arxiv.org\/abs\/2111.14301v2","488":"http:\/\/arxiv.org\/abs\/2111.14306v3","489":"http:\/\/arxiv.org\/abs\/2112.12572v1","490":"http:\/\/arxiv.org\/abs\/2112.03562v2","491":"http:\/\/arxiv.org\/abs\/2008.12552v3","492":"http:\/\/arxiv.org\/abs\/2112.04138v2","493":"http:\/\/arxiv.org\/abs\/2112.03807v3","494":"http:\/\/arxiv.org\/abs\/2011.04843v3","495":"http:\/\/arxiv.org\/abs\/2109.08796v3","496":"http:\/\/arxiv.org\/abs\/2112.04630v1","497":"http:\/\/arxiv.org\/abs\/2102.08138v2","498":"http:\/\/arxiv.org\/abs\/2111.09543v2","499":"http:\/\/arxiv.org\/abs\/2112.01476v2","500":"http:\/\/arxiv.org\/abs\/2112.04539v1","501":"http:\/\/arxiv.org\/abs\/2112.04478v1","502":"http:\/\/arxiv.org\/abs\/2112.04453v1","503":"http:\/\/arxiv.org\/abs\/2112.04446v1","504":"http:\/\/arxiv.org\/abs\/2112.04359v1","505":"http:\/\/arxiv.org\/abs\/2112.04344v1","506":"http:\/\/arxiv.org\/abs\/2109.05327v2","507":"http:\/\/arxiv.org\/abs\/2108.13659v2","508":"http:\/\/arxiv.org\/abs\/2108.10274v2","509":"http:\/\/arxiv.org\/abs\/2112.03227v2","510":"http:\/\/arxiv.org\/abs\/2112.04189v1","511":"http:\/\/arxiv.org\/abs\/2109.13871v3","512":"http:\/\/arxiv.org\/abs\/2112.04184v1","513":"http:\/\/arxiv.org\/abs\/2112.04154v1","514":"http:\/\/arxiv.org\/abs\/2112.04151v1","515":"http:\/\/arxiv.org\/abs\/2112.04139v1","516":"http:\/\/arxiv.org\/abs\/2109.09991v2","517":"http:\/\/arxiv.org\/abs\/2112.04126v1","518":"http:\/\/arxiv.org\/abs\/2112.04104v1","519":"http:\/\/arxiv.org\/abs\/2108.02866v2","520":"http:\/\/arxiv.org\/abs\/2109.08129v2","521":"http:\/\/arxiv.org\/abs\/2112.05780v1","522":"http:\/\/arxiv.org\/abs\/2112.04008v1","523":"http:\/\/arxiv.org\/abs\/2112.03984v1","524":"http:\/\/arxiv.org\/abs\/2102.12060v4","525":"http:\/\/arxiv.org\/abs\/2112.03868v1","526":"http:\/\/arxiv.org\/abs\/2112.03858v1","527":"http:\/\/arxiv.org\/abs\/2112.03857v1","528":"http:\/\/arxiv.org\/abs\/2112.03849v1","529":"http:\/\/arxiv.org\/abs\/2112.03808v1","530":"http:\/\/arxiv.org\/abs\/2108.07435v2","531":"http:\/\/arxiv.org\/abs\/2112.03799v1","532":"http:\/\/arxiv.org\/abs\/2112.03737v1","533":"http:\/\/arxiv.org\/abs\/2110.02852v4","534":"http:\/\/arxiv.org\/abs\/2112.03634v1","535":"http:\/\/arxiv.org\/abs\/2112.03625v1","536":"http:\/\/arxiv.org\/abs\/2112.02557v2","537":"http:\/\/arxiv.org\/abs\/2112.03588v1","538":"http:\/\/arxiv.org\/abs\/2109.07263v2","539":"http:\/\/arxiv.org\/abs\/2112.03572v1","540":"http:\/\/arxiv.org\/abs\/2112.01037v2","541":"http:\/\/arxiv.org\/abs\/2112.03557v1","542":"http:\/\/arxiv.org\/abs\/2107.02192v3","543":"http:\/\/arxiv.org\/abs\/2112.03529v1","544":"http:\/\/arxiv.org\/abs\/2112.03521v1","545":"http:\/\/arxiv.org\/abs\/2006.00452v3","546":"http:\/\/arxiv.org\/abs\/2012.09090v2","547":"http:\/\/arxiv.org\/abs\/2112.03473v1","548":"http:\/\/arxiv.org\/abs\/2112.03414v1","549":"http:\/\/arxiv.org\/abs\/2112.03256v1","550":"http:\/\/arxiv.org\/abs\/2109.09784v2","551":"http:\/\/arxiv.org\/abs\/2112.03221v1","552":"http:\/\/arxiv.org\/abs\/2110.02311v2","553":"http:\/\/arxiv.org\/abs\/2112.03213v1","554":"http:\/\/arxiv.org\/abs\/2107.11879v2","555":"http:\/\/arxiv.org\/abs\/2112.03162v1","556":"http:\/\/arxiv.org\/abs\/2112.03154v1","557":"http:\/\/arxiv.org\/abs\/2104.08219v2","558":"http:\/\/arxiv.org\/abs\/2112.03099v1","559":"http:\/\/arxiv.org\/abs\/2110.01509v2","560":"http:\/\/arxiv.org\/abs\/2112.03052v1","561":"http:\/\/arxiv.org\/abs\/2109.05739v2","562":"http:\/\/arxiv.org\/abs\/2112.02970v1","563":"http:\/\/arxiv.org\/abs\/2112.05277v1","564":"http:\/\/arxiv.org\/abs\/2112.02889v1","565":"http:\/\/arxiv.org\/abs\/2112.01624v2","566":"http:\/\/arxiv.org\/abs\/2010.02665v2","567":"http:\/\/arxiv.org\/abs\/2112.02770v1","568":"http:\/\/arxiv.org\/abs\/2112.03271v1","569":"http:\/\/arxiv.org\/abs\/2112.02741v1","570":"http:\/\/arxiv.org\/abs\/2108.07909v3","571":"http:\/\/arxiv.org\/abs\/2112.02721v1","572":"http:\/\/arxiv.org\/abs\/2112.02714v1","573":"http:\/\/arxiv.org\/abs\/2112.02706v1","574":"http:\/\/arxiv.org\/abs\/2112.02701v1","575":"http:\/\/arxiv.org\/abs\/2104.10726v3","576":"http:\/\/arxiv.org\/abs\/2112.02650v1","577":"http:\/\/arxiv.org\/abs\/2112.02611v1","578":"http:\/\/arxiv.org\/abs\/2112.02607v1","579":"http:\/\/arxiv.org\/abs\/2108.04616v2","580":"http:\/\/arxiv.org\/abs\/2112.02512v1","581":"http:\/\/arxiv.org\/abs\/2112.02505v1","582":"http:\/\/arxiv.org\/abs\/2011.13354v4","583":"http:\/\/arxiv.org\/abs\/2112.13910v1","584":"http:\/\/arxiv.org\/abs\/2112.06642v1","585":"http:\/\/arxiv.org\/abs\/2106.05346v2","586":"http:\/\/arxiv.org\/abs\/2112.02399v1","587":"http:\/\/arxiv.org\/abs\/2109.08900v2","588":"http:\/\/arxiv.org\/abs\/2112.02325v1","589":"http:\/\/arxiv.org\/abs\/2112.02265v1","590":"http:\/\/arxiv.org\/abs\/2112.02246v1","591":"http:\/\/arxiv.org\/abs\/2112.02212v1","592":"http:\/\/arxiv.org\/abs\/2111.14210v2","593":"http:\/\/arxiv.org\/abs\/2112.02145v1","594":"http:\/\/arxiv.org\/abs\/2107.08661v4","595":"http:\/\/arxiv.org\/abs\/2009.05160v4","596":"http:\/\/arxiv.org\/abs\/2012.08789v2","597":"http:\/\/arxiv.org\/abs\/2112.01989v1","598":"http:\/\/arxiv.org\/abs\/2109.02102v3","599":"http:\/\/arxiv.org\/abs\/2109.09796v2","600":"http:\/\/arxiv.org\/abs\/2112.01959v1","601":"http:\/\/arxiv.org\/abs\/2112.01938v1","602":"http:\/\/arxiv.org\/abs\/2101.00146v3","603":"http:\/\/arxiv.org\/abs\/2112.01902v1","604":"http:\/\/arxiv.org\/abs\/2112.01898v1","605":"http:\/\/arxiv.org\/abs\/2102.05980v2","606":"http:\/\/arxiv.org\/abs\/2112.01894v1","607":"http:\/\/arxiv.org\/abs\/2112.01867v1","608":"http:\/\/arxiv.org\/abs\/2110.07603v2","609":"http:\/\/arxiv.org\/abs\/2112.01836v1","610":"http:\/\/arxiv.org\/abs\/2112.01822v1","611":"http:\/\/arxiv.org\/abs\/2112.01810v1","612":"http:\/\/arxiv.org\/abs\/2112.11445v1","613":"http:\/\/arxiv.org\/abs\/2103.09666v3","614":"http:\/\/arxiv.org\/abs\/2112.01764v1","615":"http:\/\/arxiv.org\/abs\/2112.01762v1","616":"http:\/\/arxiv.org\/abs\/2112.01757v1","617":"http:\/\/arxiv.org\/abs\/2111.07074v3","618":"http:\/\/arxiv.org\/abs\/2112.01742v1","619":"http:\/\/arxiv.org\/abs\/2112.01716v1","620":"http:\/\/arxiv.org\/abs\/2112.01707v1","621":"http:\/\/arxiv.org\/abs\/2112.01705v1","622":"http:\/\/arxiv.org\/abs\/2112.01697v1","623":"http:\/\/arxiv.org\/abs\/2112.11444v1","624":"http:\/\/arxiv.org\/abs\/2112.01660v1","625":"http:\/\/arxiv.org\/abs\/2112.01616v1","626":"http:\/\/arxiv.org\/abs\/2112.01591v1","627":"http:\/\/arxiv.org\/abs\/2101.05779v3","628":"http:\/\/arxiv.org\/abs\/2112.01573v1","629":"http:\/\/arxiv.org\/abs\/2104.05857v3","630":"http:\/\/arxiv.org\/abs\/2112.01404v1","631":"http:\/\/arxiv.org\/abs\/2112.01368v1","632":"http:\/\/arxiv.org\/abs\/2009.14539v2","633":"http:\/\/arxiv.org\/abs\/2112.01342v1","634":"http:\/\/arxiv.org\/abs\/2112.01184v1","635":"http:\/\/arxiv.org\/abs\/2112.03033v1","636":"http:\/\/arxiv.org\/abs\/2111.13301v2","637":"http:\/\/arxiv.org\/abs\/2110.02782v2","638":"http:\/\/arxiv.org\/abs\/2112.01073v1","639":"http:\/\/arxiv.org\/abs\/2112.01071v1","640":"http:\/\/arxiv.org\/abs\/2112.01062v1","641":"http:\/\/arxiv.org\/abs\/2111.15182v2","642":"http:\/\/arxiv.org\/abs\/2112.03032v1","643":"http:\/\/arxiv.org\/abs\/2112.01054v1","644":"http:\/\/arxiv.org\/abs\/2112.01048v1","645":"http:\/\/arxiv.org\/abs\/2112.01047v1","646":"http:\/\/arxiv.org\/abs\/2111.15588v3","647":"http:\/\/arxiv.org\/abs\/2112.01040v1","648":"http:\/\/arxiv.org\/abs\/2112.01025v1","649":"http:\/\/arxiv.org\/abs\/2112.01012v1","650":"http:\/\/arxiv.org\/abs\/2111.14110v2","651":"http:\/\/arxiv.org\/abs\/2112.00969v1","652":"http:\/\/arxiv.org\/abs\/2112.00967v1","653":"http:\/\/arxiv.org\/abs\/2112.03025v1","654":"http:\/\/arxiv.org\/abs\/2112.00894v1","655":"http:\/\/arxiv.org\/abs\/2010.12784v2","656":"http:\/\/arxiv.org\/abs\/2105.03075v5","657":"http:\/\/arxiv.org\/abs\/1910.08293v4","658":"http:\/\/arxiv.org\/abs\/2108.06643v2","659":"http:\/\/arxiv.org\/abs\/2112.00819v1","660":"http:\/\/arxiv.org\/abs\/2112.00800v1","661":"http:\/\/arxiv.org\/abs\/2112.00791v1","662":"http:\/\/arxiv.org\/abs\/2112.00590v1","663":"http:\/\/arxiv.org\/abs\/2112.00578v1","664":"http:\/\/arxiv.org\/abs\/2112.03024v1","665":"http:\/\/arxiv.org\/abs\/2112.00567v1","666":"http:\/\/arxiv.org\/abs\/2112.00566v1","667":"http:\/\/arxiv.org\/abs\/2112.00534v1","668":"http:\/\/arxiv.org\/abs\/2102.00405v2","669":"http:\/\/arxiv.org\/abs\/2112.00475v1","670":"http:\/\/arxiv.org\/abs\/2112.00468v1","671":"http:\/\/arxiv.org\/abs\/2105.09045v3","672":"http:\/\/arxiv.org\/abs\/2112.00405v1","673":"http:\/\/arxiv.org\/abs\/2112.00384v1","674":"http:\/\/arxiv.org\/abs\/2112.00350v1","675":"http:\/\/arxiv.org\/abs\/2112.00284v1","676":"http:\/\/arxiv.org\/abs\/2112.00283v1","677":"http:\/\/arxiv.org\/abs\/2110.05717v3","678":"http:\/\/arxiv.org\/abs\/2011.00740v3","679":"http:\/\/arxiv.org\/abs\/2112.00245v1","680":"http:\/\/arxiv.org\/abs\/2112.11442v1","681":"http:\/\/arxiv.org\/abs\/2112.00160v1","682":"http:\/\/arxiv.org\/abs\/2106.12066v2","683":"http:\/\/arxiv.org\/abs\/2107.06912v3","684":"http:\/\/arxiv.org\/abs\/2112.00086v1","685":"http:\/\/arxiv.org\/abs\/2112.04596v1","686":"http:\/\/arxiv.org\/abs\/2103.14785v3","687":"http:\/\/arxiv.org\/abs\/2111.13781v2","688":"http:\/\/arxiv.org\/abs\/2112.04351v1","689":"http:\/\/arxiv.org\/abs\/2111.15641v1","690":"http:\/\/arxiv.org\/abs\/2111.15622v1","691":"http:\/\/arxiv.org\/abs\/2111.15617v1","692":"http:\/\/arxiv.org\/abs\/2105.02570v3","693":"http:\/\/arxiv.org\/abs\/2111.15512v1","694":"http:\/\/arxiv.org\/abs\/2111.07130v2","695":"http:\/\/arxiv.org\/abs\/2003.09166v3","696":"http:\/\/arxiv.org\/abs\/2111.15436v1","697":"http:\/\/arxiv.org\/abs\/2111.15420v1","698":"http:\/\/arxiv.org\/abs\/2111.15417v1","699":"http:\/\/arxiv.org\/abs\/2111.15413v1","700":"http:\/\/arxiv.org\/abs\/2112.00799v1","701":"http:\/\/arxiv.org\/abs\/2111.15322v1","702":"http:\/\/arxiv.org\/abs\/2111.15298v1","703":"http:\/\/arxiv.org\/abs\/2111.15278v1","704":"http:\/\/arxiv.org\/abs\/2112.11441v1","705":"http:\/\/arxiv.org\/abs\/2111.15268v1","706":"http:\/\/arxiv.org\/abs\/2112.00006v1","707":"http:\/\/arxiv.org\/abs\/2111.15166v1","708":"http:\/\/arxiv.org\/abs\/2111.15156v1","709":"http:\/\/arxiv.org\/abs\/2104.07639v4","710":"http:\/\/arxiv.org\/abs\/2111.14106v2","711":"http:\/\/arxiv.org\/abs\/2111.14282v2","712":"http:\/\/arxiv.org\/abs\/2111.15093v1","713":"http:\/\/arxiv.org\/abs\/2111.14188v2","714":"http:\/\/arxiv.org\/abs\/2111.15016v1","715":"http:\/\/arxiv.org\/abs\/2112.11439v1","716":"http:\/\/arxiv.org\/abs\/2111.14988v1","717":"http:\/\/arxiv.org\/abs\/2111.14977v1","718":"http:\/\/arxiv.org\/abs\/2107.09609v2","719":"http:\/\/arxiv.org\/abs\/2111.14730v1","720":"http:\/\/arxiv.org\/abs\/2112.00827v1","721":"http:\/\/arxiv.org\/abs\/2111.14684v1","722":"http:\/\/arxiv.org\/abs\/2103.13272v2","723":"http:\/\/arxiv.org\/abs\/2110.03546v2","724":"http:\/\/arxiv.org\/abs\/2111.14842v1","725":"http:\/\/arxiv.org\/abs\/2108.09119v3","726":"http:\/\/arxiv.org\/abs\/2112.11438v1","727":"http:\/\/arxiv.org\/abs\/2112.11436v1","728":"http:\/\/arxiv.org\/abs\/2111.14445v1","729":"http:\/\/arxiv.org\/abs\/2112.11540v1","730":"http:\/\/arxiv.org\/abs\/2104.05094v3","731":"http:\/\/arxiv.org\/abs\/2111.05948v3","732":"http:\/\/arxiv.org\/abs\/2111.14309v1","733":"http:\/\/arxiv.org\/abs\/2111.14232v1","734":"http:\/\/arxiv.org\/abs\/2107.05612v3","735":"http:\/\/arxiv.org\/abs\/2111.14168v1","736":"http:\/\/arxiv.org\/abs\/2004.14871v2","737":"http:\/\/arxiv.org\/abs\/2107.10637v2","738":"http:\/\/arxiv.org\/abs\/2111.14119v1","739":"http:\/\/arxiv.org\/abs\/2109.04650v2","740":"http:\/\/arxiv.org\/abs\/2111.14094v1","741":"http:\/\/arxiv.org\/abs\/2111.07564v2","742":"http:\/\/arxiv.org\/abs\/2006.05236v2","743":"http:\/\/arxiv.org\/abs\/2111.14083v1","744":"http:\/\/arxiv.org\/abs\/2005.08182v2","745":"http:\/\/arxiv.org\/abs\/2103.12048v3","746":"http:\/\/arxiv.org\/abs\/2111.14066v1","747":"http:\/\/arxiv.org\/abs\/2111.14034v1","748":"http:\/\/arxiv.org\/abs\/2111.14031v1","749":"http:\/\/arxiv.org\/abs\/2108.07790v3","750":"http:\/\/arxiv.org\/abs\/2111.14003v1","751":"http:\/\/arxiv.org\/abs\/2111.13999v1","752":"http:\/\/arxiv.org\/abs\/2111.13993v1","753":"http:\/\/arxiv.org\/abs\/2111.13982v1","754":"http:\/\/arxiv.org\/abs\/2111.14830v1","755":"http:\/\/arxiv.org\/abs\/2111.13974v1","756":"http:\/\/arxiv.org\/abs\/2111.13972v1","757":"http:\/\/arxiv.org\/abs\/2107.13290v3","758":"http:\/\/arxiv.org\/abs\/2007.03834v4","759":"http:\/\/arxiv.org\/abs\/2106.04647v2","760":"http:\/\/arxiv.org\/abs\/2111.13861v1","761":"http:\/\/arxiv.org\/abs\/2109.14934v3","762":"http:\/\/arxiv.org\/abs\/2111.13833v1","763":"http:\/\/arxiv.org\/abs\/2112.05783v1","764":"http:\/\/arxiv.org\/abs\/2111.13726v1","765":"http:\/\/arxiv.org\/abs\/2111.13654v1","766":"http:\/\/arxiv.org\/abs\/2105.05091v2","767":"http:\/\/arxiv.org\/abs\/2111.13611v1","768":"http:\/\/arxiv.org\/abs\/2109.00475v2","769":"http:\/\/arxiv.org\/abs\/2109.02938v2","770":"http:\/\/arxiv.org\/abs\/2106.00218v2","771":"http:\/\/arxiv.org\/abs\/2111.13463v1","772":"http:\/\/arxiv.org\/abs\/2111.13440v1","773":"http:\/\/arxiv.org\/abs\/2112.03073v1","774":"http:\/\/arxiv.org\/abs\/2101.09624v4","775":"http:\/\/arxiv.org\/abs\/2110.03501v2","776":"http:\/\/arxiv.org\/abs\/2012.15671v5","777":"http:\/\/arxiv.org\/abs\/2111.13284v1","778":"http:\/\/arxiv.org\/abs\/2111.13259v1","779":"http:\/\/arxiv.org\/abs\/1910.14084v2","780":"http:\/\/arxiv.org\/abs\/2111.15473v1","781":"http:\/\/arxiv.org\/abs\/2112.03014v1","782":"http:\/\/arxiv.org\/abs\/2111.13138v1","783":"http:\/\/arxiv.org\/abs\/2111.15629v1","784":"http:\/\/arxiv.org\/abs\/2112.02955v1","785":"http:\/\/arxiv.org\/abs\/2112.02097v1","786":"http:\/\/arxiv.org\/abs\/2104.00312v4","787":"http:\/\/arxiv.org\/abs\/2111.12956v1","788":"http:\/\/arxiv.org\/abs\/1906.08101v3","789":"http:\/\/arxiv.org\/abs\/1812.02253v2","790":"http:\/\/arxiv.org\/abs\/2111.10154v2","791":"http:\/\/arxiv.org\/abs\/2102.08633v3","792":"http:\/\/arxiv.org\/abs\/2110.11338v3","793":"http:\/\/arxiv.org\/abs\/2111.11707v2","794":"http:\/\/arxiv.org\/abs\/2111.12802v1","795":"http:\/\/arxiv.org\/abs\/2111.12796v1","796":"http:\/\/arxiv.org\/abs\/2111.12790v1","797":"http:\/\/arxiv.org\/abs\/2111.12763v1","798":"http:\/\/arxiv.org\/abs\/2105.10362v4","799":"http:\/\/arxiv.org\/abs\/2107.11665v2","800":"http:\/\/arxiv.org\/abs\/2108.10218v2","801":"http:\/\/arxiv.org\/abs\/2111.12535v1","802":"http:\/\/arxiv.org\/abs\/2111.12477v1","803":"http:\/\/arxiv.org\/abs\/2009.01826v3","804":"http:\/\/arxiv.org\/abs\/2012.04946v3","805":"http:\/\/arxiv.org\/abs\/2111.12421v1","806":"http:\/\/arxiv.org\/abs\/2109.07346v2","807":"http:\/\/arxiv.org\/abs\/2111.11750v2","808":"http:\/\/arxiv.org\/abs\/2102.08098v3","809":"http:\/\/arxiv.org\/abs\/2111.12317v1","810":"http:\/\/arxiv.org\/abs\/2012.15197v2","811":"http:\/\/arxiv.org\/abs\/2111.12284v1","812":"http:\/\/arxiv.org\/abs\/2108.02446v3","813":"http:\/\/arxiv.org\/abs\/2111.12174v1","814":"http:\/\/arxiv.org\/abs\/2111.12062v1","815":"http:\/\/arxiv.org\/abs\/2111.12061v1","816":"http:\/\/arxiv.org\/abs\/2111.12055v1","817":"http:\/\/arxiv.org\/abs\/2111.12028v1","818":"http:\/\/arxiv.org\/abs\/2106.10328v2","819":"http:\/\/arxiv.org\/abs\/2103.04180v2","820":"http:\/\/arxiv.org\/abs\/2112.00803v1","821":"http:\/\/arxiv.org\/abs\/2109.06327v2","822":"http:\/\/arxiv.org\/abs\/2111.11894v1","823":"http:\/\/arxiv.org\/abs\/2111.11845v1","824":"http:\/\/arxiv.org\/abs\/2111.11831v1","825":"http:\/\/arxiv.org\/abs\/2111.11815v1","826":"http:\/\/arxiv.org\/abs\/2111.11766v1","827":"http:\/\/arxiv.org\/abs\/2111.07158v2","828":"http:\/\/arxiv.org\/abs\/2102.01454v3","829":"http:\/\/arxiv.org\/abs\/2104.12470v4","830":"http:\/\/arxiv.org\/abs\/2104.06486v3","831":"http:\/\/arxiv.org\/abs\/2111.11576v1","832":"http:\/\/arxiv.org\/abs\/2110.03861v3","833":"http:\/\/arxiv.org\/abs\/2111.06799v2","834":"http:\/\/arxiv.org\/abs\/2111.11520v1","835":"http:\/\/arxiv.org\/abs\/2111.11471v1","836":"http:\/\/arxiv.org\/abs\/2111.11431v1","837":"http:\/\/arxiv.org\/abs\/2111.11372v1","838":"http:\/\/arxiv.org\/abs\/2111.11363v1","839":"http:\/\/arxiv.org\/abs\/2111.11331v1","840":"http:\/\/arxiv.org\/abs\/2011.07403v3","841":"http:\/\/arxiv.org\/abs\/2111.11170v1","842":"http:\/\/arxiv.org\/abs\/2111.11159v1","843":"http:\/\/arxiv.org\/abs\/2109.02229v3","844":"http:\/\/arxiv.org\/abs\/2112.03104v1","845":"http:\/\/arxiv.org\/abs\/2111.11104v1","846":"http:\/\/arxiv.org\/abs\/2111.11030v1","847":"http:\/\/arxiv.org\/abs\/2112.03101v1","848":"http:\/\/arxiv.org\/abs\/2111.11023v1","849":"http:\/\/arxiv.org\/abs\/2110.15498v2","850":"http:\/\/arxiv.org\/abs\/2108.05098v2","851":"http:\/\/arxiv.org\/abs\/2103.03335v4","852":"http:\/\/arxiv.org\/abs\/2111.10974v1","853":"http:\/\/arxiv.org\/abs\/2111.10962v1","854":"http:\/\/arxiv.org\/abs\/2111.10957v1","855":"http:\/\/arxiv.org\/abs\/2009.06810v2","856":"http:\/\/arxiv.org\/abs\/2111.10846v1","857":"http:\/\/arxiv.org\/abs\/2112.11185v1","858":"http:\/\/arxiv.org\/abs\/2112.03011v1","859":"http:\/\/arxiv.org\/abs\/2110.09086v3","860":"http:\/\/arxiv.org\/abs\/2111.10756v1","861":"http:\/\/arxiv.org\/abs\/2111.10750v1","862":"http:\/\/arxiv.org\/abs\/2111.10746v1","863":"http:\/\/arxiv.org\/abs\/2111.10692v1","864":"http:\/\/arxiv.org\/abs\/2005.06059v2","865":"http:\/\/arxiv.org\/abs\/2110.01852v2","866":"http:\/\/arxiv.org\/abs\/2109.14350v2","867":"http:\/\/arxiv.org\/abs\/2111.10584v1","868":"http:\/\/arxiv.org\/abs\/2111.09564v2","869":"http:\/\/arxiv.org\/abs\/2111.10513v1","870":"http:\/\/arxiv.org\/abs\/2111.10501v1","871":"http:\/\/arxiv.org\/abs\/2111.10497v1","872":"http:\/\/arxiv.org\/abs\/2112.03009v1","873":"http:\/\/arxiv.org\/abs\/2111.10390v1","874":"http:\/\/arxiv.org\/abs\/2106.14233v2","875":"http:\/\/arxiv.org\/abs\/2010.03001v5","876":"http:\/\/arxiv.org\/abs\/2111.10223v1","877":"http:\/\/arxiv.org\/abs\/2111.00526v2","878":"http:\/\/arxiv.org\/abs\/2111.10177v1","879":"http:\/\/arxiv.org\/abs\/2005.10058v4","880":"http:\/\/arxiv.org\/abs\/2111.10173v1","881":"http:\/\/arxiv.org\/abs\/2111.10168v1","882":"http:\/\/arxiv.org\/abs\/2111.10157v1","883":"http:\/\/arxiv.org\/abs\/2111.10142v1","884":"http:\/\/arxiv.org\/abs\/1909.00204v3","885":"http:\/\/arxiv.org\/abs\/2111.10100v1","886":"http:\/\/arxiv.org\/abs\/2111.10097v1","887":"http:\/\/arxiv.org\/abs\/2109.05115v2","888":"http:\/\/arxiv.org\/abs\/2111.08896v3","889":"http:\/\/arxiv.org\/abs\/2110.15426v2","890":"http:\/\/arxiv.org\/abs\/2012.04207v2","891":"http:\/\/arxiv.org\/abs\/2111.10058v1","892":"http:\/\/arxiv.org\/abs\/2111.10047v1","893":"http:\/\/arxiv.org\/abs\/2104.05596v3","894":"http:\/\/arxiv.org\/abs\/2111.10044v1","895":"http:\/\/arxiv.org\/abs\/2111.09927v1","896":"http:\/\/arxiv.org\/abs\/2011.07126v2","897":"http:\/\/arxiv.org\/abs\/2110.10704v2","898":"http:\/\/arxiv.org\/abs\/2111.09836v1","899":"http:\/\/arxiv.org\/abs\/2111.09811v1","900":"http:\/\/arxiv.org\/abs\/2111.09791v1","901":"http:\/\/arxiv.org\/abs\/2111.09714v1","902":"http:\/\/arxiv.org\/abs\/2111.09029v2","903":"http:\/\/arxiv.org\/abs\/2111.08788v2","904":"http:\/\/arxiv.org\/abs\/1808.08079v3","905":"http:\/\/arxiv.org\/abs\/2112.03007v1","906":"http:\/\/arxiv.org\/abs\/2110.15731v2","907":"http:\/\/arxiv.org\/abs\/2111.09645v1","908":"http:\/\/arxiv.org\/abs\/2111.09634v1","909":"http:\/\/arxiv.org\/abs\/2111.09618v1","910":"http:\/\/arxiv.org\/abs\/2111.09612v1","911":"http:\/\/arxiv.org\/abs\/2111.09574v1","912":"http:\/\/arxiv.org\/abs\/2106.07936v3","913":"http:\/\/arxiv.org\/abs\/2104.08826v2","914":"http:\/\/arxiv.org\/abs\/2109.00648v3","915":"http:\/\/arxiv.org\/abs\/2110.10906v2","916":"http:\/\/arxiv.org\/abs\/2111.09525v1","917":"http:\/\/arxiv.org\/abs\/2111.09509v1","918":"http:\/\/arxiv.org\/abs\/2108.08411v2","919":"http:\/\/arxiv.org\/abs\/2106.07890v2","920":"http:\/\/arxiv.org\/abs\/2110.14168v2","921":"http:\/\/arxiv.org\/abs\/2111.09381v1","922":"http:\/\/arxiv.org\/abs\/2109.06387v2","923":"http:\/\/arxiv.org\/abs\/2111.05825v2","924":"http:\/\/arxiv.org\/abs\/2110.15248v2","925":"http:\/\/arxiv.org\/abs\/2111.09280v1","926":"http:\/\/arxiv.org\/abs\/2111.09276v1","927":"http:\/\/arxiv.org\/abs\/2110.07428v2","928":"http:\/\/arxiv.org\/abs\/2111.15602v1","929":"http:\/\/arxiv.org\/abs\/2111.08647v2","930":"http:\/\/arxiv.org\/abs\/2108.11896v2","931":"http:\/\/arxiv.org\/abs\/2105.06354v2","932":"http:\/\/arxiv.org\/abs\/2110.15225v3","933":"http:\/\/arxiv.org\/abs\/2111.09146v1","934":"http:\/\/arxiv.org\/abs\/2111.09075v1","935":"http:\/\/arxiv.org\/abs\/2111.09064v1","936":"http:\/\/arxiv.org\/abs\/2111.09052v1","937":"http:\/\/arxiv.org\/abs\/2111.09035v1","938":"http:\/\/arxiv.org\/abs\/2106.11148v2","939":"http:\/\/arxiv.org\/abs\/2111.08940v1","940":"http:\/\/arxiv.org\/abs\/2111.08906v1","941":"http:\/\/arxiv.org\/abs\/2108.02314v3","942":"http:\/\/arxiv.org\/abs\/2104.08768v2","943":"http:\/\/arxiv.org\/abs\/2104.01371v3","944":"http:\/\/arxiv.org\/abs\/2111.08723v1","945":"http:\/\/arxiv.org\/abs\/2111.08658v1","946":"http:\/\/arxiv.org\/abs\/2111.08634v1","947":"http:\/\/arxiv.org\/abs\/2109.01135v7","948":"http:\/\/arxiv.org\/abs\/2111.08609v1","949":"http:\/\/arxiv.org\/abs\/2111.08581v1","950":"http:\/\/arxiv.org\/abs\/2111.08546v1","951":"http:\/\/arxiv.org\/abs\/2111.08545v1","952":"http:\/\/arxiv.org\/abs\/2111.08543v1","953":"http:\/\/arxiv.org\/abs\/2111.08529v1","954":"http:\/\/arxiv.org\/abs\/2111.08510v1","955":"http:\/\/arxiv.org\/abs\/2111.08489v1","956":"http:\/\/arxiv.org\/abs\/2111.08465v1","957":"http:\/\/arxiv.org\/abs\/2111.08408v1","958":"http:\/\/arxiv.org\/abs\/2107.03466v2","959":"http:\/\/arxiv.org\/abs\/2110.15317v2","960":"http:\/\/arxiv.org\/abs\/2111.08400v1","961":"http:\/\/arxiv.org\/abs\/2105.03641v2","962":"http:\/\/arxiv.org\/abs\/2109.06515v2","963":"http:\/\/arxiv.org\/abs\/2111.08267v1","964":"http:\/\/arxiv.org\/abs\/2111.08210v1","965":"http:\/\/arxiv.org\/abs\/2111.08201v1","966":"http:\/\/arxiv.org\/abs\/2111.08191v1","967":"http:\/\/arxiv.org\/abs\/2111.08181v1","968":"http:\/\/arxiv.org\/abs\/2111.08171v1","969":"http:\/\/arxiv.org\/abs\/2111.08137v1","970":"http:\/\/arxiv.org\/abs\/2111.08133v1","971":"http:\/\/arxiv.org\/abs\/2111.08088v1","972":"http:\/\/arxiv.org\/abs\/2111.07993v1","973":"http:\/\/arxiv.org\/abs\/2007.15700v3","974":"http:\/\/arxiv.org\/abs\/2110.08226v2","975":"http:\/\/arxiv.org\/abs\/2111.07935v1","976":"http:\/\/arxiv.org\/abs\/2111.07906v1","977":"http:\/\/arxiv.org\/abs\/2111.09155v1","978":"http:\/\/arxiv.org\/abs\/2111.07864v1","979":"http:\/\/arxiv.org\/abs\/2111.07815v1","980":"http:\/\/arxiv.org\/abs\/2111.07793v1","981":"http:\/\/arxiv.org\/abs\/2104.12128v2","982":"http:\/\/arxiv.org\/abs\/2108.09484v3","983":"http:\/\/arxiv.org\/abs\/2111.07699v1","984":"http:\/\/arxiv.org\/abs\/2104.12643v2","985":"http:\/\/arxiv.org\/abs\/2010.12827v2","986":"http:\/\/arxiv.org\/abs\/2111.04318v2","987":"http:\/\/arxiv.org\/abs\/2111.07611v1","988":"http:\/\/arxiv.org\/abs\/2105.14980v2","989":"http:\/\/arxiv.org\/abs\/2111.07592v1","990":"http:\/\/arxiv.org\/abs\/2111.06832v2","991":"http:\/\/arxiv.org\/abs\/2110.04522v2","992":"http:\/\/arxiv.org\/abs\/2111.07549v1","993":"http:\/\/arxiv.org\/abs\/2111.03930v2","994":"http:\/\/arxiv.org\/abs\/2111.07525v1","995":"http:\/\/arxiv.org\/abs\/2109.04212v3","996":"http:\/\/arxiv.org\/abs\/2111.07454v1","997":"http:\/\/arxiv.org\/abs\/2111.07448v1","998":"http:\/\/arxiv.org\/abs\/2109.14144v2","999":"http:\/\/arxiv.org\/abs\/2111.07408v1","1000":"http:\/\/arxiv.org\/abs\/2111.07393v1","1001":"http:\/\/arxiv.org\/abs\/2112.02095v1","1002":"http:\/\/arxiv.org\/abs\/2111.07367v1","1003":"http:\/\/arxiv.org\/abs\/2007.06796v5","1004":"http:\/\/arxiv.org\/abs\/2112.01842v1","1005":"http:\/\/arxiv.org\/abs\/2111.05721v2","1006":"http:\/\/arxiv.org\/abs\/2111.09111v1","1007":"http:\/\/arxiv.org\/abs\/2111.07256v1","1008":"http:\/\/arxiv.org\/abs\/2111.14703v1","1009":"http:\/\/arxiv.org\/abs\/2111.07228v1","1010":"http:\/\/arxiv.org\/abs\/2111.07218v1","1011":"http:\/\/arxiv.org\/abs\/2111.07198v1","1012":"http:\/\/arxiv.org\/abs\/2111.07188v1","1013":"http:\/\/arxiv.org\/abs\/2111.07180v1","1014":"http:\/\/arxiv.org\/abs\/2111.07148v1","1015":"http:\/\/arxiv.org\/abs\/2112.03005v1","1016":"http:\/\/arxiv.org\/abs\/2111.07119v1","1017":"http:\/\/arxiv.org\/abs\/2105.09226v5","1018":"http:\/\/arxiv.org\/abs\/2112.03002v1","1019":"http:\/\/arxiv.org\/abs\/2005.00624v3","1020":"http:\/\/arxiv.org\/abs\/2111.09115v1","1021":"http:\/\/arxiv.org\/abs\/2101.00124v3","1022":"http:\/\/arxiv.org\/abs\/2111.06971v1","1023":"http:\/\/arxiv.org\/abs\/2111.06902v1","1024":"http:\/\/arxiv.org\/abs\/2111.06801v1","1025":"http:\/\/arxiv.org\/abs\/2111.06787v1","1026":"http:\/\/arxiv.org\/abs\/2109.02738v2","1027":"http:\/\/arxiv.org\/abs\/2111.06664v1","1028":"http:\/\/arxiv.org\/abs\/2111.06647v1","1029":"http:\/\/arxiv.org\/abs\/2111.06644v1","1030":"http:\/\/arxiv.org\/abs\/2111.06625v1","1031":"http:\/\/arxiv.org\/abs\/2111.06599v1","1032":"http:\/\/arxiv.org\/abs\/2111.06580v1","1033":"http:\/\/arxiv.org\/abs\/2010.14784v2","1034":"http:\/\/arxiv.org\/abs\/2010.09905v3","1035":"http:\/\/arxiv.org\/abs\/2111.06515v1","1036":"http:\/\/arxiv.org\/abs\/2111.06464v1","1037":"http:\/\/arxiv.org\/abs\/2102.07349v2","1038":"http:\/\/arxiv.org\/abs\/2111.06345v1","1039":"http:\/\/arxiv.org\/abs\/2111.06336v1","1040":"http:\/\/arxiv.org\/abs\/2111.06334v1","1041":"http:\/\/arxiv.org\/abs\/2111.06331v1","1042":"http:\/\/arxiv.org\/abs\/2111.06310v1","1043":"http:\/\/arxiv.org\/abs\/2111.06230v1","1044":"http:\/\/arxiv.org\/abs\/2112.03004v1","1045":"http:\/\/arxiv.org\/abs\/2109.00343v2","1046":"http:\/\/arxiv.org\/abs\/2111.06181v1","1047":"http:\/\/arxiv.org\/abs\/2111.06133v1","1048":"http:\/\/arxiv.org\/abs\/2111.06103v1","1049":"http:\/\/arxiv.org\/abs\/2111.06086v1","1050":"http:\/\/arxiv.org\/abs\/2111.06070v1","1051":"http:\/\/arxiv.org\/abs\/2111.06053v1","1052":"http:\/\/arxiv.org\/abs\/2110.09749v4","1053":"http:\/\/arxiv.org\/abs\/2111.06012v1","1054":"http:\/\/arxiv.org\/abs\/2012.02339v3","1055":"http:\/\/arxiv.org\/abs\/2111.05988v1","1056":"http:\/\/arxiv.org\/abs\/2111.05940v1","1057":"http:\/\/arxiv.org\/abs\/2111.05937v1","1058":"http:\/\/arxiv.org\/abs\/2005.12423v2","1059":"http:\/\/arxiv.org\/abs\/2111.05823v1","1060":"http:\/\/arxiv.org\/abs\/2111.05808v1","1061":"http:\/\/arxiv.org\/abs\/2111.05805v1","1062":"http:\/\/arxiv.org\/abs\/2010.01556v2","1063":"http:\/\/arxiv.org\/abs\/2111.05754v1","1064":"http:\/\/arxiv.org\/abs\/2110.08094v2","1065":"http:\/\/arxiv.org\/abs\/2111.05671v1","1066":"http:\/\/arxiv.org\/abs\/2008.05759v2","1067":"http:\/\/arxiv.org\/abs\/2111.05610v1","1068":"http:\/\/arxiv.org\/abs\/2111.05605v1","1069":"http:\/\/arxiv.org\/abs\/2110.15871v2","1070":"http:\/\/arxiv.org\/abs\/2107.10326v3","1071":"http:\/\/arxiv.org\/abs\/2107.07502v2","1072":"http:\/\/arxiv.org\/abs\/2108.12637v2","1073":"http:\/\/arxiv.org\/abs\/2111.05193v2","1074":"http:\/\/arxiv.org\/abs\/2106.09775v3","1075":"http:\/\/arxiv.org\/abs\/2111.05414v1","1076":"http:\/\/arxiv.org\/abs\/2111.05412v1","1077":"http:\/\/arxiv.org\/abs\/2111.05407v1","1078":"http:\/\/arxiv.org\/abs\/2109.04711v2","1079":"http:\/\/arxiv.org\/abs\/2012.15332v2","1080":"http:\/\/arxiv.org\/abs\/2111.05241v1","1081":"http:\/\/arxiv.org\/abs\/2111.05204v1","1082":"http:\/\/arxiv.org\/abs\/2111.02168v2","1083":"http:\/\/arxiv.org\/abs\/2111.02265v2","1084":"http:\/\/arxiv.org\/abs\/2111.05147v1","1085":"http:\/\/arxiv.org\/abs\/2111.05139v1","1086":"http:\/\/arxiv.org\/abs\/2111.05039v1","1087":"http:\/\/arxiv.org\/abs\/2103.10685v3","1088":"http:\/\/arxiv.org\/abs\/2111.05013v1","1089":"http:\/\/arxiv.org\/abs\/2112.03003v1","1090":"http:\/\/arxiv.org\/abs\/2103.04037v2","1091":"http:\/\/arxiv.org\/abs\/2111.03937v2","1092":"http:\/\/arxiv.org\/abs\/2111.04951v1","1093":"http:\/\/arxiv.org\/abs\/2111.04933v1","1094":"http:\/\/arxiv.org\/abs\/2106.03143v3","1095":"http:\/\/arxiv.org\/abs\/2111.00640v2","1096":"http:\/\/arxiv.org\/abs\/2111.04862v1","1097":"http:\/\/arxiv.org\/abs\/2103.03874v2","1098":"http:\/\/arxiv.org\/abs\/2103.06268v2","1099":"http:\/\/arxiv.org\/abs\/2105.09938v3","1100":"http:\/\/arxiv.org\/abs\/2111.04823v1","1101":"http:\/\/arxiv.org\/abs\/2111.04785v1","1102":"http:\/\/arxiv.org\/abs\/2107.07170v2","1103":"http:\/\/arxiv.org\/abs\/2108.08787v2","1104":"http:\/\/arxiv.org\/abs\/2111.04574v1","1105":"http:\/\/arxiv.org\/abs\/2111.04551v1","1106":"http:\/\/arxiv.org\/abs\/2111.04530v1","1107":"http:\/\/arxiv.org\/abs\/2111.00514v2","1108":"http:\/\/arxiv.org\/abs\/2111.04517v1","1109":"http:\/\/arxiv.org\/abs\/2111.04507v1","1110":"http:\/\/arxiv.org\/abs\/2108.02923v3","1111":"http:\/\/arxiv.org\/abs\/2109.06679v2","1112":"http:\/\/arxiv.org\/abs\/2101.09465v2","1113":"http:\/\/arxiv.org\/abs\/2111.04321v1","1114":"http:\/\/arxiv.org\/abs\/2105.00150v2","1115":"http:\/\/arxiv.org\/abs\/2111.04261v1","1116":"http:\/\/arxiv.org\/abs\/2006.03950v5","1117":"http:\/\/arxiv.org\/abs\/2104.08762v2","1118":"http:\/\/arxiv.org\/abs\/2101.11214v3","1119":"http:\/\/arxiv.org\/abs\/2111.05095v1","1120":"http:\/\/arxiv.org\/abs\/2111.04194v1","1121":"http:\/\/arxiv.org\/abs\/2111.04158v1","1122":"http:\/\/arxiv.org\/abs\/2111.04138v1","1123":"http:\/\/arxiv.org\/abs\/2111.04130v1","1124":"http:\/\/arxiv.org\/abs\/2103.12906v3","1125":"http:\/\/arxiv.org\/abs\/2111.04099v1","1126":"http:\/\/arxiv.org\/abs\/2111.04079v1","1127":"http:\/\/arxiv.org\/abs\/2111.04052v1","1128":"http:\/\/arxiv.org\/abs\/2111.04045v1","1129":"http:\/\/arxiv.org\/abs\/2111.04040v1","1130":"http:\/\/arxiv.org\/abs\/2012.15717v2","1131":"http:\/\/arxiv.org\/abs\/2106.05784v3","1132":"http:\/\/arxiv.org\/abs\/2012.00190v2","1133":"http:\/\/arxiv.org\/abs\/2111.14929v1","1134":"http:\/\/arxiv.org\/abs\/2111.03916v1","1135":"http:\/\/arxiv.org\/abs\/2108.12731v2","1136":"http:\/\/arxiv.org\/abs\/2111.09741v1","1137":"http:\/\/arxiv.org\/abs\/2111.03837v1","1138":"http:\/\/arxiv.org\/abs\/2111.03813v1","1139":"http:\/\/arxiv.org\/abs\/2111.03800v1","1140":"http:\/\/arxiv.org\/abs\/2112.02994v1","1141":"http:\/\/arxiv.org\/abs\/2111.03715v1","1142":"http:\/\/arxiv.org\/abs\/2111.03651v1","1143":"http:\/\/arxiv.org\/abs\/2111.03642v1","1144":"http:\/\/arxiv.org\/abs\/2104.06378v4","1145":"http:\/\/arxiv.org\/abs\/2111.03612v1","1146":"http:\/\/arxiv.org\/abs\/2104.08620v3","1147":"http:\/\/arxiv.org\/abs\/2110.12780v2","1148":"http:\/\/arxiv.org\/abs\/2112.02995v1","1149":"http:\/\/arxiv.org\/abs\/2111.03547v1","1150":"http:\/\/arxiv.org\/abs\/2111.03511v1","1151":"http:\/\/arxiv.org\/abs\/2111.03496v1","1152":"http:\/\/arxiv.org\/abs\/2110.06981v2","1153":"http:\/\/arxiv.org\/abs\/2111.03375v1","1154":"http:\/\/arxiv.org\/abs\/2111.03350v1","1155":"http:\/\/arxiv.org\/abs\/2111.03349v1","1156":"http:\/\/arxiv.org\/abs\/2111.03342v1","1157":"http:\/\/arxiv.org\/abs\/2104.08757v2","1158":"http:\/\/arxiv.org\/abs\/2111.03299v1","1159":"http:\/\/arxiv.org\/abs\/2111.03294v1","1160":"http:\/\/arxiv.org\/abs\/2111.03284v1","1161":"http:\/\/arxiv.org\/abs\/2111.03250v1","1162":"http:\/\/arxiv.org\/abs\/1911.04115v3","1163":"http:\/\/arxiv.org\/abs\/2109.08925v2","1164":"http:\/\/arxiv.org\/abs\/2107.14154v3","1165":"http:\/\/arxiv.org\/abs\/2110.13032v2","1166":"http:\/\/arxiv.org\/abs\/2111.03212v1","1167":"http:\/\/arxiv.org\/abs\/2111.03205v1","1168":"http:\/\/arxiv.org\/abs\/2110.07803v2","1169":"http:\/\/arxiv.org\/abs\/2107.03438v3","1170":"http:\/\/arxiv.org\/abs\/2111.03120v1","1171":"http:\/\/arxiv.org\/abs\/2111.03108v1","1172":"http:\/\/arxiv.org\/abs\/2108.01828v3","1173":"http:\/\/arxiv.org\/abs\/2108.04927v2","1174":"http:\/\/arxiv.org\/abs\/2111.03000v1","1175":"http:\/\/arxiv.org\/abs\/2111.02188v2","1176":"http:\/\/arxiv.org\/abs\/2111.02878v1","1177":"http:\/\/arxiv.org\/abs\/2109.14199v2","1178":"http:\/\/arxiv.org\/abs\/2111.02844v1","1179":"http:\/\/arxiv.org\/abs\/2111.02259v2","1180":"http:\/\/arxiv.org\/abs\/2111.02827v1","1181":"http:\/\/arxiv.org\/abs\/2111.02760v1","1182":"http:\/\/arxiv.org\/abs\/2111.02705v1","1183":"http:\/\/arxiv.org\/abs\/2111.02687v1","1184":"http:\/\/arxiv.org\/abs\/2111.02674v1","1185":"http:\/\/arxiv.org\/abs\/2109.11541v2","1186":"http:\/\/arxiv.org\/abs\/2111.02654v1","1187":"http:\/\/arxiv.org\/abs\/2006.02567v3","1188":"http:\/\/arxiv.org\/abs\/2111.02622v1","1189":"http:\/\/arxiv.org\/abs\/2111.02603v1","1190":"http:\/\/arxiv.org\/abs\/2111.02574v1","1191":"http:\/\/arxiv.org\/abs\/2111.02570v1","1192":"http:\/\/arxiv.org\/abs\/2110.04400v3","1193":"http:\/\/arxiv.org\/abs\/2111.02519v1","1194":"http:\/\/arxiv.org\/abs\/2109.04847v2","1195":"http:\/\/arxiv.org\/abs\/2011.10369v3","1196":"http:\/\/arxiv.org\/abs\/2111.02362v1","1197":"http:\/\/arxiv.org\/abs\/2111.02358v1","1198":"http:\/\/arxiv.org\/abs\/1809.00656v2","1199":"http:\/\/arxiv.org\/abs\/2111.02326v1","1200":"http:\/\/arxiv.org\/abs\/2112.02998v1","1201":"http:\/\/arxiv.org\/abs\/2111.01676v2","1202":"http:\/\/arxiv.org\/abs\/2111.02216v1","1203":"http:\/\/arxiv.org\/abs\/2111.02194v1","1204":"http:\/\/arxiv.org\/abs\/2111.02172v1","1205":"http:\/\/arxiv.org\/abs\/2110.15726v2","1206":"http:\/\/arxiv.org\/abs\/2111.02120v1","1207":"http:\/\/arxiv.org\/abs\/2111.02114v1","1208":"http:\/\/arxiv.org\/abs\/2109.08914v2","1209":"http:\/\/arxiv.org\/abs\/2111.02086v1","1210":"http:\/\/arxiv.org\/abs\/2111.02041v1","1211":"http:\/\/arxiv.org\/abs\/1908.07822v4","1212":"http:\/\/arxiv.org\/abs\/2104.08698v2","1213":"http:\/\/arxiv.org\/abs\/2106.12566v2","1214":"http:\/\/arxiv.org\/abs\/2111.01998v1","1215":"http:\/\/arxiv.org\/abs\/2111.01992v1","1216":"http:\/\/arxiv.org\/abs\/2111.01689v2","1217":"http:\/\/arxiv.org\/abs\/2106.01540v2","1218":"http:\/\/arxiv.org\/abs\/2111.01740v1","1219":"http:\/\/arxiv.org\/abs\/2111.01706v1","1220":"http:\/\/arxiv.org\/abs\/2105.09680v4","1221":"http:\/\/arxiv.org\/abs\/2111.01582v1","1222":"http:\/\/arxiv.org\/abs\/2111.01543v1","1223":"http:\/\/arxiv.org\/abs\/2111.01515v1","1224":"http:\/\/arxiv.org\/abs\/2111.01471v1","1225":"http:\/\/arxiv.org\/abs\/2111.01465v1","1226":"http:\/\/arxiv.org\/abs\/2111.01414v1","1227":"http:\/\/arxiv.org\/abs\/2111.01398v1","1228":"http:\/\/arxiv.org\/abs\/2109.09010v2","1229":"http:\/\/arxiv.org\/abs\/2110.01895v2","1230":"http:\/\/arxiv.org\/abs\/2111.01340v1","1231":"http:\/\/arxiv.org\/abs\/2111.01326v1","1232":"http:\/\/arxiv.org\/abs\/2111.01322v1","1233":"http:\/\/arxiv.org\/abs\/2112.02997v1","1234":"http:\/\/arxiv.org\/abs\/2110.15720v2","1235":"http:\/\/arxiv.org\/abs\/2111.01243v1","1236":"http:\/\/arxiv.org\/abs\/2109.05112v2","1237":"http:\/\/arxiv.org\/abs\/2111.01231v1","1238":"http:\/\/arxiv.org\/abs\/2104.07149v2","1239":"http:\/\/arxiv.org\/abs\/2111.01205v1","1240":"http:\/\/arxiv.org\/abs\/2103.01242v2","1241":"http:\/\/arxiv.org\/abs\/2109.08113v2","1242":"http:\/\/arxiv.org\/abs\/2111.01193v1","1243":"http:\/\/arxiv.org\/abs\/2111.01136v1","1244":"http:\/\/arxiv.org\/abs\/2110.09456v2","1245":"http:\/\/arxiv.org\/abs\/2111.01026v1","1246":"http:\/\/arxiv.org\/abs\/2111.01023v1","1247":"http:\/\/arxiv.org\/abs\/2110.12200v2","1248":"http:\/\/arxiv.org\/abs\/2111.00981v1","1249":"http:\/\/arxiv.org\/abs\/2110.09338v2","1250":"http:\/\/arxiv.org\/abs\/2111.00976v1","1251":"http:\/\/arxiv.org\/abs\/2111.00974v1","1252":"http:\/\/arxiv.org\/abs\/2111.00884v1","1253":"http:\/\/arxiv.org\/abs\/2111.00830v1","1254":"http:\/\/arxiv.org\/abs\/2111.00808v1","1255":"http:\/\/arxiv.org\/abs\/2010.10041v4","1256":"http:\/\/arxiv.org\/abs\/2110.04399v2","1257":"http:\/\/arxiv.org\/abs\/2010.11003v2","1258":"http:\/\/arxiv.org\/abs\/2111.00767v1","1259":"http:\/\/arxiv.org\/abs\/2104.11559v2","1260":"http:\/\/arxiv.org\/abs\/2102.08549v3","1261":"http:\/\/arxiv.org\/abs\/2111.00732v1","1262":"http:\/\/arxiv.org\/abs\/2111.00702v1","1263":"http:\/\/arxiv.org\/abs\/2111.00677v1","1264":"http:\/\/arxiv.org\/abs\/2111.00667v1","1265":"http:\/\/arxiv.org\/abs\/2101.06426v2","1266":"http:\/\/arxiv.org\/abs\/2111.00611v1","1267":"http:\/\/arxiv.org\/abs\/2111.00610v1","1268":"http:\/\/arxiv.org\/abs\/2111.00580v1","1269":"http:\/\/arxiv.org\/abs\/2111.00572v1","1270":"http:\/\/arxiv.org\/abs\/2111.00570v1","1271":"http:\/\/arxiv.org\/abs\/2110.14780v2","1272":"http:\/\/arxiv.org\/abs\/2111.00556v1","1273":"http:\/\/arxiv.org\/abs\/2111.00554v1","1274":"http:\/\/arxiv.org\/abs\/2111.00539v1","1275":"http:\/\/arxiv.org\/abs\/2104.05062v2","1276":"http:\/\/arxiv.org\/abs\/2111.00490v1","1277":"http:\/\/arxiv.org\/abs\/2111.00417v1","1278":"http:\/\/arxiv.org\/abs\/2111.00404v1","1279":"http:\/\/arxiv.org\/abs\/2111.00400v1","1280":"http:\/\/arxiv.org\/abs\/2104.02242v3","1281":"http:\/\/arxiv.org\/abs\/2111.00350v1","1282":"http:\/\/arxiv.org\/abs\/2111.00310v1","1283":"http:\/\/arxiv.org\/abs\/2101.01213v3","1284":"http:\/\/arxiv.org\/abs\/2109.01900v2","1285":"http:\/\/arxiv.org\/abs\/2109.08722v5","1286":"http:\/\/arxiv.org\/abs\/2110.13522v2","1287":"http:\/\/arxiv.org\/abs\/2105.00309v2","1288":"http:\/\/arxiv.org\/abs\/2107.05038v2","1289":"http:\/\/arxiv.org\/abs\/2111.00230v1","1290":"http:\/\/arxiv.org\/abs\/2103.05825v2","1291":"http:\/\/arxiv.org\/abs\/2111.00197v1","1292":"http:\/\/arxiv.org\/abs\/2111.00192v1","1293":"http:\/\/arxiv.org\/abs\/2111.00191v1","1294":"http:\/\/arxiv.org\/abs\/2109.05182v2","1295":"http:\/\/arxiv.org\/abs\/2111.00180v1","1296":"http:\/\/arxiv.org\/abs\/2111.00160v1","1297":"http:\/\/arxiv.org\/abs\/2111.00035v1","1298":"http:\/\/arxiv.org\/abs\/2110.15957v1","1299":"http:\/\/arxiv.org\/abs\/2110.15931v1","1300":"http:\/\/arxiv.org\/abs\/2110.15905v1","1301":"http:\/\/arxiv.org\/abs\/2110.15789v1","1302":"http:\/\/arxiv.org\/abs\/2110.03611v3","1303":"http:\/\/arxiv.org\/abs\/2010.12527v4","1304":"http:\/\/arxiv.org\/abs\/2104.08078v2","1305":"http:\/\/arxiv.org\/abs\/2010.12305v2","1306":"http:\/\/arxiv.org\/abs\/2110.15778v1","1307":"http:\/\/arxiv.org\/abs\/2110.15763v1","1308":"http:\/\/arxiv.org\/abs\/2109.10255v3","1309":"http:\/\/arxiv.org\/abs\/2110.15682v1","1310":"http:\/\/arxiv.org\/abs\/2110.15659v1","1311":"http:\/\/arxiv.org\/abs\/2110.15622v1","1312":"http:\/\/arxiv.org\/abs\/2110.15621v1","1313":"http:\/\/arxiv.org\/abs\/2110.15269v2","1314":"http:\/\/arxiv.org\/abs\/2110.15599v1","1315":"http:\/\/arxiv.org\/abs\/2111.01910v1","1316":"http:\/\/arxiv.org\/abs\/2111.05364v1","1317":"http:\/\/arxiv.org\/abs\/2110.15542v1","1318":"http:\/\/arxiv.org\/abs\/2110.15534v1","1319":"http:\/\/arxiv.org\/abs\/2110.15527v1","1320":"http:\/\/arxiv.org\/abs\/2110.15453v1","1321":"http:\/\/arxiv.org\/abs\/2110.15430v1","1322":"http:\/\/arxiv.org\/abs\/2101.08248v4","1323":"http:\/\/arxiv.org\/abs\/2005.10899v2","1324":"http:\/\/arxiv.org\/abs\/2110.15409v1","1325":"http:\/\/arxiv.org\/abs\/2110.15349v1","1326":"http:\/\/arxiv.org\/abs\/2110.15766v1","1327":"http:\/\/arxiv.org\/abs\/2110.15235v1","1328":"http:\/\/arxiv.org\/abs\/2110.06309v2","1329":"http:\/\/arxiv.org\/abs\/2110.15181v1","1330":"http:\/\/arxiv.org\/abs\/2110.15149v1","1331":"http:\/\/arxiv.org\/abs\/2010.07212v3","1332":"http:\/\/arxiv.org\/abs\/2110.15134v1","1333":"http:\/\/arxiv.org\/abs\/2110.15132v1","1334":"http:\/\/arxiv.org\/abs\/2110.15130v1","1335":"http:\/\/arxiv.org\/abs\/2105.01466v4","1336":"http:\/\/arxiv.org\/abs\/2110.15023v1","1337":"http:\/\/arxiv.org\/abs\/2110.15722v1","1338":"http:\/\/arxiv.org\/abs\/2110.14957v1","1339":"http:\/\/arxiv.org\/abs\/2110.14945v1","1340":"http:\/\/arxiv.org\/abs\/2107.05768v2","1341":"http:\/\/arxiv.org\/abs\/2110.14883v1","1342":"http:\/\/arxiv.org\/abs\/2110.01147v2","1343":"http:\/\/arxiv.org\/abs\/2110.14843v1","1344":"http:\/\/arxiv.org\/abs\/2110.14839v1","1345":"http:\/\/arxiv.org\/abs\/2103.11474v2","1346":"http:\/\/arxiv.org\/abs\/2107.11976v2","1347":"http:\/\/arxiv.org\/abs\/2107.14641v2","1348":"http:\/\/arxiv.org\/abs\/2107.02173v3","1349":"http:\/\/arxiv.org\/abs\/2106.00786v2","1350":"http:\/\/arxiv.org\/abs\/2110.14769v1","1351":"http:\/\/arxiv.org\/abs\/2102.04130v3","1352":"http:\/\/arxiv.org\/abs\/2110.14729v1","1353":"http:\/\/arxiv.org\/abs\/2102.07492v3","1354":"http:\/\/arxiv.org\/abs\/2110.14694v1","1355":"http:\/\/arxiv.org\/abs\/2110.14566v1","1356":"http:\/\/arxiv.org\/abs\/2110.15797v1","1357":"http:\/\/arxiv.org\/abs\/2106.07759v2","1358":"http:\/\/arxiv.org\/abs\/2110.14398v1","1359":"http:\/\/arxiv.org\/abs\/2106.11520v2","1360":"http:\/\/arxiv.org\/abs\/2110.14273v1","1361":"http:\/\/arxiv.org\/abs\/2110.14266v1","1362":"http:\/\/arxiv.org\/abs\/2110.14241v1","1363":"http:\/\/arxiv.org\/abs\/2110.14203v1","1364":"http:\/\/arxiv.org\/abs\/2110.05722v2","1365":"http:\/\/arxiv.org\/abs\/2110.14182v1","1366":"http:\/\/arxiv.org\/abs\/2110.14171v1","1367":"http:\/\/arxiv.org\/abs\/2102.08473v2","1368":"http:\/\/arxiv.org\/abs\/2108.07127v3","1369":"http:\/\/arxiv.org\/abs\/2110.14091v1","1370":"http:\/\/arxiv.org\/abs\/2106.03257v3","1371":"http:\/\/arxiv.org\/abs\/2110.13980v1","1372":"http:\/\/arxiv.org\/abs\/2110.13971v1","1373":"http:\/\/arxiv.org\/abs\/2110.13880v1","1374":"http:\/\/arxiv.org\/abs\/2110.13877v1","1375":"http:\/\/arxiv.org\/abs\/2106.05933v2","1376":"http:\/\/arxiv.org\/abs\/2104.07472v2","1377":"http:\/\/arxiv.org\/abs\/2110.03111v3","1378":"http:\/\/arxiv.org\/abs\/2104.08642v2","1379":"http:\/\/arxiv.org\/abs\/2012.08508v3","1380":"http:\/\/arxiv.org\/abs\/2102.01951v2","1381":"http:\/\/arxiv.org\/abs\/2110.13658v1","1382":"http:\/\/arxiv.org\/abs\/2110.03215v3","1383":"http:\/\/arxiv.org\/abs\/2103.06511v2","1384":"http:\/\/arxiv.org\/abs\/2110.13710v1","1385":"http:\/\/arxiv.org\/abs\/2110.13692v1","1386":"http:\/\/arxiv.org\/abs\/2110.13691v1","1387":"http:\/\/arxiv.org\/abs\/2110.13683v1","1388":"http:\/\/arxiv.org\/abs\/2110.13640v1","1389":"http:\/\/arxiv.org\/abs\/2108.07994v2","1390":"http:\/\/arxiv.org\/abs\/2103.02227v3","1391":"http:\/\/arxiv.org\/abs\/2110.13577v1","1392":"http:\/\/arxiv.org\/abs\/2105.11832v2","1393":"http:\/\/arxiv.org\/abs\/2009.06891v5","1394":"http:\/\/arxiv.org\/abs\/2110.15794v1","1395":"http:\/\/arxiv.org\/abs\/2110.13505v1","1396":"http:\/\/arxiv.org\/abs\/2110.13495v1","1397":"http:\/\/arxiv.org\/abs\/2110.13480v1","1398":"http:\/\/arxiv.org\/abs\/2106.13033v2","1399":"http:\/\/arxiv.org\/abs\/2110.13472v1","1400":"http:\/\/arxiv.org\/abs\/2106.01609v3","1401":"http:\/\/arxiv.org\/abs\/2110.05745v2","1402":"http:\/\/arxiv.org\/abs\/2110.13434v1","1403":"http:\/\/arxiv.org\/abs\/2106.03831v2","1404":"http:\/\/arxiv.org\/abs\/2110.03163v2","1405":"http:\/\/arxiv.org\/abs\/2110.13398v1","1406":"http:\/\/arxiv.org\/abs\/2110.13376v1","1407":"http:\/\/arxiv.org\/abs\/1908.03265v4","1408":"http:\/\/arxiv.org\/abs\/2109.11888v2","1409":"http:\/\/arxiv.org\/abs\/2110.13317v1","1410":"http:\/\/arxiv.org\/abs\/2107.02968v2","1411":"http:\/\/arxiv.org\/abs\/2110.13244v1","1412":"http:\/\/arxiv.org\/abs\/2110.13231v1","1413":"http:\/\/arxiv.org\/abs\/2110.13213v1","1414":"http:\/\/arxiv.org\/abs\/2110.13090v1","1415":"http:\/\/arxiv.org\/abs\/2105.02472v2","1416":"http:\/\/arxiv.org\/abs\/2110.13016v1","1417":"http:\/\/arxiv.org\/abs\/2110.12949v1","1418":"http:\/\/arxiv.org\/abs\/2110.12948v1","1419":"http:\/\/arxiv.org\/abs\/2005.02233v3","1420":"http:\/\/arxiv.org\/abs\/2109.01942v2","1421":"http:\/\/arxiv.org\/abs\/2107.01076v2","1422":"http:\/\/arxiv.org\/abs\/2105.05686v2","1423":"http:\/\/arxiv.org\/abs\/2110.12765v1","1424":"http:\/\/arxiv.org\/abs\/2110.12764v1","1425":"http:\/\/arxiv.org\/abs\/2110.12687v1","1426":"http:\/\/arxiv.org\/abs\/2110.12680v1","1427":"http:\/\/arxiv.org\/abs\/2110.03888v3","1428":"http:\/\/arxiv.org\/abs\/2110.12646v1","1429":"http:\/\/arxiv.org\/abs\/2110.12645v1","1430":"http:\/\/arxiv.org\/abs\/2110.10470v2","1431":"http:\/\/arxiv.org\/abs\/2110.11624v2","1432":"http:\/\/arxiv.org\/abs\/2107.03054v2","1433":"http:\/\/arxiv.org\/abs\/2110.12609v1","1434":"http:\/\/arxiv.org\/abs\/2108.06314v5","1435":"http:\/\/arxiv.org\/abs\/2110.12567v1","1436":"http:\/\/arxiv.org\/abs\/2110.12552v1","1437":"http:\/\/arxiv.org\/abs\/2110.12551v1","1438":"http:\/\/arxiv.org\/abs\/2110.12501v1","1439":"http:\/\/arxiv.org\/abs\/2110.15054v1","1440":"http:\/\/arxiv.org\/abs\/2110.12416v1","1441":"http:\/\/arxiv.org\/abs\/2110.12412v1","1442":"http:\/\/arxiv.org\/abs\/2110.12383v1","1443":"http:\/\/arxiv.org\/abs\/2109.04513v2","1444":"http:\/\/arxiv.org\/abs\/2110.12374v1","1445":"http:\/\/arxiv.org\/abs\/2110.12370v1","1446":"http:\/\/arxiv.org\/abs\/2109.05473v3","1447":"http:\/\/arxiv.org\/abs\/2110.12349v1","1448":"http:\/\/arxiv.org\/abs\/2110.12342v1","1449":"http:\/\/arxiv.org\/abs\/2110.12341v1","1450":"http:\/\/arxiv.org\/abs\/2110.12335v1","1451":"http:\/\/arxiv.org\/abs\/2110.12320v1","1452":"http:\/\/arxiv.org\/abs\/2110.15799v1","1453":"http:\/\/arxiv.org\/abs\/2109.08270v3","1454":"http:\/\/arxiv.org\/abs\/2110.12243v1","1455":"http:\/\/arxiv.org\/abs\/2110.08975v2","1456":"http:\/\/arxiv.org\/abs\/2110.12201v1","1457":"http:\/\/arxiv.org\/abs\/2110.12199v1","1458":"http:\/\/arxiv.org\/abs\/2110.01188v3","1459":"http:\/\/arxiv.org\/abs\/2110.10358v2","1460":"http:\/\/arxiv.org\/abs\/2110.06502v2","1461":"http:\/\/arxiv.org\/abs\/2105.04780v2","1462":"http:\/\/arxiv.org\/abs\/2106.09063v3","1463":"http:\/\/arxiv.org\/abs\/2110.12010v1","1464":"http:\/\/arxiv.org\/abs\/2110.11938v1","1465":"http:\/\/arxiv.org\/abs\/2110.11934v1","1466":"http:\/\/arxiv.org\/abs\/2110.11929v1","1467":"http:\/\/arxiv.org\/abs\/2110.11899v1","1468":"http:\/\/arxiv.org\/abs\/2110.11881v1","1469":"http:\/\/arxiv.org\/abs\/2110.11850v1","1470":"http:\/\/arxiv.org\/abs\/2109.15086v2","1471":"http:\/\/arxiv.org\/abs\/2102.05379v3","1472":"http:\/\/arxiv.org\/abs\/2110.11692v1","1473":"http:\/\/arxiv.org\/abs\/2104.07123v2","1474":"http:\/\/arxiv.org\/abs\/2109.07234v2","1475":"http:\/\/arxiv.org\/abs\/2110.05035v2","1476":"http:\/\/arxiv.org\/abs\/2112.00709v1","1477":"http:\/\/arxiv.org\/abs\/2004.03808v4","1478":"http:\/\/arxiv.org\/abs\/2110.11589v1","1479":"http:\/\/arxiv.org\/abs\/2110.11560v1","1480":"http:\/\/arxiv.org\/abs\/2106.00200v2","1481":"http:\/\/arxiv.org\/abs\/2106.02636v3","1482":"http:\/\/arxiv.org\/abs\/2110.11514v1","1483":"http:\/\/arxiv.org\/abs\/2106.09553v2","1484":"http:\/\/arxiv.org\/abs\/2109.13238v2","1485":"http:\/\/arxiv.org\/abs\/2110.11333v1","1486":"http:\/\/arxiv.org\/abs\/2110.11309v1","1487":"http:\/\/arxiv.org\/abs\/2010.07668v2","1488":"http:\/\/arxiv.org\/abs\/2110.11207v1","1489":"http:\/\/arxiv.org\/abs\/2110.11199v1","1490":"http:\/\/arxiv.org\/abs\/2104.04580v2","1491":"http:\/\/arxiv.org\/abs\/2110.11164v1","1492":"http:\/\/arxiv.org\/abs\/2110.11115v1","1493":"http:\/\/arxiv.org\/abs\/2108.06130v3","1494":"http:\/\/arxiv.org\/abs\/2110.10973v1","1495":"http:\/\/arxiv.org\/abs\/2110.10963v1","1496":"http:\/\/arxiv.org\/abs\/2109.11034v2","1497":"http:\/\/arxiv.org\/abs\/2110.10874v1","1498":"http:\/\/arxiv.org\/abs\/2110.10871v1","1499":"http:\/\/arxiv.org\/abs\/2110.07752v2","1500":"http:\/\/arxiv.org\/abs\/2104.08663v4","1501":"http:\/\/arxiv.org\/abs\/2110.10834v1","1502":"http:\/\/arxiv.org\/abs\/2104.08667v2","1503":"http:\/\/arxiv.org\/abs\/2110.10817v1","1504":"http:\/\/arxiv.org\/abs\/2110.10778v1","1505":"http:\/\/arxiv.org\/abs\/2103.07601v3","1506":"http:\/\/arxiv.org\/abs\/2110.10774v1","1507":"http:\/\/arxiv.org\/abs\/2110.10746v1","1508":"http:\/\/arxiv.org\/abs\/2106.09608v2","1509":"http:\/\/arxiv.org\/abs\/2110.10668v1","1510":"http:\/\/arxiv.org\/abs\/2110.10577v1","1511":"http:\/\/arxiv.org\/abs\/2110.10575v1","1512":"http:\/\/arxiv.org\/abs\/2010.10216v4","1513":"http:\/\/arxiv.org\/abs\/1908.11017v4","1514":"http:\/\/arxiv.org\/abs\/2101.06053v2","1515":"http:\/\/arxiv.org\/abs\/2107.11757v2","1516":"http:\/\/arxiv.org\/abs\/2110.10478v1","1517":"http:\/\/arxiv.org\/abs\/2110.10472v1","1518":"http:\/\/arxiv.org\/abs\/2008.09150v2","1519":"http:\/\/arxiv.org\/abs\/2110.10431v1","1520":"http:\/\/arxiv.org\/abs\/2110.10429v1","1521":"http:\/\/arxiv.org\/abs\/2110.08591v2","1522":"http:\/\/arxiv.org\/abs\/2110.05856v2","1523":"http:\/\/arxiv.org\/abs\/2106.11483v3","1524":"http:\/\/arxiv.org\/abs\/2110.10372v1","1525":"http:\/\/arxiv.org\/abs\/2110.09702v2","1526":"http:\/\/arxiv.org\/abs\/2110.10340v1","1527":"http:\/\/arxiv.org\/abs\/2010.14649v2","1528":"http:\/\/arxiv.org\/abs\/2110.10329v1","1529":"http:\/\/arxiv.org\/abs\/2110.10328v1","1530":"http:\/\/arxiv.org\/abs\/2110.10319v1","1531":"http:\/\/arxiv.org\/abs\/2110.10318v1","1532":"http:\/\/arxiv.org\/abs\/2110.06388v2","1533":"http:\/\/arxiv.org\/abs\/2110.10213v1","1534":"http:\/\/arxiv.org\/abs\/2110.15801v1","1535":"http:\/\/arxiv.org\/abs\/2110.10189v1","1536":"http:\/\/arxiv.org\/abs\/2110.10185v1","1537":"http:\/\/arxiv.org\/abs\/2107.02681v2","1538":"http:\/\/arxiv.org\/abs\/2109.04993v2","1539":"http:\/\/arxiv.org\/abs\/2110.10064v1","1540":"http:\/\/arxiv.org\/abs\/2110.10015v1","1541":"http:\/\/arxiv.org\/abs\/2111.00867v1","1542":"http:\/\/arxiv.org\/abs\/2110.09915v1","1543":"http:\/\/arxiv.org\/abs\/2110.09877v1","1544":"http:\/\/arxiv.org\/abs\/2110.13815v1","1545":"http:\/\/arxiv.org\/abs\/2108.04049v2","1546":"http:\/\/arxiv.org\/abs\/2110.03618v2","1547":"http:\/\/arxiv.org\/abs\/2110.09779v1","1548":"http:\/\/arxiv.org\/abs\/2110.09756v1","1549":"http:\/\/arxiv.org\/abs\/2110.09753v1","1550":"http:\/\/arxiv.org\/abs\/2008.02742v3","1551":"http:\/\/arxiv.org\/abs\/2110.08270v2","1552":"http:\/\/arxiv.org\/abs\/2110.09721v1","1553":"http:\/\/arxiv.org\/abs\/2110.09710v1","1554":"http:\/\/arxiv.org\/abs\/2011.10896v4","1555":"http:\/\/arxiv.org\/abs\/2108.06743v2","1556":"http:\/\/arxiv.org\/abs\/2110.09698v1","1557":"http:\/\/arxiv.org\/abs\/2110.09665v1","1558":"http:\/\/arxiv.org\/abs\/2110.09646v1","1559":"http:\/\/arxiv.org\/abs\/2110.11240v1","1560":"http:\/\/arxiv.org\/abs\/2110.05994v2","1561":"http:\/\/arxiv.org\/abs\/2110.09574v1","1562":"http:\/\/arxiv.org\/abs\/2110.12003v1","1563":"http:\/\/arxiv.org\/abs\/2110.09570v1","1564":"http:\/\/arxiv.org\/abs\/2107.13935v2","1565":"http:\/\/arxiv.org\/abs\/2110.09495v1","1566":"http:\/\/arxiv.org\/abs\/2110.15802v1","1567":"http:\/\/arxiv.org\/abs\/2110.09454v1","1568":"http:\/\/arxiv.org\/abs\/2110.09424v1","1569":"http:\/\/arxiv.org\/abs\/2110.09421v1","1570":"http:\/\/arxiv.org\/abs\/2110.09393v1","1571":"http:\/\/arxiv.org\/abs\/2104.07644v3","1572":"http:\/\/arxiv.org\/abs\/2110.09324v1","1573":"http:\/\/arxiv.org\/abs\/2110.09216v1","1574":"http:\/\/arxiv.org\/abs\/2003.12739v2","1575":"http:\/\/arxiv.org\/abs\/2110.09179v1","1576":"http:\/\/arxiv.org\/abs\/2110.07187v2","1577":"http:\/\/arxiv.org\/abs\/2110.09147v1","1578":"http:\/\/arxiv.org\/abs\/2110.09103v1","1579":"http:\/\/arxiv.org\/abs\/2110.11403v1","1580":"http:\/\/arxiv.org\/abs\/2110.09094v1","1581":"http:\/\/arxiv.org\/abs\/2110.01500v5","1582":"http:\/\/arxiv.org\/abs\/2109.05941v2","1583":"http:\/\/arxiv.org\/abs\/2110.09930v1","1584":"http:\/\/arxiv.org\/abs\/2110.09036v1","1585":"http:\/\/arxiv.org\/abs\/2109.14420v3","1586":"http:\/\/arxiv.org\/abs\/2107.04082v4","1587":"http:\/\/arxiv.org\/abs\/2110.08931v1","1588":"http:\/\/arxiv.org\/abs\/2103.14804v4","1589":"http:\/\/arxiv.org\/abs\/2110.08887v1","1590":"http:\/\/arxiv.org\/abs\/2110.08875v1","1591":"http:\/\/arxiv.org\/abs\/2110.08874v1","1592":"http:\/\/arxiv.org\/abs\/2110.08845v1","1593":"http:\/\/arxiv.org\/abs\/2109.07680v3","1594":"http:\/\/arxiv.org\/abs\/2110.08745v1","1595":"http:\/\/arxiv.org\/abs\/2109.02418v2","1596":"http:\/\/arxiv.org\/abs\/2110.08678v1","1597":"http:\/\/arxiv.org\/abs\/2106.09685v2","1598":"http:\/\/arxiv.org\/abs\/2110.08604v1","1599":"http:\/\/arxiv.org\/abs\/2110.08583v1","1600":"http:\/\/arxiv.org\/abs\/1908.09128v2","1601":"http:\/\/arxiv.org\/abs\/2110.08559v1","1602":"http:\/\/arxiv.org\/abs\/2110.08554v1","1603":"http:\/\/arxiv.org\/abs\/2110.08551v1","1604":"http:\/\/arxiv.org\/abs\/2110.08545v1","1605":"http:\/\/arxiv.org\/abs\/2110.08538v1","1606":"http:\/\/arxiv.org\/abs\/2110.08536v1","1607":"http:\/\/arxiv.org\/abs\/2110.08534v1","1608":"http:\/\/arxiv.org\/abs\/2110.08532v1","1609":"http:\/\/arxiv.org\/abs\/2110.08520v1","1610":"http:\/\/arxiv.org\/abs\/2108.13741v3","1611":"http:\/\/arxiv.org\/abs\/2110.08514v1","1612":"http:\/\/arxiv.org\/abs\/2110.08462v1","1613":"http:\/\/arxiv.org\/abs\/2110.08460v1","1614":"http:\/\/arxiv.org\/abs\/2110.08455v1","1615":"http:\/\/arxiv.org\/abs\/2104.05848v7","1616":"http:\/\/arxiv.org\/abs\/2110.08445v1","1617":"http:\/\/arxiv.org\/abs\/2110.08430v1","1618":"http:\/\/arxiv.org\/abs\/2110.08426v1","1619":"http:\/\/arxiv.org\/abs\/2110.08420v1","1620":"http:\/\/arxiv.org\/abs\/2110.08419v1","1621":"http:\/\/arxiv.org\/abs\/2110.08413v1","1622":"http:\/\/arxiv.org\/abs\/2110.08412v1","1623":"http:\/\/arxiv.org\/abs\/2110.08395v1","1624":"http:\/\/arxiv.org\/abs\/2105.01051v4","1625":"http:\/\/arxiv.org\/abs\/2110.08383v1","1626":"http:\/\/arxiv.org\/abs\/2110.08381v1","1627":"http:\/\/arxiv.org\/abs\/2110.15733v1","1628":"http:\/\/arxiv.org\/abs\/2110.08355v1","1629":"http:\/\/arxiv.org\/abs\/2110.08352v1","1630":"http:\/\/arxiv.org\/abs\/2110.08323v1","1631":"http:\/\/arxiv.org\/abs\/2104.02145v3","1632":"http:\/\/arxiv.org\/abs\/2106.02016v2","1633":"http:\/\/arxiv.org\/abs\/2106.06797v2","1634":"http:\/\/arxiv.org\/abs\/2109.04712v2","1635":"http:\/\/arxiv.org\/abs\/2110.08247v1","1636":"http:\/\/arxiv.org\/abs\/2110.08246v1","1637":"http:\/\/arxiv.org\/abs\/2110.08241v1","1638":"http:\/\/arxiv.org\/abs\/2110.08228v1","1639":"http:\/\/arxiv.org\/abs\/2107.12079v3","1640":"http:\/\/arxiv.org\/abs\/2110.08213v1","1641":"http:\/\/arxiv.org\/abs\/2110.08182v1","1642":"http:\/\/arxiv.org\/abs\/2110.08175v1","1643":"http:\/\/arxiv.org\/abs\/2110.08152v1","1644":"http:\/\/arxiv.org\/abs\/2110.08118v1","1645":"http:\/\/arxiv.org\/abs\/2104.07198v2","1646":"http:\/\/arxiv.org\/abs\/2110.08036v1","1647":"http:\/\/arxiv.org\/abs\/2110.08032v1","1648":"http:\/\/arxiv.org\/abs\/2110.08021v1","1649":"http:\/\/arxiv.org\/abs\/2110.08020v1","1650":"http:\/\/arxiv.org\/abs\/2110.08015v1","1651":"http:\/\/arxiv.org\/abs\/2110.08011v1","1652":"http:\/\/arxiv.org\/abs\/2110.08010v1","1653":"http:\/\/arxiv.org\/abs\/2012.02957v2","1654":"http:\/\/arxiv.org\/abs\/2110.07982v1","1655":"http:\/\/arxiv.org\/abs\/2106.04258v3","1656":"http:\/\/arxiv.org\/abs\/2110.07938v1","1657":"http:\/\/arxiv.org\/abs\/2106.07385v3","1658":"http:\/\/arxiv.org\/abs\/2110.07918v1","1659":"http:\/\/arxiv.org\/abs\/2110.07909v1","1660":"http:\/\/arxiv.org\/abs\/2108.10643v2","1661":"http:\/\/arxiv.org\/abs\/2110.11984v1","1662":"http:\/\/arxiv.org\/abs\/2110.07867v1","1663":"http:\/\/arxiv.org\/abs\/2110.07850v1","1664":"http:\/\/arxiv.org\/abs\/2109.13348v2","1665":"http:\/\/arxiv.org\/abs\/2110.07844v1","1666":"http:\/\/arxiv.org\/abs\/2110.07840v1","1667":"http:\/\/arxiv.org\/abs\/2110.07837v1","1668":"http:\/\/arxiv.org\/abs\/2110.07833v1","1669":"http:\/\/arxiv.org\/abs\/2110.07831v1","1670":"http:\/\/arxiv.org\/abs\/2110.15732v1","1671":"http:\/\/arxiv.org\/abs\/2101.03289v5","1672":"http:\/\/arxiv.org\/abs\/2110.07827v1","1673":"http:\/\/arxiv.org\/abs\/2110.00678v3","1674":"http:\/\/arxiv.org\/abs\/2110.07816v1","1675":"http:\/\/arxiv.org\/abs\/2110.07811v1","1676":"http:\/\/arxiv.org\/abs\/2110.07804v1","1677":"http:\/\/arxiv.org\/abs\/2110.07792v1","1678":"http:\/\/arxiv.org\/abs\/2104.08737v2","1679":"http:\/\/arxiv.org\/abs\/2107.11020v2","1680":"http:\/\/arxiv.org\/abs\/2110.07736v1","1681":"http:\/\/arxiv.org\/abs\/2104.08540v2","1682":"http:\/\/arxiv.org\/abs\/2110.06823v2","1683":"http:\/\/arxiv.org\/abs\/2109.04726v2","1684":"http:\/\/arxiv.org\/abs\/2110.07693v1","1685":"http:\/\/arxiv.org\/abs\/2110.06495v2","1686":"http:\/\/arxiv.org\/abs\/2110.07686v1","1687":"http:\/\/arxiv.org\/abs\/2110.06209v2","1688":"http:\/\/arxiv.org\/abs\/2108.08102v3","1689":"http:\/\/arxiv.org\/abs\/2110.07640v1","1690":"http:\/\/arxiv.org\/abs\/2110.07595v1","1691":"http:\/\/arxiv.org\/abs\/2110.07581v1","1692":"http:\/\/arxiv.org\/abs\/2110.07575v1","1693":"http:\/\/arxiv.org\/abs\/2110.07574v1","1694":"http:\/\/arxiv.org\/abs\/2110.07572v1","1695":"http:\/\/arxiv.org\/abs\/2110.07566v1","1696":"http:\/\/arxiv.org\/abs\/2110.07560v1","1697":"http:\/\/arxiv.org\/abs\/2110.07550v1","1698":"http:\/\/arxiv.org\/abs\/2105.11314v2","1699":"http:\/\/arxiv.org\/abs\/2110.07515v1","1700":"http:\/\/arxiv.org\/abs\/2109.11728v3","1701":"http:\/\/arxiv.org\/abs\/2110.07477v1","1702":"http:\/\/arxiv.org\/abs\/2108.00719v3","1703":"http:\/\/arxiv.org\/abs\/2110.07444v1","1704":"http:\/\/arxiv.org\/abs\/2110.07431v1","1705":"http:\/\/arxiv.org\/abs\/2110.07420v1","1706":"http:\/\/arxiv.org\/abs\/2110.07410v1","1707":"http:\/\/arxiv.org\/abs\/2110.07383v1","1708":"http:\/\/arxiv.org\/abs\/2110.07382v1","1709":"http:\/\/arxiv.org\/abs\/1911.01528v4","1710":"http:\/\/arxiv.org\/abs\/2110.07367v1","1711":"http:\/\/arxiv.org\/abs\/2110.07331v1","1712":"http:\/\/arxiv.org\/abs\/2110.07330v1","1713":"http:\/\/arxiv.org\/abs\/2110.07310v1","1714":"http:\/\/arxiv.org\/abs\/1904.06217v3","1715":"http:\/\/arxiv.org\/abs\/2104.11710v2","1716":"http:\/\/arxiv.org\/abs\/2110.07304v1","1717":"http:\/\/arxiv.org\/abs\/2110.07303v1","1718":"http:\/\/arxiv.org\/abs\/2010.12643v2","1719":"http:\/\/arxiv.org\/abs\/2109.10604v2","1720":"http:\/\/arxiv.org\/abs\/2110.07240v1","1721":"http:\/\/arxiv.org\/abs\/2110.05896v3","1722":"http:\/\/arxiv.org\/abs\/2110.06696v2","1723":"http:\/\/arxiv.org\/abs\/2110.07210v1","1724":"http:\/\/arxiv.org\/abs\/2110.07209v1","1725":"http:\/\/arxiv.org\/abs\/2110.08049v1","1726":"http:\/\/arxiv.org\/abs\/2110.07178v1","1727":"http:\/\/arxiv.org\/abs\/2110.07174v1","1728":"http:\/\/arxiv.org\/abs\/2110.07166v1","1729":"http:\/\/arxiv.org\/abs\/2110.07161v1","1730":"http:\/\/arxiv.org\/abs\/2110.07160v1","1731":"http:\/\/arxiv.org\/abs\/2110.07150v1","1732":"http:\/\/arxiv.org\/abs\/2110.07143v1","1733":"http:\/\/arxiv.org\/abs\/2110.07139v1","1734":"http:\/\/arxiv.org\/abs\/2110.07137v1","1735":"http:\/\/arxiv.org\/abs\/2109.15196v2","1736":"http:\/\/arxiv.org\/abs\/2110.07055v1","1737":"http:\/\/arxiv.org\/abs\/2110.07031v1","1738":"http:\/\/arxiv.org\/abs\/2103.06960v2","1739":"http:\/\/arxiv.org\/abs\/2110.07027v1","1740":"http:\/\/arxiv.org\/abs\/2109.06304v2","1741":"http:\/\/arxiv.org\/abs\/2010.01496v2","1742":"http:\/\/arxiv.org\/abs\/2110.07002v1","1743":"http:\/\/arxiv.org\/abs\/2101.00371v2","1744":"http:\/\/arxiv.org\/abs\/2110.06997v1","1745":"http:\/\/arxiv.org\/abs\/2110.06962v1","1746":"http:\/\/arxiv.org\/abs\/2110.06920v1","1747":"http:\/\/arxiv.org\/abs\/2104.08161v2","1748":"http:\/\/arxiv.org\/abs\/2110.06905v1","1749":"http:\/\/arxiv.org\/abs\/2110.06894v1","1750":"http:\/\/arxiv.org\/abs\/2110.06884v1","1751":"http:\/\/arxiv.org\/abs\/2110.06874v1","1752":"http:\/\/arxiv.org\/abs\/2110.06865v1","1753":"http:\/\/arxiv.org\/abs\/2102.03044v4","1754":"http:\/\/arxiv.org\/abs\/2110.06847v1","1755":"http:\/\/arxiv.org\/abs\/2110.06821v1","1756":"http:\/\/arxiv.org\/abs\/2110.06744v1","1757":"http:\/\/arxiv.org\/abs\/2110.06733v1","1758":"http:\/\/arxiv.org\/abs\/2110.06674v1","1759":"http:\/\/arxiv.org\/abs\/2108.12026v2","1760":"http:\/\/arxiv.org\/abs\/2110.06620v1","1761":"http:\/\/arxiv.org\/abs\/2110.15730v1","1762":"http:\/\/arxiv.org\/abs\/2105.02544v2","1763":"http:\/\/arxiv.org\/abs\/2110.15729v1","1764":"http:\/\/arxiv.org\/abs\/2110.06560v1","1765":"http:\/\/arxiv.org\/abs\/2110.08254v1","1766":"http:\/\/arxiv.org\/abs\/2109.07833v2","1767":"http:\/\/arxiv.org\/abs\/2012.12641v3","1768":"http:\/\/arxiv.org\/abs\/2110.06533v1","1769":"http:\/\/arxiv.org\/abs\/2109.13662v3","1770":"http:\/\/arxiv.org\/abs\/2110.06510v1","1771":"http:\/\/arxiv.org\/abs\/2110.06507v1","1772":"http:\/\/arxiv.org\/abs\/2110.06500v1","1773":"http:\/\/arxiv.org\/abs\/2107.05541v6","1774":"http:\/\/arxiv.org\/abs\/2110.06486v1","1775":"http:\/\/arxiv.org\/abs\/2110.06474v1","1776":"http:\/\/arxiv.org\/abs\/2110.06461v1","1777":"http:\/\/arxiv.org\/abs\/2110.06446v1","1778":"http:\/\/arxiv.org\/abs\/2110.05748v2","1779":"http:\/\/arxiv.org\/abs\/2110.06419v1","1780":"http:\/\/arxiv.org\/abs\/2109.03137v2","1781":"http:\/\/arxiv.org\/abs\/2110.06397v1","1782":"http:\/\/arxiv.org\/abs\/2110.06393v1","1783":"http:\/\/arxiv.org\/abs\/2110.06384v1","1784":"http:\/\/arxiv.org\/abs\/2110.06376v1","1785":"http:\/\/arxiv.org\/abs\/2110.06341v1","1786":"http:\/\/arxiv.org\/abs\/2110.06288v1","1787":"http:\/\/arxiv.org\/abs\/2110.06280v1","1788":"http:\/\/arxiv.org\/abs\/2110.06274v1","1789":"http:\/\/arxiv.org\/abs\/2110.06223v1","1790":"http:\/\/arxiv.org\/abs\/2110.07333v1","1791":"http:\/\/arxiv.org\/abs\/2110.06151v1","1792":"http:\/\/arxiv.org\/abs\/2110.06078v1","1793":"http:\/\/arxiv.org\/abs\/2104.08512v2","1794":"http:\/\/arxiv.org\/abs\/2110.15728v1","1795":"http:\/\/arxiv.org\/abs\/2110.05999v1","1796":"http:\/\/arxiv.org\/abs\/2110.02869v3","1797":"http:\/\/arxiv.org\/abs\/2110.05892v1","1798":"http:\/\/arxiv.org\/abs\/2110.05877v1","1799":"http:\/\/arxiv.org\/abs\/2110.05146v2","1800":"http:\/\/arxiv.org\/abs\/2110.05866v1","1801":"http:\/\/arxiv.org\/abs\/2106.05707v3","1802":"http:\/\/arxiv.org\/abs\/2110.05006v2","1803":"http:\/\/arxiv.org\/abs\/2110.05847v1","1804":"http:\/\/arxiv.org\/abs\/2110.05838v1","1805":"http:\/\/arxiv.org\/abs\/2105.12667v2","1806":"http:\/\/arxiv.org\/abs\/2008.12804v4","1807":"http:\/\/arxiv.org\/abs\/2110.05780v1","1808":"http:\/\/arxiv.org\/abs\/2110.05775v1","1809":"http:\/\/arxiv.org\/abs\/2103.03125v2","1810":"http:\/\/arxiv.org\/abs\/2110.04984v2","1811":"http:\/\/arxiv.org\/abs\/2110.05752v1","1812":"http:\/\/arxiv.org\/abs\/2110.05750v1","1813":"http:\/\/arxiv.org\/abs\/2110.05727v1","1814":"http:\/\/arxiv.org\/abs\/2110.05723v1","1815":"http:\/\/arxiv.org\/abs\/2110.05719v1","1816":"http:\/\/arxiv.org\/abs\/2109.01951v3","1817":"http:\/\/arxiv.org\/abs\/2110.05699v1","1818":"http:\/\/arxiv.org\/abs\/2110.04725v2","1819":"http:\/\/arxiv.org\/abs\/2110.05691v1","1820":"http:\/\/arxiv.org\/abs\/2110.05679v1","1821":"http:\/\/arxiv.org\/abs\/2110.05665v1","1822":"http:\/\/arxiv.org\/abs\/2104.12763v2","1823":"http:\/\/arxiv.org\/abs\/2110.05663v1","1824":"http:\/\/arxiv.org\/abs\/2110.05633v1","1825":"http:\/\/arxiv.org\/abs\/2110.05573v1","1826":"http:\/\/arxiv.org\/abs\/2110.05571v1","1827":"http:\/\/arxiv.org\/abs\/2110.05464v1","1828":"http:\/\/arxiv.org\/abs\/2110.05456v1","1829":"http:\/\/arxiv.org\/abs\/2110.05448v1","1830":"http:\/\/arxiv.org\/abs\/2110.05423v1","1831":"http:\/\/arxiv.org\/abs\/2110.05422v1","1832":"http:\/\/arxiv.org\/abs\/2109.09725v4","1833":"http:\/\/arxiv.org\/abs\/2110.05376v1","1834":"http:\/\/arxiv.org\/abs\/2110.05369v1","1835":"http:\/\/arxiv.org\/abs\/2110.05367v1","1836":"http:\/\/arxiv.org\/abs\/2110.05362v1","1837":"http:\/\/arxiv.org\/abs\/2106.08858v2","1838":"http:\/\/arxiv.org\/abs\/2110.05301v1","1839":"http:\/\/arxiv.org\/abs\/2110.05287v1","1840":"http:\/\/arxiv.org\/abs\/2110.05249v1","1841":"http:\/\/arxiv.org\/abs\/2110.05221v1","1842":"http:\/\/arxiv.org\/abs\/2110.05213v1","1843":"http:\/\/arxiv.org\/abs\/2110.05172v1","1844":"http:\/\/arxiv.org\/abs\/2109.11377v2","1845":"http:\/\/arxiv.org\/abs\/2105.05887v2","1846":"http:\/\/arxiv.org\/abs\/2111.04416v1","1847":"http:\/\/arxiv.org\/abs\/1902.02181v4","1848":"http:\/\/arxiv.org\/abs\/2110.05133v1","1849":"http:\/\/arxiv.org\/abs\/2109.14776v2","1850":"http:\/\/arxiv.org\/abs\/2110.05115v1","1851":"http:\/\/arxiv.org\/abs\/2110.05111v1","1852":"http:\/\/arxiv.org\/abs\/2010.04480v3","1853":"http:\/\/arxiv.org\/abs\/2010.03855v3","1854":"http:\/\/arxiv.org\/abs\/2110.05071v1","1855":"http:\/\/arxiv.org\/abs\/2110.15727v1","1856":"http:\/\/arxiv.org\/abs\/2110.03873v2","1857":"http:\/\/arxiv.org\/abs\/2110.05021v1","1858":"http:\/\/arxiv.org\/abs\/2110.04977v1","1859":"http:\/\/arxiv.org\/abs\/2110.04932v1","1860":"http:\/\/arxiv.org\/abs\/2110.04889v1","1861":"http:\/\/arxiv.org\/abs\/2110.04888v1","1862":"http:\/\/arxiv.org\/abs\/2104.12265v5","1863":"http:\/\/arxiv.org\/abs\/2104.12227v5","1864":"http:\/\/arxiv.org\/abs\/2105.07510v2","1865":"http:\/\/arxiv.org\/abs\/2110.00116v2","1866":"http:\/\/arxiv.org\/abs\/2110.04878v1","1867":"http:\/\/arxiv.org\/abs\/2110.04863v1","1868":"http:\/\/arxiv.org\/abs\/2105.00826v2","1869":"http:\/\/arxiv.org\/abs\/2110.15725v1","1870":"http:\/\/arxiv.org\/abs\/2110.04845v1","1871":"http:\/\/arxiv.org\/abs\/2109.02401v4","1872":"http:\/\/arxiv.org\/abs\/2110.15724v1","1873":"http:\/\/arxiv.org\/abs\/2110.04821v1","1874":"http:\/\/arxiv.org\/abs\/2110.15723v1","1875":"http:\/\/arxiv.org\/abs\/2110.04794v1","1876":"http:\/\/arxiv.org\/abs\/2104.07302v2","1877":"http:\/\/arxiv.org\/abs\/2110.03609v2","1878":"http:\/\/arxiv.org\/abs\/2110.04754v1","1879":"http:\/\/arxiv.org\/abs\/2110.04741v1","1880":"http:\/\/arxiv.org\/abs\/2110.04711v1","1881":"http:\/\/arxiv.org\/abs\/2104.08808v3","1882":"http:\/\/arxiv.org\/abs\/2110.04647v1","1883":"http:\/\/arxiv.org\/abs\/2110.04644v1","1884":"http:\/\/arxiv.org\/abs\/2110.04620v1","1885":"http:\/\/arxiv.org\/abs\/2110.04614v1","1886":"http:\/\/arxiv.org\/abs\/2110.04612v1","1887":"http:\/\/arxiv.org\/abs\/2104.08200v3","1888":"http:\/\/arxiv.org\/abs\/2110.04590v1","1889":"http:\/\/arxiv.org\/abs\/2109.09161v2","1890":"http:\/\/arxiv.org\/abs\/2110.04544v1","1891":"http:\/\/arxiv.org\/abs\/2110.04526v1","1892":"http:\/\/arxiv.org\/abs\/2012.01815v2","1893":"http:\/\/arxiv.org\/abs\/2110.04518v1","1894":"http:\/\/arxiv.org\/abs\/2110.04517v1","1895":"http:\/\/arxiv.org\/abs\/2110.04484v1","1896":"http:\/\/arxiv.org\/abs\/2110.04482v1","1897":"http:\/\/arxiv.org\/abs\/2110.04480v1","1898":"http:\/\/arxiv.org\/abs\/2110.04475v1","1899":"http:\/\/arxiv.org\/abs\/2107.09278v2","1900":"http:\/\/arxiv.org\/abs\/2104.09864v2","1901":"http:\/\/arxiv.org\/abs\/2110.04441v1","1902":"http:\/\/arxiv.org\/abs\/2110.04435v1","1903":"http:\/\/arxiv.org\/abs\/2107.04734v2","1904":"http:\/\/arxiv.org\/abs\/2110.04429v1","1905":"http:\/\/arxiv.org\/abs\/2110.04419v1","1906":"http:\/\/arxiv.org\/abs\/2110.07498v1","1907":"http:\/\/arxiv.org\/abs\/2110.04406v1","1908":"http:\/\/arxiv.org\/abs\/2111.04415v1","1909":"http:\/\/arxiv.org\/abs\/2110.04392v1","1910":"http:\/\/arxiv.org\/abs\/2110.04384v1","1911":"http:\/\/arxiv.org\/abs\/2110.04374v1","1912":"http:\/\/arxiv.org\/abs\/2110.03179v2","1913":"http:\/\/arxiv.org\/abs\/2110.04330v1","1914":"http:\/\/arxiv.org\/abs\/2110.04327v1","1915":"http:\/\/arxiv.org\/abs\/2108.07638v2","1916":"http:\/\/arxiv.org\/abs\/2110.04291v1","1917":"http:\/\/arxiv.org\/abs\/2110.04257v1","1918":"http:\/\/arxiv.org\/abs\/2110.04236v1","1919":"http:\/\/arxiv.org\/abs\/2110.04204v1","1920":"http:\/\/arxiv.org\/abs\/2003.06658v4","1921":"http:\/\/arxiv.org\/abs\/2110.04151v1","1922":"http:\/\/arxiv.org\/abs\/2110.04123v1","1923":"http:\/\/arxiv.org\/abs\/2109.05729v3","1924":"http:\/\/arxiv.org\/abs\/2110.04093v1","1925":"http:\/\/arxiv.org\/abs\/2110.04040v1","1926":"http:\/\/arxiv.org\/abs\/2110.02019v2","1927":"http:\/\/arxiv.org\/abs\/2110.11167v1","1928":"http:\/\/arxiv.org\/abs\/2104.02724v2","1929":"http:\/\/arxiv.org\/abs\/2110.04001v1","1930":"http:\/\/arxiv.org\/abs\/2101.10421v2","1931":"http:\/\/arxiv.org\/abs\/2109.11797v2","1932":"http:\/\/arxiv.org\/abs\/2110.03949v1","1933":"http:\/\/arxiv.org\/abs\/2103.15722v4","1934":"http:\/\/arxiv.org\/abs\/2110.03895v1","1935":"http:\/\/arxiv.org\/abs\/2110.03879v1","1936":"http:\/\/arxiv.org\/abs\/2110.03866v1","1937":"http:\/\/arxiv.org\/abs\/2110.03857v1","1938":"http:\/\/arxiv.org\/abs\/2110.03848v1","1939":"http:\/\/arxiv.org\/abs\/2110.03847v1","1940":"http:\/\/arxiv.org\/abs\/2109.06822v2","1941":"http:\/\/arxiv.org\/abs\/2109.04620v2","1942":"http:\/\/arxiv.org\/abs\/2110.05241v1","1943":"http:\/\/arxiv.org\/abs\/2110.02334v2","1944":"http:\/\/arxiv.org\/abs\/2110.03756v1","1945":"http:\/\/arxiv.org\/abs\/2110.03730v1","1946":"http:\/\/arxiv.org\/abs\/2104.08401v2","1947":"http:\/\/arxiv.org\/abs\/2110.03572v1","1948":"http:\/\/arxiv.org\/abs\/2110.03567v1","1949":"http:\/\/arxiv.org\/abs\/2110.03560v1","1950":"http:\/\/arxiv.org\/abs\/2110.03504v1","1951":"http:\/\/arxiv.org\/abs\/2110.03389v1","1952":"http:\/\/arxiv.org\/abs\/2104.08259v2","1953":"http:\/\/arxiv.org\/abs\/2110.03353v1","1954":"http:\/\/arxiv.org\/abs\/2110.03326v1","1955":"http:\/\/arxiv.org\/abs\/2110.03318v1","1956":"http:\/\/arxiv.org\/abs\/2104.07412v2","1957":"http:\/\/arxiv.org\/abs\/2110.03298v1","1958":"http:\/\/arxiv.org\/abs\/2110.03281v1","1959":"http:\/\/arxiv.org\/abs\/2110.03269v1","1960":"http:\/\/arxiv.org\/abs\/2110.03252v1","1961":"http:\/\/arxiv.org\/abs\/2110.03212v1","1962":"http:\/\/arxiv.org\/abs\/2110.03192v1","1963":"http:\/\/arxiv.org\/abs\/2110.02069v2","1964":"http:\/\/arxiv.org\/abs\/2110.03142v1","1965":"http:\/\/arxiv.org\/abs\/2110.02220v2","1966":"http:\/\/arxiv.org\/abs\/2108.03533v3","1967":"http:\/\/arxiv.org\/abs\/2101.10539v4","1968":"http:\/\/arxiv.org\/abs\/2109.00698v2","1969":"http:\/\/arxiv.org\/abs\/2110.03073v1","1970":"http:\/\/arxiv.org\/abs\/2006.03654v6","1971":"http:\/\/arxiv.org\/abs\/2110.03047v1","1972":"http:\/\/arxiv.org\/abs\/2110.03036v1","1973":"http:\/\/arxiv.org\/abs\/2110.15717v1","1974":"http:\/\/arxiv.org\/abs\/2110.02991v1","1975":"http:\/\/arxiv.org\/abs\/2106.07704v3","1976":"http:\/\/arxiv.org\/abs\/2110.02887v1","1977":"http:\/\/arxiv.org\/abs\/2110.02884v1","1978":"http:\/\/arxiv.org\/abs\/2110.02848v1","1979":"http:\/\/arxiv.org\/abs\/2110.02834v1","1980":"http:\/\/arxiv.org\/abs\/2110.02791v1","1981":"http:\/\/arxiv.org\/abs\/2104.07012v2","1982":"http:\/\/arxiv.org\/abs\/2104.13225v3","1983":"http:\/\/arxiv.org\/abs\/2107.14638v4","1984":"http:\/\/arxiv.org\/abs\/2110.02708v1","1985":"http:\/\/arxiv.org\/abs\/2110.02204v2","1986":"http:\/\/arxiv.org\/abs\/2110.02591v1","1987":"http:\/\/arxiv.org\/abs\/2110.02577v1","1988":"http:\/\/arxiv.org\/abs\/2108.12777v2","1989":"http:\/\/arxiv.org\/abs\/2110.02523v1","1990":"http:\/\/arxiv.org\/abs\/2008.12813v2","1991":"http:\/\/arxiv.org\/abs\/2110.02488v1","1992":"http:\/\/arxiv.org\/abs\/2109.14788v2","1993":"http:\/\/arxiv.org\/abs\/2110.02467v1","1994":"http:\/\/arxiv.org\/abs\/2102.02340v2","1995":"http:\/\/arxiv.org\/abs\/2012.02821v2","1996":"http:\/\/arxiv.org\/abs\/2110.02432v1","1997":"http:\/\/arxiv.org\/abs\/2110.02411v1","1998":"http:\/\/arxiv.org\/abs\/2110.02406v1","1999":"http:\/\/arxiv.org\/abs\/2110.02402v1","2000":"http:\/\/arxiv.org\/abs\/2110.15716v1","2001":"http:\/\/arxiv.org\/abs\/2110.02386v1","2002":"http:\/\/arxiv.org\/abs\/2012.15524v3","2003":"http:\/\/arxiv.org\/abs\/2110.02370v1","2004":"http:\/\/arxiv.org\/abs\/2106.03269v3","2005":"http:\/\/arxiv.org\/abs\/2010.11918v2","2006":"http:\/\/arxiv.org\/abs\/2110.02207v1","2007":"http:\/\/arxiv.org\/abs\/2110.02200v1","2008":"http:\/\/arxiv.org\/abs\/2109.15101v2","2009":"http:\/\/arxiv.org\/abs\/2110.02198v1","2010":"http:\/\/arxiv.org\/abs\/2110.01159v2","2011":"http:\/\/arxiv.org\/abs\/2004.03422v3","2012":"http:\/\/arxiv.org\/abs\/2110.03427v1","2013":"http:\/\/arxiv.org\/abs\/2007.11073v2","2014":"http:\/\/arxiv.org\/abs\/2110.02148v1","2015":"http:\/\/arxiv.org\/abs\/2004.14848v2","2016":"http:\/\/arxiv.org\/abs\/2104.04298v3","2017":"http:\/\/arxiv.org\/abs\/2109.12870v2","2018":"http:\/\/arxiv.org\/abs\/2110.02067v1","2019":"http:\/\/arxiv.org\/abs\/2110.02047v1","2020":"http:\/\/arxiv.org\/abs\/2110.02042v1","2021":"http:\/\/arxiv.org\/abs\/2110.02035v1","2022":"http:\/\/arxiv.org\/abs\/2006.11063v4","2023":"http:\/\/arxiv.org\/abs\/2110.02030v1","2024":"http:\/\/arxiv.org\/abs\/2110.01951v1","2025":"http:\/\/arxiv.org\/abs\/2110.01948v1","2026":"http:\/\/arxiv.org\/abs\/2110.01938v1","2027":"http:\/\/arxiv.org\/abs\/2110.01857v1","2028":"http:\/\/arxiv.org\/abs\/2110.09321v1","2029":"http:\/\/arxiv.org\/abs\/2110.01839v1","2030":"http:\/\/arxiv.org\/abs\/2109.14895v2","2031":"http:\/\/arxiv.org\/abs\/2110.15709v1","2032":"http:\/\/arxiv.org\/abs\/2110.01811v1","2033":"http:\/\/arxiv.org\/abs\/2110.01804v1","2034":"http:\/\/arxiv.org\/abs\/2110.01799v1","2035":"http:\/\/arxiv.org\/abs\/2102.11573v2","2036":"http:\/\/arxiv.org\/abs\/2110.15710v1","2037":"http:\/\/arxiv.org\/abs\/2105.06829v2","2038":"http:\/\/arxiv.org\/abs\/2007.15342v4","2039":"http:\/\/arxiv.org\/abs\/2110.01643v1","2040":"http:\/\/arxiv.org\/abs\/2110.01599v1","2041":"http:\/\/arxiv.org\/abs\/2110.03529v1","2042":"http:\/\/arxiv.org\/abs\/2110.01552v1","2043":"http:\/\/arxiv.org\/abs\/2110.01550v1","2044":"http:\/\/arxiv.org\/abs\/2110.01518v1","2045":"http:\/\/arxiv.org\/abs\/2104.07540v3","2046":"http:\/\/arxiv.org\/abs\/2012.11926v2","2047":"http:\/\/arxiv.org\/abs\/2110.01425v1","2048":"http:\/\/arxiv.org\/abs\/2104.08792v2","2049":"http:\/\/arxiv.org\/abs\/2110.03663v1","2050":"http:\/\/arxiv.org\/abs\/2109.11491v2","2051":"http:\/\/arxiv.org\/abs\/2007.13626v2","2052":"http:\/\/arxiv.org\/abs\/2110.01349v1","2053":"http:\/\/arxiv.org\/abs\/2110.01336v1","2054":"http:\/\/arxiv.org\/abs\/2109.03228v2","2055":"http:\/\/arxiv.org\/abs\/2109.07926v2","2056":"http:\/\/arxiv.org\/abs\/2110.01295v1","2057":"http:\/\/arxiv.org\/abs\/2110.01280v1","2058":"http:\/\/arxiv.org\/abs\/2110.01258v1","2059":"http:\/\/arxiv.org\/abs\/2110.01256v1","2060":"http:\/\/arxiv.org\/abs\/2110.03664v1","2061":"http:\/\/arxiv.org\/abs\/2110.01186v1","2062":"http:\/\/arxiv.org\/abs\/2110.01176v1","2063":"http:\/\/arxiv.org\/abs\/2110.01160v1","2064":"http:\/\/arxiv.org\/abs\/2110.01140v1","2065":"http:\/\/arxiv.org\/abs\/2110.01113v1","2066":"http:\/\/arxiv.org\/abs\/2110.01094v1","2067":"http:\/\/arxiv.org\/abs\/2109.09276v2","2068":"http:\/\/arxiv.org\/abs\/2110.01078v1","2069":"http:\/\/arxiv.org\/abs\/2110.01073v1"},"updated":{"0":1640993308000,"1":1640989601000,"2":1640983220000,"3":1640976226000,"4":1640969431000,"5":1640953658000,"6":1640942139000,"7":1640941256000,"8":1640934899000,"9":1640923428000,"10":1640922813000,"11":1640922175000,"12":1640917453000,"13":1640910948000,"14":1640882788000,"15":1640878912000,"16":1640872138000,"17":1640871025000,"18":1640869628000,"19":1640861036000,"20":1640860564000,"21":1640845967000,"22":1640842782000,"23":1640834696000,"24":1640834160000,"25":1640831249000,"26":1640824230000,"27":1640810043000,"28":1640806241000,"29":1640804524000,"30":1640803175000,"31":1640798965000,"32":1640794099000,"33":1640789684000,"34":1640787762000,"35":1640775444000,"36":1640774280000,"37":1640772652000,"38":1640772610000,"39":1640765191000,"40":1640750222000,"41":1640747024000,"42":1640744705000,"43":1640739287000,"44":1640735160000,"45":1640730472000,"46":1640729649000,"47":1640721808000,"48":1640720660000,"49":1640716944000,"50":1640715511000,"51":1640706388000,"52":1640703258000,"53":1640701176000,"54":1640685404000,"55":1640682376000,"56":1640667146000,"57":1640666914000,"58":1640660201000,"59":1640655382000,"60":1640650486000,"61":1640639963000,"62":1640632627000,"63":1640631078000,"64":1640630863000,"65":1640626264000,"66":1640625334000,"67":1640625177000,"68":1640623411000,"69":1640621550000,"70":1640621465000,"71":1640619935000,"72":1640615486000,"73":1640609106000,"74":1640605312000,"75":1640603338000,"76":1640600371000,"77":1640600203000,"78":1640591509000,"79":1640581390000,"80":1640543885000,"81":1640542004000,"82":1640535325000,"83":1640530554000,"84":1640528692000,"85":1640527944000,"86":1640525777000,"87":1640522470000,"88":1640515592000,"89":1640504613000,"90":1640497851000,"91":1640497076000,"92":1640494585000,"93":1640475688000,"94":1640467182000,"95":1640452453000,"96":1640443209000,"97":1640441201000,"98":1640440989000,"99":1640420468000,"100":1640403702000,"101":1640373550000,"102":1640347055000,"103":1640334918000,"104":1640319934000,"105":1640319657000,"106":1640313764000,"107":1640298906000,"108":1640298800000,"109":1640287219000,"110":1640280948000,"111":1640275879000,"112":1640262465000,"113":1640254730000,"114":1640253865000,"115":1640253218000,"116":1640253087000,"117":1640251073000,"118":1640244302000,"119":1640236308000,"120":1640234406000,"121":1640226430000,"122":1640226396000,"123":1640206670000,"124":1640192097000,"125":1640192046000,"126":1640191154000,"127":1640190594000,"128":1640189973000,"129":1640187870000,"130":1640185403000,"131":1640177825000,"132":1640172908000,"133":1640172329000,"134":1640171749000,"135":1640168960000,"136":1640168744000,"137":1640168014000,"138":1640166791000,"139":1640164443000,"140":1640164080000,"141":1640160331000,"142":1640156794000,"143":1640152884000,"144":1640151296000,"145":1640149481000,"146":1640142825000,"147":1640142387000,"148":1640127289000,"149":1640114916000,"150":1640114841000,"151":1640113202000,"152":1640108946000,"153":1640108834000,"154":1640108106000,"155":1640103202000,"156":1640099097000,"157":1640097488000,"158":1640095986000,"159":1640092584000,"160":1640081275000,"161":1640077407000,"162":1640074227000,"163":1640064241000,"164":1640059162000,"165":1640053411000,"166":1640051824000,"167":1640048722000,"168":1640048648000,"169":1640043670000,"170":1640026421000,"171":1640019911000,"172":1640019155000,"173":1640016527000,"174":1640016362000,"175":1640011561000,"176":1640010400000,"177":1640009318000,"178":1640005458000,"179":1640001717000,"180":1639993712000,"181":1639983268000,"182":1639971148000,"183":1639935075000,"184":1639932297000,"185":1639913429000,"186":1639909757000,"187":1639894267000,"188":1639890541000,"189":1639878357000,"190":1639873495000,"191":1639868301000,"192":1639855653000,"193":1639836474000,"194":1639833618000,"195":1639833334000,"196":1639831597000,"197":1639813237000,"198":1639810716000,"199":1639804226000,"200":1639801727000,"201":1639801579000,"202":1639772868000,"203":1639771952000,"204":1639771254000,"205":1639765796000,"206":1639765606000,"207":1639764194000,"208":1639762867000,"209":1639760380000,"210":1639759860000,"211":1639758109000,"212":1639755243000,"213":1639754411000,"214":1639751023000,"215":1639745942000,"216":1639742941000,"217":1639741541000,"218":1639740903000,"219":1639734221000,"220":1639730883000,"221":1639723758000,"222":1639723334000,"223":1639721977000,"224":1639716655000,"225":1639711734000,"226":1639710927000,"227":1639708378000,"228":1639694177000,"229":1639693242000,"230":1639691248000,"231":1639690825000,"232":1639686693000,"233":1639684590000,"234":1639684562000,"235":1639681255000,"236":1639681057000,"237":1639681038000,"238":1639679362000,"239":1639679347000,"240":1639678577000,"241":1639677579000,"242":1639676840000,"243":1639674346000,"244":1639665461000,"245":1639664796000,"246":1639664675000,"247":1639660061000,"248":1639659444000,"249":1639659112000,"250":1639655078000,"251":1639654836000,"252":1639653478000,"253":1639651505000,"254":1639650862000,"255":1639648595000,"256":1639647664000,"257":1639646574000,"258":1639646478000,"259":1639645720000,"260":1639643646000,"261":1639643306000,"262":1639642727000,"263":1639638602000,"264":1639637311000,"265":1639635946000,"266":1639635277000,"267":1639634802000,"268":1639632889000,"269":1639632084000,"270":1639632015000,"271":1639629733000,"272":1639628199000,"273":1639628078000,"274":1639626241000,"275":1639626228000,"276":1639625654000,"277":1639625371000,"278":1639624861000,"279":1639624590000,"280":1639624384000,"281":1639622443000,"282":1639621259000,"283":1639619190000,"284":1639619133000,"285":1639618341000,"286":1639617577000,"287":1639617068000,"288":1639616991000,"289":1639616163000,"290":1639614726000,"291":1639612922000,"292":1639612581000,"293":1639604156000,"294":1639602172000,"295":1639601526000,"296":1639601443000,"297":1639600497000,"298":1639599680000,"299":1639595191000,"300":1639594969000,"301":1639594797000,"302":1639594578000,"303":1639594474000,"304":1639594214000,"305":1639593468000,"306":1639593051000,"307":1639592412000,"308":1639591854000,"309":1639589730000,"310":1639587611000,"311":1639586759000,"312":1639586755000,"313":1639586213000,"314":1639584572000,"315":1639583349000,"316":1639582412000,"317":1639581113000,"318":1639580850000,"319":1639578692000,"320":1639578086000,"321":1639577568000,"322":1639574098000,"323":1639573709000,"324":1639573432000,"325":1639572484000,"326":1639566605000,"327":1639565676000,"328":1639560092000,"329":1639554976000,"330":1639553936000,"331":1639552262000,"332":1639547713000,"333":1639546407000,"334":1639544778000,"335":1639544712000,"336":1639543993000,"337":1639543095000,"338":1639542542000,"339":1639542453000,"340":1639542194000,"341":1639542035000,"342":1639523181000,"343":1639523085000,"344":1639521628000,"345":1639521597000,"346":1639517619000,"347":1639515335000,"348":1639509823000,"349":1639509488000,"350":1639509334000,"351":1639507767000,"352":1639507766000,"353":1639506902000,"354":1639506765000,"355":1639501659000,"356":1639500587000,"357":1639500321000,"358":1639498964000,"359":1639497651000,"360":1639494296000,"361":1639493984000,"362":1639493243000,"363":1639488229000,"364":1639488071000,"365":1639486137000,"366":1639486099000,"367":1639484784000,"368":1639481236000,"369":1639475273000,"370":1639474711000,"371":1639466049000,"372":1639462773000,"373":1639461858000,"374":1639457799000,"375":1639455940000,"376":1639453307000,"377":1639446799000,"378":1639444623000,"379":1639444460000,"380":1639444284000,"381":1639440516000,"382":1639435186000,"383":1639431981000,"384":1639429684000,"385":1639422017000,"386":1639421899000,"387":1639421142000,"388":1639419004000,"389":1639417756000,"390":1639413181000,"391":1639411052000,"392":1639410576000,"393":1639410054000,"394":1639409467000,"395":1639408146000,"396":1639407969000,"397":1639400226000,"398":1639399193000,"399":1639391709000,"400":1639391094000,"401":1639389387000,"402":1639388321000,"403":1639388031000,"404":1639384085000,"405":1639383261000,"406":1639380962000,"407":1639379081000,"408":1639378462000,"409":1639378114000,"410":1639369040000,"411":1639368133000,"412":1639359517000,"413":1639350172000,"414":1639346287000,"415":1639344452000,"416":1639339031000,"417":1639338994000,"418":1639334307000,"419":1639317018000,"420":1639307439000,"421":1639306201000,"422":1639304205000,"423":1639290315000,"424":1639278963000,"425":1639272629000,"426":1639268217000,"427":1639255815000,"428":1639252124000,"429":1639242414000,"430":1639238489000,"431":1639234908000,"432":1639228296000,"433":1639217416000,"434":1639193798000,"435":1639182432000,"436":1639180754000,"437":1639173496000,"438":1639173260000,"439":1639172058000,"440":1639169278000,"441":1639166504000,"442":1639166486000,"443":1639166021000,"444":1639165763000,"445":1639160144000,"446":1639159053000,"447":1639158697000,"448":1639156854000,"449":1639153404000,"450":1639150003000,"451":1639145332000,"452":1639135106000,"453":1639134584000,"454":1639132747000,"455":1639129876000,"456":1639120509000,"457":1639119485000,"458":1639119187000,"459":1639115688000,"460":1639094560000,"461":1639094325000,"462":1639093423000,"463":1639091980000,"464":1639088320000,"465":1639086022000,"466":1639082941000,"467":1639081568000,"468":1639080461000,"469":1639079842000,"470":1639076374000,"471":1639076249000,"472":1639071198000,"473":1639064775000,"474":1639062378000,"475":1639058096000,"476":1639056556000,"477":1639056086000,"478":1639055802000,"479":1639054141000,"480":1639053933000,"481":1639048271000,"482":1639047438000,"483":1639046960000,"484":1639045576000,"485":1639044671000,"486":1639043420000,"487":1639043131000,"488":1639043022000,"489":1639042085000,"490":1639033044000,"491":1639032500000,"492":1639031817000,"493":1639026566000,"494":1639017463000,"495":1639014933000,"496":1639009229000,"497":1639004672000,"498":1639001243000,"499":1638996084000,"500":1638992067000,"501":1638989896000,"502":1638987979000,"503":1638987297000,"504":1638979788000,"505":1638978687000,"506":1638973402000,"507":1638972776000,"508":1638960457000,"509":1638957853000,"510":1638955581000,"511":1638955195000,"512":1638954963000,"513":1638950043000,"514":1638949418000,"515":1638945298000,"516":1638944521000,"517":1638942491000,"518":1638936770000,"519":1638931156000,"520":1638927136000,"521":1638917398000,"522":1638913243000,"523":1638910580000,"524":1638903373000,"525":1638900095000,"526":1638899374000,"527":1638899270000,"528":1638898761000,"529":1638894750000,"530":1638893784000,"531":1638893761000,"532":1638888447000,"533":1638876608000,"534":1638875719000,"535":1638874027000,"536":1638872572000,"537":1638869459000,"538":1638867969000,"539":1638867220000,"540":1638866088000,"541":1638864761000,"542":1638861804000,"543":1638860302000,"544":1638858678000,"545":1638858143000,"546":1638849345000,"547":1638848702000,"548":1638832748000,"549":1638817167000,"550":1638815163000,"551":1638815009000,"552":1638814605000,"553":1638814426000,"554":1638810237000,"555":1638809510000,"556":1638808886000,"557":1638806327000,"558":1638803397000,"559":1638800648000,"560":1638798848000,"561":1638796630000,"562":1638793858000,"563":1638785531000,"564":1638782844000,"565":1638777375000,"566":1638773531000,"567":1638762716000,"568":1638758766000,"569":1638757400000,"570":1638757139000,"571":1638751079000,"572":1638748553000,"573":1638745993000,"574":1638744894000,"575":1638740511000,"576":1638729632000,"577":1638721041000,"578":1638720316000,"579":1638702300000,"580":1638694132000,"581":1638691989000,"582":1638671670000,"583":1638670501000,"584":1638650726000,"585":1638646294000,"586":1638642864000,"587":1638638866000,"588":1638623892000,"589":1638600919000,"590":1638594809000,"591":1638581588000,"592":1638572194000,"593":1638561971000,"594":1638556832000,"595":1638556002000,"596":1638551044000,"597":1638547362000,"598":1638546840000,"599":1638544116000,"600":1638543805000,"601":1638542344000,"602":1638540721000,"603":1638538518000,"604":1638537717000,"605":1638537607000,"606":1638537317000,"607":1638532972000,"608":1638531351000,"609":1638528559000,"610":1638526922000,"611":1638524718000,"612":1638522406000,"613":1638521593000,"614":1638517462000,"615":1638517365000,"616":1638516433000,"617":1638515714000,"618":1638513836000,"619":1638507707000,"620":1638506088000,"621":1638505609000,"622":1638502998000,"623":1638495208000,"624":1638492977000,"625":1638481649000,"626":1638476177000,"627":1638474957000,"628":1638473247000,"629":1638467061000,"630":1638463781000,"631":1638461373000,"632":1638459737000,"633":1638459652000,"634":1638449842000,"635":1638442920000,"636":1638439555000,"637":1638438845000,"638":1638437085000,"639":1638436981000,"640":1638436089000,"641":1638435463000,"642":1638434442000,"643":1638433766000,"644":1638433223000,"645":1638433182000,"646":1638432993000,"647":1638432179000,"648":1638429994000,"649":1638428084000,"650":1638418774000,"651":1638417369000,"652":1638416925000,"653":1638416710000,"654":1638404961000,"655":1638400685000,"656":1638392730000,"657":1638392255000,"658":1638392011000,"659":1638391144000,"660":1638387663000,"661":1638386645000,"662":1638374506000,"663":1638373845000,"664":1638373621000,"665":1638372973000,"666":1638372879000,"667":1638369943000,"668":1638366244000,"669":1638364383000,"670":1638363905000,"671":1638360657000,"672":1638355502000,"673":1638353304000,"674":1638349059000,"675":1638336067000,"676":1638335627000,"677":1638333903000,"678":1638327889000,"679":1638327561000,"680":1638322468000,"681":1638313505000,"682":1638312479000,"683":1638309750000,"684":1638304616000,"685":1638303969000,"686":1638303510000,"687":1638302937000,"688":1638299706000,"689":1638296732000,"690":1638296466000,"691":1638296046000,"692":1638291326000,"693":1638287524000,"694":1638285904000,"695":1638284188000,"696":1638282573000,"697":1638281672000,"698":1638281422000,"699":1638281215000,"700":1638276064000,"701":1638274043000,"702":1638271363000,"703":1638269621000,"704":1638268595000,"705":1638268337000,"706":1638265719000,"707":1638255073000,"708":1638253738000,"709":1638251870000,"710":1638247419000,"711":1638243519000,"712":1638242364000,"713":1638236879000,"714":1638227694000,"715":1638223883000,"716":1638223326000,"717":1638222094000,"718":1638210951000,"719":1638207278000,"720":1638206451000,"721":1638204389000,"722":1638200550000,"723":1638199163000,"724":1638198816000,"725":1638197696000,"726":1638188642000,"727":1638183744000,"728":1638183495000,"729":1638179820000,"730":1638170441000,"731":1638170105000,"732":1638154542000,"733":1638131167000,"734":1638128003000,"735":1638112385000,"736":1638107871000,"737":1638102648000,"738":1638100082000,"739":1638096987000,"740":1638094631000,"741":1638094157000,"742":1638090154000,"743":1638089918000,"744":1638087948000,"745":1638084596000,"746":1638083891000,"747":1638069097000,"748":1638068886000,"749":1638063141000,"750":1638055189000,"751":1638052926000,"752":1638051170000,"753":1638046073000,"754":1638043399000,"755":1638041174000,"756":1638040649000,"757":1638034198000,"758":1638027691000,"759":1638020920000,"760":1638008549000,"761":1637999045000,"762":1637996056000,"763":1637974074000,"764":1637954571000,"765":1637951639000,"766":1637947974000,"767":1637947098000,"768":1637939642000,"769":1637934492000,"770":1637929903000,"771":1637929394000,"772":1637927347000,"773":1637913491000,"774":1637909687000,"775":1637909440000,"776":1637890448000,"777":1637888077000,"778":1637876658000,"779":1637863806000,"780":1637863421000,"781":1637858244000,"782":1637855390000,"783":1637846181000,"784":1637836030000,"785":1637835545000,"786":1637831081000,"787":1637826045000,"788":1637821919000,"789":1637819698000,"790":1637814863000,"791":1637814680000,"792":1637812396000,"793":1637811511000,"794":1637789023000,"795":1637787685000,"796":1637786652000,"797":1637783626000,"798":1637776307000,"799":1637776172000,"800":1637767141000,"801":1637766380000,"802":1637759465000,"803":1637753240000,"804":1637752308000,"805":1637752139000,"806":1637746783000,"807":1637745644000,"808":1637745188000,"809":1637740727000,"810":1637740257000,"811":1637733396000,"812":1637724089000,"813":1637706076000,"814":1637691734000,"815":1637691672000,"816":1637691334000,"817":1637688900000,"818":1637688192000,"819":1637687106000,"820":1637683348000,"821":1637683102000,"822":1637676831000,"823":1637673391000,"824":1637671996000,"825":1637669355000,"826":1637663038000,"827":1637654571000,"828":1637647956000,"829":1637647090000,"830":1637629977000,"831":1637623852000,"832":1637623539000,"833":1637614133000,"834":1637613521000,"835":1637608312000,"836":1637607574000,"837":1637602160000,"838":1637601681000,"839":1637599170000,"840":1637589204000,"841":1637586641000,"842":1637585736000,"843":1637581310000,"844":1637578955000,"845":1637578239000,"846":1637566420000,"847":1637566037000,"848":1637565552000,"849":1637558817000,"850":1637556035000,"851":1637553072000,"852":1637552812000,"853":1637549764000,"854":1637549123000,"855":1637525504000,"856":1637509995000,"857":1637500763000,"858":1637493710000,"859":1637481203000,"860":1637479364000,"861":1637474712000,"862":1637473712000,"863":1637447303000,"864":1637445149000,"865":1637420627000,"866":1637414753000,"867":1637414038000,"868":1637391706000,"869":1637380597000,"870":1637376335000,"871":1637374932000,"872":1637366456000,"873":1637348602000,"874":1637341135000,"875":1637332978000,"876":1637330246000,"877":1637329115000,"878":1637323816000,"879":1637323471000,"880":1637323433000,"881":1637322239000,"882":1637320417000,"883":1637318063000,"884":1637311858000,"885":1637311848000,"886":1637311652000,"887":1637308479000,"888":1637306528000,"889":1637303769000,"890":1637303319000,"891":1637301519000,"892":1637298556000,"893":1637297678000,"894":1637297565000,"895":1637264865000,"896":1637262151000,"897":1637260755000,"898":1637258616000,"899":1637256452000,"900":1637254076000,"901":1637245474000,"902":1637244081000,"903":1637243341000,"904":1637243171000,"905":1637240047000,"906":1637236793000,"907":1637236699000,"908":1637234688000,"909":1637232768000,"910":1637231941000,"911":1637223909000,"912":1637222413000,"913":1637222218000,"914":1637221649000,"915":1637217853000,"916":1637211751000,"917":1637208429000,"918":1637200663000,"919":1637199965000,"920":1637195025000,"921":1637181076000,"922":1637180051000,"923":1637179124000,"924":1637174041000,"925":1637173834000,"926":1637173204000,"927":1637172838000,"928":1637170500000,"929":1637166295000,"930":1637165113000,"931":1637162051000,"932":1637160651000,"933":1637159515000,"934":1637152422000,"935":1637151003000,"936":1637149603000,"937":1637147199000,"938":1637137480000,"939":1637132999000,"940":1637125251000,"941":1637121090000,"942":1637105636000,"943":1637103388000,"944":1637089203000,"945":1637084664000,"946":1637083451000,"947":1637082856000,"948":1637080987000,"949":1637078389000,"950":1637075881000,"951":1637075758000,"952":1637075557000,"953":1637074685000,"954":1637073069000,"955":1637071928000,"956":1637069966000,"957":1637065247000,"958":1637064853000,"959":1637063740000,"960":1637063727000,"961":1637051106000,"962":1637049232000,"963":1637048065000,"964":1637032480000,"965":1637031629000,"966":1637029069000,"967":1637027126000,"968":1637025403000,"969":1637017884000,"970":1637017639000,"971":1637011518000,"972":1637002498000,"973":1637002300000,"974":1637000804000,"975":1636997801000,"976":1636995479000,"977":1636994656000,"978":1636992435000,"979":1636988289000,"980":1636986501000,"981":1636979275000,"982":1636978635000,"983":1636978148000,"984":1636976229000,"985":1636974035000,"986":1636968017000,"987":1636966930000,"988":1636966612000,"989":1636964006000,"990":1636963284000,"991":1636960034000,"992":1636955909000,"993":1636952308000,"994":1636948610000,"995":1636940326000,"996":1636925178000,"997":1636923484000,"998":1636915266000,"999":1636914559000,"1000":1636910889000,"1001":1636907445000,"1002":1636903889000,"1003":1636902660000,"1004":1636894529000,"1005":1636889269000,"1006":1636879723000,"1007":1636871821000,"1008":1636866098000,"1009":1636858927000,"1010":1636853437000,"1011":1636840098000,"1012":1636835911000,"1013":1636833255000,"1014":1636821435000,"1015":1636813727000,"1016":1636812397000,"1017":1636808177000,"1018":1636786767000,"1019":1636782527000,"1020":1636767850000,"1021":1636766640000,"1022":1636756307000,"1023":1636743666000,"1024":1636734212000,"1025":1636732839000,"1026":1636724940000,"1027":1636715926000,"1028":1636713030000,"1029":1636712623000,"1030":1636709895000,"1031":1636705101000,"1032":1636699444000,"1033":1636698551000,"1034":1636680547000,"1035":1636678662000,"1036":1636665321000,"1037":1636665030000,"1038":1636653457000,"1039":1636652911000,"1040":1636652883000,"1041":1636652690000,"1042":1636649873000,"1043":1636640775000,"1044":1636638921000,"1045":1636635601000,"1046":1636634864000,"1047":1636626753000,"1048":1636620697000,"1049":1636616356000,"1050":1636612542000,"1051":1636606858000,"1052":1636601701000,"1053":1636595461000,"1054":1636588370000,"1055":1636587443000,"1056":1636577768000,"1057":1636577489000,"1058":1636571703000,"1059":1636565950000,"1060":1636563636000,"1061":1636563230000,"1062":1636560736000,"1063":1636559560000,"1064":1636551374000,"1065":1636547598000,"1066":1636543228000,"1067":1636538711000,"1068":1636538041000,"1069":1636537738000,"1070":1636531661000,"1071":1636529516000,"1072":1636520160000,"1073":1636511288000,"1074":1636508451000,"1075":1636491205000,"1076":1636490598000,"1077":1636489950000,"1078":1636480816000,"1079":1636475280000,"1080":1636475211000,"1081":1636471783000,"1082":1636471034000,"1083":1636466931000,"1084":1636465523000,"1085":1636464634000,"1086":1636453681000,"1087":1636451125000,"1088":1636449021000,"1089":1636443911000,"1090":1636442257000,"1091":1636432939000,"1092":1636432220000,"1093":1636428678000,"1094":1636427007000,"1095":1636417922000,"1096":1636412155000,"1097":1636407018000,"1098":1636406602000,"1099":1636406204000,"1100":1636404830000,"1101":1636400633000,"1102":1636396412000,"1103":1636390821000,"1104":1636385781000,"1105":1636383666000,"1106":1636381461000,"1107":1636380402000,"1108":1636380189000,"1109":1636379355000,"1110":1636370961000,"1111":1636364146000,"1112":1636360304000,"1113":1636359505000,"1114":1636346178000,"1115":1636343649000,"1116":1636343264000,"1117":1636328772000,"1118":1636328119000,"1119":1636324301000,"1120":1636323472000,"1121":1636313511000,"1122":1636308096000,"1123":1636305239000,"1124":1636297614000,"1125":1636295700000,"1126":1636291139000,"1127":1636284248000,"1128":1636280994000,"1129":1636278811000,"1130":1636262627000,"1131":1636232030000,"1132":1636231720000,"1133":1636228743000,"1134":1636217148000,"1135":1636213269000,"1136":1636205309000,"1137":1636189456000,"1138":1636179946000,"1139":1636172753000,"1140":1636148235000,"1141":1636142818000,"1142":1636135117000,"1143":1636134614000,"1144":1636132757000,"1145":1636131428000,"1146":1636130066000,"1147":1636128360000,"1148":1636126343000,"1149":1636124950000,"1150":1636120859000,"1151":1636119116000,"1152":1636109421000,"1153":1636108285000,"1154":1636105123000,"1155":1636105001000,"1156":1636104561000,"1157":1636097591000,"1158":1636096936000,"1159":1636096068000,"1160":1636093582000,"1161":1636085675000,"1162":1636081877000,"1163":1636079971000,"1164":1636077602000,"1165":1636076461000,"1166":1636076267000,"1167":1636073760000,"1168":1636062692000,"1169":1636054728000,"1170":1636054728000,"1171":1636052894000,"1172":1636052133000,"1173":1636045962000,"1174":1636044839000,"1175":1636035147000,"1176":1636034866000,"1177":1636032951000,"1178":1636031350000,"1179":1636030084000,"1180":1636029858000,"1181":1636024854000,"1182":1636018156000,"1183":1636015471000,"1184":1636012620000,"1185":1636009026000,"1186":1636007901000,"1187":1636003275000,"1188":1636000742000,"1189":1635995992000,"1190":1635988094000,"1191":1635986595000,"1192":1635975880000,"1193":1635972860000,"1194":1635970591000,"1195":1635963660000,"1196":1635960412000,"1197":1635960036000,"1198":1635959357000,"1199":1635956416000,"1200":1635949764000,"1201":1635947878000,"1202":1635946607000,"1203":1635944597000,"1204":1635942243000,"1205":1635939821000,"1206":1635935792000,"1207":1635934599000,"1208":1635933858000,"1209":1635930977000,"1210":1635922820000,"1211":1635920701000,"1212":1635914213000,"1213":1635911701000,"1214":1635910274000,"1215":1635908599000,"1216":1635903987000,"1217":1635884589000,"1218":1635872609000,"1219":1635869840000,"1220":1635867399000,"1221":1635859040000,"1222":1635855904000,"1223":1635853374000,"1224":1635848057000,"1225":1635847726000,"1226":1635840475000,"1227":1635837363000,"1228":1635827275000,"1229":1635826956000,"1230":1635821925000,"1231":1635818117000,"1232":1635817809000,"1233":1635813561000,"1234":1635801955000,"1235":1635797285000,"1236":1635796997000,"1237":1635795728000,"1238":1635793286000,"1239":1635793130000,"1240":1635792276000,"1241":1635792127000,"1242":1635791927000,"1243":1635785407000,"1244":1635780863000,"1245":1635780615000,"1246":1635780447000,"1247":1635778291000,"1248":1635777770000,"1249":1635777655000,"1250":1635777426000,"1251":1635777314000,"1252":1635769265000,"1253":1635764521000,"1254":1635762118000,"1255":1635757523000,"1256":1635757451000,"1257":1635756008000,"1258":1635755850000,"1259":1635755361000,"1260":1635751029000,"1261":1635750526000,"1262":1635742311000,"1263":1635737376000,"1264":1635735053000,"1265":1635732431000,"1266":1635720633000,"1267":1635720510000,"1268":1635711021000,"1269":1635707549000,"1270":1635706867000,"1271":1635704675000,"1272":1635703069000,"1273":1635702672000,"1274":1635698136000,"1275":1635693007000,"1276":1635685759000,"1277":1635664414000,"1278":1635653167000,"1279":1635652219000,"1280":1635633301000,"1281":1635631342000,"1282":1635620688000,"1283":1635620410000,"1284":1635618862000,"1285":1635618732000,"1286":1635612099000,"1287":1635608462000,"1288":1635600267000,"1289":1635592063000,"1290":1635578605000,"1291":1635577884000,"1292":1635576828000,"1293":1635576821000,"1294":1635572838000,"1295":1635571985000,"1296":1635564587000,"1297":1635532129000,"1298":1635530344000,"1299":1635528454000,"1300":1635526310000,"1301":1635523151000,"1302":1635520720000,"1303":1635520366000,"1304":1635517310000,"1305":1635516341000,"1306":1635515138000,"1307":1635513965000,"1308":1635507883000,"1309":1635505679000,"1310":1635501763000,"1311":1635496666000,"1312":1635496607000,"1313":1635495373000,"1314":1635494329000,"1315":1635491735000,"1316":1635484831000,"1317":1635484517000,"1318":1635482191000,"1319":1635480092000,"1320":1635459279000,"1321":1635453542000,"1322":1635452375000,"1323":1635451101000,"1324":1635449863000,"1325":1635443846000,"1326":1635442986000,"1327":1635435944000,"1328":1635433858000,"1329":1635433071000,"1330":1635430843000,"1331":1635430242000,"1332":1635430184000,"1333":1635429921000,"1334":1635429843000,"1335":1635423453000,"1336":1635419754000,"1337":1635412115000,"1338":1635411417000,"1339":1635409947000,"1340":1635398247000,"1341":1635396355000,"1342":1635391728000,"1343":1635386042000,"1344":1635384941000,"1345":1635384471000,"1346":1635379880000,"1347":1635371631000,"1348":1635370626000,"1349":1635369344000,"1350":1635368401000,"1351":1635368258000,"1352":1635362959000,"1353":1635359640000,"1354":1635359011000,"1355":1635352633000,"1356":1635350889000,"1357":1635350154000,"1358":1635339139000,"1359":1635333361000,"1360":1635324702000,"1361":1635324016000,"1362":1635321002000,"1363":1635315931000,"1364":1635313704000,"1365":1635312745000,"1366":1635310931000,"1367":1635300159000,"1368":1635293367000,"1369":1635293073000,"1370":1635282527000,"1371":1635276820000,"1372":1635276026000,"1373":1635269958000,"1374":1635269720000,"1375":1635269442000,"1376":1635266458000,"1377":1635266250000,"1378":1635264589000,"1379":1635263756000,"1380":1635263263000,"1381":1635260356000,"1382":1635259150000,"1383":1635257805000,"1384":1635256726000,"1385":1635254933000,"1386":1635254908000,"1387":1635254368000,"1388":1635252334000,"1389":1635251109000,"1390":1635249840000,"1391":1635247224000,"1392":1635243349000,"1393":1635243070000,"1394":1635240016000,"1395":1635238844000,"1396":1635238073000,"1397":1635236600000,"1398":1635236211000,"1399":1635235835000,"1400":1635232135000,"1401":1635231468000,"1402":1635229561000,"1403":1635228913000,"1404":1635222762000,"1405":1635221025000,"1406":1635217781000,"1407":1635216510000,"1408":1635210893000,"1409":1635204236000,"1410":1635203000000,"1411":1635192259000,"1412":1635190418000,"1413":1635187901000,"1414":1635179758000,"1415":1635177570000,"1416":1635173622000,"1417":1635169068000,"1418":1635169043000,"1419":1635160357000,"1420":1635156321000,"1421":1635156123000,"1422":1635155643000,"1423":1635155206000,"1424":1635155186000,"1425":1635145862000,"1426":1635144791000,"1427":1635143081000,"1428":1635138901000,"1429":1635138730000,"1430":1635136983000,"1431":1635136650000,"1432":1635130815000,"1433":1635129687000,"1434":1635124238000,"1435":1635123297000,"1436":1635117954000,"1437":1635117929000,"1438":1635097760000,"1439":1635094237000,"1440":1635074789000,"1441":1635073968000,"1442":1635062501000,"1443":1635061614000,"1444":1635060519000,"1445":1635059439000,"1446":1635057910000,"1447":1635048832000,"1448":1635045990000,"1449":1635045484000,"1450":1635043383000,"1451":1635034906000,"1452":1635024849000,"1453":1635024418000,"1454":1635002565000,"1455":1634994608000,"1456":1634990811000,"1457":1634989321000,"1458":1634970312000,"1459":1634959527000,"1460":1634941902000,"1461":1634940243000,"1462":1634939476000,"1463":1634928454000,"1464":1634924883000,"1465":1634923997000,"1466":1634923325000,"1467":1634920437000,"1468":1634918836000,"1469":1634916745000,"1470":1634911408000,"1471":1634910241000,"1472":1634898788000,"1473":1634898077000,"1474":1634893288000,"1475":1634892406000,"1476":1634891462000,"1477":1634881489000,"1478":1634879080000,"1479":1634870607000,"1480":1634865331000,"1481":1634858666000,"1482":1634857984000,"1483":1634854589000,"1484":1634840008000,"1485":1634839165000,"1486":1634838116000,"1487":1634831384000,"1488":1634830350000,"1489":1634829298000,"1490":1634827576000,"1491":1634825879000,"1492":1634821461000,"1493":1634819569000,"1494":1634805371000,"1495":1634804509000,"1496":1634796312000,"1497":1634787466000,"1498":1634786518000,"1499":1634779624000,"1500":1634779108000,"1501":1634775362000,"1502":1634773355000,"1503":1634772285000,"1504":1634763902000,"1505":1634763465000,"1506":1634762231000,"1507":1634758831000,"1508":1634752561000,"1509":1634750469000,"1510":1634738894000,"1511":1634738653000,"1512":1634735583000,"1513":1634729169000,"1514":1634728544000,"1515":1634727316000,"1516":1634726337000,"1517":1634725109000,"1518":1634724497000,"1519":1634720282000,"1520":1634719330000,"1521":1634719164000,"1522":1634715563000,"1523":1634711586000,"1524":1634705574000,"1525":1634702134000,"1526":1634696453000,"1527":1634694763000,"1528":1634691576000,"1529":1634691459000,"1530":1634688637000,"1531":1634688386000,"1532":1634672238000,"1533":1634671418000,"1534":1634670634000,"1535":1634667181000,"1536":1634666827000,"1537":1634663640000,"1538":1634661834000,"1539":1634658268000,"1540":1634654129000,"1541":1634649922000,"1542":1634646400000,"1543":1634644376000,"1544":1634639680000,"1545":1634639541000,"1546":1634629940000,"1547":1634629914000,"1548":1634623842000,"1549":1634623284000,"1550":1634621534000,"1551":1634619327000,"1552":1634615924000,"1553":1634613926000,"1554":1634612040000,"1555":1634612006000,"1556":1634610910000,"1557":1634602519000,"1558":1634597481000,"1559":1634592551000,"1560":1634583853000,"1561":1634583323000,"1562":1634582780000,"1563":1634582446000,"1564":1634581390000,"1565":1634579156000,"1566":1634578541000,"1567":1634575531000,"1568":1634572395000,"1569":1634572205000,"1570":1634570672000,"1571":1634570185000,"1572":1634564908000,"1573":1634558777000,"1574":1634556612000,"1575":1634554250000,"1576":1634553368000,"1577":1634551399000,"1578":1634547151000,"1579":1634546477000,"1580":1634545850000,"1581":1634544192000,"1582":1634543666000,"1583":1634541364000,"1584":1634537711000,"1585":1634535926000,"1586":1634528946000,"1587":1634507678000,"1588":1634497383000,"1589":1634495123000,"1590":1634492213000,"1591":1634492109000,"1592":1634483794000,"1593":1634483131000,"1594":1634455663000,"1595":1634454718000,"1596":1634427804000,"1597":1634409634000,"1598":1634401363000,"1599":1634394865000,"1600":1634389882000,"1601":1634385588000,"1602":1634384663000,"1603":1634383382000,"1604":1634381332000,"1605":1634379148000,"1606":1634378654000,"1607":1634378373000,"1608":1634377783000,"1609":1634375892000,"1610":1634375494000,"1611":1634374132000,"1612":1634356313000,"1613":1634355428000,"1614":1634354876000,"1615":1634351272000,"1616":1634350216000,"1617":1634346047000,"1618":1634345408000,"1619":1634343702000,"1620":1634343604000,"1621":1634342599000,"1622":1634342382000,"1623":1634336751000,"1624":1634335479000,"1625":1634334399000,"1626":1634334076000,"1627":1634333158000,"1628":1634330249000,"1629":1634329707000,"1630":1634325625000,"1631":1634325043000,"1632":1634323161000,"1633":1634322949000,"1634":1634322618000,"1635":1634320726000,"1636":1634320725000,"1637":1634320362000,"1638":1634319496000,"1639":1634319370000,"1640":1634318282000,"1641":1634315297000,"1642":1634313820000,"1643":1634311719000,"1644":1634308605000,"1645":1634300143000,"1646":1634299744000,"1647":1634299007000,"1648":1634297537000,"1649":1634297424000,"1650":1634296768000,"1651":1634296517000,"1652":1634296426000,"1653":1634293752000,"1654":1634292634000,"1655":1634287389000,"1656":1634286973000,"1657":1634285936000,"1658":1634284820000,"1659":1634284227000,"1660":1634283346000,"1661":1634279833000,"1662":1634276639000,"1663":1634271446000,"1664":1634270495000,"1665":1634270142000,"1666":1634268465000,"1667":1634268150000,"1668":1634267639000,"1669":1634267366000,"1670":1634266989000,"1671":1634266675000,"1672":1634266209000,"1673":1634265822000,"1674":1634265108000,"1675":1634264615000,"1676":1634263006000,"1677":1634260250000,"1678":1634249384000,"1679":1634249339000,"1680":1634247603000,"1681":1634244433000,"1682":1634243350000,"1683":1634242872000,"1684":1634241816000,"1685":1634241281000,"1686":1634241167000,"1687":1634239087000,"1688":1634238694000,"1689":1634234591000,"1690":1634234195000,"1691":1634233506000,"1692":1634233100000,"1693":1634233092000,"1694":1634233024000,"1695":1634232923000,"1696":1634232449000,"1697":1634232130000,"1698":1634229775000,"1699":1634229372000,"1700":1634227245000,"1701":1634226588000,"1702":1634225604000,"1703":1634224325000,"1704":1634223533000,"1705":1634223022000,"1706":1634222558000,"1707":1634220772000,"1708":1634220672000,"1709":1634220085000,"1710":1634219575000,"1711":1634216706000,"1712":1634216678000,"1713":1634214321000,"1714":1634214004000,"1715":1634213920000,"1716":1634213662000,"1717":1634213551000,"1718":1634211694000,"1719":1634210888000,"1720":1634203337000,"1721":1634202094000,"1722":1634202020000,"1723":1634199366000,"1724":1634199304000,"1725":1634198454000,"1726":1634194219000,"1727":1634192839000,"1728":1634191374000,"1729":1634190152000,"1730":1634189199000,"1731":1634186189000,"1732":1634184325000,"1733":1634183656000,"1734":1634183423000,"1735":1634181996000,"1736":1634163071000,"1737":1634158800000,"1738":1634158586000,"1739":1634158477000,"1740":1634157324000,"1741":1634154088000,"1742":1634153440000,"1743":1634152956000,"1744":1634152619000,"1745":1634148374000,"1746":1634147902000,"1747":1634147722000,"1748":1634146765000,"1749":1634145856000,"1750":1634145406000,"1751":1634144987000,"1752":1634144549000,"1753":1634143115000,"1754":1634142922000,"1755":1634141282000,"1756":1634135121000,"1757":1634133787000,"1758":1634127489000,"1759":1634125464000,"1760":1634120706000,"1761":1634118306000,"1762":1634115862000,"1763":1634114011000,"1764":1634113012000,"1765":1634111233000,"1766":1634110520000,"1767":1634109724000,"1768":1634108267000,"1769":1634107910000,"1770":1634104017000,"1771":1634103050000,"1772":1634102100000,"1773":1634099514000,"1774":1634098489000,"1775":1634096284000,"1776":1634093776000,"1777":1634091496000,"1778":1634091465000,"1779":1634086792000,"1780":1634085970000,"1781":1634080837000,"1782":1634079755000,"1783":1634076746000,"1784":1634075017000,"1785":1634071175000,"1786":1634066605000,"1787":1634065312000,"1788":1634064438000,"1789":1634061602000,"1790":1634061116000,"1791":1634057133000,"1792":1634052621000,"1793":1634048471000,"1794":1634047074000,"1795":1634046066000,"1796":1634037532000,"1797":1634036763000,"1798":1634034782000,"1799":1634034577000,"1800":1634032892000,"1801":1634031694000,"1802":1634031527000,"1803":1634030637000,"1804":1634029246000,"1805":1634025056000,"1806":1634024625000,"1807":1634023452000,"1808":1634022776000,"1809":1634020375000,"1810":1634019645000,"1811":1634017410000,"1812":1634017188000,"1813":1634010769000,"1814":1634008690000,"1815":1634008354000,"1816":1634007809000,"1817":1634006145000,"1818":1634005535000,"1819":1634005380000,"1820":1634003127000,"1821":1634000737000,"1822":1633999794000,"1823":1633999542000,"1824":1633990366000,"1825":1633980491000,"1826":1633980230000,"1827":1633974907000,"1828":1633974491000,"1829":1633973734000,"1830":1633972078000,"1831":1633972058000,"1832":1633970499000,"1833":1633968541000,"1834":1633967711000,"1835":1633967536000,"1836":1633966907000,"1837":1633962666000,"1838":1633961909000,"1839":1633960808000,"1840":1633957506000,"1841":1633955790000,"1842":1633955227000,"1843":1633953192000,"1844":1633952374000,"1845":1633950934000,"1846":1633950518000,"1847":1633949695000,"1848":1633947824000,"1849":1633946276000,"1850":1633945606000,"1851":1633944814000,"1852":1633944695000,"1853":1633942197000,"1854":1633940131000,"1855":1633938161000,"1856":1633937468000,"1857":1633933338000,"1858":1633922493000,"1859":1633910337000,"1860":1633896087000,"1861":1633896009000,"1862":1633895937000,"1863":1633895893000,"1864":1633895799000,"1865":1633895566000,"1866":1633891759000,"1867":1633887224000,"1868":1633885839000,"1869":1633884224000,"1870":1633883034000,"1871":1633882549000,"1872":1633879665000,"1873":1633879279000,"1874":1633876268000,"1875":1633873179000,"1876":1633866631000,"1877":1633866304000,"1878":1633861640000,"1879":1633857684000,"1880":1633844642000,"1881":1633824989000,"1882":1633814906000,"1883":1633813761000,"1884":1633802575000,"1885":1633799561000,"1886":1633799477000,"1887":1633798734000,"1888":1633791969000,"1889":1633787346000,"1890":1633779570000,"1891":1633772182000,"1892":1633771567000,"1893":1633770956000,"1894":1633770905000,"1895":1633763362000,"1896":1633762838000,"1897":1633762276000,"1898":1633762008000,"1899":1633761511000,"1900":1633751007000,"1901":1633749878000,"1902":1633748019000,"1903":1633747447000,"1904":1633743903000,"1905":1633739975000,"1906":1633738640000,"1907":1633736245000,"1908":1633735817000,"1909":1633730228000,"1910":1633728620000,"1911":1633726312000,"1912":1633721969000,"1913":1633718399000,"1914":1633717992000,"1915":1633715907000,"1916":1633715879000,"1917":1633713031000,"1918":1633711256000,"1919":1633707687000,"1920":1633706172000,"1921":1633702716000,"1922":1633699753000,"1923":1633699339000,"1924":1633697126000,"1925":1633692460000,"1926":1633687449000,"1927":1633687296000,"1928":1633687243000,"1929":1633686762000,"1930":1633686115000,"1931":1633684695000,"1932":1633679087000,"1933":1633670388000,"1934":1633670021000,"1935":1633664169000,"1936":1633661194000,"1937":1633658968000,"1938":1633656214000,"1939":1633655950000,"1940":1633655203000,"1941":1633651593000,"1942":1633642608000,"1943":1633636159000,"1944":1633634298000,"1945":1633631346000,"1946":1633628697000,"1947":1633621856000,"1948":1633621265000,"1949":1633620562000,"1950":1633617815000,"1951":1633609651000,"1952":1633607655000,"1953":1633607131000,"1954":1633603322000,"1955":1633602124000,"1956":1633600264000,"1957":1633599240000,"1958":1633597815000,"1959":1633596709000,"1960":1633594766000,"1961":1633589986000,"1962":1633585492000,"1963":1633585173000,"1964":1633573399000,"1965":1633565571000,"1966":1633563334000,"1967":1633563090000,"1968":1633562927000,"1969":1633554766000,"1970":1633554120000,"1971":1633550873000,"1972":1633549698000,"1973":1633544437000,"1974":1633543559000,"1975":1633540275000,"1976":1633536825000,"1977":1633536632000,"1978":1633533540000,"1979":1633532972000,"1980":1633529817000,"1981":1633529099000,"1982":1633528160000,"1983":1633525510000,"1984":1633524780000,"1985":1633516237000,"1986":1633510682000,"1987":1633509729000,"1988":1633501108000,"1989":1633501025000,"1990":1633495927000,"1991":1633492405000,"1992":1633488875000,"1993":1633488538000,"1994":1633488536000,"1995":1633481317000,"1996":1633481040000,"1997":1633476808000,"1998":1633476376000,"1999":1633476037000,"2000":1633474989000,"2001":1633473406000,"2002":1633472312000,"2003":1633470046000,"2004":1633464822000,"2005":1633459024000,"2006":1633456549000,"2007":1633456035000,"2008":1633455882000,"2009":1633455881000,"2010":1633453000000,"2011":1633452376000,"2012":1633451937000,"2013":1633451091000,"2014":1633451059000,"2015":1633447472000,"2016":1633443945000,"2017":1633443277000,"2018":1633443167000,"2019":1633442147000,"2020":1633441700000,"2021":1633440788000,"2022":1633440658000,"2023":1633440100000,"2024":1633433338000,"2025":1633433064000,"2026":1633431853000,"2027":1633419955000,"2028":1633419486000,"2029":1633415317000,"2030":1633414730000,"2031":1633409077000,"2032":1633406496000,"2033":1633405077000,"2034":1633404151000,"2035":1633401524000,"2036":1633380617000,"2037":1633375638000,"2038":1633373961000,"2039":1633371332000,"2040":1633369867000,"2041":1633367858000,"2042":1633365928000,"2043":1633365856000,"2044":1633361827000,"2045":1633359388000,"2046":1633359123000,"2047":1633352933000,"2048":1633350978000,"2049":1633350374000,"2050":1633349867000,"2051":1633349067000,"2052":1633348483000,"2053":1633347231000,"2054":1633344759000,"2055":1633343847000,"2056":1633341622000,"2057":1633340627000,"2058":1633337793000,"2059":1633337496000,"2060":1633328232000,"2061":1633323071000,"2062":1633319955000,"2063":1633315934000,"2064":1633310563000,"2065":1633300711000,"2066":1633292574000,"2067":1633289909000,"2068":1633289781000,"2069":1633288228000},"published":{"0":"2021-12-31T23:28:28Z","1":"2021-12-31T22:26:41Z","2":"2019-07-22T14:53:48Z","3":"2021-03-18T17:48:54Z","4":"2021-12-31T16:50:31Z","5":"2021-03-23T07:42:09Z","6":"2021-12-31T09:15:39Z","7":"2021-05-11T12:25:57Z","8":"2021-12-31T07:14:59Z","9":"2021-12-31T04:03:48Z","10":"2021-12-31T03:53:33Z","11":"2021-12-31T03:42:55Z","12":"2021-12-22T02:35:29Z","13":"2021-12-31T00:35:48Z","14":"2021-12-30T16:46:28Z","15":"2021-12-30T15:41:52Z","16":"2021-12-30T13:48:58Z","17":"2021-12-30T13:30:25Z","18":"2021-12-30T13:07:08Z","19":"2021-12-30T10:43:56Z","20":"2021-12-30T10:36:04Z","21":"2021-12-30T06:32:47Z","22":"2021-12-30T05:39:42Z","23":"2021-12-05T07:30:17Z","24":"2021-05-05T07:03:41Z","25":"2021-12-30T02:27:29Z","26":"2021-06-10T10:25:15Z","27":"2021-12-29T20:34:03Z","28":"2019-06-30T20:54:21Z","29":"2021-12-29T19:02:04Z","30":"2021-12-29T18:39:35Z","31":"2021-03-29T04:54:28Z","32":"2021-11-19T15:18:12Z","33":"2021-09-06T09:55:58Z","34":"2021-12-29T14:22:42Z","35":"2020-09-21T09:21:52Z","36":"2020-12-10T06:54:54Z","37":"2021-02-02T15:19:41Z","38":"2021-12-29T10:10:10Z","39":"2021-09-30T18:03:10Z","40":"2021-12-29T03:57:02Z","41":"2021-12-29T03:03:44Z","42":"2021-10-01T17:00:14Z","43":"2021-12-29T00:54:47Z","44":"2021-12-28T23:46:00Z","45":"2021-12-28T22:27:52Z","46":"2018-09-11T19:52:44Z","47":"2021-04-17T21:34:10Z","48":"2021-12-27T08:48:57Z","49":"2021-10-04T15:57:02Z","50":"2021-09-01T13:11:57Z","51":"2021-12-28T15:46:28Z","52":"2021-12-28T14:54:18Z","53":"2021-12-28T14:19:36Z","54":"2021-12-28T09:56:44Z","55":"2021-09-13T10:05:11Z","56":"2021-12-27T17:52:48Z","57":"2019-06-20T08:03:58Z","58":"2021-12-28T02:56:41Z","59":"2021-12-28T01:36:22Z","60":"2021-12-28T00:14:46Z","61":"2021-12-27T21:19:23Z","62":"2021-12-27T19:17:07Z","63":"2021-12-27T18:51:18Z","64":"2021-12-27T18:47:43Z","65":"2021-12-27T17:31:04Z","66":"2020-07-31T22:01:39Z","67":"2021-12-27T17:12:57Z","68":"2021-12-27T16:43:31Z","69":"2021-12-27T16:12:30Z","70":"2021-12-27T16:11:05Z","71":"2021-12-27T15:45:35Z","72":"2019-10-30T23:47:25Z","73":"2021-12-27T12:45:06Z","74":"2021-12-27T11:41:52Z","75":"2021-12-27T11:08:58Z","76":"2020-08-26T21:57:25Z","77":"2021-12-27T10:16:43Z","78":"2021-12-27T07:51:49Z","79":"2021-12-27T05:03:10Z","80":"2021-12-26T18:38:05Z","81":"2021-12-26T18:06:44Z","82":"2021-11-06T20:45:17Z","83":"2021-05-23T10:38:23Z","84":"2021-09-14T19:28:31Z","85":"2021-05-15T06:13:39Z","86":"2021-06-03T05:08:11Z","87":"2021-12-26T12:41:10Z","88":"2021-12-26T10:46:32Z","89":"2021-12-07T14:16:26Z","90":"2021-12-26T05:50:51Z","91":"2021-12-26T05:37:56Z","92":"2021-04-15T11:51:52Z","93":"2021-08-29T22:30:15Z","94":"2021-12-25T21:19:42Z","95":"2021-12-25T17:14:13Z","96":"2021-12-25T14:40:09Z","97":"2021-12-25T14:06:41Z","98":"2021-12-25T14:03:09Z","99":"2020-09-14T05:24:28Z","100":"2021-12-25T03:41:42Z","101":"2020-10-16T18:02:07Z","102":"2019-09-29T15:35:08Z","103":"2021-12-24T08:35:18Z","104":"2021-12-24T04:25:34Z","105":"2021-12-24T04:20:57Z","106":"2021-12-24T02:42:44Z","107":"2021-11-03T10:08:05Z","108":"2021-12-23T22:33:20Z","109":"2021-12-23T19:20:19Z","110":"2021-12-23T17:35:48Z","111":"2021-12-23T16:11:19Z","112":"2021-12-23T12:27:45Z","113":"2021-12-23T10:18:50Z","114":"2021-12-23T10:04:25Z","115":"2021-12-23T09:53:38Z","116":"2021-07-01T18:01:46Z","117":"2021-07-18T10:28:48Z","118":"2021-12-23T07:25:02Z","119":"2021-12-23T05:11:48Z","120":"2021-12-23T04:40:06Z","121":"2021-12-23T02:27:10Z","122":"2021-06-01T11:20:02Z","123":"2021-12-22T20:57:50Z","124":"2021-12-22T16:54:57Z","125":"2021-12-22T16:54:06Z","126":"2021-12-22T16:39:14Z","127":"2021-07-23T18:54:39Z","128":"2021-12-16T14:33:12Z","129":"2021-12-22T15:44:30Z","130":"2021-12-22T15:03:23Z","131":"2021-12-22T12:57:05Z","132":"2020-08-02T00:09:03Z","133":"2021-06-23T13:24:39Z","134":"2021-12-22T11:15:49Z","135":"2021-12-22T10:29:20Z","136":"2021-06-04T09:48:28Z","137":"2021-12-22T10:13:34Z","138":"2021-07-05T16:32:45Z","139":"2021-12-22T09:14:03Z","140":"2021-12-22T09:08:00Z","141":"2021-10-26T14:04:02Z","142":"2021-06-16T13:44:03Z","143":"2021-11-06T19:34:33Z","144":"2021-12-22T05:34:56Z","145":"2021-12-22T05:04:41Z","146":"2021-12-22T03:13:45Z","147":"2021-12-22T03:06:27Z","148":"2020-04-25T03:09:48Z","149":"2021-05-21T15:13:05Z","150":"2021-12-21T19:27:21Z","151":"2021-12-21T19:00:02Z","152":"2021-12-21T17:49:06Z","153":"2021-12-21T17:47:14Z","154":"2021-12-21T17:35:06Z","155":"2020-10-16T06:59:34Z","156":"2021-12-21T15:04:57Z","157":"2021-10-08T16:06:54Z","158":"2021-12-21T14:13:06Z","159":"2021-12-21T13:16:24Z","160":"2021-12-21T10:07:55Z","161":"2021-09-13T15:20:06Z","162":"2021-12-21T08:10:27Z","163":"2021-12-21T05:24:01Z","164":"2021-10-10T22:02:06Z","165":"2021-04-08T17:28:43Z","166":"2021-12-21T01:57:04Z","167":"2021-10-27T06:39:33Z","168":"2021-12-21T01:04:08Z","169":"2021-05-06T07:38:43Z","170":"2021-12-20T18:53:41Z","171":"2021-12-20T17:05:11Z","172":"2021-12-20T16:52:35Z","173":"2021-12-01T18:43:00Z","174":"2020-12-14T13:33:34Z","175":"2021-09-28T06:18:57Z","176":"2021-12-20T14:26:40Z","177":"2021-12-20T14:08:38Z","178":"2021-12-20T13:04:18Z","179":"2020-08-23T02:34:26Z","180":"2021-12-20T09:48:32Z","181":"2021-12-20T06:54:28Z","182":"2021-12-20T03:32:28Z","183":"2021-12-19T17:31:15Z","184":"2021-12-19T16:44:57Z","185":"2021-12-19T11:30:29Z","186":"2021-12-19T10:29:17Z","187":"2021-12-19T06:11:07Z","188":"2021-12-19T05:09:01Z","189":"2021-12-19T01:45:57Z","190":"2021-10-06T17:57:22Z","191":"2021-12-18T22:58:21Z","192":"2021-12-18T19:27:33Z","193":"2021-12-18T14:07:54Z","194":"2021-12-18T13:20:18Z","195":"2021-12-18T13:15:34Z","196":"2021-12-10T04:20:08Z","197":"2021-12-18T07:40:37Z","198":"2021-12-18T06:58:36Z","199":"2021-09-15T08:00:33Z","200":"2021-05-18T08:30:37Z","201":"2021-12-18T04:26:19Z","202":"2021-12-17T20:27:48Z","203":"2021-06-14T05:57:46Z","204":"2021-12-17T20:00:54Z","205":"2021-12-17T18:29:56Z","206":"2020-09-07T00:15:36Z","207":"2021-12-17T18:03:14Z","208":"2021-06-02T02:43:18Z","209":"2021-12-17T16:59:40Z","210":"2021-12-17T16:51:00Z","211":"2021-12-17T16:21:49Z","212":"2021-12-17T15:34:03Z","213":"2021-08-30T15:46:09Z","214":"2021-12-17T14:23:43Z","215":"2021-12-17T12:59:02Z","216":"2021-12-17T12:09:01Z","217":"2021-12-16T10:07:39Z","218":"2021-12-14T14:13:05Z","219":"2021-12-15T13:14:36Z","220":"2021-11-09T11:56:38Z","221":"2021-12-17T06:49:18Z","222":"2020-10-30T09:30:54Z","223":"2021-12-17T06:19:37Z","224":"2020-12-01T23:40:21Z","225":"2021-12-17T03:28:54Z","226":"2021-02-08T09:43:05Z","227":"2021-12-17T02:32:58Z","228":"2021-12-16T22:36:17Z","229":"2020-11-01T04:04:43Z","230":"2021-12-16T21:47:28Z","231":"2021-04-17T04:45:52Z","232":"2019-02-02T23:42:42Z","233":"2021-12-14T13:33:57Z","234":"2021-12-14T13:32:13Z","235":"2021-12-16T19:00:55Z","236":"2021-12-16T18:57:37Z","237":"2020-10-12T18:27:05Z","238":"2021-11-17T18:49:42Z","239":"2021-12-16T18:29:07Z","240":"2021-01-12T01:35:56Z","241":"2021-12-16T17:59:39Z","242":"2021-12-16T17:47:20Z","243":"2021-08-02T14:46:46Z","244":"2021-12-16T14:37:41Z","245":"2021-12-16T14:26:36Z","246":"2021-12-16T14:24:35Z","247":"2021-07-28T14:09:40Z","248":"2021-11-18T15:23:27Z","249":"2021-12-16T12:51:52Z","250":"2021-12-16T11:44:38Z","251":"2021-12-16T11:40:36Z","252":"2021-12-16T11:17:58Z","253":"2021-12-16T10:45:05Z","254":"2021-12-16T10:34:22Z","255":"2021-12-16T09:56:35Z","256":"2021-12-16T09:41:04Z","257":"2021-12-16T09:22:54Z","258":"2021-12-16T09:21:18Z","259":"2021-12-16T09:08:40Z","260":"2021-12-16T08:34:06Z","261":"2021-12-16T08:28:26Z","262":"2021-12-16T08:18:47Z","263":"2021-12-16T07:10:02Z","264":"2021-12-16T06:48:31Z","265":"2021-12-16T06:25:46Z","266":"2021-12-16T06:14:37Z","267":"2021-12-16T06:06:42Z","268":"2021-12-02T18:38:50Z","269":"2021-12-16T05:21:24Z","270":"2020-10-24T00:27:44Z","271":"2021-12-16T04:42:13Z","272":"2021-12-16T04:16:39Z","273":"2021-12-16T04:14:38Z","274":"2021-12-16T03:44:01Z","275":"2020-12-10T01:27:24Z","276":"2021-12-16T03:34:14Z","277":"2021-12-16T03:29:31Z","278":"2021-12-16T03:21:01Z","279":"2021-12-16T03:16:30Z","280":"2021-12-16T03:13:04Z","281":"2021-12-16T02:40:43Z","282":"2021-12-16T02:20:59Z","283":"2021-12-16T01:46:30Z","284":"2021-12-16T01:45:33Z","285":"2021-12-16T01:32:21Z","286":"2021-12-16T01:19:37Z","287":"2021-12-16T01:11:08Z","288":"2021-12-16T01:09:51Z","289":"2021-03-19T17:27:58Z","290":"2021-12-16T00:32:06Z","291":"2021-12-16T00:02:02Z","292":"2021-12-15T23:56:21Z","293":"2021-12-15T21:35:56Z","294":"2021-11-29T17:07:49Z","295":"2021-02-01T23:11:57Z","296":"2020-04-29T12:19:50Z","297":"2021-12-15T20:34:57Z","298":"2021-12-15T20:21:20Z","299":"2021-12-15T19:06:31Z","300":"2021-12-15T19:02:49Z","301":"2021-12-15T18:59:57Z","302":"2021-12-15T18:56:18Z","303":"2021-12-15T18:54:34Z","304":"2021-12-15T18:50:14Z","305":"2021-09-02T18:04:10Z","306":"2021-12-15T18:30:51Z","307":"2021-12-15T18:20:12Z","308":"2021-12-15T18:10:54Z","309":"2021-12-15T17:35:30Z","310":"2021-12-15T17:00:11Z","311":"2021-11-21T09:28:49Z","312":"2021-12-15T16:45:55Z","313":"2021-12-15T16:36:53Z","314":"2021-07-06T17:59:49Z","315":"2020-08-12T17:26:55Z","316":"2021-07-22T21:57:18Z","317":"2021-12-15T15:11:53Z","318":"2021-11-01T17:41:01Z","319":"2021-12-15T14:31:32Z","320":"2021-12-15T14:21:26Z","321":"2021-12-15T14:12:48Z","322":"2021-12-15T13:14:58Z","323":"2021-10-29T21:09:17Z","324":"2021-10-29T22:33:45Z","325":"2021-12-15T12:48:04Z","326":"2021-07-02T21:01:17Z","327":"2021-12-15T10:54:36Z","328":"2021-12-15T09:21:32Z","329":"2021-12-15T07:56:16Z","330":"2021-04-18T05:44:41Z","331":"2021-12-15T07:11:02Z","332":"2021-12-10T14:59:06Z","333":"2021-12-15T05:33:27Z","334":"2021-12-15T05:06:18Z","335":"2021-12-15T05:05:12Z","336":"2021-12-15T04:53:13Z","337":"2021-12-15T04:38:15Z","338":"2021-12-15T04:29:02Z","339":"2021-12-15T04:27:33Z","340":"2021-12-15T04:23:14Z","341":"2021-12-15T04:20:35Z","342":"2021-12-14T23:06:21Z","343":"2021-04-23T22:24:33Z","344":"2021-12-14T22:40:28Z","345":"2021-12-14T22:39:57Z","346":"2021-12-14T21:33:39Z","347":"2021-12-14T20:55:35Z","348":"2021-12-14T19:23:43Z","349":"2021-12-14T19:18:08Z","350":"2021-09-14T17:12:38Z","351":"2021-04-12T07:11:40Z","352":"2021-12-14T18:49:26Z","353":"2021-12-14T18:35:02Z","354":"2019-10-22T11:58:59Z","355":"2021-05-14T13:21:12Z","356":"2021-12-14T16:49:47Z","357":"2021-08-24T20:54:56Z","358":"2021-12-14T16:22:44Z","359":"2021-12-14T16:00:51Z","360":"2021-12-14T15:04:56Z","361":"2021-12-14T14:59:44Z","362":"2021-12-14T14:47:23Z","363":"2021-12-14T13:23:49Z","364":"2021-12-14T13:21:11Z","365":"2021-12-03T14:05:52Z","366":"2021-12-14T12:48:19Z","367":"2021-12-14T12:26:24Z","368":"2021-12-14T11:27:16Z","369":"2021-12-14T09:47:53Z","370":"2021-12-14T09:38:31Z","371":"2021-12-14T07:14:09Z","372":"2021-08-19T18:58:02Z","373":"2020-11-17T16:57:41Z","374":"2021-12-14T04:56:39Z","375":"2021-12-13T09:11:38Z","376":"2021-09-23T04:26:15Z","377":"2021-04-25T09:36:23Z","378":"2021-03-23T00:49:36Z","379":"2021-12-14T01:14:20Z","380":"2021-04-30T06:38:23Z","381":"2021-12-14T00:08:36Z","382":"2021-12-13T22:39:46Z","383":"2021-12-13T21:46:21Z","384":"2021-12-13T21:08:04Z","385":"2021-12-13T19:00:17Z","386":"2021-12-13T18:58:19Z","387":"2021-12-13T18:45:42Z","388":"2021-04-05T06:35:30Z","389":"2021-12-13T17:49:16Z","390":"2021-12-13T16:33:01Z","391":"2021-12-13T15:57:32Z","392":"2021-12-13T15:49:36Z","393":"2021-12-13T15:40:54Z","394":"2021-12-13T15:31:07Z","395":"2021-12-13T15:09:06Z","396":"2021-12-13T15:06:09Z","397":"2021-09-16T12:52:48Z","398":"2021-12-13T12:39:53Z","399":"2021-12-13T10:35:09Z","400":"2021-12-13T10:24:54Z","401":"2021-12-13T09:56:27Z","402":"2021-12-13T09:38:41Z","403":"2021-10-05T12:45:59Z","404":"2021-12-10T16:49:49Z","405":"2021-12-13T08:14:21Z","406":"2021-12-13T07:36:02Z","407":"2021-12-13T07:04:41Z","408":"2021-11-04T05:40:13Z","409":"2020-12-03T09:06:23Z","410":"2021-12-13T04:17:20Z","411":"2021-12-13T04:02:13Z","412":"2021-12-13T01:38:37Z","413":"2021-12-12T23:02:52Z","414":"2021-12-12T21:58:07Z","415":"2021-12-12T21:27:32Z","416":"2021-12-12T19:57:11Z","417":"2021-12-12T19:56:34Z","418":"2021-12-12T18:38:27Z","419":"2021-12-12T13:50:18Z","420":"2021-12-12T11:10:39Z","421":"2021-12-12T10:50:01Z","422":"2021-12-12T10:16:45Z","423":"2021-12-12T06:25:15Z","424":"2021-12-12T03:16:03Z","425":"2021-12-12T01:30:29Z","426":"2021-06-25T20:31:33Z","427":"2020-06-03T18:47:24Z","428":"2021-11-24T20:30:09Z","429":"2021-11-28T16:25:04Z","430":"2021-12-11T16:01:29Z","431":"2020-10-30T02:06:10Z","432":"2021-12-11T13:11:36Z","433":"2021-12-09T09:35:48Z","434":"2021-12-11T03:36:38Z","435":"2021-06-18T03:42:56Z","436":"2021-12-10T23:59:14Z","437":"2021-12-10T21:58:16Z","438":"2021-12-10T21:54:20Z","439":"2021-04-30T17:53:07Z","440":"2021-12-10T20:47:58Z","441":"2021-12-10T20:01:44Z","442":"2021-12-10T20:01:26Z","443":"2021-12-10T19:53:41Z","444":"2021-10-13T18:03:47Z","445":"2021-12-10T18:15:44Z","446":"2021-12-10T17:57:33Z","447":"2021-12-10T17:51:37Z","448":"2021-09-24T17:53:47Z","449":"2021-12-10T16:23:24Z","450":"2021-12-10T15:26:43Z","451":"2021-12-10T14:08:52Z","452":"2021-12-10T11:18:26Z","453":"2021-12-10T11:09:44Z","454":"2021-12-10T10:39:07Z","455":"2021-12-10T09:51:16Z","456":"2021-12-10T07:15:09Z","457":"2021-12-10T06:58:05Z","458":"2021-03-07T16:56:56Z","459":"2021-12-10T05:54:48Z","460":"2021-12-10T00:02:40Z","461":"2021-12-09T23:58:45Z","462":"2021-10-14T00:34:51Z","463":"2020-10-23T21:19:03Z","464":"2021-04-16T16:37:13Z","465":"2021-12-01T22:24:34Z","466":"2021-12-09T20:49:01Z","467":"2021-10-08T14:52:25Z","468":"2021-12-09T20:07:41Z","469":"2021-12-09T19:57:22Z","470":"2021-12-09T18:59:34Z","471":"2021-12-09T18:57:29Z","472":"2021-12-09T17:33:18Z","473":"2021-12-09T15:46:15Z","474":"2021-12-09T15:06:18Z","475":"2021-12-09T13:54:56Z","476":"2021-12-02T15:32:24Z","477":"2021-12-09T13:21:26Z","478":"2021-12-09T13:16:42Z","479":"2021-12-09T12:49:01Z","480":"2021-12-09T12:45:33Z","481":"2021-08-02T22:56:26Z","482":"2021-12-09T10:57:18Z","483":"2020-12-25T13:57:04Z","484":"2021-06-02T09:30:29Z","485":"2021-03-04T08:51:00Z","486":"2021-12-09T09:50:20Z","487":"2021-11-29T02:14:38Z","488":"2021-11-29T02:39:59Z","489":"2021-12-09T09:28:05Z","490":"2021-12-07T08:23:42Z","491":"2020-08-28T09:37:39Z","492":"2021-12-08T06:32:52Z","493":"2021-12-07T16:30:40Z","494":"2020-11-10T00:35:46Z","495":"2021-09-18T01:30:08Z","496":"2021-12-09T00:20:29Z","497":"2021-02-16T13:22:00Z","498":"2021-11-18T06:48:00Z","499":"2021-12-02T18:25:56Z","500":"2021-12-08T19:34:27Z","501":"2021-12-08T18:58:16Z","502":"2021-12-08T18:26:19Z","503":"2021-12-08T18:14:57Z","504":"2021-12-08T16:09:48Z","505":"2021-12-08T15:51:27Z","506":"2021-09-11T17:44:13Z","507":"2021-08-31T07:49:15Z","508":"2021-08-23T16:22:50Z","509":"2021-12-06T18:37:33Z","510":"2021-12-08T09:26:21Z","511":"2021-09-28T17:00:10Z","512":"2021-12-08T09:16:03Z","513":"2021-12-08T07:54:03Z","514":"2021-12-08T07:43:38Z","515":"2021-12-08T06:34:58Z","516":"2021-09-21T06:42:53Z","517":"2021-12-08T05:48:11Z","518":"2021-12-08T04:12:50Z","519":"2021-08-05T22:04:13Z","520":"2021-09-16T17:35:01Z","521":"2021-12-07T22:49:58Z","522":"2021-12-07T21:40:43Z","523":"2021-12-07T20:56:20Z","524":"2021-02-24T04:25:01Z","525":"2021-12-07T18:01:35Z","526":"2021-12-07T17:49:34Z","527":"2021-12-07T17:47:50Z","528":"2021-12-07T17:39:21Z","529":"2021-12-07T16:32:30Z","530":"2021-08-17T04:13:11Z","531":"2021-12-07T16:16:01Z","532":"2021-12-07T14:47:27Z","533":"2021-10-06T15:23:40Z","534":"2021-12-07T11:15:19Z","535":"2021-12-07T10:47:07Z","536":"2021-12-05T12:42:40Z","537":"2021-12-07T09:30:59Z","538":"2021-09-15T12:58:51Z","539":"2021-12-07T08:53:40Z","540":"2021-12-02T07:59:11Z","541":"2021-12-07T08:12:41Z","542":"2021-07-05T18:00:14Z","543":"2021-12-07T06:58:22Z","544":"2021-12-07T06:31:18Z","545":"2020-05-31T06:57:34Z","546":"2020-12-16T17:17:47Z","547":"2021-12-07T03:45:02Z","548":"2021-12-06T23:19:08Z","549":"2021-12-06T18:59:27Z","550":"2021-08-30T15:40:52Z","551":"2021-12-06T18:23:29Z","552":"2021-09-27T16:05:03Z","553":"2021-12-06T18:13:46Z","554":"2021-07-25T19:29:53Z","555":"2021-12-06T16:51:50Z","556":"2021-12-06T16:41:26Z","557":"2021-04-16T16:53:48Z","558":"2021-12-06T15:09:57Z","559":"2021-10-04T15:24:07Z","560":"2021-12-06T13:54:08Z","561":"2021-09-13T06:55:14Z","562":"2021-12-06T12:30:58Z","563":"2021-12-06T10:12:11Z","564":"2021-12-06T09:27:24Z","565":"2021-10-17T03:24:05Z","566":"2020-10-06T12:35:13Z","567":"2021-12-06T03:51:56Z","568":"2021-12-06T02:46:06Z","569":"2021-12-06T02:23:20Z","570":"2021-08-17T23:56:04Z","571":"2021-12-06T00:37:59Z","572":"2021-12-05T23:55:53Z","573":"2021-12-05T23:13:13Z","574":"2021-12-05T22:54:54Z","575":"2021-04-21T19:06:58Z","576":"2021-12-05T18:40:32Z","577":"2021-12-05T16:17:21Z","578":"2021-12-05T16:05:16Z","579":"2021-08-10T11:59:42Z","580":"2021-12-05T08:48:52Z","581":"2021-12-05T08:13:09Z","582":"2020-11-26T15:36:06Z","583":"2021-12-05T02:15:01Z","584":"2021-12-04T20:45:26Z","585":"2021-06-09T19:25:37Z","586":"2021-12-04T18:34:24Z","587":"2021-09-18T10:53:39Z","588":"2021-12-04T13:18:12Z","589":"2021-12-04T06:55:19Z","590":"2021-12-04T05:13:29Z","591":"2021-12-04T01:33:08Z","592":"2021-11-28T18:59:57Z","593":"2021-12-03T20:06:11Z","594":"2021-07-19T07:43:49Z","595":"2020-09-10T22:18:57Z","596":"2020-12-16T08:21:51Z","597":"2021-12-03T16:02:42Z","598":"2021-09-05T15:25:28Z","599":"2021-09-20T19:03:16Z","600":"2021-12-03T15:03:25Z","601":"2021-12-03T14:39:04Z","602":"2021-01-01T03:09:31Z","603":"2021-12-03T13:35:18Z","604":"2021-12-03T13:21:57Z","605":"2021-02-11T12:49:39Z","606":"2021-12-03T13:15:17Z","607":"2021-12-03T12:02:52Z","608":"2021-10-14T17:59:57Z","609":"2021-12-03T10:49:19Z","610":"2021-12-03T10:22:02Z","611":"2021-12-03T09:45:18Z","612":"2021-12-03T09:06:46Z","613":"2021-03-17T14:05:05Z","614":"2021-12-03T07:44:22Z","615":"2021-12-03T07:42:45Z","616":"2021-12-03T07:27:13Z","617":"2021-11-13T09:22:39Z","618":"2021-12-03T06:43:56Z","619":"2021-12-03T05:01:47Z","620":"2021-12-03T04:34:48Z","621":"2021-12-03T04:26:49Z","622":"2021-12-03T03:43:18Z","623":"2021-12-03T01:33:28Z","624":"2021-12-03T00:56:17Z","625":"2021-12-02T21:47:29Z","626":"2021-12-02T20:16:17Z","627":"2021-01-14T18:32:21Z","628":"2021-12-02T19:27:27Z","629":"2021-04-12T23:00:40Z","630":"2021-12-02T16:49:41Z","631":"2021-12-02T16:09:33Z","632":"2020-09-30T09:50:39Z","633":"2021-12-02T15:40:52Z","634":"2021-12-02T12:57:22Z","635":"2021-12-02T11:02:00Z","636":"2021-11-26T03:16:09Z","637":"2021-10-06T14:01:56Z","638":"2021-12-02T09:24:45Z","639":"2021-12-02T09:23:01Z","640":"2021-12-02T09:08:09Z","641":"2021-11-30T07:46:07Z","642":"2021-12-02T08:40:42Z","643":"2021-12-02T08:29:26Z","644":"2021-12-02T08:20:23Z","645":"2021-12-02T08:19:42Z","646":"2021-11-23T17:06:01Z","647":"2021-12-02T08:02:59Z","648":"2021-12-02T07:26:34Z","649":"2021-12-02T06:54:44Z","650":"2021-11-28T11:21:21Z","651":"2021-12-02T03:56:09Z","652":"2021-12-02T03:48:45Z","653":"2021-12-02T03:45:10Z","654":"2021-12-02T00:29:21Z","655":"2020-10-24T05:06:29Z","656":"2021-05-07T06:03:45Z","657":"2019-10-18T07:52:01Z","658":"2021-08-15T01:58:45Z","659":"2021-12-01T20:39:04Z","660":"2021-12-01T19:41:03Z","661":"2021-12-01T19:24:05Z","662":"2021-12-01T16:01:46Z","663":"2021-12-01T15:50:45Z","664":"2021-12-01T15:47:01Z","665":"2021-12-01T15:36:13Z","666":"2021-12-01T15:34:39Z","667":"2021-12-01T14:45:43Z","668":"2021-01-31T07:56:08Z","669":"2021-12-01T13:13:03Z","670":"2021-12-01T13:05:05Z","671":"2021-05-19T10:24:50Z","672":"2021-12-01T10:45:02Z","673":"2021-12-01T10:08:24Z","674":"2021-12-01T08:57:39Z","675":"2021-12-01T05:21:07Z","676":"2021-12-01T05:13:47Z","677":"2021-10-12T03:10:21Z","678":"2020-11-02T04:28:16Z","679":"2021-12-01T02:59:21Z","680":"2021-12-01T01:34:28Z","681":"2021-11-30T23:05:05Z","682":"2021-06-22T21:25:43Z","683":"2021-07-14T18:00:54Z","684":"2021-11-30T20:36:56Z","685":"2021-11-30T20:26:09Z","686":"2021-03-27T02:12:28Z","687":"2021-11-27T00:21:36Z","688":"2021-11-30T19:15:06Z","689":"2021-11-30T18:25:32Z","690":"2021-11-30T18:21:06Z","691":"2021-11-30T18:14:06Z","692":"2021-05-06T10:27:43Z","693":"2021-11-30T15:52:04Z","694":"2021-11-13T15:07:13Z","695":"2020-03-20T09:55:10Z","696":"2021-11-30T14:29:33Z","697":"2021-11-30T14:14:32Z","698":"2021-11-30T14:10:22Z","699":"2021-11-30T14:06:55Z","700":"2021-11-30T12:41:04Z","701":"2021-11-30T12:07:23Z","702":"2021-11-30T11:22:43Z","703":"2021-11-30T10:53:41Z","704":"2021-11-30T10:36:35Z","705":"2021-11-30T10:32:17Z","706":"2021-11-30T09:48:39Z","707":"2021-11-30T06:51:13Z","708":"2021-11-30T06:28:58Z","709":"2021-04-15T17:51:03Z","710":"2021-11-28T11:14:16Z","711":"2021-11-29T00:58:22Z","712":"2021-11-30T03:19:24Z","713":"2021-11-28T16:02:13Z","714":"2021-11-29T23:14:54Z","715":"2021-11-29T22:11:23Z","716":"2021-11-29T22:02:06Z","717":"2021-11-29T21:41:34Z","718":"2021-07-20T16:42:58Z","719":"2021-11-29T17:34:38Z","720":"2021-11-29T17:20:51Z","721":"2021-11-29T16:46:29Z","722":"2021-03-24T15:40:28Z","723":"2021-10-07T15:08:24Z","724":"2021-11-29T15:13:36Z","725":"2021-08-20T11:36:24Z","726":"2021-11-29T12:24:02Z","727":"2021-11-29T11:02:24Z","728":"2021-11-29T10:58:15Z","729":"2021-11-29T09:57:00Z","730":"2021-04-11T20:13:24Z","731":"2021-11-10T21:18:59Z","732":"2021-11-29T02:55:42Z","733":"2021-11-28T20:26:07Z","734":"2021-07-12T17:47:19Z","735":"2021-11-28T15:13:05Z","736":"2020-04-30T15:15:40Z","737":"2021-07-19T14:17:42Z","738":"2021-11-28T11:48:02Z","739":"2021-09-10T03:32:19Z","740":"2021-11-28T10:17:11Z","741":"2021-11-15T07:27:35Z","742":"2020-06-09T13:12:44Z","743":"2021-11-28T08:58:38Z","744":"2020-05-17T07:53:15Z","745":"2021-03-22T17:51:10Z","746":"2021-11-28T07:18:11Z","747":"2021-11-28T03:11:37Z","748":"2021-11-28T03:08:06Z","749":"2021-08-04T22:18:10Z","750":"2021-11-27T23:19:49Z","751":"2021-11-27T22:42:06Z","752":"2021-11-27T22:12:50Z","753":"2021-11-27T20:47:53Z","754":"2021-11-27T20:03:19Z","755":"2021-11-27T19:26:14Z","756":"2021-11-27T19:17:29Z","757":"2021-07-28T11:34:00Z","758":"2020-07-08T00:41:53Z","759":"2021-06-08T19:17:04Z","760":"2021-11-27T10:22:29Z","761":"2021-09-30T09:04:11Z","762":"2021-11-27T06:54:16Z","763":"2021-11-27T00:47:54Z","764":"2021-11-26T19:22:51Z","765":"2021-11-26T18:33:59Z","766":"2021-05-11T14:44:05Z","767":"2021-11-26T17:18:18Z","768":"2021-09-01T16:28:24Z","769":"2021-09-07T08:40:14Z","770":"2021-06-01T04:13:39Z","771":"2021-11-26T12:23:14Z","772":"2021-11-26T11:49:07Z","773":"2021-11-26T07:58:11Z","774":"2021-01-24T01:28:05Z","775":"2021-10-07T14:37:06Z","776":"2020-12-31T15:49:49Z","777":"2021-11-26T00:54:37Z","778":"2021-11-25T21:44:18Z","779":"2019-10-30T18:57:28Z","780":"2021-11-25T18:03:41Z","781":"2021-11-25T16:37:24Z","782":"2021-11-25T15:49:50Z","783":"2021-11-25T13:16:21Z","784":"2021-11-25T10:27:10Z","785":"2021-11-25T10:19:05Z","786":"2021-04-01T07:36:04Z","787":"2021-11-25T07:40:45Z","788":"2019-06-19T13:54:25Z","789":"2018-12-05T22:27:20Z","790":"2021-11-19T11:07:07Z","791":"2021-02-17T08:55:01Z","792":"2021-10-20T09:00:51Z","793":"2021-11-23T08:01:21Z","794":"2021-11-24T21:23:43Z","795":"2021-11-24T21:01:25Z","796":"2021-11-24T20:44:12Z","797":"2021-11-24T19:53:46Z","798":"2021-05-21T15:28:49Z","799":"2021-07-24T17:55:55Z","800":"2021-08-23T14:53:03Z","801":"2021-11-24T15:06:20Z","802":"2021-11-24T13:11:05Z","803":"2020-09-03T17:44:44Z","804":"2020-12-09T10:02:09Z","805":"2021-11-24T11:08:59Z","806":"2021-09-15T14:58:46Z","807":"2021-11-23T09:52:45Z","808":"2021-02-16T11:45:35Z","809":"2021-11-24T07:58:47Z","810":"2020-12-30T15:38:26Z","811":"2021-11-24T05:56:36Z","812":"2021-08-05T08:27:26Z","813":"2021-11-23T22:21:16Z","814":"2021-11-23T18:22:14Z","815":"2021-11-23T18:21:12Z","816":"2021-11-23T18:15:34Z","817":"2021-11-23T17:35:00Z","818":"2021-06-18T19:38:28Z","819":"2021-03-06T19:25:37Z","820":"2021-11-23T16:02:28Z","821":"2021-09-13T21:10:29Z","822":"2021-11-23T14:13:51Z","823":"2021-11-23T13:16:31Z","824":"2021-11-23T12:53:16Z","825":"2021-11-23T12:09:15Z","826":"2021-11-23T10:23:58Z","827":"2021-11-13T17:27:49Z","828":"2021-02-02T11:59:28Z","829":"2021-04-26T11:00:56Z","830":"2021-04-13T19:59:34Z","831":"2021-11-22T23:30:52Z","832":"2021-10-06T14:44:51Z","833":"2021-11-12T16:16:46Z","834":"2021-11-22T20:38:41Z","835":"2021-11-22T19:11:52Z","836":"2021-11-22T18:59:34Z","837":"2021-11-22T17:29:20Z","838":"2021-11-22T17:21:21Z","839":"2021-11-22T16:39:30Z","840":"2020-11-14T22:18:45Z","841":"2021-11-22T13:10:41Z","842":"2021-11-22T12:55:36Z","843":"2021-09-06T03:44:43Z","844":"2021-11-22T11:02:35Z","845":"2021-11-22T10:50:39Z","846":"2021-11-22T07:33:40Z","847":"2021-11-22T07:27:17Z","848":"2021-11-22T07:19:12Z","849":"2021-10-29T02:36:24Z","850":"2021-08-11T08:43:13Z","851":"2021-03-04T21:08:06Z","852":"2021-11-22T03:46:52Z","853":"2021-11-22T02:56:04Z","854":"2021-11-22T02:45:23Z","855":"2020-09-15T01:18:21Z","856":"2021-11-21T15:53:15Z","857":"2021-11-21T13:19:23Z","858":"2021-11-21T11:21:50Z","859":"2021-10-18T08:20:40Z","860":"2021-11-21T07:22:44Z","861":"2021-11-21T06:05:12Z","862":"2021-11-21T05:48:32Z","863":"2021-11-20T22:28:23Z","864":"2020-05-12T21:26:04Z","865":"2021-10-05T07:35:32Z","866":"2021-09-29T11:15:00Z","867":"2021-11-20T13:13:58Z","868":"2021-11-18T07:46:35Z","869":"2021-11-20T03:56:37Z","870":"2021-11-20T02:45:35Z","871":"2021-11-20T02:22:12Z","872":"2021-11-20T00:00:56Z","873":"2021-11-19T19:03:22Z","874":"2021-06-27T13:32:39Z","875":"2020-10-06T20:05:43Z","876":"2021-11-19T13:57:26Z","877":"2021-10-31T15:41:56Z","878":"2021-11-19T12:10:16Z","879":"2020-05-20T14:08:56Z","880":"2021-11-19T12:03:53Z","881":"2021-11-19T11:43:59Z","882":"2021-11-19T11:13:37Z","883":"2021-11-19T10:34:23Z","884":"2019-08-31T12:08:53Z","885":"2021-11-19T08:50:48Z","886":"2021-11-19T08:47:32Z","887":"2021-09-10T21:31:42Z","888":"2021-11-17T04:25:11Z","889":"2021-10-28T20:31:04Z","890":"2020-12-08T04:31:38Z","891":"2021-11-19T05:58:39Z","892":"2021-11-19T05:09:16Z","893":"2021-04-12T16:18:20Z","894":"2021-11-19T04:52:45Z","895":"2021-11-18T19:47:45Z","896":"2020-11-13T20:57:53Z","897":"2021-10-20T18:00:40Z","898":"2021-11-18T18:03:36Z","899":"2021-11-18T17:27:32Z","900":"2021-11-18T16:47:56Z","901":"2021-11-18T14:24:34Z","902":"2021-11-17T10:47:47Z","903":"2021-11-16T21:33:07Z","904":"2018-08-24T10:29:45Z","905":"2021-11-18T12:54:07Z","906":"2021-10-14T13:50:52Z","907":"2021-11-18T11:58:19Z","908":"2021-11-18T11:24:48Z","909":"2021-11-18T10:52:48Z","910":"2021-11-18T10:39:01Z","911":"2021-11-18T08:25:09Z","912":"2021-06-15T07:37:52Z","913":"2021-04-18T11:39:33Z","914":"2021-09-01T23:40:38Z","915":"2021-10-21T05:38:45Z","916":"2021-11-18T05:02:31Z","917":"2021-11-18T04:07:09Z","918":"2021-08-18T23:46:46Z","919":"2021-06-15T05:40:51Z","920":"2021-10-27T04:49:45Z","921":"2021-11-17T20:31:16Z","922":"2021-09-14T01:25:15Z","923":"2021-11-10T17:45:33Z","924":"2021-10-28T16:06:42Z","925":"2021-11-17T18:30:34Z","926":"2021-11-17T18:20:04Z","927":"2021-10-14T14:54:52Z","928":"2021-11-17T17:35:00Z","929":"2021-11-16T17:30:56Z","930":"2021-08-26T16:34:51Z","931":"2021-05-13T15:27:00Z","932":"2021-10-28T15:39:11Z","933":"2021-11-17T14:31:55Z","934":"2021-11-17T12:33:42Z","935":"2021-11-17T12:10:03Z","936":"2021-11-17T11:46:43Z","937":"2021-11-17T11:06:39Z","938":"2021-06-21T14:36:38Z","939":"2021-11-17T07:09:59Z","940":"2021-11-17T05:00:51Z","941":"2021-08-04T23:27:10Z","942":"2021-04-18T08:13:06Z","943":"2021-04-03T10:52:14Z","944":"2021-11-16T19:00:03Z","945":"2021-11-16T17:44:24Z","946":"2021-11-16T17:24:11Z","947":"2021-09-02T17:58:08Z","948":"2021-11-16T16:43:07Z","949":"2021-11-16T15:59:49Z","950":"2021-11-16T15:18:01Z","951":"2021-11-16T15:15:58Z","952":"2021-11-16T15:12:37Z","953":"2021-11-16T14:58:05Z","954":"2021-11-16T14:31:09Z","955":"2021-11-16T14:12:08Z","956":"2021-11-16T13:39:26Z","957":"2021-11-16T12:20:47Z","958":"2021-07-07T20:20:10Z","959":"2021-10-28T17:31:51Z","960":"2021-11-16T11:55:27Z","961":"2021-05-08T08:53:16Z","962":"2021-09-14T08:21:18Z","963":"2021-11-16T07:34:25Z","964":"2021-11-16T03:14:40Z","965":"2021-11-16T03:00:29Z","966":"2021-11-16T02:17:49Z","967":"2021-11-16T01:45:26Z","968":"2021-11-16T01:16:43Z","969":"2021-11-15T23:11:24Z","970":"2021-11-15T23:07:19Z","971":"2021-11-15T21:25:18Z","972":"2021-11-15T18:54:58Z","973":"2020-07-30T19:25:00Z","974":"2021-10-15T17:38:08Z","975":"2021-11-15T17:36:41Z","976":"2021-11-15T16:57:59Z","977":"2021-11-15T16:44:16Z","978":"2021-11-15T16:07:15Z","979":"2021-11-15T14:58:09Z","980":"2021-11-15T14:28:21Z","981":"2021-04-25T10:59:31Z","982":"2021-08-21T10:21:21Z","983":"2021-11-15T12:09:08Z","984":"2021-04-26T15:12:13Z","985":"2020-10-24T08:06:18Z","986":"2021-11-08T08:10:47Z","987":"2021-11-15T09:02:10Z","988":"2021-05-31T14:11:08Z","989":"2021-11-15T08:13:26Z","990":"2021-11-12T17:34:11Z","991":"2021-10-09T09:24:11Z","992":"2021-11-15T05:58:29Z","993":"2021-11-06T18:09:22Z","994":"2021-11-15T03:56:50Z","995":"2021-09-09T12:32:28Z","996":"2021-11-14T21:26:18Z","997":"2021-11-14T20:58:04Z","998":"2021-09-29T02:25:39Z","999":"2021-11-14T18:29:19Z","1000":"2021-11-14T17:28:09Z","1001":"2021-11-14T16:30:45Z","1002":"2021-11-14T15:31:29Z","1003":"2020-07-14T03:49:43Z","1004":"2021-11-14T12:55:29Z","1005":"2021-11-10T14:58:29Z","1006":"2021-11-14T08:48:43Z","1007":"2021-11-14T06:37:01Z","1008":"2021-11-14T05:01:38Z","1009":"2021-11-14T03:02:07Z","1010":"2021-11-14T01:30:37Z","1011":"2021-11-13T21:48:18Z","1012":"2021-11-13T20:38:31Z","1013":"2021-11-13T19:54:15Z","1014":"2021-11-13T16:37:15Z","1015":"2021-11-13T14:28:47Z","1016":"2021-11-13T14:06:37Z","1017":"2021-05-19T16:12:01Z","1018":"2021-11-13T06:59:27Z","1019":"2020-05-01T21:42:32Z","1020":"2021-11-13T01:44:10Z","1021":"2021-01-01T00:52:53Z","1022":"2021-11-12T22:31:47Z","1023":"2021-11-12T19:01:06Z","1024":"2021-11-12T16:23:32Z","1025":"2021-11-12T16:00:39Z","1026":"2021-09-06T21:01:17Z","1027":"2021-11-12T11:18:46Z","1028":"2021-11-12T10:30:30Z","1029":"2021-11-12T10:23:43Z","1030":"2021-11-12T09:38:15Z","1031":"2021-11-12T08:18:21Z","1032":"2021-11-12T06:44:04Z","1033":"2020-10-28T06:32:41Z","1034":"2020-10-19T22:45:27Z","1035":"2021-11-12T00:57:42Z","1036":"2021-11-11T21:15:21Z","1037":"2021-02-15T05:23:08Z","1038":"2021-11-11T17:57:37Z","1039":"2021-11-11T17:48:31Z","1040":"2021-11-11T17:48:03Z","1041":"2021-11-11T17:44:50Z","1042":"2021-11-11T16:57:53Z","1043":"2021-11-11T14:26:15Z","1044":"2021-11-11T13:55:21Z","1045":"2021-09-01T12:35:26Z","1046":"2021-11-11T12:47:44Z","1047":"2021-11-11T10:32:33Z","1048":"2021-11-11T08:51:37Z","1049":"2021-11-11T07:39:16Z","1050":"2021-11-11T06:35:42Z","1051":"2021-11-11T05:00:58Z","1052":"2021-10-19T05:48:22Z","1053":"2021-11-11T01:51:01Z","1054":"2020-12-04T00:05:02Z","1055":"2021-11-10T23:37:23Z","1056":"2021-11-10T20:56:08Z","1057":"2021-11-10T20:51:29Z","1058":"2020-05-25T21:58:09Z","1059":"2021-11-10T17:39:10Z","1060":"2021-11-10T17:00:36Z","1061":"2021-11-10T16:53:50Z","1062":"2020-10-04T11:59:59Z","1063":"2021-11-10T15:52:40Z","1064":"2021-10-15T13:42:25Z","1065":"2021-11-10T12:33:18Z","1066":"2020-08-13T08:56:40Z","1067":"2021-11-10T10:05:11Z","1068":"2021-11-10T09:54:01Z","1069":"2021-10-29T15:53:06Z","1070":"2021-07-21T19:43:22Z","1071":"2021-07-15T17:54:36Z","1072":"2021-08-28T12:10:50Z","1073":"2021-11-08T16:55:03Z","1074":"2021-06-17T19:25:39Z","1075":"2021-11-09T20:53:25Z","1076":"2021-11-09T20:43:18Z","1077":"2021-11-09T20:32:30Z","1078":"2021-09-10T07:28:26Z","1079":"2020-12-30T21:37:28Z","1080":"2021-11-09T16:26:51Z","1081":"2021-11-09T15:29:43Z","1082":"2021-11-03T12:13:52Z","1083":"2021-11-03T14:58:52Z","1084":"2021-11-09T13:45:23Z","1085":"2021-11-09T13:30:34Z","1086":"2021-11-09T10:28:01Z","1087":"2021-03-19T08:36:52Z","1088":"2021-11-09T09:10:21Z","1089":"2021-11-09T07:45:11Z","1090":"2021-03-06T05:44:27Z","1091":"2021-11-06T18:33:20Z","1092":"2021-11-09T04:30:20Z","1093":"2021-11-09T03:31:18Z","1094":"2021-06-06T14:54:55Z","1095":"2021-11-01T00:55:32Z","1096":"2021-11-08T22:55:55Z","1097":"2021-03-05T18:59:39Z","1098":"2021-03-10T18:59:34Z","1099":"2021-05-20T17:58:42Z","1100":"2021-11-08T20:53:50Z","1101":"2021-11-08T19:43:53Z","1102":"2021-07-15T07:37:06Z","1103":"2021-08-19T16:53:43Z","1104":"2021-11-08T15:36:21Z","1105":"2021-11-08T15:01:06Z","1106":"2021-11-08T14:24:21Z","1107":"2021-10-31T14:44:01Z","1108":"2021-11-08T14:03:09Z","1109":"2021-11-08T13:49:15Z","1110":"2021-08-06T02:57:07Z","1111":"2021-09-14T13:28:13Z","1112":"2021-01-23T09:43:44Z","1113":"2021-11-08T08:18:25Z","1114":"2021-05-01T02:33:50Z","1115":"2021-11-08T03:54:09Z","1116":"2020-06-06T19:29:36Z","1117":"2021-04-18T07:50:31Z","1118":"2021-01-27T05:41:57Z","1119":"2021-11-07T22:31:41Z","1120":"2021-11-07T22:17:52Z","1121":"2021-11-07T19:31:51Z","1122":"2021-11-07T18:01:36Z","1123":"2021-11-07T17:13:59Z","1124":"2021-03-24T01:02:12Z","1125":"2021-11-07T14:35:00Z","1126":"2021-11-07T13:18:59Z","1127":"2021-11-07T11:24:08Z","1128":"2021-11-07T10:29:54Z","1129":"2021-11-07T09:53:31Z","1130":"2020-12-31T17:15:09Z","1131":"2021-06-10T14:37:28Z","1132":"2020-12-01T00:54:13Z","1133":"2021-11-06T19:59:03Z","1134":"2021-11-06T16:45:48Z","1135":"2021-08-29T01:52:11Z","1136":"2021-11-06T13:28:29Z","1137":"2021-11-06T09:04:16Z","1138":"2021-11-06T06:25:46Z","1139":"2021-11-06T04:25:53Z","1140":"2021-11-05T21:37:15Z","1141":"2021-11-05T20:06:58Z","1142":"2021-11-05T17:58:37Z","1143":"2021-11-05T17:50:14Z","1144":"2021-04-13T17:32:51Z","1145":"2021-11-05T16:57:08Z","1146":"2021-04-17T18:54:00Z","1147":"2021-10-25T10:19:17Z","1148":"2021-11-05T15:32:23Z","1149":"2021-11-05T15:09:10Z","1150":"2021-11-05T14:00:59Z","1151":"2021-11-05T13:31:56Z","1152":"2021-10-13T18:49:46Z","1153":"2021-11-05T10:31:25Z","1154":"2021-11-05T09:38:43Z","1155":"2021-11-05T09:36:41Z","1156":"2021-11-05T09:29:21Z","1157":"2021-04-18T07:42:45Z","1158":"2021-11-05T07:22:16Z","1159":"2021-11-05T07:07:48Z","1160":"2021-11-05T06:26:22Z","1161":"2021-11-05T04:14:35Z","1162":"2019-11-11T07:28:25Z","1163":"2021-09-18T12:58:55Z","1164":"2021-07-29T16:26:04Z","1165":"2021-10-25T15:14:42Z","1166":"2021-11-05T01:37:47Z","1167":"2021-11-05T00:56:00Z","1168":"2021-10-15T01:55:18Z","1169":"2021-07-07T18:55:03Z","1170":"2021-11-04T19:38:48Z","1171":"2021-11-04T19:08:14Z","1172":"2021-08-04T03:32:48Z","1173":"2021-08-10T21:24:05Z","1174":"2021-11-04T16:53:59Z","1175":"2021-11-03T12:56:13Z","1176":"2021-11-04T14:07:46Z","1177":"2021-09-29T05:30:39Z","1178":"2021-11-04T13:09:10Z","1179":"2021-11-03T14:49:50Z","1180":"2021-11-04T12:44:18Z","1181":"2021-11-04T11:20:54Z","1182":"2021-11-04T09:29:16Z","1183":"2021-11-04T08:44:31Z","1184":"2021-11-04T07:57:00Z","1185":"2021-09-23T07:47:28Z","1186":"2021-11-04T06:38:21Z","1187":"2020-06-03T22:39:24Z","1188":"2021-11-04T04:39:02Z","1189":"2021-11-04T03:19:52Z","1190":"2021-11-04T01:08:14Z","1191":"2021-11-04T00:43:15Z","1192":"2021-10-08T22:49:49Z","1193":"2021-11-03T20:54:20Z","1194":"2021-09-10T13:00:36Z","1195":"2020-11-20T12:17:21Z","1196":"2021-11-03T17:26:52Z","1197":"2021-11-03T17:20:36Z","1198":"2018-09-03T16:57:54Z","1199":"2021-11-03T16:20:16Z","1200":"2021-11-03T14:29:24Z","1201":"2021-11-02T15:37:33Z","1202":"2021-11-03T13:36:47Z","1203":"2021-11-03T13:03:17Z","1204":"2021-11-03T12:24:03Z","1205":"2021-10-19T21:17:30Z","1206":"2021-11-03T10:36:32Z","1207":"2021-11-03T10:16:39Z","1208":"2021-09-18T11:55:32Z","1209":"2021-11-03T09:16:17Z","1210":"2021-11-03T07:00:20Z","1211":"2019-08-18T10:34:59Z","1212":"2021-04-18T03:44:57Z","1213":"2021-06-23T17:51:26Z","1214":"2021-11-03T03:31:14Z","1215":"2021-11-03T03:03:19Z","1216":"2021-11-02T15:48:28Z","1217":"2021-06-03T01:47:26Z","1218":"2021-11-02T17:03:29Z","1219":"2021-11-02T16:17:20Z","1220":"2021-05-20T11:40:30Z","1221":"2021-11-02T13:17:20Z","1222":"2021-11-02T12:25:04Z","1223":"2021-11-02T11:42:54Z","1224":"2021-11-02T10:14:17Z","1225":"2021-11-02T10:08:46Z","1226":"2021-11-02T08:07:55Z","1227":"2021-11-02T07:16:03Z","1228":"2021-09-18T20:59:52Z","1229":"2021-10-05T09:30:59Z","1230":"2021-11-02T02:58:45Z","1231":"2021-11-02T01:55:17Z","1232":"2021-11-02T01:50:09Z","1233":"2021-11-02T00:39:21Z","1234":"2021-10-08T20:17:10Z","1235":"2021-11-01T20:08:05Z","1236":"2021-09-10T21:22:09Z","1237":"2021-11-01T19:42:08Z","1238":"2021-04-14T22:14:41Z","1239":"2021-11-01T18:58:50Z","1240":"2021-03-01T19:01:01Z","1241":"2021-09-16T17:07:45Z","1242":"2021-11-01T18:38:47Z","1243":"2021-11-01T16:50:07Z","1244":"2021-10-18T16:47:45Z","1245":"2021-11-01T15:30:15Z","1246":"2021-11-01T15:27:27Z","1247":"2021-10-23T11:57:36Z","1248":"2021-11-01T14:42:50Z","1249":"2021-10-18T14:05:36Z","1250":"2021-11-01T14:37:06Z","1251":"2021-11-01T14:35:14Z","1252":"2021-11-01T12:21:05Z","1253":"2021-11-01T11:02:01Z","1254":"2021-11-01T10:21:58Z","1255":"2020-10-20T05:41:35Z","1256":"2021-10-08T22:40:33Z","1257":"2020-10-21T13:44:35Z","1258":"2021-11-01T08:37:30Z","1259":"2021-04-23T12:36:13Z","1260":"2021-02-17T03:28:17Z","1261":"2021-11-01T07:08:46Z","1262":"2021-11-01T04:51:51Z","1263":"2021-11-01T03:29:36Z","1264":"2021-11-01T02:50:53Z","1265":"2021-01-16T10:49:39Z","1266":"2021-10-31T22:50:33Z","1267":"2021-10-31T22:48:30Z","1268":"2021-10-31T20:10:21Z","1269":"2021-10-31T19:12:29Z","1270":"2021-10-31T19:01:07Z","1271":"2021-10-27T21:25:10Z","1272":"2021-10-31T17:57:49Z","1273":"2021-10-31T17:51:12Z","1274":"2021-10-31T16:35:36Z","1275":"2021-04-11T17:49:21Z","1276":"2021-10-31T13:09:19Z","1277":"2021-10-31T07:13:34Z","1278":"2021-10-31T04:06:07Z","1279":"2021-10-31T03:50:19Z","1280":"2021-04-06T02:17:20Z","1281":"2021-10-30T22:02:22Z","1282":"2021-10-30T19:04:48Z","1283":"2021-01-04T19:56:01Z","1284":"2021-09-04T16:40:06Z","1285":"2021-09-17T19:07:27Z","1286":"2021-10-26T09:26:10Z","1287":"2021-05-01T17:37:01Z","1288":"2021-07-11T12:56:47Z","1289":"2021-10-30T11:07:43Z","1290":"2021-03-10T02:18:46Z","1291":"2021-10-30T07:11:24Z","1292":"2021-10-30T06:53:48Z","1293":"2021-10-30T06:53:41Z","1294":"2021-09-11T04:24:51Z","1295":"2021-10-30T05:33:05Z","1296":"2021-10-30T03:29:47Z","1297":"2021-10-29T18:28:49Z","1298":"2021-10-29T17:59:04Z","1299":"2021-10-29T17:27:34Z","1300":"2021-10-29T16:51:50Z","1301":"2021-10-29T15:59:11Z","1302":"2021-10-07T16:41:15Z","1303":"2020-10-23T16:51:09Z","1304":"2021-04-16T12:44:40Z","1305":"2020-10-23T11:16:53Z","1306":"2021-10-29T13:45:38Z","1307":"2021-10-29T13:26:05Z","1308":"2021-09-21T15:32:26Z","1309":"2021-10-29T11:07:59Z","1310":"2021-10-29T10:02:43Z","1311":"2021-10-29T08:37:46Z","1312":"2021-10-29T08:36:47Z","1313":"2021-10-28T16:26:50Z","1314":"2021-10-29T07:58:49Z","1315":"2021-10-29T07:15:35Z","1316":"2021-10-29T05:20:31Z","1317":"2021-10-29T05:15:17Z","1318":"2021-10-29T04:36:31Z","1319":"2021-10-29T04:01:32Z","1320":"2021-10-28T22:14:39Z","1321":"2021-10-28T20:39:02Z","1322":"2021-01-20T18:43:11Z","1323":"2020-05-21T20:55:22Z","1324":"2021-10-28T19:37:43Z","1325":"2021-10-28T17:57:26Z","1326":"2021-10-28T17:43:06Z","1327":"2021-10-28T15:45:44Z","1328":"2021-10-12T19:55:55Z","1329":"2021-10-28T14:57:51Z","1330":"2021-10-28T14:20:43Z","1331":"2020-10-14T16:26:13Z","1332":"2021-10-28T14:09:44Z","1333":"2021-10-28T14:05:21Z","1334":"2021-10-28T14:04:03Z","1335":"2021-05-04T12:48:17Z","1336":"2021-10-28T11:15:54Z","1337":"2021-10-28T09:08:35Z","1338":"2021-10-28T08:56:57Z","1339":"2021-10-28T08:32:27Z","1340":"2021-07-12T22:43:11Z","1341":"2021-10-28T04:45:55Z","1342":"2021-10-04T02:03:28Z","1343":"2021-10-28T01:54:02Z","1344":"2021-10-28T01:35:41Z","1345":"2021-03-21T19:55:46Z","1346":"2021-07-26T06:02:54Z","1347":"2021-07-30T14:07:34Z","1348":"2021-07-05T17:58:52Z","1349":"2021-06-01T20:36:48Z","1350":"2021-10-27T21:00:01Z","1351":"2021-02-08T11:10:27Z","1352":"2021-10-27T19:29:19Z","1353":"2021-02-15T11:50:47Z","1354":"2021-10-27T18:23:31Z","1355":"2021-10-27T16:37:13Z","1356":"2021-10-27T16:08:09Z","1357":"2021-06-14T21:15:36Z","1358":"2021-10-27T12:52:19Z","1359":"2021-06-22T03:20:53Z","1360":"2021-10-27T08:51:42Z","1361":"2021-10-27T08:40:16Z","1362":"2021-10-27T07:50:02Z","1363":"2021-10-27T06:25:31Z","1364":"2021-10-12T03:17:03Z","1365":"2021-10-27T05:32:25Z","1366":"2021-10-27T05:02:11Z","1367":"2021-02-16T22:24:29Z","1368":"2021-08-16T14:49:50Z","1369":"2021-10-27T00:04:33Z","1370":"2021-06-06T21:53:54Z","1371":"2021-10-26T19:33:40Z","1372":"2021-10-26T19:20:26Z","1373":"2021-10-26T17:39:18Z","1374":"2021-10-26T17:35:20Z","1375":"2021-06-10T17:32:25Z","1376":"2021-03-23T02:29:37Z","1377":"2021-10-06T23:50:46Z","1378":"2021-04-17T20:42:28Z","1379":"2020-12-15T18:57:40Z","1380":"2021-02-03T09:01:49Z","1381":"2021-10-26T14:59:16Z","1382":"2021-10-07T07:00:57Z","1383":"2021-03-11T07:23:45Z","1384":"2021-10-26T13:58:46Z","1385":"2021-10-26T13:28:53Z","1386":"2021-10-26T13:28:28Z","1387":"2021-10-26T13:19:28Z","1388":"2021-10-26T12:45:34Z","1389":"2021-08-18T06:49:58Z","1390":"2021-03-03T07:37:38Z","1391":"2021-10-26T11:20:24Z","1392":"2021-05-25T11:01:45Z","1393":"2020-09-15T07:09:26Z","1394":"2021-10-26T09:20:16Z","1395":"2021-10-26T09:00:44Z","1396":"2021-10-26T08:47:53Z","1397":"2021-10-26T08:23:20Z","1398":"2021-06-24T14:09:57Z","1399":"2021-10-26T08:10:35Z","1400":"2021-06-03T05:56:57Z","1401":"2021-10-12T05:31:46Z","1402":"2021-10-26T06:26:01Z","1403":"2021-06-07T17:47:16Z","1404":"2021-10-07T03:36:02Z","1405":"2021-10-26T04:03:45Z","1406":"2021-10-26T03:09:41Z","1407":"2019-08-08T20:51:17Z","1408":"2021-09-24T11:15:06Z","1409":"2021-10-25T23:23:56Z","1410":"2021-07-07T01:30:36Z","1411":"2021-10-25T20:04:19Z","1412":"2021-10-25T19:33:38Z","1413":"2021-10-25T18:51:41Z","1414":"2021-10-25T16:35:58Z","1415":"2021-05-06T07:10:00Z","1416":"2021-10-25T14:53:42Z","1417":"2021-10-25T13:37:48Z","1418":"2021-10-25T13:37:23Z","1419":"2020-05-05T14:31:24Z","1420":"2021-09-04T22:09:44Z","1421":"2021-07-02T13:32:33Z","1422":"2021-04-26T18:33:38Z","1423":"2021-10-25T09:46:46Z","1424":"2021-10-25T09:46:26Z","1425":"2021-10-25T07:11:02Z","1426":"2021-10-25T06:53:11Z","1427":"2021-10-08T04:24:51Z","1428":"2021-10-25T05:15:01Z","1429":"2021-10-25T05:12:10Z","1430":"2021-10-20T10:17:04Z","1431":"2021-10-22T07:10:41Z","1432":"2021-07-07T07:34:21Z","1433":"2021-10-25T02:41:27Z","1434":"2021-08-13T16:42:25Z","1435":"2021-10-25T00:54:57Z","1436":"2021-10-24T23:25:54Z","1437":"2021-10-24T23:25:29Z","1438":"2021-10-24T17:49:20Z","1439":"2021-10-24T16:50:37Z","1440":"2021-10-24T11:26:29Z","1441":"2021-10-24T11:12:48Z","1442":"2021-10-24T08:01:41Z","1443":"2021-09-09T18:58:14Z","1444":"2021-10-24T07:28:39Z","1445":"2021-10-24T07:10:39Z","1446":"2021-09-12T09:40:33Z","1447":"2021-10-24T04:13:52Z","1448":"2021-10-24T03:26:30Z","1449":"2021-10-24T03:18:04Z","1450":"2021-10-24T02:43:03Z","1451":"2021-10-24T00:21:46Z","1452":"2021-10-23T21:34:09Z","1453":"2021-09-17T01:12:34Z","1454":"2021-10-23T15:22:45Z","1455":"2021-10-18T02:01:39Z","1456":"2021-10-23T12:06:51Z","1457":"2021-10-23T11:42:01Z","1458":"2021-10-04T04:54:50Z","1459":"2021-10-20T03:28:58Z","1460":"2021-10-13T05:20:57Z","1461":"2021-05-11T04:51:26Z","1462":"2021-06-16T18:13:55Z","1463":"2021-10-22T18:47:34Z","1464":"2021-10-22T17:48:03Z","1465":"2021-10-22T17:33:17Z","1466":"2021-10-22T17:22:05Z","1467":"2021-10-22T16:33:57Z","1468":"2021-10-22T16:07:16Z","1469":"2021-10-22T15:32:25Z","1470":"2021-09-30T12:54:26Z","1471":"2021-02-10T11:04:17Z","1472":"2021-10-22T10:33:08Z","1473":"2021-04-14T20:56:04Z","1474":"2021-09-15T12:05:28Z","1475":"2021-10-11T07:02:34Z","1476":"2021-10-22T08:31:02Z","1477":"2020-04-08T04:48:44Z","1478":"2021-10-22T05:04:40Z","1479":"2021-10-22T02:43:27Z","1480":"2021-06-01T03:13:35Z","1481":"2021-06-04T17:57:39Z","1482":"2021-10-21T23:13:04Z","1483":"2021-06-17T14:33:55Z","1484":"2021-09-28T16:51:38Z","1485":"2021-10-21T17:59:25Z","1486":"2021-10-21T17:41:56Z","1487":"2020-10-15T11:25:54Z","1488":"2021-10-21T15:32:30Z","1489":"2021-10-21T15:14:58Z","1490":"2021-04-08T00:45:20Z","1491":"2021-10-21T14:17:59Z","1492":"2021-10-21T13:04:21Z","1493":"2021-08-13T09:12:27Z","1494":"2021-10-21T08:36:11Z","1495":"2021-10-21T08:21:49Z","1496":"2021-09-22T20:49:16Z","1497":"2021-10-21T03:37:46Z","1498":"2021-10-21T03:21:58Z","1499":"2021-10-14T22:24:57Z","1500":"2021-04-17T23:29:55Z","1501":"2021-10-21T00:16:02Z","1502":"2021-04-18T00:14:29Z","1503":"2021-10-20T23:24:45Z","1504":"2021-10-20T21:05:02Z","1505":"2021-03-13T02:32:19Z","1506":"2021-10-20T20:37:11Z","1507":"2021-10-20T19:40:31Z","1508":"2021-06-17T15:45:54Z","1509":"2021-10-20T17:21:09Z","1510":"2021-10-20T14:08:14Z","1511":"2021-10-20T14:04:13Z","1512":"2020-10-20T12:04:19Z","1513":"2019-08-29T02:00:37Z","1514":"2021-01-15T10:40:37Z","1515":"2021-07-25T08:46:18Z","1516":"2021-10-20T10:38:57Z","1517":"2021-10-20T10:18:29Z","1518":"2020-08-20T18:20:29Z","1519":"2021-10-20T08:58:02Z","1520":"2021-10-20T08:42:10Z","1521":"2021-10-16T15:26:53Z","1522":"2021-10-12T09:43:10Z","1523":"2021-06-22T02:12:29Z","1524":"2021-10-20T04:52:54Z","1525":"2021-10-19T03:08:16Z","1526":"2021-10-20T02:20:53Z","1527":"2020-10-27T22:24:01Z","1528":"2021-10-20T00:59:36Z","1529":"2021-10-20T00:57:39Z","1530":"2021-10-20T00:10:37Z","1531":"2021-10-20T00:06:26Z","1532":"2021-10-12T22:42:31Z","1533":"2021-10-19T19:23:38Z","1534":"2021-10-19T19:10:34Z","1535":"2021-10-19T18:13:01Z","1536":"2021-10-19T18:07:07Z","1537":"2021-07-06T15:41:32Z","1538":"2021-09-04T22:48:46Z","1539":"2021-10-19T15:44:28Z","1540":"2021-10-19T14:35:29Z","1541":"2021-10-19T13:25:22Z","1542":"2021-10-19T12:26:40Z","1543":"2021-10-19T11:52:56Z","1544":"2021-10-19T10:34:40Z","1545":"2021-08-09T14:02:00Z","1546":"2021-10-07T16:56:17Z","1547":"2021-10-19T07:51:54Z","1548":"2021-10-19T06:10:42Z","1549":"2021-10-19T06:01:24Z","1550":"2020-08-06T16:17:35Z","1551":"2021-10-15T12:30:21Z","1552":"2021-10-19T03:58:44Z","1553":"2021-10-19T03:25:26Z","1554":"2020-11-22T00:25:55Z","1555":"2021-08-15T13:42:10Z","1556":"2021-10-19T02:35:10Z","1557":"2021-10-19T00:15:19Z","1558":"2021-10-18T22:51:21Z","1559":"2021-10-18T21:29:11Z","1560":"2021-10-12T13:35:01Z","1561":"2021-10-18T18:55:23Z","1562":"2021-10-18T18:46:20Z","1563":"2021-10-18T18:40:46Z","1564":"2021-07-29T12:49:03Z","1565":"2021-10-18T17:45:56Z","1566":"2021-10-18T17:35:41Z","1567":"2021-10-18T16:45:31Z","1568":"2021-10-18T15:53:15Z","1569":"2021-10-18T15:50:05Z","1570":"2021-10-18T15:24:32Z","1571":"2021-04-15T17:51:36Z","1572":"2021-10-18T13:48:28Z","1573":"2021-10-18T12:06:17Z","1574":"2020-03-28T07:54:03Z","1575":"2021-10-18T10:50:50Z","1576":"2021-10-14T07:22:23Z","1577":"2021-10-18T10:03:19Z","1578":"2021-10-18T08:52:31Z","1579":"2021-10-18T08:41:17Z","1580":"2021-10-18T08:30:50Z","1581":"2021-09-27T15:04:00Z","1582":"2021-09-10T05:49:55Z","1583":"2021-10-18T07:16:04Z","1584":"2021-10-18T06:15:11Z","1585":"2021-09-29T13:48:03Z","1586":"2021-07-08T19:37:06Z","1587":"2021-10-17T21:54:38Z","1588":"2021-03-27T04:08:37Z","1589":"2021-10-17T18:25:23Z","1590":"2021-10-17T17:36:53Z","1591":"2021-10-17T17:35:09Z","1592":"2021-10-17T15:16:34Z","1593":"2021-09-16T02:55:12Z","1594":"2021-10-17T07:27:43Z","1595":"2021-09-06T12:58:25Z","1596":"2021-10-16T23:43:24Z","1597":"2021-06-17T17:37:18Z","1598":"2021-10-16T16:22:43Z","1599":"2021-10-16T14:34:25Z","1600":"2019-08-24T11:40:08Z","1601":"2021-10-16T11:59:48Z","1602":"2021-10-16T11:44:23Z","1603":"2021-10-16T11:23:02Z","1604":"2021-10-16T10:48:52Z","1605":"2021-10-16T10:12:28Z","1606":"2021-10-16T10:04:14Z","1607":"2021-10-16T09:59:33Z","1608":"2021-10-16T09:49:43Z","1609":"2021-10-16T09:18:12Z","1610":"2021-08-31T10:54:32Z","1611":"2021-10-16T08:48:52Z","1612":"2021-10-16T03:51:53Z","1613":"2021-10-16T03:37:08Z","1614":"2021-10-16T03:27:56Z","1615":"2021-04-12T22:32:58Z","1616":"2021-10-16T02:10:16Z","1617":"2021-10-16T01:00:47Z","1618":"2021-10-16T00:50:08Z","1619":"2021-10-16T00:21:42Z","1620":"2021-10-16T00:20:04Z","1621":"2021-10-16T00:03:19Z","1622":"2021-10-15T23:59:42Z","1623":"2021-10-15T22:25:51Z","1624":"2021-05-03T17:51:09Z","1625":"2021-10-15T21:46:39Z","1626":"2021-10-15T21:41:16Z","1627":"2021-10-15T21:25:58Z","1628":"2021-10-15T20:37:29Z","1629":"2021-10-15T20:28:27Z","1630":"2021-10-15T19:20:25Z","1631":"2021-04-05T20:36:11Z","1632":"2021-06-03T17:35:14Z","1633":"2021-06-12T15:28:53Z","1634":"2021-09-10T07:39:10Z","1635":"2021-10-15T17:58:46Z","1636":"2021-10-15T17:58:45Z","1637":"2021-10-15T17:52:42Z","1638":"2021-10-15T17:38:16Z","1639":"2021-07-26T09:58:39Z","1640":"2021-10-15T17:18:02Z","1641":"2021-10-15T16:28:17Z","1642":"2021-10-15T16:03:40Z","1643":"2021-10-15T15:28:39Z","1644":"2021-10-15T14:36:45Z","1645":"2021-04-15T02:00:01Z","1646":"2021-10-15T12:09:04Z","1647":"2021-10-15T11:56:47Z","1648":"2021-10-15T11:32:17Z","1649":"2021-10-15T11:30:24Z","1650":"2021-10-15T11:19:28Z","1651":"2021-10-15T11:15:17Z","1652":"2021-10-15T11:13:46Z","1653":"2020-12-05T06:10:56Z","1654":"2021-10-15T10:10:34Z","1655":"2021-06-08T11:32:11Z","1656":"2021-10-15T08:36:13Z","1657":"2021-06-10T13:43:47Z","1658":"2021-10-15T08:00:20Z","1659":"2021-10-15T07:50:27Z","1660":"2021-08-24T11:07:46Z","1661":"2021-10-15T06:37:13Z","1662":"2021-10-15T05:43:59Z","1663":"2021-10-15T04:17:26Z","1664":"2021-09-14T16:52:16Z","1665":"2021-10-15T03:55:42Z","1666":"2021-10-15T03:27:45Z","1667":"2021-10-15T03:22:30Z","1668":"2021-10-15T03:13:59Z","1669":"2021-10-15T03:09:26Z","1670":"2021-10-15T03:03:09Z","1671":"2021-01-09T04:55:52Z","1672":"2021-10-15T02:50:09Z","1673":"2021-10-01T23:11:00Z","1674":"2021-10-15T02:31:48Z","1675":"2021-10-15T02:23:35Z","1676":"2021-10-15T01:56:46Z","1677":"2021-10-15T01:10:50Z","1678":"2021-04-18T06:24:48Z","1679":"2021-07-23T04:07:14Z","1680":"2021-10-14T21:40:03Z","1681":"2021-04-17T13:34:45Z","1682":"2021-10-13T16:08:29Z","1683":"2021-09-10T08:11:56Z","1684":"2021-10-14T20:03:36Z","1685":"2021-10-13T04:44:02Z","1686":"2021-10-14T19:52:47Z","1687":"2021-10-12T00:10:28Z","1688":"2021-08-18T11:48:40Z","1689":"2021-10-14T18:03:11Z","1690":"2021-10-14T17:56:35Z","1691":"2021-10-14T17:45:06Z","1692":"2021-10-14T17:38:20Z","1693":"2021-10-14T17:38:12Z","1694":"2021-10-14T17:37:04Z","1695":"2021-10-14T17:35:23Z","1696":"2021-10-14T17:27:29Z","1697":"2021-10-14T17:22:10Z","1698":"2021-05-24T14:50:04Z","1699":"2021-10-14T16:36:12Z","1700":"2021-09-24T03:49:38Z","1701":"2021-10-14T15:49:48Z","1702":"2021-08-02T08:44:22Z","1703":"2021-10-14T15:12:05Z","1704":"2021-10-14T14:58:53Z","1705":"2021-10-14T14:50:22Z","1706":"2021-10-14T14:42:38Z","1707":"2021-10-14T14:12:52Z","1708":"2021-10-14T14:11:12Z","1709":"2019-11-04T23:16:47Z","1710":"2021-10-14T13:52:55Z","1711":"2021-10-14T13:05:06Z","1712":"2021-10-14T13:04:38Z","1713":"2021-10-14T12:25:21Z","1714":"2019-04-12T13:05:06Z","1715":"2021-04-23T16:54:13Z","1716":"2021-10-14T12:14:22Z","1717":"2021-10-14T12:12:31Z","1718":"2020-10-23T20:09:01Z","1719":"2021-09-22T09:17:09Z","1720":"2021-10-14T09:22:17Z","1721":"2021-10-12T11:13:07Z","1722":"2021-10-13T13:14:32Z","1723":"2021-10-14T08:16:06Z","1724":"2021-10-14T08:15:04Z","1725":"2021-10-14T08:00:54Z","1726":"2021-10-14T06:50:19Z","1727":"2021-10-14T06:27:19Z","1728":"2021-10-14T06:02:54Z","1729":"2021-10-14T05:42:32Z","1730":"2021-10-14T05:26:39Z","1731":"2021-10-14T04:36:29Z","1732":"2021-10-14T04:05:25Z","1733":"2021-10-14T03:54:16Z","1734":"2021-10-14T03:50:23Z","1735":"2021-09-30T15:13:48Z","1736":"2021-10-13T22:11:11Z","1737":"2021-10-13T21:00:00Z","1738":"2021-03-11T21:24:41Z","1739":"2021-10-13T20:54:37Z","1740":"2021-09-13T20:31:57Z","1741":"2020-10-04T07:23:13Z","1742":"2021-10-13T19:30:40Z","1743":"2021-01-02T05:16:46Z","1744":"2021-10-13T19:16:59Z","1745":"2021-10-13T18:06:14Z","1746":"2021-10-13T17:58:22Z","1747":"2021-04-16T15:17:23Z","1748":"2021-10-13T17:39:25Z","1749":"2021-10-13T17:24:16Z","1750":"2021-10-13T17:16:46Z","1751":"2021-10-13T17:09:47Z","1752":"2021-10-13T17:02:29Z","1753":"2021-02-05T08:00:19Z","1754":"2021-10-13T16:35:22Z","1755":"2021-10-13T16:08:02Z","1756":"2021-10-13T14:25:21Z","1757":"2021-10-13T14:03:07Z","1758":"2021-10-13T12:18:09Z","1759":"2021-08-26T20:33:35Z","1760":"2021-10-13T10:25:06Z","1761":"2021-10-13T09:45:06Z","1762":"2021-05-06T09:43:33Z","1763":"2021-10-13T08:33:31Z","1764":"2021-10-13T08:16:52Z","1765":"2021-10-13T07:47:13Z","1766":"2021-09-16T09:56:20Z","1767":"2020-12-23T13:22:53Z","1768":"2021-10-13T06:57:47Z","1769":"2021-09-28T12:30:33Z","1770":"2021-10-13T05:46:57Z","1771":"2021-10-13T05:30:50Z","1772":"2021-10-13T05:15:00Z","1773":"2021-07-12T16:09:22Z","1774":"2021-10-13T04:14:49Z","1775":"2021-10-13T03:38:04Z","1776":"2021-10-13T02:56:16Z","1777":"2021-10-13T02:18:16Z","1778":"2021-10-12T05:36:54Z","1779":"2021-10-13T00:59:52Z","1780":"2021-09-07T15:06:12Z","1781":"2021-10-12T23:20:37Z","1782":"2021-10-12T23:02:35Z","1783":"2021-10-12T22:12:26Z","1784":"2021-10-12T21:43:37Z","1785":"2021-10-12T20:39:35Z","1786":"2021-10-12T19:23:25Z","1787":"2021-10-12T19:01:52Z","1788":"2021-10-12T18:47:18Z","1789":"2021-10-12T18:00:02Z","1790":"2021-10-12T17:51:56Z","1791":"2021-10-12T16:45:33Z","1792":"2021-10-12T15:30:21Z","1793":"2021-04-17T11:07:36Z","1794":"2021-10-12T13:57:54Z","1795":"2021-10-12T13:41:06Z","1796":"2021-10-06T15:53:20Z","1797":"2021-10-12T11:06:03Z","1798":"2021-10-12T10:33:02Z","1799":"2021-10-11T10:39:13Z","1800":"2021-10-12T10:01:32Z","1801":"2021-06-10T12:47:36Z","1802":"2021-10-11T05:30:30Z","1803":"2021-10-12T09:23:57Z","1804":"2021-10-12T09:00:46Z","1805":"2021-05-26T16:30:16Z","1806":"2020-08-28T18:22:19Z","1807":"2021-10-12T07:24:12Z","1808":"2021-10-12T07:12:56Z","1809":"2021-03-04T15:50:17Z","1810":"2021-10-11T03:52:37Z","1811":"2021-10-12T05:43:30Z","1812":"2021-10-12T05:39:48Z","1813":"2021-10-12T03:52:49Z","1814":"2021-10-12T03:18:10Z","1815":"2021-10-12T03:12:34Z","1816":"2021-09-04T23:08:57Z","1817":"2021-10-12T02:35:45Z","1818":"2021-10-10T07:40:22Z","1819":"2021-10-12T02:23:00Z","1820":"2021-10-12T01:45:27Z","1821":"2021-10-12T01:05:37Z","1822":"2021-04-26T17:55:33Z","1823":"2021-10-12T00:45:42Z","1824":"2021-10-11T22:12:46Z","1825":"2021-10-11T19:28:11Z","1826":"2021-10-11T19:23:50Z","1827":"2021-10-11T17:55:07Z","1828":"2021-10-11T17:48:11Z","1829":"2021-10-11T17:35:34Z","1830":"2021-10-11T17:07:58Z","1831":"2021-10-11T17:07:38Z","1832":"2021-09-20T17:56:08Z","1833":"2021-10-11T16:09:01Z","1834":"2021-10-11T15:55:11Z","1835":"2021-10-11T15:52:16Z","1836":"2021-10-11T15:41:47Z","1837":"2021-06-16T15:28:22Z","1838":"2021-10-11T14:18:29Z","1839":"2021-10-11T14:00:08Z","1840":"2021-10-11T13:05:06Z","1841":"2021-10-11T12:36:30Z","1842":"2021-10-11T12:27:07Z","1843":"2021-10-11T11:53:12Z","1844":"2021-09-23T13:47:16Z","1845":"2021-05-12T18:23:51Z","1846":"2021-10-11T11:08:38Z","1847":"2019-02-04T17:14:13Z","1848":"2021-10-11T10:23:44Z","1849":"2021-09-30T00:50:51Z","1850":"2021-10-11T09:46:46Z","1851":"2021-10-11T09:33:34Z","1852":"2020-10-09T10:12:02Z","1853":"2020-10-08T09:17:55Z","1854":"2021-10-11T08:15:31Z","1855":"2021-10-11T07:42:41Z","1856":"2021-10-08T03:05:08Z","1857":"2021-10-11T06:22:18Z","1858":"2021-10-11T03:21:33Z","1859":"2021-10-10T23:58:57Z","1860":"2021-10-10T20:01:27Z","1861":"2021-10-10T20:00:09Z","1862":"2021-04-25T21:34:51Z","1863":"2021-04-25T18:35:39Z","1864":"2021-05-16T20:46:29Z","1865":"2021-09-30T22:55:49Z","1866":"2021-10-10T18:49:19Z","1867":"2021-10-10T17:33:44Z","1868":"2021-04-16T12:23:56Z","1869":"2021-10-10T16:43:44Z","1870":"2021-10-10T16:23:54Z","1871":"2021-09-06T12:31:21Z","1872":"2021-10-10T15:27:45Z","1873":"2021-10-10T15:21:19Z","1874":"2021-10-10T14:31:08Z","1875":"2021-10-10T13:39:39Z","1876":"2021-04-15T08:23:05Z","1877":"2021-10-07T16:37:01Z","1878":"2021-10-10T10:27:20Z","1879":"2021-10-10T09:21:24Z","1880":"2021-10-10T05:44:02Z","1881":"2021-04-18T10:41:56Z","1882":"2021-10-09T21:28:26Z","1883":"2021-10-09T21:09:21Z","1884":"2021-10-09T18:02:55Z","1885":"2021-10-09T17:12:41Z","1886":"2021-10-09T17:11:17Z","1887":"2021-04-16T16:16:44Z","1888":"2021-10-09T15:06:09Z","1889":"2021-09-19T16:39:22Z","1890":"2021-10-09T11:39:30Z","1891":"2021-10-09T09:36:22Z","1892":"2020-12-03T10:42:56Z","1893":"2021-10-09T09:15:56Z","1894":"2021-10-09T09:15:05Z","1895":"2021-10-09T07:09:22Z","1896":"2021-10-09T07:00:38Z","1897":"2021-10-09T06:51:16Z","1898":"2021-10-09T06:46:48Z","1899":"2021-07-20T06:44:13Z","1900":"2021-04-20T09:54:06Z","1901":"2021-10-09T03:24:38Z","1902":"2021-10-09T02:53:39Z","1903":"2021-07-10T02:13:25Z","1904":"2021-10-09T01:45:03Z","1905":"2021-10-09T00:39:35Z","1906":"2021-10-09T00:17:20Z","1907":"2021-10-08T23:37:25Z","1908":"2021-10-08T23:30:17Z","1909":"2021-10-08T21:57:08Z","1910":"2021-10-08T21:30:20Z","1911":"2021-10-08T20:51:52Z","1912":"2021-10-07T04:44:32Z","1913":"2021-10-08T18:39:59Z","1914":"2021-10-08T18:33:12Z","1915":"2021-08-17T14:08:23Z","1916":"2021-10-08T17:57:59Z","1917":"2021-10-08T17:10:31Z","1918":"2021-10-08T16:40:56Z","1919":"2021-10-08T15:41:27Z","1920":"2020-03-14T15:27:29Z","1921":"2021-10-08T14:18:36Z","1922":"2021-10-08T13:29:13Z","1923":"2021-09-13T06:25:45Z","1924":"2021-10-08T12:45:26Z","1925":"2021-10-08T11:27:40Z","1926":"2021-10-05T13:07:33Z","1927":"2021-10-08T10:01:36Z","1928":"2021-04-06T18:00:03Z","1929":"2021-10-08T09:52:42Z","1930":"2021-01-25T21:15:06Z","1931":"2021-09-24T08:07:29Z","1932":"2021-10-08T07:44:47Z","1933":"2021-03-29T16:09:00Z","1934":"2021-10-08T05:13:41Z","1935":"2021-10-08T03:36:09Z","1936":"2021-10-08T02:46:34Z","1937":"2021-10-08T02:09:28Z","1938":"2021-10-08T01:23:34Z","1939":"2021-10-08T01:19:10Z","1940":"2021-09-14T17:06:43Z","1941":"2021-09-10T02:06:48Z","1942":"2021-10-07T21:36:48Z","1943":"2021-10-05T20:08:25Z","1944":"2021-10-07T19:18:18Z","1945":"2021-10-07T18:29:06Z","1946":"2021-04-16T23:09:11Z","1947":"2021-10-07T15:50:56Z","1948":"2021-10-07T15:41:05Z","1949":"2021-10-07T15:29:22Z","1950":"2021-10-07T14:43:35Z","1951":"2021-10-07T12:27:31Z","1952":"2021-04-16T17:43:58Z","1953":"2021-10-07T11:45:31Z","1954":"2021-10-07T10:42:02Z","1955":"2021-10-07T10:22:04Z","1956":"2021-04-15T12:26:12Z","1957":"2021-10-07T09:34:00Z","1958":"2021-10-07T09:10:15Z","1959":"2021-10-07T08:51:49Z","1960":"2021-10-07T08:19:26Z","1961":"2021-10-07T06:59:46Z","1962":"2021-10-07T05:44:52Z","1963":"2021-10-01T07:40:56Z","1964":"2021-10-07T02:23:19Z","1965":"2021-10-05T00:33:09Z","1966":"2021-08-07T22:25:46Z","1967":"2021-01-23T02:54:30Z","1968":"2021-09-02T04:02:51Z","1969":"2021-10-06T21:12:46Z","1970":"2020-06-05T19:54:34Z","1971":"2021-10-06T20:07:53Z","1972":"2021-10-06T19:48:18Z","1973":"2021-10-06T18:20:37Z","1974":"2021-10-06T18:05:59Z","1975":"2021-06-14T18:48:40Z","1976":"2021-10-06T16:13:45Z","1977":"2021-10-06T16:10:32Z","1978":"2021-10-06T15:19:00Z","1979":"2021-10-06T15:09:32Z","1980":"2021-10-06T14:16:57Z","1981":"2021-04-14T17:52:38Z","1982":"2021-04-27T14:32:22Z","1983":"2021-07-30T14:02:52Z","1984":"2021-10-06T12:53:00Z","1985":"2021-10-05T17:50:48Z","1986":"2021-10-06T08:58:02Z","1987":"2021-10-06T08:42:09Z","1988":"2021-08-29T08:11:36Z","1989":"2021-10-06T06:17:05Z","1990":"2020-08-28T18:58:15Z","1991":"2021-10-06T03:53:25Z","1992":"2021-09-30T01:20:55Z","1993":"2021-10-06T02:48:58Z","1994":"2021-02-03T23:48:54Z","1995":"2020-12-04T19:51:31Z","1996":"2021-10-06T00:44:00Z","1997":"2021-10-05T23:33:28Z","1998":"2021-10-05T23:26:16Z","1999":"2021-10-05T23:20:37Z","2000":"2021-10-05T23:03:09Z","2001":"2021-10-05T22:36:46Z","2002":"2020-12-31T10:01:29Z","2003":"2021-10-05T21:40:46Z","2004":"2021-06-06T22:58:13Z","2005":"2020-10-22T17:49:42Z","2006":"2021-10-05T17:55:49Z","2007":"2021-10-05T17:47:15Z","2008":"2021-09-30T13:06:29Z","2009":"2021-10-05T17:44:41Z","2010":"2021-10-04T02:40:55Z","2011":"2020-04-07T14:13:38Z","2012":"2021-10-05T16:38:57Z","2013":"2020-07-21T20:11:18Z","2014":"2021-10-05T16:24:19Z","2015":"2020-04-30T15:00:21Z","2016":"2021-04-09T11:04:58Z","2017":"2021-09-27T08:43:25Z","2018":"2021-10-05T14:12:47Z","2019":"2021-10-05T13:55:47Z","2020":"2021-10-05T13:48:20Z","2021":"2021-10-05T13:33:08Z","2022":"2020-06-19T10:44:06Z","2023":"2021-10-05T13:21:40Z","2024":"2021-10-05T11:28:58Z","2025":"2021-10-05T11:24:24Z","2026":"2021-10-05T11:04:13Z","2027":"2021-10-05T07:45:55Z","2028":"2021-10-05T07:38:06Z","2029":"2021-10-05T06:28:37Z","2030":"2021-09-30T07:35:56Z","2031":"2021-10-05T04:44:37Z","2032":"2021-10-05T04:01:36Z","2033":"2021-10-05T03:37:57Z","2034":"2021-10-05T03:22:31Z","2035":"2021-02-23T09:22:29Z","2036":"2021-10-04T20:50:17Z","2037":"2021-05-14T13:45:40Z","2038":"2020-07-30T09:40:41Z","2039":"2021-10-04T18:15:32Z","2040":"2021-10-04T17:51:07Z","2041":"2021-10-04T17:17:38Z","2042":"2021-10-04T16:45:28Z","2043":"2021-10-04T16:44:16Z","2044":"2021-10-04T15:37:07Z","2045":"2021-04-15T15:51:41Z","2046":"2020-12-22T10:53:07Z","2047":"2021-10-04T13:08:53Z","2048":"2021-04-18T09:56:41Z","2049":"2021-10-04T12:26:14Z","2050":"2021-09-23T16:42:44Z","2051":"2020-07-17T16:45:22Z","2052":"2021-10-04T11:54:43Z","2053":"2021-10-04T11:33:51Z","2054":"2021-09-07T17:55:47Z","2055":"2021-09-16T12:22:17Z","2056":"2021-10-04T10:00:22Z","2057":"2021-10-04T09:43:47Z","2058":"2021-10-04T08:56:33Z","2059":"2021-10-04T08:51:36Z","2060":"2021-10-04T06:17:12Z","2061":"2021-10-04T04:51:11Z","2062":"2021-10-04T03:59:15Z","2063":"2021-10-04T02:52:14Z","2064":"2021-10-04T01:22:43Z","2065":"2021-10-03T22:38:31Z","2066":"2021-10-03T20:22:54Z","2067":"2021-09-20T03:01:46Z","2068":"2021-10-03T19:36:21Z","2069":"2021-10-03T19:10:28Z"},"title":{"0":"How do lexical semantics affect translation An empirical study","1":"A Deep Learning Approach to Integrate HumanLevel Understanding in a Chatbot","2":"Trends in Integration of Vision and Language Research. A Survey of Tasks Datasets and Methods","3":"Refining Language Models with Compositional Explanations","4":"Training and Generating Neural Networks in Compressed Weight Space","5":"Discovering Emotion and Reasoning its Flip in MultiParty Conversations using Masked Memory Network and Transformer","6":"OpenQA. Hybrid QA System Relying on Structured Knowledge Base as well as Nonstructured Data","7":"Designing an Automatic Agent for Repeated Language based Persuasion Games","8":"Deconfounded Visual Grounding","9":"Domain Adaptation with Category Attention Network for Deep Sentiment Analysis","10":"ERNIEViLG. Unified Generative Pretraining for Bidirectional VisionLanguage Generation","11":"What is Event Knowledge Graph. A Survey","12":"Diformer. Directional Transformer for Neural Machine Translation","13":"First order linear logic and tensor type calculus for categorial grammars","14":"Utilizing Wordnets for Cognate Detection among Indian Languages","15":"KIND. an Italian MultiDomain Dataset for Named Entity Recognition","16":"TextRGNN. Residual Graph Neural Networks for Text Classification","17":"Does QAbased intermediate training help finetuning language models for text classification","18":"YACLC. A Chinese Learner Corpus with Multidimensional Annotation","19":"Radiology Report Generation with a Learned Knowledge Base and Multimodal Alignment","20":"Knowledge Matters. Radiology Report Generation with General and Specific Knowledge","21":"Automatic MixedPrecision Quantization Search of BERT","22":"RheFrameDetect. A Text Classification System for Automatic Detection of Rhetorical Frames in AI from Open Sources","23":"Consistent Training and Decoding For Endtoend Speech Recognition Using Latticefree MMI","24":"FullSentence Models Perform Better in Simultaneous Translation Using the Information Enhanced Decoding Strategy","25":"QEMind. Alibabas Submission to the WMT21 Quality Estimation Shared Task","26":"U2. Unified Twopass Bidirectional Endtoend Model for Speech Recognition","27":"Application of Hierarchical Temporal Memory Theory for Document Categorization","28":"BERTphone. PhoneticallyAware Encoder Representations for UtteranceLevel Speaker and Language Recognition","29":"Attentionbased Bidirectional LSTM for Deceptive Opinion Spam Classification","30":"LeSICiN. A Heterogeneous Graphbased Approach for Automatic Legal Statute Identification from Indian Legal Documents","31":"Extending MultiSense Word Embedding to Phrases and Sentences for Unsupervised Semantic Applications","32":"Pointer over Attention. An Improved Bangla Text Summarization Approach Using Hybrid Pointer Generator Network","33":"Hocalarim. Mining Turkish Student Reviews","34":"FineTuning Transformers. Vocabulary Transfer","35":"Knowledge Bridging for Empathetic Dialogue Generation","36":"Unified Streaming and Nonstreaming Twopass Endtoend Model for Speech Recognition","37":"WeNet. Production oriented Streaming and Nonstreaming EndtoEnd Speech Recognition Toolkit","38":"FrequencyAware Contrastive Learning for Neural Machine Translation","39":"Variance of Twitter Embeddings and Temporal Trends of COVID19 cases","40":"Repairing Adversarial Texts through Perturbation","41":"Variational Learning for the Inverted BetaLiouville Mixture Model and Its Application to Text Categorization","42":"TEACh. Taskdriven Embodied Agents that Chat","43":"Fake or Genuine Contextualised Text Representation for Fake Review Detection","44":"Simple Interpretable and Stable Method for Detecting Words with Usage Change across Corpora","45":"Mirror Matching. Document Matching Approach in Seeddriven Document Ranking for Medical Systematic Reviews","46":"On learning an interpreted language with recurrent models","47":"Competency Problems. On Finding and Removing Artifacts in Language Data","48":"Polite Emotional Dialogue Acts for Conversational Analysis in Daily Dialog Data","49":"A Proposed Conceptual Framework for a Representational Approach to Information Retrieval","50":"Boosting Search Engines with Interactive Agents","51":"Robust Security Analysis Based on Random Geometry Theory for SatelliteTerrestrialVehicle Network","52":"A Survey on Gender Bias in Natural Language Processing","53":"Processing M.A. Castr\u00e9ns Materials. Multilingual Typed and Handwritten Manuscripts","54":"Cognitive Computing to Optimize IT Services","55":"Categorical Semantics of Reversible PatternMatching","56":"Pedagogical Word Recommendation. A novel task and dataset on personalized vocabulary acquisition for L2 learners","57":"Generating Empathetic Responses by Looking Ahead the Users Sentiment","58":"LINDA. Unsupervised Learning to Interpolate in Natural Language Processing","59":"A Preordered RNN Layer Boosts Neural Machine Translation in Low Resource Settings","60":"The University of Texas at Dallas HLTRIs Participation in EPICQA. Searching for Entailed Questions Revealing Novel Answer Nuggets","61":"Does CLIP Benefit Visual Question Answering in the Medical Domain as Much as it Does in the General Domain","62":"Can Social Ontological Knowledge Representations be Measured Using Machine Learning","63":"What do Large Language Models Learn about Scripts","64":"HOPE. A TaskOriented and HumanCentric Evaluation Framework Using Professional PostEditing Towards More Effective MT Evaluation","65":"A Passage to India. Pretrained Word Embeddings for Indian Languages","66":"Backpropagation through Signal Temporal Logic Specifications. Infusing Logical Structure into GradientBased Methods","67":"Contextual Sentence Analysis for the Sentiment Prediction on Financial Data","68":"Transformer Uncertainty Estimation with Hierarchical Stochastic Attention","69":"Bridging the Gap. Using Deep Acoustic Representations to Learn Grounded Language from Percepts and Raw Speech","70":"Secondary Use of Clinical Problem List Entries for Neural NetworkBased Disease Code Assignment","71":"Hamtajoo. A Persian Plagiarism Checker for Academic Manuscripts","72":"Higher Criticism for Discriminating WordFrequency Tables and Testing Authorship","73":"A Survey on nonEnglish Question Answering Dataset","74":"Parameter Differentiation based Multilingual Neural Machine Translation","75":"CUGE. A Chinese Language Understanding and Generation Evaluation Benchmark","76":"On the Optimality of Vagueness. Around Between and the Gricean Maxims","77":"HeteroQA. Learning towards QuestionandAnswering through Multiple Information Sources via Heterogeneous Graph Modeling","78":"Towards Personalized Answer Generation in ECommerce via MultiPerspective Preference Modeling","79":"Eventbased clinical findings extraction from radiology reports with pretrained language model","80":"New Methods  Metrics for LFQA tasks","81":"ArT. Allround Thinker for Unsupervised Commonsense QuestionAnswering","82":"Profitable TradeOff Between Memory and Performance In MultiDomain Chatbot Architectures","83":"Killing One Bird with Two Stones. Model Extraction and Attribute Inference Attacks against BERTbased APIs","84":"On the Languagespecificity of Multilingual BERT and the Impact of Finetuning","85":"Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter","86":"Automatically Detecting Cyberbullying Comments on Online Game Forums","87":"Delivery Issues Identification from Customer Feedback Data","88":"An Interdisciplinary Approach for the Automated Detection and Visualization of Media Bias in News Articles","89":"GKS. Graphbased Knowledge Selector for Taskoriented Dialog System","90":"Budget Sensitive Reannotation of Noisy Relation Classification Data Using Label Hierarchy","91":"Quantum Algorithm for the Shortest Superstring Problem","92":"Node Cooccurrence based Graph Neural Networks for Knowledge Graph Link Prediction","93":"Mischievous Nominal Constructions in Universal Dependencies","94":"Stance Quantification. Definition of the Problem","95":"Deeper Clinical Document Understanding Using Relation Extraction","96":"A Preliminary Study for Literary Rhyme Generation based on Neuronal Representation Semantics and Shallow Parsing","97":"PerCQA. Persian Community Question Answering Dataset","98":"CABACE. Injecting Character Sequence Information and Domain Knowledge for Enhanced Acronym and LongForm Extraction","99":"On Robustness and Bias Analysis of BERTbased Relation Extraction","100":"Combining Improvements for Exploiting Dependency Trees in Neural Semantic Parsing","101":"Reflective Decoding. Beyond Unidirectional Generation with OfftheShelf Language Models","102":"Controllable Data Synthesis Method for Grammatical Error Correction","103":"Distinguishing Transformative from Incremental Clinical Evidence. A Classifier of Clinical Research using Textual features from Abstracts and Citing Sentences","104":"Analyzing Scientific Publications using DomainSpecific Word Embedding and Topic Modelling","105":"Counterfactual Memorization in Neural Language Models","106":"Spoiler in a Textstack. How Much Can Transformers Help","107":"Automatic Evaluation and Moderation of Opendomain Dialogue Systems","108":"Measuring Attribution in Natural Language Generation Models","109":"BiDirectional Recurrent Neural Ordinary Differential Equations for Social Media Text Classification","110":"ERNIE 3.0 Titan. Exploring Largerscale Knowledge Enhanced Pretraining for Language Understanding and Generation","111":"Towards more patient friendly clinical notes through language models and ontologies","112":"TFW2V. An Enhanced Document Similarity Method for the Morphologically Rich Finnish Language","113":"More Than Words. Towards Better Quality Interpretations of Text Classifiers","114":"TODDA. Towards Boosting the Robustness of Taskoriented Dialogue Modeling on Spoken Conversations","115":"Sparsesoftmax. A Simpler and Faster Alternative Softmax Transformation","116":"A Primer on Pretrained Multilingual Language Models","117":"Pretrained Language Models as Prior Knowledge for Playing Textbased Games","118":"SPAGE. A Speaker and PositionAware Graph Neural Network Model for Emotion Recognition in Conversation","119":"Traffic event description based on Twitter data using Unsupervised Learning Methods for Indian road conditions","120":"Do MultiLingual Pretrained Language Models Reveal Consistent Token Attributions in Different Languages","121":"Investigating Effect of Dialogue History in Multilingual Task Oriented Dialogue Systems","122":"SubCharacter Tokenization for Chinese Pretrained Language Models","123":"Evolution and tradeoff dynamics of functional load","124":"VoiceMoji. A Novel OnDevice Pipeline for Seamless Emoji Insertion in Dictation","125":"Adaptive Beam Search to Enhance Ondevice Abstractive Summarization","126":"Quantifying Gender Biases Towards Politicians on Reddit","127":"Brazilian Portuguese Speech Recognition Using Wav2vec 2.0","128":"Characterizing and addressing the issue of oversmoothing in neural autoregressive sequence modeling","129":"Toward Educatorfocused Automated Scoring Systems for Reading and Writing","130":"CRASS. A Novel Data Set and Benchmark to Test Counterfactual Reasoning of Large Language Models","131":"Multimodal Analysis of memes for sentiment extraction","132":"A Survey on Text Classification. From Shallow to Deep Learning","133":"Reinforcement Learningbased Dialogue Guided Event Extraction to Exploit Argument Relations","134":"STEREO. Scientific Text Reuse in Open Access Publications","135":"The Importance of the Current Input in Sequence Modeling","136":"Annotation Curricula to Implicitly Train NonExpert Annotators","137":"On Theoretical Complexity and Boolean Satisfiability","138":"A Compact Survey on Event Extraction. Approaches and Applications","139":"A Label Dependenceaware Sequence Generation Model for Multilevel Implicit Discourse Relation Recognition","140":"A Survey of Natural Language Generation","141":"ConE. Cone Embeddings for MultiHop Reasoning over Knowledge Graphs","142":"SEOVER. Sentencelevel Emotion Orientation Vector based Conversation Emotion Recognition Model","143":"Towards Building ASR Systems for the Next Billion Users","144":"Domain Adaptation with Pretrained Transformers for Query Focused Abstractive Text Summarization","145":"How Should PreTrained Language Models Be FineTuned Towards Adversarial Robustness","146":"Jointtraining on Symbiosis Networks for Deep Nueral Machine Translation models","147":"SelfDistillation Mixup Training for Nonautoregressive Neural Machine Translation","148":"Reevaluating Adversarial Examples in Natural Language","149":"Language Understanding for Field and Service Robots in a Priori Unknown Environments","150":"Sentence Embeddings and Highspeed Similarity Search for Fast Computer Assisted Annotation of Legal Documents","151":"Towards a Science of HumanAI Decision Making. A Survey of Empirical Studies","152":"Voice Quality and Pitch Features in TransformerBased Speech Recognition","153":"Supervised Graph Contrastive Pretraining for Text Classification","154":"Morphological classifiers","155":"Lexiconconstrained Copying Network for Chinese Abstractive Summarization","156":"Multimodal Entity Tagging with Multimodal Knowledge Base","157":"Contrastive String Representation Learning using Synthetic Data","158":"An ASPbased Approach to Answering Natural Language Questions for Texts","159":"Taskoriented Dialogue Systems. performance vs. qualityoptima a review","160":"An Inference Approach To Question Answering Over Knowledge Graphs","161":"FewShot CrossLingual Stance Detection with SentimentBased PreTraining","162":"On CrossLingual Retrieval with Multilingual Text Encoders","163":"Regularizing EndtoEnd Speech Translation with Triangular Decomposition Agreement","164":"Are Words the Quanta of Human Language Extending the Domain of Quantum Cognition","165":"Machine Learning Based on Natural Language Processing to Detect Cardiac Failure in Clinical Narratives","166":"Watch Those Words. Video Falsification Detection Using WordConditioned Facial Motion","167":"How Much Coffee Was Consumed During EMNLP 2019 Fermi Problems. A New Reasoning Challenge for AI","168":"DBBERT. a Database Tuning Tool that Reads the Manual","169":"Towards General Natural Language Understanding with Probabilistic Worldbuilding","170":"Learning SemiStructured Representations of Radiology Reports","171":"Efficient Large Scale Language Modeling with Mixtures of Experts","172":"Fewshot Learning with Multilingual Language Models","173":"STEM. Unsupervised STructural EMbedding for Stance Detection","174":"A learning perspective on the emergence of abstractions. the curious case of phonemes","175":"VoxCeleb Enrichment for Age and Gender Recognition","176":"Training dataset and dictionary sizes matter in BERT models. the case of Baltic languages","177":"Spiral Language Modeling","178":"Between words and characters. A Brief History of OpenVocabulary Modeling and Tokenization in NLP","179":"Quantum Language Model with Entanglement Embedding for Question Answering","180":"Unifying Model Explainability and Robustness for Joint Text Classification and Rationale Extraction","181":"May the Force Be with Your Copy Mechanism. Enhanced SupervisedCopy Method for Natural Language Generation","182":"Article Reranking by MemoryEnhanced Key Sentence Matching for Detecting Previously FactChecked Claims","183":"Integrating Knowledge in EndtoEnd Automatic Speech Recognition for MandarinEnglish CodeSwitching","184":"LUC at ComMA2021 Shared Task. Multilingual Gender Biased and Communal Language Identification without using linguistic features","185":"Early Detection of SecurityRelevant Bug Reports using Machine Learning. How Far Are We","186":"Investigation of Densely Connected Convolutional Networks with Domain Adversarial Learning for Noise Robust Speech Recognition","187":"Unified Named Entity Recognition as WordWord Relation Classification","188":"Data Augmentation for Mental Health Classification on Social Media","189":"Predicting Patient Readmission Risk from Medical Text via Knowledge Graph Enhanced Multiview Graph Convolution","190":"SelfSupervised Knowledge Assimilation for ExpertLayman Text Style Transfer","191":"Continual Learning with Knowledge Transfer for Sentiment Classification","192":"Leveraging Transformers for Hate Speech Detection in Conversational CodeMixed Tweets","193":"SyntacticGCN Bert based Chinese Event Extraction","194":"Word Graph Guided Summarization for Radiology Findings","195":"The Web Is Your Oyster  KnowledgeIntensive NLP against a Very Large Web Corpus","196":"Multimodal Interactions Using Pretrained Unimodal Models for SIMMC 2.0","197":"Cascading Adaptors to Leverage English Data to Improve Performance of Question Answering for LowResource Languages","198":"Morpheme Boundary Detection  Grammatical Feature Prediction for Gujarati . Dataset  Model","199":"On the Universality of Deep Contextual Language Models","200":"Exploiting Adapters for Crosslingual Lowresource Speech Recognition","201":"Assessing Postediting Effort in the EnglishHindi Direction","202":"Best of Both Worlds. A Hybrid Approach for MultiHop Explanation with Declarative Facts","203":"SAS. SelfAugmentation Strategy for Language Model Pretraining","204":"Can we Fix the Scope for Coreference Problems and Solutions for Benchmarks beyond OntoNotes","205":"Explain Edit and Understand. Rethinking User Study Design for Evaluating Model Explanations","206":"EBERT. A Phrase and Product Knowledge Enhanced Language Model for Ecommerce","207":"Reasoning Chain Based Adversarial Attack for Multihop Question Answering","208":"MathBERT. A Pretrained Language Model for General NLP Tasks in Mathematics Education","209":"Sparsifying Sparse Representations for Passage Retrieval by Topk Masking","210":"NILCMetrix. assessing the complexity of written and spoken language in Brazilian Portuguese","211":"Transcribing Natural Languages for The Deaf via Neural Editing Programs","212":"An ensemble deep learning technique for detecting suicidal ideation from posts in social media platforms","213":"N24News. A New Dataset for Multimodal News Classification","214":"Challenge Dataset of Cognates and False Friend Pairs from Indian Languages","215":"Joint Chinese Word Segmentation and Partofspeech Tagging via Twostage Span Labeling","216":"A Multimodal Approach for Automatic Mania Assessment in Bipolar Disorder","217":"CLINX. pretrained language models and a study on crosstask transfer for concept extraction in the clinical domain","218":"Towards A Reliable GroundTruth For Biased Language Detection","219":"Maskcombine Decoding and Classification Approach for Punctuation Prediction with realtime Inference Constraints","220":"Neural News Recommendation with Event Extraction","221":"Expedition. A System for the Unsupervised Learning of a Hierarchy of Concepts","222":"HyperText. Endowing FastText with Hyperbolic Geometry","223":"KGBoost. A Classificationbased Knowledge Base Completion Method with Negative Sampling","224":"Evaluating Explanations. How much do explanations from the teacher aid students","225":"Overview of the HASOC Subtrack at FIRE 2021. Hate Speech and Offensive Content Identification in English and IndoAryan Languages","226":"VeeAlign. Multifaceted Context Representation using Dual Attention for Ontology Alignment","227":"Neural Architectures for Biological InterSentence Relation Extraction","228":"Twoview Graph Neural Networks for Knowledge Graph Completion","229":"Deep Learning for Text Style Transfer. A Survey","230":"Hyperbolic Disentangled Representation for FineGrained Aspect Extraction","231":"Threelevel Hierarchical Transformer Networks for Longsequence and Multiple Clinical Documents Classification","232":"NonSuicidal SelfInjury Online Posts. Implications for Mental Health Professionals","233":"Do You Think Its Biased How To Ask For The Perception Of Media Bias","234":"TASSY  A Text Annotation Survey System","235":"An Empirical Investigation of the Role of Pretraining in Lifelong Learning","236":"Towards Unsupervised Dense Information Retrieval with Contrastive Learning","237":"COMETATOMIC 2020. On Symbolic and Neural Commonsense Knowledge Graphs","238":"XLSR. Selfsupervised Crosslingual Speech Representation Learning at Scale","239":"Learning and Analyzing Generation Order for Undirected Sequence Models","240":"Quantum Mathematics in Artificial Intelligence","241":"Models in the Loop. Aiding Crowdworkers with Generative Annotation Assistants","242":"Pushing the Limits of Rule Reasoning in Transformers through Natural Language Satisfiability","243":"StyleGANNADA. CLIPGuided Domain Adaptation of Image Generators","244":"Khmer Word Search. Challenges Solutions and SemanticAware Search","245":"Gendered Language in Resumes and its Implications for Algorithmic Bias in Hiring","246":"Inherently Explainable Reinforcement Learning in Natural Language","247":"Learning to solve complex tasks by growing knowledge culturally across generations","248":"Detecting CrossLanguage Plagiarism using Open Knowledge Graphs","249":"Adapting DocumentGrounded Dialog Systems to Spoken Conversations using Data Augmentation and a Noisy Channel Model","250":"Simple Questions Generate Named Entity Recognition Datasets","251":"CrossSum. Beyond EnglishCentric CrossLingual Abstractive Text Summarization for 1500 Language Pairs","252":"Harnessing Crosslingual Features to Improve Cognate Detection for Lowresource Languages","253":"SelfSupervised Learning for speech recognition with Intermediate layer supervision","254":"A PropositionLevel Clustering Approach for MultiDocument Summarization","255":"ALP. Data Augmentation using Lexicalized PCFGs for FewShot Text Classification","256":"Pay More Attention to History. A Context Modeling Strategy for Conversational TexttoSQL","257":"NeuroLogic Aesque Decoding. Constrained Text Generation with Lookahead Heuristics","258":"Distilled DualEncoder Model for VisionLanguage Understanding","259":"CONFIT. Toward Faithful Dialogue Summarization with LinguisticallyInformed Contrastive Finetuning","260":"FewShot Semantic Parsing with Language Models Trained On Code","261":"Lacuna Reconstruction. Selfsupervised Pretraining for LowResource Historical Document Transcription","262":"Evidentialityguided Generation for KnowledgeIntensive NLP Tasks","263":"Amortized Noisy Channel Neural Machine Translation","264":"MAVE. A Product Dataset for Multisource Attribute Value Extraction","265":"Taming Repetition in Dialogue Generation","266":"Reconsidering the Past. Optimizing Hidden States in Language Models","267":"Extreme ZeroShot Learning for Extreme Text Classification","268":"ColBERTv2. Effective and Efficient Retrieval via Lightweight Late Interaction","269":"FRUIT. Faithfully Reflecting Updated Information in Text","270":"Constrained Abstractive Summarization. Preserving Factual Consistency with Constrained Generation","271":"Masked Measurement Prediction. Learning to Jointly Predict Quantities and Units from Textual Context","272":"DuQM. A Chinese Dataset of Linguistically Perturbed Natural Questions for Evaluating the Robustness of Question Matching Models","273":"QuALITY. Question Answering with Long Input Texts Yes","274":"Guiding Neural Story Generation with Reader Models","275":"Infusing Finetuning with Semantic Dependencies","276":"GoalDirected Story Generation. Augmenting Generative Language Models with Reinforcement Learning","277":"Idiomatic Expression Paraphrasing without Strong Supervision","278":"Improving Ethical Outcomes with MachineintheLoop. Broadening Human Understanding of Data Annotations","279":"SGEITL. Scene Graph Enhanced ImageText Learning for Visual Commonsense Reasoning","280":"Does Pretraining Induce Systematic Inference How Masked Language Models Acquire Commonsense Knowledge","281":"CLICKER. A Computational LInguistics Classification Scheme for Educational Resources","282":"Can Multilinguality benefit Nonautoregressive Machine Translation","283":"Hierarchical CrossModality Semantic Correlation Learning Model for Multimodal Summarization","284":"BlockSkim. Efficient Question Answering for Transformer","285":"A Deep Learning Approach for Ontology Enrichment from Unstructured Text","286":"Neural Content Extraction for Poster Generation of Scientific Papers","287":"ProsodyAware Neural Machine Translation for Dubbing","288":"Learning Rich Representation of Keyphrases from Text","289":"Play the Shannon Game With Language Models. A HumanFree Approach to Summary Evaluation","290":"Intelligent Online Selling Point Extraction for ECommerce Recommendation","291":"Trees in transformers. a theoretical analysis of the Transformers ability to represent trees","292":"PennHelsinki Parsed Corpus of Early Modern English. First Parsing Results and Analysis","293":"Human Languages with Greater Information Density Increase Communication Speed but Decrease Conversation Breadth","294":"Linguistic Knowledge in Data Augmentation for Natural Language Processing. An Example on Chinese Question Matching","295":"Inducing Meaningful Units from Character Sequences with Slot Attention","296":"Learning NonMonotonic Automatic PostEditing of Translations from Human Orderings","297":"InstaVAX. A Multimodal Benchmark for AntiVaccine and Misinformation Posts Detection on Social Media","298":"Applying SoftTriple Loss for Supervised Language Model Fine Tuning","299":"Automatic Product Copywriting for ECommerce","300":"DSGPT. DomainSpecific Generative PreTraining of Transformers for Text Generation in Ecommerce Title and Review Summarization","301":"Design Challenges for a MultiPerspective Search Engine","302":"Database Search Results Disambiguation for TaskOriented Dialog Systems","303":"Simple Text Detoxification by Identifying a Linear Toxic Subspace in Language Model Embeddings","304":"DG2. Data Augmentation Through Document Grounded Dialogue Generation","305":"Challenges in Generalization in Open Domain Question Answering","306":"AllWOZ. Towards Multilingual TaskOriented Dialog Systems for All","307":"Evaluating Pretrained Transformer Models for Entity Linking in TaskOriented Dialog","308":"CheckDST. Measuring RealWorld Generalization of Dialogue State Tracking Performance","309":"Decomposing Natural Logic Inferences in Neural NLI","310":"KGR4. Retrieval Retrospect Refine and Rethink for Commonsense Generation","311":"Is Speech Emotion Recognition LanguageIndependent Analysis of English and Bangla Languages using LanguageIndependent Vocal Features","312":"One System to Rule them All. a Universal Intent Recognition System for Customer Service Chatbots","313":"Estce que vous compute Codeswitching cultural identity and AI","314":"Improving Coherence and Consistency in Neural Sequence Models with DualSystem NeuroSymbolic Reasoning","315":"Profiling Gas Consumption in Solidity Smart Contracts","316":"GraphBased Learning for Stock Movement Prediction with Textual and Relational Data","317":"Lesan  Machine Translation for Low Resource Languages","318":"ParsiNorm. A Persian Toolkit for Speech Processing Normalization","319":"One size does not fit all. Investigating strategies for differentiallyprivate learning across NLP tasks","320":"Faster Nearest Neighbor Machine Translation","321":"Improving Conversational Recommendation Systems Quality with ContextAware Item Meta Information","322":"Assisted Text Annotation Using Active Learning to Achieve High Quality with Little Effort","323":"Measuring a Texts Fairness Dimensions Using Machine Learning Based on Social Psychological Factors","324":"The Golden Rule as a Heuristic to Measure the Fairness of Texts Using Machine Learning","325":"Cognitionaware Cognate Detection","326":"Relaxed Attention. A Simple Method to Boost Performance of EndtoEnd Automatic Speech Recognition","327":"Named entity recognition architecture combining contextual and global features","328":"Solving the Data Sparsity Problem in Predicting the Success of the Startups with Machine Learning Methods","329":"The exploitation of Multiple Feature Extraction Techniques for Speaker Identification in Emotional States under Disguised Voices","330":"Revealing Persona Biases in Dialogue Systems","331":"KnowledgeGrounded Dialogue Generation with a Unified Knowledge Representation","332":"Unified Multimodal Pretraining and Promptbased Tuning for VisionLanguage Understanding and Generation","333":"Large Dual Encoders Are Generalizable Retrievers","334":"Event Linking. Grounding Event Mentions to Wikipedia","335":"KnowledgeRich SelfSupervised Entity Linking","336":"Lex Rosetta. Transfer of Predictive Models Across Languages Jurisdictions and Legal Domains","337":"Learning to Transpile AMR into SPARQL","338":"Oracle Linguistic Graphs Complement a Pretrained Transformer Language Model. A Crossformalism Comparison","339":"Tracing Text Provenance via ContextAware Lexical Substitution","340":"CrossDomain Generalization and Knowledge Transfer in Transformers Trained on Legal Data","341":"FineTuning Large Neural Language Models for Biomedical Natural Language Processing","342":"Online antiSemitism across platforms","343":"Playing Lottery Tickets with Vision and Language","344":"Do Answers to Boolean Questions Need Explanations Yes","345":"Boosted Dense Retriever","346":"How are cities pledging net zero A computational approach to analyzing subnational climate strategies","347":"Classifying Emails into Human vs Machine Category","348":"Representing Inferences and their Lexicalization","349":"Learning to Retrieve Passages without Supervision","350":"Types of OutofDistribution Texts and How to Detect Them","351":"Factual Probing Is MASK. Learning vs. Learning to Recall","352":"On the Use of External Data for Spoken Named Entity Recognition","353":"Towards Interactive Language Modeling","354":"Wordlevel Embeddings for CrossTask Transfer Learning in Speech Processing","355":"A costbenefit analysis of crosslingual transfer methods","356":"Scaling Up QueryFocused Summarization to Meet OpenDomain Question Answering","357":"Robustness Evaluation of Entity Disambiguation Using Prior Probes.the Case of Entity Overshadowing","358":"CoCoBERT. Improving VideoLanguage Pretraining with Contrastive Crossmodal Matching and Denoising","359":"Sentiment Dynamics of Success. Fractal Scaling of Story Arcs Predicts Reader Preferences","360":"Measuring Fairness with Biased Rulers. A Survey on Quantifying Biases in Pretrained Language Models","361":"Text Classification Models for Form Entity Linking","362":"Exploring the Limits of Natural Language Inference Based Setup for FewShot Intent Detection","363":"Identification of Biased Terms in News Articles by Comparison of Outletspecific Word Embeddings","364":"You Only Need One Model for Opendomain Question Answering","365":"MetaQA. Combining Expert Agents for MultiSkill Question Answering","366":"MultiInstance Training for Question Answering Across Table and Linked Text","367":"Model UncertaintyAware Knowledge Amalgamation for PreTrained Language Models","368":"Conversational Search with MixedInitiative  Asking Good Clarification Questions backedup by Passage Retrieval","369":"TopNet. Learning from Neural Topic Model to Generate Long Stories","370":"Improving Hybrid CTCAttention Endtoend Speech Recognition with Pretrained Acoustic and Language Model","371":"From Dense to Sparse. Contrastive Pruning for Better Pretrained Language Model Compression","372":"SentenceT5. Scalable Sentence Encoders from Pretrained TexttoText Models","373":"KddRES. A Multilevel Knowledgedriven Dialogue Dataset for Restaurant Towards Customized Dialogue System","374":"Discovering Explanatory Sentences in Legal Case Decisions Using Pretrained Language Models","375":"Native Chinese Reader. A Dataset Towards NativeLevel Chinese Machine Reading Comprehension","376":"NonParametric Online Learning from Human Feedback for Neural Machine Translation","377":"Open Intent Discovery through Unsupervised Semantic Clustering and Dependency Parsing","378":"MultiModal Answer Validation for KnowledgeBased VQA","379":"Building on Huang et al. GlossBERT for Word Sense Disambiguation","380":"OutofScope Domain and Intent Classification through Hierarchical Joint Modeling","381":"BACON. DeepLearning Powered AI for Poetry Generation with Author Linguistic Style Transfer","382":"Language Models are not Models of Language","383":"Framework para Caracterizar Fake News en Terminos de Emociones","384":"Event Based TimeVectors for auditory features extraction. a neuromorphic approach for low power audio recognition","385":"Controlled Cue Generation for Play Scripts","386":"GLaM. Efficient Scaling of Language Models with MixtureofExperts","387":"Improving and Diagnosing KnowledgeBased Visual Question Answering via Entity Enhanced Knowledge Injection","388":"A Heuristicdriven Uncertainty based Ensemble Framework for Fake News Detection in Tweets and News Articles","389":"Sparse Interventions in Language Models with Differentiable Masking","390":"Keyphrase Generation Beyond the Boundaries of Title and Abstract","391":"Khmer Text Classification Using Word Embedding and Neural Networks","392":"Attentive Contextual Carryover for MultiTurn EndtoEnd Spoken Language Understanding","393":"RoofBERT. Divide Understanding Labour and Join in Work","394":"Generating Fluent Fact Checking Explanations with Unsupervised PostEditing","395":"ANEA. Automated Named Entity Annotation for German DomainSpecific Texts","396":"Understanding and Improving the Exemplarbased Generation for Opendomain Conversation","397":"RetrievalSum. A Retrieval Enhanced Framework for Abstractive Summarization","398":"Detecting Emotion Carriers by Combining Acoustic and Lexical Representations","399":"English2Gbe. A multilingual machine translation model for FonEweGbe","400":"A Study on Token Pruning for ColBERT","401":"Translating Human Mobility Forecasting through Natural Language Generation","402":"Automated Evidence Collection for Fake News Detection","403":"Mastering the Explicit Opinionrole Interaction. Syntaxaided Neural Transition System for Unified Opinion Role Labeling","404":"Match Your Words A Study of Lexical Matching in Neural Information Retrieval","405":"On the Compression of Natural Language Models","406":"Predicting User CodeSwitching Level from Sociological and Psychological Profiles","407":"Plurality and Quantification in Graph Representation of Meaning","408":"Response Generation with ContextAware Prompt Learning","409":"DialogBERT. DiscourseAware Response Generation via Learning to Recover and Rank Utterances","410":"A Survey of Toxic Comment Classification Methods","411":"ISEEQ. Information Seeking Question Generation using Dynamic MetaInformation Retrieval and Knowledge Graphs","412":"Dependency Learning for Legal Judgment Prediction with a Unified TexttoText Transformer","413":"ValueNet. A New Dataset for Human Value Driven Dialogue System","414":"Graphbased hierarchical record clustering for unsupervised entity resolution","415":"Improving Codeswitching Language Modeling with Artificially Generated Texts using Cycleconsistent Adversarial Networks","416":"Reading Task Classification Using EEG and EyeTracking Data","417":"Improving Speech Recognition on Noisy Speech via Speech Enhancement with MultiDiscriminators CycleGAN","418":"Towards More Efficient Insertion Transformer with Fractional Positional Encoding","419":"Improving LogicalLevel Natural Language Generation with TopicConditioned Data Augmentation and Logical Form Generation","420":"FewShot OutofDomain Transfer Learning of Natural Language Explanations","421":"Learning Nigerian accent embeddings from speech. preliminary results based on SautiDBNaija corpus","422":"Predicting AboveSentence Discourse Structure using Distant Supervision from Topic Segmentation","423":"Topic Detection and Tracking with TimeAware Document Embeddings","424":"CommunicationEfficient Federated Learning for Neural Machine Translation","425":"Injecting Numerical Reasoning Skills into Knowledge Base Question Answering Models","426":"RationaleInspired Natural Language Explanations with Commonsense","427":"M2P2. Multimodal Persuasion Prediction using Adaptive Fusion","428":"For the Purpose of Curry. A UD Treebank for Ashokan Prakrit","429":"ZeroShot CrossLingual Transfer in Legal Domain Using Transformer Models","430":"Efficient Documentlevel Event Extraction via PseudoTriggeraware Pruned Complete Graph","431":"CliniQG4QA. Generating Diverse Questions for Domain Adaptation of Clinical Question Answering","432":"Prosody Labelled Dataset for Hindi using SemiAutomated Approach","433":"Detecting Potentially Harmful and Protective Suiciderelated Content on Twitter. A Machine Learning Approach","434":"An Empirical Study on Relation Extraction in the Biomedical Domain","435":"Bad Characters. Imperceptible NLP Attacks","436":"TempoQR. Temporal Question Reasoning over Knowledge Graphs","437":"Am I Me or You StateoftheArt Dialogue Models Cannot Maintain an Identity","438":"Revisiting the Boundary between ASR and NLU in the Age of Conversational Dialog Systems","439":"ExplanationBased Human Debugging of NLP Models. A Survey","440":"Sequencelevel selflearning with multiple hypotheses","441":"AtteSTNet  An attention and subword tokenization based approach for codeswitched HindiEnglish hate speech detection","442":"LSH methods for data deduplication in a Wikipedia artificial dataset","443":"ComputerAssisted Creation of Boolean Search Rules for Text Classification in the Legal Domain","444":"Language Modelling via Learning to Rank","445":"DiscourseAware Prompt Design for Text Generation","446":"Pruning Pretrained Encoders with a Multitask Objective","447":"Sampling from Discrete EnergyBased Models with QualityEfficiency Tradeoffs","448":"GERNERMED  An Open German Medical NER Model","449":"Analysis and Prediction of NLP Models Via Task Embeddings","450":"Automated tabulation of clinical trial results. A joint entity and relation extraction approach with transformerbased language representations","451":"Shennong. a Python toolbox for audio speech features extraction","452":"Sentiment Analysis on Brazilian Portuguese User Reviews","453":"Improving the Question Answering Quality using Answer Candidate Filtering based on NaturalLanguage Features","454":"DEBACER. a method for slicing moderated debates","455":"Predicting Physical World Destinations for Commands Given to SelfDriving Cars","456":"Human Interpretation and Exploitation of Selfattention Patterns in Transformers. A Case Study in Extractive Summarization","457":"Sketching as a Tool for Understanding and Accelerating Selfattention for Long Sequences","458":"Improving TexttoSQL with Schema Dependency Learning","459":"Findings on Conversation Disentanglement","460":"Semantic Construction Grammar. Bridging the NL  Logic Divide","461":"MAGMA  Multimodal Augmentation of Generative Models through Adapterbased Finetuning","462":"Identifying Introductions in Podcast Episodes from Automatically Generated Transcripts","463":"Overcoming Conflicting Data when Updating a Neural Semantic Parser","464":"Robust OpenVocabulary Translation from Visual Text Representations","465":"A General Language Assistant as a Laboratory for Alignment","466":"Compositional Generalization for Natural Language Interfaces to Web APIs","467":"Iterative Decoding for Compositional Generalization in Transformers","468":"SelfSupervised Bot Play for Conversational Recommendation with Justifications","469":"Word Embeddings via Causal Inference. Gender Bias Reducing and Semantic Information Preserving","470":"PTR. A Benchmark for Partbased Conceptual Relational and Physical Reasoning","471":"Transferring BERTlike Transformers Knowledge for Authorship Verification","472":"Opinion Extraction as A Structured Sentiment Analysis using Transformers","473":"FewShot NLU with Vector Projection Distance and Abstract Triangular CRF","474":"How Universal is Genre in Universal Dependencies","475":"SelfSupervised ImagetoText and TexttoImage Synthesis","476":"Towards Generating Citation Sentences for Multiple References with Intent Control","477":"A Bilingual OpenWorld Video Text Dataset and Endtoend Video Text Spotter with Transformer","478":"Semantic Search as Extractive Paraphrase Span Detection","479":"Nice perfume. How long did you marinate in it Multimodal Sarcasm Explanation","480":"KGECL. Contrastive Learning of Knowledge Graph Embeddings","481":"The RareDis corpus. a corpus annotated with rare diseases their signs and symptoms","482":"Multimodal Fake News Detection","483":"LOREN. LogicRegularized Reasoning for Interpretable Fact Verification","484":"HiTransformer. Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling","485":"On the privacyutility tradeoff in differentially private hierarchical text classification","486":"Combining Textual Features for the Detection of Hateful and Offensive Language","487":"PSG. Promptbased Sequence Generation for Acronym Extraction","488":"SimCLAD. A Simple Framework for Contrastive Learning of Acronym Disambiguation","489":"Are E2E ASR models ready for an industrial usage","490":"CMACLIP. CrossModality Attention CLIP for ImageText Classification","491":"Probabilistic Random Indexing for Continuous Event Detection","492":"Contrastive InstructionTrajectory Learning for VisionLanguage Navigation","493":"raceBERT  A Transformerbased Model for Predicting Race and Ethnicity from Names","494":"Multidocument Summarization via Deep Learning Techniques. A Survey","495":"Solar cell patent classification method based on keyword extraction and deep neural network","496":"Towards Neural Functional Program Evaluation","497":"IronMan. GNNassisted Design Space Exploration in HighLevel Synthesis via Reinforcement Learning","498":"DeBERTaV3. Improving DeBERTa using ELECTRAStyle PreTraining with GradientDisentangled Embedding Sharing","499":"KPDrop. An Approach to Improving Absent Keyphrase Generation","500":"Promptbased Zeroshot Relation Classification with Semantic Knowledge Augmentation","501":"Prompting VisualLanguage Models for Efficient Video Understanding","502":"MLP Architectures for VisionandLanguage Modeling. An Empirical Study","503":"Everything at Once  Multimodal Fusion Transformer for Video Retrieval","504":"Ethical and social risks of harm from Language Models","505":"Does Structure Matter Leveraging DatatoText Generation for Answering Complex Information Needs","506":"An Objective Metric for Explainable AI. How and Why to Estimate the Degree of Explainability","507":"Gray Cycles of Maximum Length Related to kCharacter Substitutions","508":"Towards Explainable Fact Checking","509":"CALVIN. A Benchmark for Languageconditioned Policy Learning for Longhorizon Robot Manipulation Tasks","510":"TransformerBased Approach for Joint Handwriting and Named Entity Recognition in Historical documents","511":"Expectationbased Minimalist Grammars","512":"ZeroShot Recommendation as Language Modeling","513":"SNEAK. Synonymous SentencesAware Adversarial Attack on Natural Language Video Localization","514":"A study on native American English speech recognition by Indian listeners with varying word familiarity level","515":"Bidimensional Leaderboards. Generate and Evaluate Language Hand in Hand","516":"Learning KernelSmoothed Machine Translation with Retrieved Examples","517":"FreeTalky. Dont Be Afraid Conversations Made Easier by a Humanoid Robot using Personabased Dialogue","518":"Learning to Select the Next Reasonable Mention for Entity Linking","519":"Dual ReaderParser on Hybrid Textual and Tabular Evidence for Open Domain Question Answering","520":"Does Summary Evaluation Survive Translation to Other Languages","521":"A Scoping Review of Publicly Available Language Tasks in Clinical Natural Language Processing","522":"Multinational Address Parsing. A ZeroShot Evaluation","523":"EmotionCause Pair Extraction in Customer Reviews","524":"Teach Me to Explain. A Review of Datasets for Explainable Natural Language Processing","525":"EmTract. Investor Emotions and Market Behavior","526":"Reducing Target Group Bias in Hate Speech Detectors","527":"Grounded LanguageImage Pretraining","528":"Natural Answer Generation. From Factoid Answer to Fulllength Answer using Grammar Correction","529":"Automated Story Generation as QuestionAnswering","530":"Modeling Protein Using Largescale Pretrain Language Model","531":"A pragmatic account of the weak evidence effect","532":"UCDCS at TREC 2021 Incident Streams Track","533":"Pretrained Transformers for Offensive Language Identification in Tanglish","534":"Change Summarization of Diachronic Scholarly Paper Collections by Semantic Evolution Analysis","535":"Parsing with Pretrained Language Models Multiple Datasets and Dataset Embeddings","536":"Interpretable Privacy Preservation of Text Representations Using Vector Steganography","537":"A deep language model to predict metabolic network equilibria","538":"EndtoEnd Learning of Flowchart Grounded TaskOriented Dialogs","539":"Question Answering Survey. Directions Challenges Datasets Evaluation Matrices","540":"Inferring Prototypes for MultiLabel FewShot Image Classification with Word Vector Guided Attention","541":"Multispeaker Emotional Texttospeech Synthesizer","542":"LongShort Transformer. Efficient Transformers for Language and Vision","543":"GroundTruth Whose Truth  Examining the Challenges with Annotating Toxic Text Datasets","544":"UNITERBased Situated Coreference Resolution with Rich Multimodal Input","545":"CrossedTime Delay Neural Network for Speaker Recognition","546":"You Are What You Tweet. Profiling Users by Past Tweets to Improve Hate Speech Detection","547":"Improving Neural CrossLingual Summarization via Employing Optimal Transport Distance for Knowledge Distillation","548":"JUSTICE. A Benchmark Dataset for Supreme Courts Judgment Prediction","549":"Impact of Target Word and Context on EndtoEnd Metonymy Detection","550":"Hallucinated but Factual Inspecting the Factuality of Hallucinations in Abstractive Summarization","551":"Text2Mesh. TextDriven Neural Stylization for Meshes","552":"COVID19 India Dataset. Parsing COVID19 Data in Daily Health Bulletins from States in India","553":"Zeroshot hashtag segmentation for multilingual sentiment analysis","554":"Hybrid Autoregressive Inference for Scalable Multihop Explanation Regeneration","555":"Embedding Arithmetic for Textdriven Image Transformation","556":"VAE based Text Style Transfer with Pivot Words Enhancement Learning","557":"Flexible InstanceSpecific Rationalization of NLP Models","558":"VocBench. A Neural Vocoder Benchmark for Speech Synthesis","559":"DeepA2. A Modular Framework for Deep Argument Analysis with Pretrained Neural Text2Text Language Models","560":"Scaling Up Influence Functions","561":"CEM. Commonsenseaware Empathetic Response Generation","562":"Fast and Accurate Spanbased Semantic Role Labeling as Graph Parsing","563":"Skeletal Graph SelfAttention. Embedding a Skeleton Inductive Bias into Sign Language Production","564":"Joint Learning of Localized Representations from Medical Images and Reports","565":"A Survey on Awesome Korean NLP Datasets","566":"Metaphor Interpretation Using Word Embeddings","567":"Search and Learn. Improving Semantic Coverage for DatatoText Generation","568":"Adapting BERT for Continual Learning of a Sequence of Aspect Sentiment Classification Tasks","569":"Team Hitachi  AutoMin 2021. Referencefree Automatic Minuting Pipeline with Argument Structure Construction over Topicbased Summarization","570":"A comparative study of universal quantum computing models. towards a physical unification","571":"NLAugmenter. A Framework for TaskSensitive Natural Language Augmentation","572":"CLASSIC. Continual and Contrastive Learning of Aspect Sentiment Classification Tasks","573":"Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning","574":"Protecting Intellectual Property of Language Generation APIs with Lexical Watermark","575":"Learning Finegrained FactArticle Correspondence in Legal Cases","576":"VarCLR. Variable Semantic Representation Pretraining via Contrastive Learning","577":"Contextual MultiView Query Learning for Short Text Classification in UserGenerated Data","578":"Differentiating Approach and Avoidance from Traditional Notions of Sentiment in Economic Contexts","579":"Hope Speech detection in underresourced Kannada language","580":"The Linear Arrangement Library. A new tool for research on syntactic dependency structures","581":"Causal Distillation for Language Models","582":"Braid. Weaving Symbolic and Neural Knowledge into Coherent Logical Explanations","583":"Visual Persuasion in COVID19 Social Media Content. A MultiModal Characterization","584":"Unraveling Social Perceptions  Behaviors towards Migrants on Twitter","585":"EndtoEnd Training of MultiDocument Reader and Retriever for OpenDomain Question Answering","586":"VTCLIP. Enhancing VisionLanguage Models with Visualguided Texts","587":"Dependency distance minimization predicts compression","588":"A Russian Jeopardy Data Set for QuestionAnswering Systems","589":"Stop Asian Hate . Refining Detection of AntiAsian Hate Speech During the COVID19 Pandemic","590":"Controllable Response Generation for Assistive Usecases","591":"Hierarchical Neural Data Synthesis for Semantic Parsing","592":"Emergent Graphical Conventions in a Visual Communication Game","593":"Exploratory Data Analysis of Urdu Poetry","594":"Translatotron 2. Robust direct speechtospeech translation","595":"Rank over Class. The Untapped Potential of Ranking in Natural Language Processing","596":"Learning from Mistakes. Using Mispredictions as Harm Alerts in Language PreTraining","597":"Survey on English Entity Linking on Wikidata","598":"Teaching Autoregressive Language Models Complex Tasks By Demonstration","599":"Transforming Fake News. Robust Generalisable News Classification Using Transformers","600":"Augmenting Customer Support with an NLPbased Receptionist","601":"Shapes of Emotions. Multimodal Emotion Recognition in Conversations via Emotion Shifts","602":"Deidentifying Hospital Discharge Summaries. An EndtoEnd Framework using Ensemble of Deep Learning Models","603":"HSBAN. A Benchmark Dataset of Social Media Comments for Hate Speech Detection in Bangla","604":"Linear algebra with transformers","605":"An Endtoend Model for Entitylevel Relation Extraction using Multiinstance Learning","606":"The Catalan Language CLUB","607":"Evaluating NLP Systems On a Novel Cloze Task. Judging the Plausibility of Possible Fillers in Instructional Texts","608":"Subword Level Lip Reading With Visual Attention","609":"Semantic Segmentation of Legal Documents via Rhetorical Roles","610":"Translating Politeness Across Cultures. Case of Hindi and English","611":"Siamese BERTbased Model for Web Search Relevance Ranking Evaluated on a New Czech Dataset","612":"Controversy Detection. a Text and Graph Neural Network Based Approach","613":"Multimodal EndtoEnd Sparse Model for Emotion Recognition","614":"Creating and Managing a large annotated parallel corpora of Indian languages","615":"Given Users Recommendations Based on Reviews on Yelp","616":"BBSKWS.The Mandarin Keyword Spotting System Won the Video Keyword Wakeup Challenge","617":"Memotion Analysis through the Lens of Joint Embedding","618":"Multitask Finetuning for Improving Neural Machine Translation in Indian Languages","619":"Reduced Reused and Recycled. The Life of a Dataset in Machine Learning Research","620":"TransCouplet.Transformer based Chinese Couplet Generation","621":"Multilingual Text Classification for Dravidian Languages","622":"LMRCBT. Learning Modalityfused Representations with CBTransformer for Multimodal Emotion Recognition from Unaligned Multimodal Sequences","623":"ESAN. Efficient Sentiment Analysis Network of AShares Research Reports for Stock Price Prediction","624":"The Influence of Data Preprocessing and Postprocessing on Long Document Summarization","625":"Evaluator for Emotionally Consistent Chatbots","626":"PLSUM. Generating PTBR Wikipedia by Summarizing Multiple Websites","627":"Structured Prediction as Translation between Augmented Natural Languages","628":"FuseDream. TrainingFree TexttoImage Generation with Improved CLIPGAN Space Optimization","629":"From partners to populations. A hierarchical Bayesian account of coordination and convention","630":"LOGEN. Fewshot Logical KnowledgeConditioned Text Generation with Selftraining","631":"ScaleVLAD. Improving Multimodal Sentiment Analysis via MultiScale Fusion of Locally Descriptors","632":"Casebased Abductive Natural Language Inference","633":"How not to Lie with a Benchmark. Rearranging NLP Leaderboards","634":"ASTTransformer. Encoding Abstract Syntax Trees Efficiently for Code Summarization","635":"Unsupervised Law Article Mining based on Deep PreTrained Language Representation Models with Application to the Italian Civil Code","636":"Simple Contrastive Representation Adversarial Learning for NLP Tasks","637":"How BPE Affects Memorization in Transformers","638":"Controllable Video Captioning with an Exemplar Sentence","639":"DenseCLIP. Extract Free Dense Labels from CLIP","640":"Syntax Customized Video Captioning by Imitating Exemplar Sentences","641":"Easy Semantification of Bioassays","642":"Transfer Learning in Conversational Analysis through Reusing Preprocessing Data as Supervisors","643":"Emotions are Subtle. Learning Sentiment Based Text Representations Using Contrastive Learning","644":"From Consensus to Disagreement. MultiTeacher Distillation for SemiSupervised Relation Extraction","645":"DKPLM. Decomposable Knowledgeenhanced Pretrained Language Model for Natural Language Understanding","646":"SimpleTron. Eliminating Softmax from Attention Computation","647":"EngineKGI. ClosedLoop Knowledge Graph Inference","648":"A Mixture of Expert Based Deep Neural Network for Improved ASR","649":"Improving Controllability of Educational Question Generation by Keyword Provision","650":"Enhancing Identification of Structure Function of Academic Articles Using Contextual Information","651":"ObjectCentric Unsupervised Image Captioning","652":"Relational Graph Learning for Grounded Video Description Generation","653":"Investigating the Impact of 911 on The Simpsons through Natural Language Processing","654":"ContextDependent Semantic Parsing for Temporal Relation Extraction","655":"Deep Clustering of Text Representations for Supervisionfree Probing of Syntax","656":"A Survey of Data Augmentation Approaches for NLP","657":"ALOHA. Artificial Learning of Human Attributes for Dialogue Agents","658":"SAPPHIRE. Approaches for Enhanced ConcepttoText Generation","659":"COSTAR. Conceptualisation of Stereotypes for Analysis and Reasoning","660":"Iconary. A PictionaryBased Game for Testing Multimodal Communication with Drawings and Text","661":"Controlling Conditional Language Models with Distributional Policy Gradients","662":"Building astroBERT a language model for Astronomy  Astrophysics","663":"Systematic Generalization with Edge Transformers","664":"Domainoriented Language Pretraining with Adaptive Hybrid Masking and Optimal Transport Alignment","665":"DPRKBERT. The Supreme Language Model","666":"NLP Research and Resources at DaSciM Ecole Polytechnique","667":"Empirical evaluation of shallow and deep learning classifiers for Arabic sentiment analysis","668":"BNLP. Natural language processing toolkit for Bengali language","669":"WeaklySupervised Video Object Grounding via Causal Intervention","670":"Seeking Sinhala Sentiment. Predicting Facebook Reactions of Sinhala Posts","671":"Do Models Learn the Directionality of Relations A New Evaluation. Relation Direction Recognition","672":"NERBERT. A Pretrained Model for LowResource Entity Tagging","673":"Translationequivariant Image Quantizer for Bidirectional ImageText Generation","674":"Investigation of Training Label Error Impact on RNNT","675":"Interactive Model with Structural Loss for Languagebased Abductive Reasoning","676":"Wiki to Automotive. Understanding the Distribution Shift and its impact on Named Entity Recognition","677":"Relationaware Video Reading Comprehension for Temporal Language Grounding","678":"Influence Patterns for Explaining Information Flow in BERT","679":"True or False. Does the Deep Learning Model Learn to Detect Rumors","680":"Deliberation of Streaming RNNTransducer by Nonautoregressive Decoding","681":"Towards FullFledged Argument Search. A Framework for Extracting and Clustering Arguments from Unstructured Text","682":"Its All in the Heads. Using Attention Heads as a Baseline for CrossLingual Transfer in Commonsense Reasoning","683":"From Show to Tell. A Survey on Deep Learningbased Image Captioning","684":"DynabAbI. unlocking bAbIs potential with dynamic synthetic benchmarking","685":"Refined Commonsense Knowledge from LargeScale Web Contents","686":"A Comprehensive Review of the VideotoText Problem","687":"Common Sense Knowledge Learning for Open Vocabulary Neural Reasoning. A First View into Chronic Disease Literature","688":"Sentiment Analysis and Effect of COVID19 Pandemic using College SubReddit Data","689":"Automatic Extraction of Medication Names in Tweets as Named Entity Recognition","690":"Chemical Identification and Indexing in PubMed Articles via BERT and TexttoText Approaches","691":"Text Mining DrugChemicalProtein Interactions using an Ensemble of BERT and T5 Based Models","692":"Capturing the diversity of multilingual societies","693":"What Do You See in this Patient Behavioral Testing of Clinical NLP Models","694":"Prediction of Listener Perception of Argumentative Speech in a Crowdsourced Dataset Using PsychoLinguistic and Fluency Features","695":"TNTKID. Transformerbased Neural Tagger for Keyword Identification","696":"KARLTransNER. Knowledge Aware Representation Learning for Named Entity Recognition using Transformers","697":"Undecidability in Finite Transducers Defense Systems and Finite Substitutions","698":"A Comparative Study of Transformers on Word Sense Disambiguation","699":"Minor changes make a difference. a case study on the consistency of UDbased dependency parsers","700":"Finding Scoring and Explaining Arguments in Bayesian Networks","701":"Challenges in Developing LRs for NonScheduled Languages. A Case of Magahi","702":"Generating Rich Product Descriptions for Conversational Ecommerce Systems","703":"Bilingual Topic Models for Comparable Corpora","704":"NLP Techniques for Water Quality Analysis in Social Media Content","705":"Towards automatic identification of linguistic politeness in Hindi texts","706":"Towards algorithmfree physical equilibrium model of computing","707":"Improvement in Machine Translation with Generative Adversarial Networks","708":"Automated Speech Scoring System Under The Lens. Evaluating and interpreting the linguistic cues for language proficiency","709":"Robust Optimization for Multilingual Translation with Imbalanced Data","710":"Enhancing Keyphrase Extraction from Academic Articles with their Reference Information","711":"Customer Sentiment Analysis using Weak Supervision for CustomerAgent Chat","712":"Learning to Predict Persona Information forDialogue Personalization without Explicit Persona Description","713":"An Empirical Study of Topic Transition in Dialogue","714":"Joint Modeling of CodeSwitched and Monolingual ASR via Conditional Factorization","715":"Automated DrugRelated Information Extraction from French Clinical Documents. ReLyfe Approach","716":"Adversarial Training for a Hybrid Approach to AspectBased Sentiment Analysis","717":"A Natural Language Processing and Deep Learning based Model for Automated Vehicle Diagnostics using FreeText Customer Service Reports","718":"QVHighlights. Detecting Moments and Highlights in Videos via Natural Language Queries","719":"Understanding Outofdistribution. A Perspective of Data Dynamics","720":"Changepoint Analysis of Topic Proportions in Temporal Text Data","721":"Speech Tasks Relevant to Sleepiness Determined with Deep Transfer Learning","722":"LowResource Machine Translation Training Curriculum Fit for LowResource Languages","723":"mRATSQLGAP.A Portuguese TexttoSQL Transformer","724":"Do We Still Need Automatic Speech Recognition for Spoken Language Understanding","725":"Semantic Communication with Adaptive Universal Transformer","726":"Mixed Precision Lowbit Quantization of Neural Network Language Models for Speech Recognition","727":"Lyric document embeddings for music tagging","728":"Action based Network for Conversation Question Reformulation","729":"Mixed Precision of Quantization of Transformer Language Models for Speech Recognition","730":"Constructing Contrastive samples via Summarization for Text Classification with limited annotations","731":"Scaling ASR Improves Zero and Few Shot Learning","732":"A General Framework for Defending Against Backdoor Attacks via Influence Graph","733":"Longrange and hierarchical language predictions in brains and algorithms","734":"A Persistent Spatial Semantic Representation for Highlevel Natural Language Instruction Execution","735":"Mapping Industry 4.0 Technologies. From CyberPhysical Systems to Artificial Intelligence","736":"MultiDomain Spoken Language Understanding Using Domain and TaskAware Parameterization","737":"A baseline model for computationally inexpensive speech recognition for Kazakh using the Coqui STT framework","738":"Context Matters in Semantically Controlled Language Generation for Taskoriented Dialogue Systems","739":"What Changes Can Largescale Language Models Bring Intensive Study on HyperCLOVA. Billionsscale Korean Generative Pretrained Transformers","740":"Topic Driven Adaptive Network for CrossDomain Sentiment Classification","741":"Adding more data does not always help. A study in medical conversation summarization with PEGASUS","742":"audino. A Modern Annotation Tool for Audio and Speech","743":"A Grounded Wellbeing Conversational Agent with Multiple Interaction Modes. Preliminary Results","744":"Multimodal Automated Speech Scoring using Attention Fusion","745":"Extracting the Unknown from Long Math Problems","746":"Natural Language and Spatial Rules","747":"ORCHARD. A Benchmark For Measuring Systematic Generalization of MultiHierarchical Reasoning","748":"FastTrees. Parallel Latent TreeInduction for Faster Sequence Encoding","749":"Mitigating harm in language models with conditionallikelihood filtration","750":"Answer Generation for Questions With Multiple Information Sources in ECommerce","751":"Exploring LowCost Transformer Model Compression for LargeScale Commercial Reply Suggestions","752":"An analysis of document graph construction methods for AMR summarization","753":"Language models in word sense disambiguation for Polish","754":"Abusive and Threatening Language Detection in Urdu using Boosting based and BERT based models. A Comparative Approach","755":"Exploring Transformer Based Models to Identify Hate Speech and Offensive Content in English and IndoAryan Languages","756":"Tapping BERT for Preposition Sense Disambiguation","757":"Arabic aspect based sentiment classification using BERT","758":"Language Modeling with Reduced Densities","759":"Compacter. Efficient LowRank Hypercomplex Adapter Layers","760":"AIS. A nonlinear activation function for industrial safety engineering","761":"Prose2Poem. The Blessing of Transformers in Translating Prose to Persian Poetry","762":"Partner Personas Generation for Diverse Dialogue Generation","763":"The Hierarchical Organization of Syntax","764":"BCHNLP at BioCreative VII Track 3. medications detection in tweets using transformer networks and multitask learning","765":"Do Language Models Have Beliefs Methods for Detecting Updating and Visualizing Model Beliefs","766":"Towards Using Diachronic Distributed Word Representations as Models of Lexical Development","767":"Predicting Document Coverage for Relation Extraction","768":"Capturing Stance Dynamics in Social Media. Open Challenges and Research Directions","769":"Naturalness Evaluation of Natural Language Generation in Taskoriented Dialogues using BERT","770":"Discontinuous Named Entity Recognition as Maximal Clique Discovery","771":"Soliciting User Preferences in Conversational Recommender Systems via Usagerelated Questions","772":"True FewShot Learning with Prompts  A RealWorld Perspective","773":"Active Learning for Event Extraction with Memorybased Loss Prediction Model","774":"A Review of Speaker Diarization. Recent Advances with Deep Learning","775":"Pretrained Language Models are Symbolic Mathematics Solvers too","776":"Vocabulary Learning via Optimal Transport for Neural Machine Translation","777":"Ensembling of Distilled Models from Multitask Teachers for Constrained Resource Language Pairs","778":"Identification of Bias Against People with Disabilities in Sentiment Analysis and Toxicity Detection Models","779":"Building an Application Independent Natural Language Interface","780":"New Approaches to Long Document Summarization. Fourier Transform Based Attention in a Transformer Model","781":"Transformerbased Korean Pretrained Language Models. A Survey on Three Years of Progress","782":"TunBERT. Pretrained Contextualized Text Representation for Tunisian Dialect","783":"DiPD. Disruptive event Prediction Dataset from Twitter","784":"Does constituency analysis enhance domainspecific pretrained BERT models for relation extraction","785":"Global alignment for relation extraction in Microbiology","786":"Normal vs. Adversarial. Saliencebased Analysis of Adversarial Samples for Relation Extraction","787":"NearZeroShot Suggestion Mining with a Little Help from WordNet","788":"PreTraining with Whole Word Masking for Chinese BERT","789":"Weighted Global Normalization for Multiple Choice Reading Comprehension over Long Documents","790":"Small Changes Make Big Differences. Improving Multiturn Response Selection in Dialogue Systems via FineGrained Contrastive Learning","791":"OpenRetrieval Conversational Machine Reading","792":"VLDeformer. VisionLanguage Decomposed Transformer for Fast CrossModal Retrieval","793":"Boosting Neural Machine Translation with DependencyScaled SelfAttention Network","794":"A RulebasedBPSO Approach to Produce Lowdimensional Semantic Basis Vectors Set","795":"OutofCategory Document Identification Using TargetCategory Names as Weak Supervision","796":"Temporal Effects on Pretrained Models for Language Processing Tasks","797":"Sparse is Enough in Scaling Transformers","798":"Functionals in the Clouds. An abstract architecture of serverless CloudNative Apps","799":"Clinical Utility of the Automatic Phenotype Annotation in Unstructured Clinical Notes. ICU Use Cases","800":"Analysis of Chronic Pain Experiences Based on Online Reports. the RRCP Dataset for qualityoflife assessment","801":"Knowledge Enhanced Sports Game Summarization","802":"Selection of pseudoannotated data for adverse drug reaction classification across drug groups","803":"A Python Library for Exploratory Data Analysis on Twitter Data based on Tokens and Aggregated OriginDestination Information","804":"Generating semantic maps through multidimensional scaling. linguistic applications and theory","805":"Fewshot Named Entity Recognition with Cloze Questions","806":"Introducing an Abusive Language Classification Framework for Telegram to Investigate the German Hater Community","807":"SSimCSE. Sampled Subnetworks for Contrastive Learning of Sentence Embedding","808":"GradInit. Learning to Initialize Neural Networks for Stable and Efficient Training","809":"Handling treestructured text. parsing directory pages","810":"SemGloVe. Semantic Cooccurrences for GloVe from BERT","811":"A SelfSupervised Automatic PostEditing Data Generation Tool","812":"Finetuning Pretrained Transformers into Variational Autoencoders","813":"Using Distributional Principles for the Semantic Study of Contextual Language Models","814":"DABS. A DomainAgnostic Benchmark for SelfSupervised Learning","815":"A bifurcation threshold for contactinduced language change","816":"Generating GPU Compiler Heuristics using Reinforcement Learning","817":"Romanian Speech Recognition Experiments from the ROBIN Project","818":"Process for Adapting Language Models to Society PALMS with ValuesTargeted Datasets","819":"Neural networks can understand compositional functions that humans do not in the context of emergent communication","820":"A Review of Web Infodemic Analysis and Detection Trends across Multimodalities using Deep Neural Networks","821":"Evaluating Transferability of BERT Models on Uralic Languages","822":"TWEETSUMM  A Dialog Summarization Dataset for Customer Service","823":"Triple Classification for Scholarly Knowledge Graph Completion","824":"SpeechMoE2. MixtureofExperts Model with Improved Routing","825":"CLNERIL. A CrossLingual Model for NER in Indian Languages","826":"Evaluating the application of NLP tools in mainstream participatory budgeting processes in Scotland","827":"Robust Deep Reinforcement Learning for Extractive Legal Summarization","828":"MAUVE. Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers","829":"Easy and Efficient Transformer . Scalable Inference Solution For large NLP model","830":"MS2. MultiDocument Summarization of Medical Studies","831":"Building GoalOriented Dialogue Systems with Situated Visual Context","832":"QTNVQC. An EndtoEnd Learning framework for Quantum Neural Networks","833":"Deciphering Speech. a ZeroResource Approach to CrossLingual Transfer in ASR","834":"ZeroShot OpenBook Question Answering","835":"Visual Sentiment Analysis. A Natural DisasterUsecase Task at MediaEval 2021","836":"RedCaps. webcurated imagetext data created by the people for the people","837":"Namesakes. Ambiguously Named Entities from Wikipedia and News","838":"DLVGen. A Dual Latent Variable Approach to Personalized Dialogue Generation","839":"Vector Space Semantics for Lambek Calculus with Soft Subexponentials","840":"A Hybrid Approach for Improved Low Resource Neural Machine Translation using Monolingual Data","841":"HumanMachine Interaction Speech Corpus from the ROBIN project","842":"Investigating CrossLinguistic Gender Bias in HindiEnglish Across Domains","843":"Efficient Combinatorial Optimization for Wordlevel Adversarial Textual Attack","844":"HTMOT . Hierarchical Topic Modelling Over Time","845":"Hierarchy Decoder is All You Need To Text Classification","846":"Reinforcement Learning for FewShot Text Generation Adaptation","847":"Keyword Assisted Embedded Topic Model","848":"MultiChannel MultiSpeaker ASR Using 3D Spatial Feature","849":"Learning Personal Food Preferences via Food Logs Embedding","850":"Positionbased Contributive Embeddings for AspectBased Sentiment Analysis","851":"A Systematic Evaluation of Transfer Learning and Pseudolabeling with BERTbased Ranking Models","852":"Many Heads but One Brain. an Overview of Fusion Brain Challenge on AI Journey 2021","853":"Knowledge Based Multilingual Language Model","854":"Hierarchical Knowledge Distillation for Dialogue Sequence Labeling","855":"Using Known Words to Learn More Words. A Distributional Analysis of Child Vocabulary Development","856":"Jointly Dynamic Topic Model for Recognition of Leadlag Relationship in Two Text Corpora","857":"Fake News Detection Tools and Methods  A Review","858":"Isomer. Transfer enhanced DualChannel Heterogeneous Dependency Attention Network for Aspectbased Sentiment Classification","859":"ViraPart. A Text Refinement Framework for Automatic Speech Recognition and Natural Language Processing Tasks in Persian","860":"TraVLR. Now You See It Now You Dont Evaluating CrossModal Transfer of VisioLinguistic Reasoning","861":"More Romanian word embeddings from the RETEROM project","862":"Capitalization and Punctuation Restoration. a Survey","863":"Textbook to triples. Creating knowledge graph in the form of triples from AI TextBook","864":"A computational model implementing subjectivity with the Room Theory. The case of detecting Emotion from Text","865":"Data Augmentation Approaches in Natural Language Processing. A Survey","866":"Call Larisa Ivanovna. CodeSwitching Fools Multilingual NLU Models","867":"Improving Tagging Consistency and Entity Coverage for Chemical Identification in Fulltext Articles","868":"LAnoBERT . System Log Anomaly Detection based on BERT Masked Language Model","869":"Data Processing Matters. SRPHKonvergen AIs Machine Translation System for WMT21","870":"Exploring Language Patterns in a Medical Licensure Exam Item Bank","871":"Combining Datadriven Supervision with Humanintheloop Feedback for Entity Resolution","872":"Weakly Supervised Prototype Topic Model with Discriminative Seed Words. Modifying the Category Prior by Selfexploring Supervised Signals","873":"The ComMA Dataset V0.2. Annotating Aggression and Bias in Multilingual Social Media Discourse","874":"KGRefiner. Knowledge Graph Refinement for Improving Accuracy of Translational Link Prediction Methods","875":"A Review on Fact Extraction and Verification","876":"Toxicity Detection can be Sensitive to the Conversational Context","877":"FinEAS. Financial Embedding Analysis of Sentiment","878":"Prosodic Clustering for Phonemelevel Prosody Control in EndtoEnd Speech Synthesis","879":"On embedding Lambek calculus into commutative categorial grammars","880":"WordLevel Style Control for Expressive Nonattentive Speech Synthesis","881":"Improved Prosodic Clustering for Multispeaker and Speakerindependent Phonemelevel Prosody Control","882":"Lattention. Latticeattention in ASR rescoring","883":"Between welcome culture and border fence. A dataset on the European refugee crisis in German newspaper reports","884":"NEZHA. Neural Contextualized Representation for Chinese Language Understanding","885":"Does BERT look at sentiment lexicon","886":"Lexiconbased Methods vs. BERT for Text Sentiment Analysis","887":"PartiallySupervised Novel Object Captioning Leveraging Context from Paired Data","888":"Achieving Human Parity on Visual Question Answering","889":"RadBERTCL. FactuallyAware Contrastive Learning For Radiology Report Classification","890":"Efficient Estimation of Influence of a Training Instance","891":"DeepQR. Neuralbased Quality Ratings for Learnersourced MultipleChoice Questions","892":"Semisupervised transfer learning for language expansion of endtoend speech recognition models to lowresource languages","893":"Samanantar. The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages","894":"Building a Question Answering System for the Manufacturing Domain","895":"Quality and Cost Tradeoffs in Passage Reranking Task","896":"Zeroshot Relation Classification from Side Information","897":"A SelfExplainable Stylish Image Captioning Framework via MultiReferences","898":"PegasusDravidianCodeMixHASOC2021. Analyzing Social Media Content for Detection of Offensive Text","899":"Findings of the Sentiment Analysis of Dravidian Languages in CodeMixed Text","900":"Supporting Undotted Arabic with Pretrained Language Models","901":"You Only Sample Almost Once. Linear Cost SelfAttention Via Bernoulli Sampling","902":"Towards Interpretable and Reliable Reading Comprehension. A Pipeline Model with Unanswerability Prediction","903":"Facilitating reflection in teletandem through automatically generated conversation metrics and playback video","904":"Under the Hood. Using Diagnostic Classifiers to Investigate and Improve how Language Models Track Agreement Information","905":"How to Build Robust FAQ Chatbot with Controllable Question Generator","906":"CORAA. a large corpus of spontaneous and prepared speech manually validated for speech recognition in Brazilian Portuguese","907":"DynamicTinyBERT. Boost TinyBERTs Inference Efficiency by Dynamic Sequence Length","908":"Seeking Common but Distinguishing Difference A Joint Aspectbased Sentiment Analysis Model","909":"To Augment or Not to Augment A Comparative Study on Text Augmentation Techniques for LowResource NLP","910":"How Emotionally Stable is ALBERT Testing Robustness with Stochastic Weight Averaging on a Sentiment Analysis Task","911":"Automatic Expansion and Retargeting of Arabic Offensive Language Training","912":"Modeling morphology with Linear Discriminative Learning. considerations and design choices","913":"GPT3Mix. Leveraging Largescale Language Models for Text Augmentation","914":"The VoicePrivacy 2020 Challenge. Results and findings","915":"SingleModal Entropy based Active Learning for Visual Question Answering","916":"SummaC. ReVisiting NLIbased Models for Inconsistency Detection in Summarization","917":"How much do language models copy from their training data Evaluating linguistic novelty in text generation using RAVEN","918":"FeelsGoodMan. Inferring Semantics of Twitch Neologisms","919":"An enriched category theory of language. from syntax to semantics","920":"Training Verifiers to Solve Math Word Problems","921":"MEDCOD. A MedicallyAccurate Emotive Diverse and Controllable Dialog System","922":"Rationales for Sequential Predictions","923":"A TwoStage Approach towards Generalization in Knowledge Base Question Answering","924":"\u00daFAL at MultiLexNorm 2021. Improving Multilingual Lexical Normalization by Finetuning ByT5","925":"Character Transformations for NonAutoregressive GEC Tagging","926":"Induce Edit Retrieve. Language Grounded Multimodal Schema for Instructional Video Retrieval","927":"Understanding Model Robustness to Usergenerated Noisy Texts","928":"Finegrained prediction of food insecurity using news streams","929":"DataCLUE. A Benchmark Suite for Datacentric NLP","930":"A Survey on Automated FactChecking","931":"Predicting Text Readability from Scrolling Interactions","932":"Pruning Attention Heads of Transformer Models Using A Search. A Novel Approach to Compress Big NLP Architectures","933":"RappingSinging Voice Synthesis based on Phonemelevel Prosody Control","934":"Crosslingual Low Resource Speaker Adaptation Using Phonological Features","935":"Guiding Generative Language Models for Data Augmentation in FewShot Text Classification","936":"High Quality Streaming Speech Synthesis with Low SentenceLengthIndependent Latency","937":"MultiAttribute Relation Extraction MARE  Simplifying the Application of Relation Extraction","938":"Explicit Interaction Network for Aspect Sentiment Triplet Extraction","939":"Transparent Human Evaluation for Image Captioning","940":"Using Sampling to Estimate and Improve Performance of Automated Scoring Systems with Guarantees","941":"Automatic Detection of COVID19 Vaccine Misinformation with Graph Link Prediction","942":"Constrained Language Models Yield FewShot Semantic Parsers","943":"Convex Aggregation for Opinion Summarization","944":"Who Decides if AI is Fair The Labels Problem in Algorithmic Auditing","945":"A Comparative Study on Transfer Learning and Distance Metrics in Semantic Clustering over the COVID19 Tweets","946":"NVIDIA NeMo Neural Machine Translation Systems for EnglishGerman and EnglishRussian News and Biomedical Tasks at WMT21","947":"SequencetoSequence Learning with Latent Neural Grammars","948":"Document AI. Benchmarks Models and Applications","949":"Words of Wisdom. Representational Harms in Learning From AI Communication","950":"Interpreting Language Models Through Knowledge Graph Extraction","951":"Coral. An Approach for Conversational Agents in Mental Health Applications","952":"WikiContradiction. Detecting SelfContradiction Articles on Wikipedia","953":"Improving the robustness and accuracy of biomedical language models through adversarial training","954":"CVSSBERT. Explainable Natural Language Processing to Determine the Severity of a Computer Security Vulnerability from its Description","955":"Generative PreTrained Transformer for Design Concept Generation. An Exploration","956":"The role of attractionrepulsion dynamics in simulating the emergence of inflectional class systems","957":"STAMP 4 NLP  An Agile Framework for Rapid QualityDriven NLP Applications Development","958":"A repeatedmeasures study on emotional responses after a year in the pandemic","959":"Bridge the Gap Between CV and NLP A Gradientbased Textual Adversarial Attack Framework","960":"Integrated Semantic and Phonetic Postcorrection for Chinese Speech Recognition","961":"Diversifying Neural Text Generation with PartofSpeech Guided Softmax and Sampling","962":"Netmarble AI Centers WMT21 Automatic PostEditing Shared Task Submission","963":"Solving Probability and Statistics Problems by Program Synthesis","964":"Meeting Summarization with Pretraining and Clustering Methods","965":"Attentionbased Multihypothesis Fusion for Speech Summarization","966":"CCAMDD. A Coupled CrossAttention based Framework for Streaming Mispronunciation detection and diagnosis","967":"Adversarially Constructed Evaluation Sets Are More Challenging but May Not Be Fair","968":"Solving Linear Algebra by Program Synthesis","969":"Joint Unsupervised and Supervised Training for Multilingual ASR","970":"Exploring Story Generation with Multitask Objectives in Variational Autoencoders","971":"Assessing gender bias in medical and scientific masked language models with StereoSet","972":"CoLLIE. Continual Learning of Language Grounding from LanguageImage Embeddings","973":"The Unreasonable Effectiveness of Machine Learning in Moldavian versus Romanian Dialect Identification","974":"Guiding Visual Question Generation","975":"QuestionBased Salient Span Selection for More Controllable Text Summarization","976":"IIITTDravidianCodeMixFIRE2021. Transliterate or translate Sentiment analysis of codemixed text in Dravidian languages","977":"Oil and Gas Pipeline Monitoring during COVID19 Pandemic via Unmanned Aerial Vehicle","978":"Evaluating Metrics for Bias in Word Embeddings","979":"Sentiment Analysis of Fashion Related Posts in Social Media","980":"Data Augmentation for Speech Recognition in Maltese. A LowResource Perspective","981":"Automatic PostEditing for Vietnamese","982":"cushLEPOR. customising hLEPOR metric using Optuna for higher agreement with human judgments or pretrained language model LaBSE","983":"Measuring Uncertainty in Translation Quality Evaluation TQE","984":"Exploring Bayesian Deep Learning for Urgent Instructor Intervention Need in MOOC Forums","985":"Contextaware Decoder for Neural Machine Translation using a Targetside DocumentLevel Language Model","986":"AutoEncoding Knowledge Graph for Unsupervised Medical Report Generation","987":"Rationale production to support clinical decisionmaking","988":"Crowdsourcing Learning as Domain Adaptation. A Case Study on Named Entity Recognition","989":"Say What Collaborative Pop Lyric Generation Using Multitask Transfer Learning","990":"Speeding Up Entmax","991":"Rumor Detection on Twitter with ClaimGuided Hierarchical Graph Attention Networks","992":"Improving Prosody for Unseen Texts in Speech Synthesis by Utilizing Linguistic Information and Noisy Data","993":"TipAdapter. Trainingfree CLIPAdapter for Better VisionLanguage Modeling","994":"Automatic Analysis of Linguistic Features in Journal Articles of Different Academic Impacts with Feature Engineering Techniques","995":"Efficient Nearest Neighbor Language Models","996":"Towards Interpretability of Speech Pause in Dementia Detection using Adversarial Learning","997":"Contrastive Clustering. Toward Unsupervised Bias Reduction for Emotion and Sentiment Classification","998":"Improving Dialogue State Tracking by Joint Slot Modeling","999":"Time Waits for No One Analysis and Challenges of Temporal Misalignment","1000":"DEEP. DEnoising Entity Pretraining for Neural Machine Translation","1001":"Intelligent Trading Systems. A SentimentAware Reinforcement Learning Approach","1002":"Will You Find These Shortcuts A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification","1003":"Evaluation Toolkit For Robustness Testing Of Automatic Essay Scoring Systems","1004":"Automatic evaluation of scientific abstracts through natural language processing","1005":"Critical Sentence Identification in Legal Cases Using MultiClass Classification","1006":"Forecasting Crude Oil Price Using Event Extraction","1007":"Towards annotation of text worlds in a literary work","1008":"Question Answering for Complex Electronic Health Records Database using Unified EncoderDecoder Architecture","1009":"Curriculum Learning for VisionandLanguage Navigation","1010":"MetaVoice. Fast fewshot style transfer for expressive voice cloning using meta learning","1011":"Keyphrase Extraction Using Neighborhood Knowledge Based on Word Embeddings","1012":"A feast for trolls  Engagement analysis of counternarratives against online toxicity","1013":"Explainable Semantic Space by Grounding Language to Vision with CrossModal Contrastive Learning","1014":"SocialBERT  Transformers for Online SocialNetwork Language Modelling","1015":"MultiClass and Automated Tweet Categorization","1016":"Extracting and filtering paraphrases by bridging natural language inference and paraphrasing","1017":"Detection of Emotions in HindiEnglish Code Mixed Text Data","1018":"GraphPrompt. Biomedical Entity Normalization Using Graphbased Prompt Templates","1019":"Minimally Supervised Categorization of Text with Metadata","1020":"Using Deep Learning to Identify Patients with Cognitive Impairment in Electronic Health Records","1021":"Discourselevel Relation Extraction via Graph Pooling","1022":"Exploiting all samples in lowresource sentence classification. early stopping and initialization parameters","1023":"MSLaTTE. A Dataset of Where and When Todo Tasks are Completed","1024":"Benchmarking deep generative models for diverse antibody sequence design","1025":"BitextEdit. Automatic Bitext Editing for Improved LowResource Machine Translation","1026":"Does BERT Learn as Humans Perceive Understanding Linguistic Styles through Lexica","1027":"Extraction of Medication Names from Twitter Using Augmentation and an Ensemble of Language Models","1028":"Speaker and Timeaware Joint Contextual Learning for Dialogueact Classification in Counselling Conversations","1029":"Variation and generality in encoding of syntactic anomaly information in sentence embeddings","1030":"A Convolutional Neural Network Based Approach to Recognize Bangla Spoken Digits from Speech Signal","1031":"PESTO. Switching Point based Dynamic and Relative Positional Encoding for CodeMixed Languages","1032":"OntheFly Rectification for Robust LargeVocabulary Topic Inference","1033":"A Chinese Text Classification Method With Low Hardware Requirement Based on Improved Model Concatenation","1034":"SmartTriage. A system for personalized patient data capture documentation generation and decision support","1035":"RATE. Overcoming Noise and Sparsity of Textual Features in RealTime Location Estimation","1036":"Catalytic Role Of Noise And Necessity Of Inductive Biases In The Emergence Of Compositional Communication","1037":"MATCH. MetadataAware Text Classification in A Large Hierarchy","1038":"Poisoning Knowledge Graph Embeddings via Relation Inference Patterns","1039":"Characterlevel HyperNetworks for Hate Speech Detection","1040":"Identification of FineGrained Location Mentions in Crisis Tweets","1041":"Towards an Efficient Voice Identification Using Wav2Vec2.0 and HuBERT Based on the Quran Reciters Dataset","1042":"SelfNormalized Importance Sampling for Neural Language Modeling","1043":"Training CrossLingual embeddings for Setswana and Sepedi","1044":"CUUD. textmining drug and chemicalprotein interactions with ensembles of BERTbased models","1045":"Exploring deep learning methods for recognizing rare diseases and their clinical manifestations from texts","1046":"Multilingual and Multilabel Emotion Recognition using Virtual Adversarial Training","1047":"From words to connections. Word use similarity as an honest signal conducive to employees digital communication","1048":"Towards Robust Knowledge Graph Embedding via Multitask Reinforcement Learning","1049":"A Chinese Multitype Complex Questions Answering Dataset over Wikidata","1050":"Explainable SentenceLevel Sentiment Analysis for Amazon Product Reviews","1051":"Improving Largescale Language Models and Resources for Filipino","1052":"Importance Estimation from Multiple Perspectives for Keyphrase Extraction","1053":"Kronecker Factorization for Preventing Catastrophic Forgetting in Largescale Medical Entity Linking","1054":"Understanding Guided Image Captioning Performance across Domains","1055":"Crosslanguage Information Retrieval","1056":"A Novel Corpus of Discourse Structure in Humans and Computers","1057":"Recent Advances in Automated Question Answering In Biomedical Domain","1058":"Racism is a Virus. AntiAsian Hate and Counterspeech in Social Media during the COVID19 Crisis","1059":"Understanding COVID19 Vaccine Reaction through Comparative Analysis on Twitter","1060":"BagBERT. BERTbased baggingstacking for multitopic classification","1061":"Crosslingual Adaption ModelAgnostic MetaLearning for Natural Language Understanding","1062":"Reverse Operation based Data Augmentation for Solving Math Word Problems","1063":"Prune Once for All. Sparse PreTrained Language Models","1064":"Jurassic is almost All You Need. FewShot MeaningtoText Generation for OpenDomain Dialogue","1065":"Pretrained TransformerBased Approach for Arabic Question Answering . A Comparative Study","1066":"MICE. Mining Idioms with Contextual Embeddings","1067":"CLIP2TV. An Empirical Study on Transformerbased Methods for VideoText Retrieval","1068":"The Wind in Our Sails. Developing a Reusable and Maintainable Dutch Maritime History Knowledge Graph","1069":"From Theories on Styles to their Transfer in Text. Bridging the Gap with a Hierarchical Survey","1070":"COfEE. A Comprehensive Ontology for Event Extraction from text","1071":"MultiBench. Multiscale Benchmarks for Multimodal Representation Learning","1072":"Oh My Mistake. Toward Realistic Dialogue State Tracking including Turnback Utterances","1073":"A Survey on Green Deep Learning","1074":"An Information Retrieval Approach to Building Datasets for Hate Speech Detection","1075":"A Computational Approach to Walt Whitmans Stylistic Changes in Leaves of Grass","1076":"MNetSim. A Multilayered Semantic Similarity Network to Evaluate Sentence Similarity","1077":"Learning Logic Rules for Documentlevel Relation Extraction","1078":"Pretrain or Annotate Domain Adaptation with a Constrained Budget","1079":"Corrected CBOW Performs as well as Skipgram","1080":"A Survey of NLPRelated Crowdsourcing HITs. what works and what does not","1081":"Reason first then respond. Modular Generation for Knowledgeinfused Dialogue","1082":"The Klarna Product Page Dataset. A Realistic Benchmark for Web Representation Learning","1083":"SERC. Syntactic and Semantic Sequence based Event Relation Classification","1084":"Tackling Morphological Analogies Using Deep Learning  Extended Version","1085":"HumanintheLoop Disinformation Detection. Stance Sentiment or Something Else","1086":"Multimodal intelligibility of scholarly hypertext. the documentalists contribution. A required collaboration for serial documentisation in the scientific editorial process","1087":"Controllable Generation from Pretrained Language Models via Inverse Prompting","1088":"Learning to Generalize Compositionally by Transferring Across Semantic Parsing Tasks","1089":"What goes on inside rumour and nonrumour tweets and their reactions. A Psycholinguistic Analyses","1090":"Perspectives and Prospects on Transformer Architecture for CrossModal Tasks with Language and Vision","1091":"Transformer Based Bengali Chatbot Using General Knowledge Dataset","1092":"American Hate Crime Trends Prediction with Event Extraction","1093":"DSBERT.Unsupervised Dialogue Structure learning with BERT","1094":"CAPE. Encoding Relative Positions with Continuous Augmented Positional Embeddings","1095":"VSEC. Transformerbased Model for Vietnamese Spelling Correction","1096":"Explaining Face Presentation Attack Detection Using Natural Language","1097":"Measuring Mathematical Problem Solving With the MATH Dataset","1098":"CUAD. An ExpertAnnotated NLP Dataset for Legal Contract Review","1099":"Measuring Coding Challenge Competence With APPS","1100":"Cascaded Multilingual AudioVisual Learning from Videos","1101":"Visual Question Answering based on Formal Logic","1102":"FLEX. Unifying Evaluation for FewShot NLP","1103":"Mr. TyDi. A Multilingual Benchmark for Dense Retrieval","1104":"Detecting Depression in Thai Blog Posts. a Dataset and a Baseline","1105":"Sexism Prediction in Spanish and English Tweets Using Monolingual and Multilingual BERT and Ensemble Models","1106":"AIUPV at IberLEF2021 DETOXIS task. Toxicity Detection in ImmigrationRelated Web News Comments Using Transformers and Statistical Models","1107":"Visualization. the missing factor in Simultaneous Speech Translation","1108":"Anagrammatic quotients of free groups","1109":"Ontologybased question answering over corporate structured data","1110":"StrucTexT. Structured Text Understanding with MultiModal Transformers","1111":"Efficient Inference for Multilingual Neural Machine Translation","1112":"WebSRC. A Dataset for WebBased Structural Reading Comprehension","1113":"Towards Debiasing Temporal Sentence Grounding in Video","1114":"Capturing Logical Structure of Visually Structured Documents with Multimodal Transition Parser","1115":"JaMIE. A Pipeline Japanese Medical Information Extraction System","1116":"ValNorm Quantifies Semantics to Reveal Consistent Valence Biases Across Languages and Over Centuries","1117":"Casebased Reasoning for Natural Language Queries over Knowledge Bases","1118":"Towards Robustness to Label Noise in Text Classification via Noise Modeling","1119":"Speaker Generation","1120":"Retrieving Speaker Information from Personalized Acoustic Models for Speech Recognition","1121":"A Word on Machine Ethics. A Response to Jiang et al. 2021","1122":"Look at the Variance Efficient Blackbox Explanations with Sobolbased Sensitivity Analysis","1123":"NLP From Scratch Without LargeScale Pretraining. A Simple and Efficient Framework","1124":"CSFCube  A Test Collection of Computer Science Research Articles for Faceted Query by Example","1125":"Developing neural machine translation models for HungarianEnglish","1126":"VarianceAware Machine Translation Test Sets","1127":"How does a PreTrained Transformer Integrate Contextual Keywords Application to Humanitarian Computing","1128":"Information Extraction from Visually Rich Documents with Font Style Embeddings","1129":"MetaTTS. MetaLearning for FewShot Speaker Adaptive TexttoSpeech","1130":"FGraDA. A Dataset and Benchmark for FineGrained Domain Adaptation in Machine Translation","1131":"Programming Puzzles","1132":"Towards LabelAgnostic Emotion Embeddings","1133":"Trend and Thoughts. Understanding Climate Change Concern using Machine Learning and Social Media Data","1134":"Distinguishing Commercial from Editorial Content in News","1135":"kFolden. kFold Ensemble for OutOfDistribution Detection","1136":"Patent Sentiment Analysis to Highlight Patent Paragraphs","1137":"Focusing on Possible Named Entities in Active Named Entity Label Acquisition","1138":"Analyzing Architectures for Neural Machine Translation Using Low Computational Resources","1139":"Finnish Dialect Identification. The Effect of Audio and Text","1140":"IBERT. Idiom Clozestyle reading comprehension with Attention","1141":"Leveraging Sentiment Analysis Knowledge to Solve Emotion Detection Tasks","1142":"The Curious Layperson. FineGrained Image Recognition without Expert Labels","1143":"Grounded Graph Decoding Improves Compositional Generalization in Question Answering","1144":"QAGNN. Reasoning with Language Models and Knowledge Graphs for Question Answering","1145":"Sexism Identification in Tweets and Gabs using Deep Neural Networks","1146":"Decrypting Cryptic Crosswords. Semantically Complex Wordplay Puzzles as a Target for NLP","1147":"Battling Hateful Content in Indic Languages HASOC 21","1148":"TaskDrop. A Competitive Baseline for Continual Learning of Sentiment Classification","1149":"POSHAN. Cardinal POS Pattern Guided Attention for News Headline Incongruence","1150":"Disengagement CauseandEffect Relationships Extraction Using an NLP Pipeline","1151":"Monitoring geometrical properties of word embeddings for detecting the emergence of new topics","1152":"FlexiTerm. A more efficient implementation of flexible multiword term recognition","1153":"Developing Successful Shared Tasks on Offensive Language Identification for Dravidian Languages","1154":"Feature Selective Likelihood Ratio Estimator for Low and Zerofrequency Ngrams","1155":"Negative Sample is Negative in Its Own Way. Tailoring Negative Sentences for ImageText Retrieval","1156":"LTL under reductions with weaker conditions than stutterinvariance","1157":"Zeroshot Crosslingual Transfer of Neural Machine Translation with Multilingual Pretrained Encoders","1158":"Dataset of Fake News Detection and Fact Verification. A Survey","1159":"A SyntaxGuided Grammatical Error Correction Model with Dependency Tree Correction","1160":"Dialogue Inspectional Summarization with Factual Inconsistency Awareness","1161":"ContextAware Transformer Transducer for Speech Recognition","1162":"Text classification with pixel embedding","1163":"Benchmarking the Combinatorial Generalizability of Complex Query Answering on Knowledge Graphs","1164":"SeqScore. Addressing Barriers to Reproducible Named Entity Recognition Evaluation","1165":"Paradigm Shift in Language Modeling. Revisiting CNN for Modeling Sanskrit Originated Bengali and Hindi Language","1166":"An overview of event extraction and its applications","1167":"LILA. LanguageInformed Latent Actions","1168":"ContraQA. Question Answering under Contradicting Contexts","1169":"LanguageRefer. SpatialLanguage Model for 3D Visual Grounding","1170":"Adversarial Attacks on Knowledge Graph Embeddings via Instance Attribution Methods","1171":"How Do Neural Sequence Models Generalize Local and Global Context Cues for OutofDistribution Prediction","1172":"Emergent Discrete Communication in Semantic Spaces","1173":"Embodied BERT. A Transformer Model for Embodied Languageguided Visual Task Completion","1174":"Reducing the impact of out of vocabulary words in the translation of natural language questions into SPARQL queries","1175":"BERTDRE. BERT with Deep Recursive Encoder for Natural Language Sentence Matching","1176":"Unsupervised and Distributional Detection of MachineGenerated Text","1177":"Who speaks like a style of Vitamin. Towards SyntaxAware DialogueSummarization using Multitask Learning","1178":"A text autoencoder from transformer for fast encoding language representation","1179":"A Case Study and Qualitative Analysis of Simple CrossLingual Opinion Mining","1180":"Towards Learning to Speak and Hear Through MultiAgent Communication over a Continuous Acoustic Channel","1181":"Medicines Question Answering System MeQA","1182":"Benchmarking Multimodal AutoML for Tabular Data with Text Fields","1183":"CoreLM. Coreferenceaware Language Model FineTuning","1184":"Voice Conversion Can Improve ASR in Very LowResource Settings","1185":"CSAGN. Conversational Structure Aware Graph Network for Conversational Semantic Role Labeling","1186":"Speech recognition for air traffic control via feature learning and endtoend training","1187":"Extracting a Knowledge Base of COVID19 Events from Social Media","1188":"Lexically Aware SemiSupervised Learning for OCR PostCorrection","1189":"On Semantic Cognition Inductive Generalization and Language Models","1190":"Contextual Semantic Parsing for Multilingual TaskOriented Dialogues","1191":"CLUES. FewShot Learning Evaluation in Natural Language Understanding","1192":"HydraSum. Disentangling Stylistic Features in Text Summarization using MultiDecoder Models","1193":"Athena 2.0. Contextualized Dialogue Management for an Alexa Prize SocialBot","1194":"Active learning for reducing labeling effort in text classification tasks","1195":"ONION. A Simple and Effective Defense Against Textual Backdoor Attacks","1196":"HmBlogs. A big general Persian corpus","1197":"VLMo. Unified VisionLanguage PreTraining with MixtureofModalityExperts","1198":"Exploring the Landscape of Relational Syllogistic Logics","1199":"EndtoEnd Annotator Bias Approximation on Crowdsourced SingleLabel Sentiment Analysis","1200":"A PubMedBERTbased Classifier with Data Augmentation Strategy for Detecting Medication Mentions in Tweets","1201":"Towards Textbased Phishing Detection","1202":"Automatic Embedding of Stories Into Collections of Independent Media","1203":"Learning Implicit Sentiment in Aspectbased Sentiment Analysis with Supervised Contrastive PreTraining","1204":"A crossmodal fusion network based on selfattention and residual structure for multimodal emotion recognition","1205":"Social Media Reveals UrbanRural Differences in Stress across China","1206":"Lingua Custodias participation at the WMT 2021 Machine Translation using Terminologies shared task","1207":"LAION400M. Open Dataset of CLIPFiltered 400 Million ImageText Pairs","1208":"Text Detoxification using Large Pretrained Neural Models","1209":"Multilingual Machine Translation Systems from Microsoft for WMT21 Shared Task","1210":"A Comparative Study of Speaker Role Identification in Air Traffic Communication Using Deep Learning Approaches","1211":"A Multilevel Neural Network for Implicit Causality Detection in Web Texts","1212":"A Simple and Effective Positional Encoding for Transformers","1213":"Stable Fast and Accurate. Kernelized Attention with Relative Positional Encoding","1214":"OpenPrompt. An Opensource Framework for Promptlearning","1215":"Leveraging Advantages of Interactive and NonInteractive Models for VectorBased CrossLingual Information Retrieval","1216":"Improving Classifier Training Efficiency for Automatic Cyberbullying Detection with Feature Density","1217":"Luna. Linear Unified Nested Attention","1218":"Personalized OneShot Lipreading for an ALS Patient","1219":"Assessing Effectiveness of Using Internal Signals for CheckWorthy Claim Identification in Unlabeled Data for Automated FactChecking","1220":"KLUE. Korean Language Understanding Evaluation","1221":"LMdiff. A Visual Diff Tool to Compare Language Models","1222":"UQuAD1.0. Development of an Urdu Question Answering Training Data for Machine Reading Comprehension","1223":"Detection of Hate Speech using BERT and Hate Speech Word Embedding with Deep Model","1224":"ZeroShot Translation using Diffusion Models","1225":"System Combination for Grammatical Error Correction Based on Integer Programming","1226":"A Review of Dialogue Systems. From Trained Monkeys to Stochastic Parrots","1227":"Integrating Pretrained Language Model for Dialogue Policy Learning","1228":"Augmenting semantic lexicons using word embeddings and transfer learning","1229":"Investigating the Impact of Pretrained Language Models on Dialog Evaluation","1230":"Adapting to the Long Tail. A MetaAnalysis of Transfer Learning Research for Language Understanding Tasks","1231":"Crosslingual Transfer for Speech Processing using Acoustic Language Similarity","1232":"Diverse Distributions of SelfSupervised Tasks for MetaLearning in NLP","1233":"Language Semantics Interpretation with an Interactionbased Recurrent Neural Networks","1234":"Weakly Supervised Concept Map Generation through TaskGuided Graph Translation","1235":"Recent Advances in Natural Language Processing via Large PreTrained Language Models. A Survey","1236":"Improved Latent Tree Induction with Distant Supervision via Span Constraints","1237":"Switch Point biased SelfTraining. Repurposing Pretrained Models for CodeSwitching","1238":"On the Robustness of Intent Classification and Slot Labeling in Goaloriented Dialog Systems to Realworld Noise","1239":"Evaluating robustness of You Only Hear OnceYOHO Algorithm on noisy audios in the VOICe Dataset","1240":"Cryptonite. A Cryptic Crossword Benchmark for Extreme Ambiguity in Language","1241":"MeLT. MessageLevel Transformer with Masked Document Representations as PreTraining for Stance Detection","1242":"Transformers for promptlevel EMA nonresponse prediction","1243":"ASMDD. Arabic Speech Mispronunciation Detection Dataset","1244":"NormFormer. Improved Transformer Pretraining with Extra Normalization","1245":"Introspective Distillation for Robust Question Answering","1246":"Interpretable contrastive word movers embedding","1247":"Hate and Offensive Speech Detection in Hindi and Marathi","1248":"Crosslingual Hate Speech Detection using Transformer Models","1249":"Contextual Hate Speech Detection in Code Mixed Text using Transformer Based Approaches","1250":"A transfer learning based approach for pronunciation scoring","1251":"Transductive Data Augmentation with Relational Path Rule Mining for Knowledge Graph Embedding","1252":"Enhanced Language Representation with Label Knowledge for Span Extraction","1253":"Deep Learning Transformer Architecture for Named Entity Recognition on Low Resourced Languages. State of the art results","1254":"Unsupervised Discovery of Unaccusative and Unergative Verbs","1255":"Looking for Clues of Language in Multilingual BERT to Improve Crosslingual Generalization","1256":"Global Explainability of BERTBased Evaluation Metrics by Disentangling along Linguistic Factors","1257":"Unsupervised Multiple Choices Question Answering. Start Learning from Basic Knowledge","1258":"A New Tool for Efficiently Generating Quality Estimation Datasets","1259":"Optimizing small BERTs trained for German NER","1260":"First Target and Opinion then Polarity. Enhancing Targetopinion Correlation for Aspect Sentiment Triplet Extraction","1261":"Outlining and Filling. Hierarchical Query Graph Generation for Answering Complex Questions over Knowledge Graph","1262":"Comparative Study of Long Document Classification","1263":"Domainadaptation of spherical embeddings","1264":"Unsupervised Domain Adaptation with Adapter","1265":"A Survey on Extraction of Causal Relations from Natural Language Text","1266":"RBERTCNN. Drugtarget interactions extraction from biomedical literature","1267":"Towards Language Modelling in the Speech Domain Using Subword Linguistic Units","1268":"Text Classification for Taskbased Source Code Related Questions","1269":"What Went Wrong Explaining Overall Dialogue Quality through UtteranceLevel Impacts","1270":"An Approach to InferenceDriven Dialogue Management within a Social Chatbot","1271":"Combining Vagueness Detection with Deep Learning to Identify Fake News","1272":"Revealing and Protecting Labels in Distributed Training","1273":"Quality Estimation Using Roundtrip Translation with Sentence Embeddings","1274":"CrossDomain Reasoning via Template Filling","1275":"Achieving Model Robustness through Discrete Adversarial Training","1276":"DSCIITISM at FinCausal 2021. Combining POS tagging with Attentionbased Contextual Representations for Identifying Causal Relationships in Financial Documents","1277":"Hierarchical Deep Residual Reasoning for Temporal Moment Localization","1278":"Speech Emotion Recognition Using Quaternion Convolutional Neural Networks","1279":"FANS. Fusing ASR and NLU for ondevice SLU","1280":"HBert  BiasCorp  Fighting Racism on the Web","1281":"AdvCodeMix. Adversarial Attack on CodeMixed Data","1282":"EmpBot. A T5based Empathetic Chatbot focusing on Sentiments","1283":"Improving Portuguese Semantic Role Labeling with Transformers and Transfer Learning","1284":"Uncovering the Limits of Textbased Emotion Detection","1285":"Efficient Variational Graph Autoencoders for Unsupervised Crossdomain Prerequisite Chains","1286":"Probabilistic Entity Representation Model for Reasoning over Knowledge Graphs","1287":"PREDICT. Persian Reverse Dictionary","1288":"Multilingual and crosslingual speech recognition using phonologicalvector based phone embeddings","1289":"Magic Pyramid. Accelerating Inference with Early Exiting and Token Pruning","1290":"ELLA. Exploration through Learned Language Abstraction","1291":"Backdoor Pretrained Models Can Transfer to All","1292":"Automatic Knowledge Augmentation for Generative Commonsense Reasoning","1293":"How should human translation coexist with NMT Efficient tool for building high quality parallel corpus","1294":"SpeakerOriented Latent Structures for DialogueBased Relation Extraction","1295":"Hierarchical Heterogeneous Graph Representation Learning for Short Text Classification","1296":"DSEE. Dually Sparsityembedded Efficient Tuning of Pretrained Language Models","1297":"Skyformer. Remodel SelfAttention with Gaussian Kernel and Nystr\u00f6m Method","1298":"Visual Keyword Spotting with Attention","1299":"Unsupervised Full Constituency Parsing with Neighboring Distribution Divergence","1300":"Transformer Ensembles for Sexism Detection","1301":"On the Feasibility of Predicting Questions being Forgotten in Stack Overflow","1302":"Adversarial RetrieverRanker for dense text retrieval","1303":"Answering OpenDomain Questions of Varying Reasoning Steps from Text","1304":"To Share or not to Share. Predicting Sets of Sources for Model Transfer Learning","1305":"FAME. FeatureBased Adversarial MetaEmbeddings for Robust Input Representations","1306":"Comparing Machine LearningCentered Approaches for Forecasting Language Patterns During Frustration in Early Childhood","1307":"How to Leverage Multimodal EHR Data for Better Medical Predictions","1308":"MultiTask Learning with Sentiment Emotion and Target Detection to Recognize Hate Speech and Offensive Language","1309":"Overview of ADoBo 2021. Automatic Detection of Unassimilated Borrowings in the Spanish Press","1310":"Amendable Generation for Dialogue State Tracking","1311":"PathEnhanced MultiRelational Question Answering with Knowledge Graph Embeddings","1312":"MentalBERT. Publicly Available Pretrained Language Models for Mental Healthcare","1313":"Cognitive network science quantifies feelings expressed in suicide letters and Reddit mental health communities","1314":"Handshakes AI Research at CASE 2021 Task 1. Exploring different approaches for multilingual tasks","1315":"Deep Keyphrase Completion","1316":"Towards Tractable Mathematical Reasoning. Challenges Strategies and Opportunities for Solving Math Word Problems","1317":"Automatic Hand Sign Recognition. Identify Unusuality through Latent Cognizance","1318":"Structureaware Finetuning of Sequencetosequence Transformers for Transitionbased AMR Parsing","1319":"Pretraining Coevolutionary Protein Representation via A Pairwise Masked Language Model","1320":"Using Text Analytics for Health to Get Meaningful Insights from a Corpus of COVID Scientific Papers","1321":"Improving Noise Robustness of Contrastive Speech Representation Learning with Speech Reconstruction","1322":"Datatotext Generation by Splicing Together Nearest Neighbors","1323":"Extracting Daily Dosage from Medication Instructions in EHRs. An Automated Approach and Lessons Learned","1324":"What makes us curious analysis of a corpus of opendomain questions","1325":"Learning to Ground MultiAgent Communication with Autoencoders","1326":"NxMTransformer. SemiStructured Sparsification for Natural Language Understanding via ADMM","1327":"Multistage Clarification in Conversational AI. The case of QuestionAnswering Dialogue Systems","1328":"Exploring Wav2vec 2.0 finetuning for improved speech emotion recognition","1329":"BERTian Poetics. Constrained Composition with Masked LMs","1330":"DiversityDriven Combination for Grammatical Error Correction","1331":"Geometry matters. Exploring language examples at the decision boundary","1332":"An Analysis of Programming Course Evaluations Before and After the Introduction of an Autograder","1333":"Generating Table Vector Representations","1334":"Confounds and Overestimations in Fake Review Detection. Experimentally Controlling for ProductOwnership and DataOrigin","1335":"GraphTMT. Unsupervised Graphbased Topic Modeling from Video Transcripts","1336":"Empirical Analysis of Korean Public AI Hub Parallel Corpora and indepth Analysis using LIWC","1337":"A Novel Sequence Tagging Framework for Consumer EventCause Extraction","1338":"EndtoEnd Speech Emotion Recognition. Challenges of RealLife Emergency Call Centers Data Recordings","1339":"Preventing posterior collapse in variational autoencoders for text generation via decoder regularization","1340":"Combiner. Full Attention Transformer with Sparse Computation Cost","1341":"ColossalAI. A Unified Deep Learning System For LargeScale Parallel Training","1342":"On the Interplay Between Sparsity Naturalness Intelligibility and Prosody in Speech Synthesis","1343":"A Sequence to Sequence Model for Extracting Multiple Product Name Entities from Dialog","1344":"Hate Speech Classifiers Learn HumanLike Social Stereotypes","1345":"PraCegoVer. A Large Dataset for Image Captioning in Portuguese","1346":"One Question Answering Model for Many Languages with Crosslingual Dense Passage Retrieval","1347":"Investigating Disagreement in the Scientific Literature","1348":"Is Automated Topic Model Evaluation Broken. The Incoherence of Coherence","1349":"The OutofDistribution Problem in Explainability and Search Methods for Feature Importance Explanations","1350":"Detecting Dementia from Speech and Transcripts using Transformers","1351":"Bias OutoftheBox. An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models","1352":"AnomalyInjected Deep Support Vector Data Description for Text Outlier Detection","1353":"DOBF. A Deobfuscation PreTraining Objective for Programming Languages","1354":"Towards Realistic SingleTask Continuous Learning Research for NER","1355":"IndoNLI. A Natural Language Inference Dataset for Indonesian","1356":"Discovering Nonmonotonic Autoregressive Orderings with Variational Inference","1357":"Kaizen. Continuously improving teacher using Exponential Moving Average for semisupervised speech recognition","1358":"Can Linguistic Distance help Language Classification Assessing HawramiZaza and KurmanjiSorani","1359":"BARTScore. Evaluating Generated Text as Text Generation","1360":"Deep Learning For Prominence Detection In Childrens Read Speech","1361":"SQALER. Scaling Question Answering by Decoupling MultiHop and Logical Reasoning","1362":"Dynamic populationbased metalearning for multiagent communication with natural language","1363":"Syllabic Quantity Patterns as Rhythmic Features for Latin Authorship Attribution","1364":"LightSeq2. Accelerated Training for Transformerbased Models on GPUs","1365":"Evidential Softmax for Sparse Multimodal Distributions in Deep Generative Models","1366":"Diversity Enhanced Active Learning with Strictly Proper Scoring Rules","1367":"COCOLM. Correcting and Contrasting Text Sequences for Language Model Pretraining","1368":"Active Learning for Massively Parallel Translation of Constrained Text into Low Resource Languages","1369":"ConnecttheDots. Bridging Semantics between Words and Definitions via Aligning Word Sense Inventories","1370":"Structured Reordering for Modeling Latent Alignments in Sequence Transduction","1371":"Adversarial Attacks and Defenses for Social Network Text Processing Applications. Techniques Challenges and Future Research Directions","1372":"Diachronic Text Mining Investigation of Therapeutic Candidates for COVID19","1373":"Understanding Interlocking Dynamics of Cooperative Rationalization","1374":"Assessing Evaluation Metrics for SpeechtoSpeech Translation","1375":"PARP. Prune Adjust and RePrune for SelfSupervised Speech Recognition","1376":"Fabula Entropy Indexing. Objective Measures of Story Coherence","1377":"Cut the CARP. Fishing for zeroshot story evaluation","1378":"Customized determination of stop words using Random Matrix Theory approach","1379":"Attention over learned object embeddings enables complex visual reasoning","1380":"Mind the Gap. Assessing Temporal Generalization in Neural Language Models","1381":"Can Characterbased Language Models Improve Downstream Task Performance in LowResource and Noisy Language Scenarios","1382":"Towards Continual Knowledge Learning of Language Models","1383":"Does the Magic of BERT Apply to Medical Code Assignment A Quantitative Study","1384":"DASentimental. Detecting depression anxiety and stress in texts via emotional recall cognitive networks and machine learning","1385":"Annotating Implicit Reasoning in Arguments with Causal Links","1386":"An ExplicitJoint and SupervisedContrastive Learning Framework for FewShot Intent Classification and Slot Filling","1387":"BioIE. Biomedical Information Extraction with Multihead Attention Enhanced Graph Convolutional Network","1388":"s2sft. FineTuning Pretrained Transformer Encoders for SequencetoSequence Learning","1389":"EviDR. EvidenceEmphasized Discrete Reasoning for Reasoning Machine Reading Comprehension","1390":"Data Augmentation with Hierarchical SQLtoQuestion Generation for Crossdomain TexttoSQL Parsing","1391":"Open Rule Induction","1392":"Estimating Redundancy in Clinical Text","1393":"Globalaware Beam Search for Neural Abstractive Summarization","1394":"CLAUSEREC. A Clause Recommendation Framework for AIaided Contract Authoring","1395":"Part  Whole Extraction. Towards A Deep Understanding of Quantitative Facts for Percentages in Text","1396":"Assessing the Sufficiency of Arguments through Conclusion Generation","1397":"Simultaneous Neural Machine Translation with Constituent Label Prediction","1398":"A Transformerbased Crossmodal Fusion Model with Adversarial Training for VQA Challenge 2021","1399":"Decomposing Complex Questions Makes MultiHop QA Easier and More Interpretable","1400":"TailtoTail NonAutoregressive Sequence Prediction for Chinese Grammatical Error Correction","1401":"VarArray. ArrayGeometryAgnostic Continuous Speech Separation","1402":"AVocaDo. Strategy for Adapting Vocabulary to Downstream Domain","1403":"Counterfactual Maximum Likelihood Estimation for Training Deep Networks","1404":"Transliteration of Foreign Words in Burmese","1405":"Unified Instance and Knowledge Alignment Pretraining for Aspectbased Sentiment Analysis","1406":"TaskSpecific Dependencybased Word Embedding Methods","1407":"On the Variance of the Adaptive Learning Rate and Beyond","1408":"Robustness and Sensitivity of BERT Models Predicting Alzheimers Disease from Text","1409":"Exposure of occupations to technologies of the fourth industrial revolution","1410":"Deep Extrapolation for AttributeEnhanced Generation","1411":"DeepHelp. Deep Learning for Shout Crisis Text Conversations","1412":"Improving the Diversity of Unsupervised Paraphrasing with Embedding Outputs","1413":"Findings from Experiments of Online Joint Reinforcement Learning of Semantic Parser and Dialogue Manager with real Users","1414":"SciClops. Detecting and Contextualizing Scientific Claims for Assisting Manual FactChecking","1415":"XeroAlign. ZeroShot Crosslingual Transformer Alignment","1416":"Generating artificial texts as substitution or complement of training data","1417":"Persona Authentication through Generative Dialogue","1418":"Generating Watermarked Adversarial Texts","1419":"A Survey on Dialog Management. Recent Advances and Challenges","1420":"On the ability of monolingual models to learn languageagnostic representations","1421":"DUKweb. Diachronic word representations from the UK Web Archive corpus","1422":"Yes BM25 is a Strong Baseline for Legal Case Retrieval","1423":"So You Think Youre Funny. Rating the Humour Quotient in Standup Comedy","1424":"Contrastive Learning for Neural Topic Model","1425":"Finetuning of Pretrained Transformers for Hate Offensive and Profane Content Detection in English and Marathi","1426":"TODSum. TaskOriented Dialogue Summarization with State Tracking","1427":"M610T. A SharingDelinking Paradigm for Efficient MultiTrillion Parameter Pretraining","1428":"ZeroShot Dialogue Disentanglement by SelfSupervised Entangled Response Selection","1429":"SgSum. Transforming Multidocument Summarization into Subgraph Selection","1430":"Interpreting Deep Learning Models in Natural Language Processing. A Review","1431":"SciCap. Generating Captions for Scientific Figures","1432":"EchoEA. Echo Information between Entities and Relations for Entity Alignment","1433":"No News is Good News. A Critique of the One Billion Word Benchmark","1434":"A Dataset for Answering TimeSensitive Questions","1435":"Alignment Attention by Matching Key and Query Distributions","1436":"Noisy UGC Translation at the Character Level. Revisiting OpenVocabulary Capabilities and Robustness of CharBased Models","1437":"Understanding the Impact of UGC Specificities on Translation Quality","1438":"Abstractified Multiinstance Learning AMIL for Biomedical Relation Extraction","1439":"Adaptive Multimodal and Multisensory Empathic Technologies for Enhanced Human Communication","1440":"Sentence Punctuation for Collaborative Commentary Generation in Esports LiveStreaming","1441":"Improved Goal Oriented Dialogue via Utterance Generation and Look Ahead","1442":"Automated Extraction of Sentencing Decisions from Court Cases in the Hebrew Language","1443":"Filling the Gaps in Ancient Akkadian Texts. A Masked Language Modelling Approach","1444":"Transliterating Kurdish texts in Latin into PersianArabic script","1445":"Team Enigma at ArgMiningEMNLP 2021. Leveraging Pretrained Language Models for Key Point Matching","1446":"Exploring Task Difficulty for FewShot Relation Extraction","1447":"Think about it Improving defeasible reasoning by first modeling the question scenario","1448":"Distributed neural encoding of binding to thematic roles","1449":"Scalable knowledge base completion with superposition memories","1450":"Chinese Traditional Poetry Generating System Based on Deep Learning","1451":"CoVA. Contextaware Visual Attention for Webpage Information Extraction","1452":"Guided Policy Search for Parameterized Skills using Adverbs","1453":"Language Models as a Knowledge Source for Cognitive Agents","1454":"PASTRIE. A Corpus of Prepositions Annotated with Supersense Tags in Reddit International English","1455":"Deep Transfer Learning  Beyond. Transformer Language Models in Information Systems Research","1456":"Spanish Legalese Language Model and Corpora","1457":"PhoMT. A HighQuality and LargeScale Benchmark Dataset for VietnameseEnglish Machine Translation","1458":"LawSum. A weakly supervised approach for Indian Legal Document Summarization","1459":"Hierarchical Aspectguided Explanation Generation for Explainable Recommendation","1460":"Prompttuning in ASR systems for efficient domainadaptation","1461":"CrossModal Generative Augmentation for Visual Question Answering","1462":"Specializing Multilingual Language Models. An Empirical Study","1463":"ClimateBert. A Pretrained Language Model for ClimateRelated Text","1464":"A Framework for Learning Assessment through Multimodal Analysis of Reading Behaviour and Language Comprehension","1465":"Cleaning Dirty Books. PostOCR Processing for Previously Scanned Texts","1466":"Double Trouble. How to not explain a text classifiers decisions using counterfactuals synthesized by masked language models","1467":"Challenges in Procedural Multimodal Machine Comprehension.A Novel Way To Benchmark","1468":"Simple Dialogue System with AUDITED","1469":"Lightweight Decoding Strategies for Increasing Specificity","1470":"Key Point Analysis via Contrastive Learning and Extractive Argument Summarization","1471":"Argmax Flows and Multinomial Diffusion. Learning Categorical Distributions","1472":"ListReader. Extracting Listform Answers for Opinion Questions","1473":"The MuSe 2021 Multimodal Sentiment Analysis Challenge. Sentiment Emotion PhysiologicalEmotion and Stress","1474":"The Unreasonable Effectiveness of the Baseline. Discussing SVMs in Legal Text Classification","1475":"Using Personality Detection Tools for Software Engineering Research. How Far Can We Go","1476":"GPUAccelerated ForwardBackward algorithm with Application to LatticeFree MMI","1477":"Improving BERT with SelfSupervised Attention","1478":"Text Counterfactuals via Latent Optimization and ShapleyGuided Search","1479":"Adaptive Bridge between Training and Inference for Dialogue","1480":"Iterative Hierarchical Attention for Answering Complex Questions over Long Documents","1481":"MERLOT. Multimodal Neural Script Knowledge Models","1482":"SYNERGY. Building Task Bots at Scale Using Symbolic Knowledge and Machine Teaching","1483":"Do Large Scale Molecular Language Representations Capture Important Structural Information","1484":"Visually Grounded Reasoning across Languages and Cultures","1485":"A Python Package to Detect AntiVaccine Users on Twitter","1486":"Fast Model Editing at Scale","1487":"Inducing Alignment Structure with Gated Graph Attention Networks for Sentence Matching","1488":"TopicGuided Abstractive MultiDocument Summarization","1489":"Asynchronous Decentralized Distributed Training of Acoustic Models","1490":"Predicting the Reproducibility of Social and Behavioral Science Papers Using Supervised Learning Models","1491":"Modeling Performance in OpenDomain Dialogue with PARADISE","1492":"Improving Nonautoregressive Generation with Mixup Training","1493":"Semantic Answer Similarity for Evaluating Question Answering Models","1494":"LOA. Logical Optimal Actions for Textbased Interaction Games","1495":"NeuroSymbolic Reinforcement Learning with FirstOrder Logic","1496":"Conditional Poisson Stochastic Beam Search","1497":"CNewSum. A Largescale Chinese News Summarization Dataset with Humanannotated Adequacy and Deducibility Level","1498":"Principled Representation Learning for Entity Alignment","1499":"Hindsight. Posteriorguided training of retrievers for improved openended generation","1500":"BEIR. A Heterogenous Benchmark for Zeroshot Evaluation of Information Retrieval Models","1501":"Integrating Visuospatial Linguistic and Commonsense Structure into Story Visualization","1502":"SIMMC 2.0. A Taskoriented Dialog Dataset for Immersive Multimodal Conversations","1503":"The R package sentometrics to compute aggregate and predict with textual sentiment","1504":"Contrastive Document Representation Learning with Graph Attention Networks","1505":"Approximating How Single Head Attention Learns","1506":"SciXGen. A Scientific Paper Dataset for ContextAware Text Generation","1507":"Better than Average. Paired Evaluation of NLP Systems","1508":"Learning Knowledge Graphbased World Models of Textual Environments","1509":"Evaluating the Evaluation Metrics for Style Transfer. A Case Study in Multilingual Formality Transfer","1510":"Overview of the 2021 Key Point Analysis Shared Task","1511":"SocialVisTUM. An Interactive Visualization Toolkit for Correlated Neural Topic Models on Social Media Opinion Mining","1512":"Simulated Chats for Building Dialog Systems. Learning to Generate Conversations from Instructions","1513":"A Joint Model for AspectCategory Sentiment Analysis with Shared Sentiment Prediction Layer","1514":"The Multimodal Sentiment Analysis in Car Reviews MuSeCaR Dataset. Collection Insights and Improvements","1515":"MuSeToolbox. The Multimodal Sentiment Analysis Continuous Annotation Fusion and Discrete Class Transformation Toolbox","1516":"Continual Learning in Multilingual NMT via LanguageSpecific Embeddings","1517":"Multilingual Unsupervised Neural Machine Translation with Denoising Adapters","1518":"VisualSem. A Highquality Knowledge Graph for Vision and Language","1519":"Discontinuous Grammar as a Foreign Language","1520":"Knowledge distillation from language model to acoustic model. a hierarchical multitask learning approach","1521":"nstage Latent Dirichlet Allocation. A Novel Approach for LDA","1522":"text2sdg. An opensource solution to monitoring sustainable development goals from text","1523":"A Comprehensive Exploration of Pretraining Language Models","1524":"Distributionally Robust Classifiers in Sentiment Analysis","1525":"A nonhierarchical attention network with modality dropout for textual response generation in multimodal dialogue systems","1526":"Newsbased Business Sentiment and its Properties as an Economic Index","1527":"Learning Contextualised Crosslingual Word Embeddings and Alignments for Extremely LowResource Languages Using Parallel Corpora","1528":"SLAM. A Unified Encoder for Speech and Language Modeling via SpeechText Joint PreTraining","1529":"R3Net.Relationembedded Representation Reconstruction Network for Change Captioning","1530":"LMSOC. An Approach for Socially Sensitive Pretraining","1531":"Improved Multilingual Language Model Pretraining for Social Media Text via Translation Pair Prediction","1532":"HETFORMER. Heterogeneous Transformer with Sparse Attention for LongText Extractive Summarization","1533":"Neural Medication Extraction. A Comparison of Recent Models in Supervised and Semisupervised Learning Settings","1534":"Application of the Multilabel Residual Convolutional Neural Network text classifier using ContentBased Routing process","1535":"StructFormer. Learning Spatial Structure for LanguageGuided Semantic Rearrangement of Novel Objects","1536":"GenNI. HumanAI Collaboration for DataBacked Text Generation","1537":"VidLanKD. Improving Language Understanding via VideoDistilled Knowledge Transfer","1538":"LAViTeR. Learning Aligned Visual and Textual Representations Assisted by Image and Caption Generation","1539":"Idiomatic Expression Identification using Semantic Compatibility","1540":"DEEPAG\u00c9. Answering Questions in Portuguese about the Brazilian Environment","1541":"Interpretive Blindness","1542":"Entity Relation Extraction as Dependency Parsing in Visually Rich Documents","1543":"Twostage Voice Application Recommender System for Unhandled Utterances in Intelligent Personal Assistant","1544":"As long as you talk about me. The importance of family firm brands and the contingent role of familyfirm identity","1545":"Multimodal Retrieval of Tables and Texts Using Triencoder Models","1546":"Causal Direction of Data Collection Matters. Implications of Causal and Anticausal Learning for NLP","1547":"Opendomain clarification question generation without question examples","1548":"A Picture is Worth a Thousand Words. A Unified System for Diverse Captions and Rich Images Generation","1549":"Unifying Multimodal Transformer for Bidirectional Image and Text Generation","1550":"Compositional Networks Enable Systematic Generalization for Grounded Language Understanding","1551":"From Multimodal to Unimodal Attention in Transformers using Knowledge Distillation","1552":"Exploring the Sensory Spaces of English Perceptual Verbs in Natural Language Data","1553":"InterSense. An Investigation of Sensory Blending in Fiction","1554":"HALO 1.0. A Hardwareagnostic Accelerator Orchestration Framework for Enabling Hardwareagnostic Programming with True Performance Portability for Heterogeneous HPC","1555":"Exploring Generalization Ability of Pretrained Language Models on Arithmetic and Logical Reasoning","1556":"Neural Lexicon Reader. Reduce Pronunciation Errors in Endtoend TTS by Leveraging External Textual Knowledge","1557":"Ensemble ALBERT on SQuAD 2.0","1558":"Monotonic Simultaneous Translation with Chunkwise Reordering and Refinement","1559":"A Systematic Review on the Detection of Fake News Articles","1560":"Word Order Does Not Matter For Speech Recognition","1561":"Multilingual Domain Adaptation for NMT. Decoupling Language and Domain Information with Adapters","1562":"Embracing advanced AIML to help investors achieve success. Vanguard Reinforcement Learning for Financial Goal Planning","1563":"A Data Bootstrapping Recipe for Low Resource Multilingual Relation Classification","1564":"Break Perturb Build. Automatic Perturbation of Reasoning Paths Through Question Decomposition","1565":"Protecting Anonymous Speech. A Generative Adversarial Network Methodology for Removing Stylistic Indicators in Text","1566":"BERMo. What can BERT learn from ELMo","1567":"SentimentArcs. A Novel Method for SelfSupervised Sentiment Analysis of Time Series Shows SOTA Transformers Can Struggle Finding Narrative Arcs","1568":"Dont Judge Me by My Face . An Indirect Adversarial Approach to Remove Sensitive Information From Multimodal Neural Representation in Asynchronous Job Video Interviews","1569":"Measuring Cognitive Status from Speech in a Smart Home Environment","1570":"Ceasing hate withMoH. Hate Speech Detection in HindiEnglish CodeSwitched Language","1571":"ExplaGraphs. An Explanation Graph Generation Task for Structured Commonsense Reasoning","1572":"Automatic Learning of Subword Dependent Model Scales","1573":"The Arabic Parallel Gender Corpus 2.0. Extensions and Analyses","1574":"Modulating BottomUp and TopDown Visual Processing via LanguageConditional Filters","1575":"Analysis of French Phonetic Idiosyncrasies for Accent Recognition","1576":"Revisiting IPAbased Crosslingual Texttospeech","1577":"BEAMetrics. A Benchmark for Language Generation Evaluation Evaluation","1578":"LDNet. Unified Listener Dependent Modeling in MOS Prediction for Synthetic Speech","1579":"SCENIC. A JAX Library for Computer Vision Research and Beyond","1580":"Using Natural Language Processing to Understand Reasons and Motivators Behind Customer Calls in Financial Domain","1581":"Factorized Neural Transducer for Efficient Language Model Adaptation","1582":"Efficient Contrastive Learning via Novel Data Augmentation and Curriculum Learning","1583":"Speech Representation Learning Through Selfsupervised Pretraining And Multitask Finetuning","1584":"Ranking Facts for Explaining Answers to Elementary Science Questions","1585":"FastCorrect 2. Fast Error Correction on Multiple Candidates for Automatic Speech Recognition","1586":"Improved Language Identification Through CrossLingual SelfSupervised Learning","1587":"Quantifying the TaskSpecific Information in TextBased Classifications","1588":"LSTM Based Sentiment Analysis for Cryptocurrency Prediction","1589":"Schr\u00f6dingers Tree  On Syntax and Neural Language Models","1590":"Predicting the Performance of Multilingual NLP Models","1591":"Prioritization of COVID19related literature via unsupervised keyphrase extraction and document representation learning","1592":"FineGrained Opinion Summarization with Minimal Supervision","1593":"Jointly Modeling Aspect and Polarity for Aspectbased Sentiment Analysis in Persian Reviews","1594":"Reminding the Incremental Language Model via DataFree SelfDistillation","1595":"Multitask Balanced and Recalibrated Network for Medical Code Prediction","1596":"Transformer with a Mixture of Gaussian Keys","1597":"LoRA. LowRank Adaptation of Large Language Models","1598":"Back to Reality. Leveraging Patterndriven Modeling to Enable Affordable Sentiment Dependency Learning","1599":"ASR4REAL. An extended benchmark for speech models","1600":"PositionAware SelfAttention based Neural Sequence Labeling","1601":"FrugalScore. Learning Cheaper Lighter and Faster Evaluation Metricsfor Automatic Text Generation","1602":"PAGnol. An ExtraLarge French Generative Model","1603":"HRKD. Hierarchical Relational Knowledge Distillation for Crossdomain Language Model Compression","1604":"A Unified Speaker Adaptation Approach for ASR","1605":"Substructure Distribution Projection for ZeroShot CrossLingual Dependency Parsing","1606":"Sparse Distillation. Speeding Up Text Classification by Using Bigger Models","1607":"Lifelong Pretraining. Continually Adapting Language Models to Emerging Corpora","1608":"ProKD. Progressive Distillation by Following the Footsteps of the Teacher","1609":"A Dataset for Discourse Structure in Peer Review Discussions","1610":"Monolingual versus Multilingual BERTology for Vietnamese Extractive MultiDocument Summarization","1611":"Analyzing Dynamic Adversarial Training Data in the Limit","1612":"Leveraging Knowledge in Multilingual Commonsense Reasoning","1613":"A Short Study on Compressing DecoderBased Language Models","1614":"Knowledge Enhanced Pretrained Language Models. A Compreshensive Survey","1615":"Family of Origin and Family of Choice. Massively Parallel Lexiconized Iterative Pretraining for Severely Low Resource Machine Translation","1616":"How Well Do You Know Your Audience Readeraware Question Generation","1617":"Metadata Shaping. Natural Language Annotations for the Tail","1618":"EncT5. Finetuning T5 Encoder for Nonautoregressive Tasks","1619":"InformationTheoretic Measures of Dataset Difficulty","1620":"What do Compressed Large Language Models Forget Robustness Challenges in Model Compression","1621":"Invariant Language Modeling","1622":"Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking Allegedly Important Tokens and Retraining","1623":"DSTOD. Efficient Domain Specialization for Task Oriented Dialog","1624":"SUPERB. Speech processing Universal PERformance Benchmark","1625":"Training Conversational Agents with Generative Conversational Networks","1626":"On The Ingredients of an Effective Zeroshot Semantic Parser","1627":"Detecting Gender Bias in Transformerbased Models. A Case Study on BERT","1628":"Learning with Noisy Labels by Targeted Relabeling","1629":"Omnisparsity DNN. Fast Sparsity Optimization for OnDevice Streaming E2E ASR via Supernet","1630":"On Learning the Transformer Kernel","1631":"What Will it Take to Fix Benchmarking in Natural Language Understanding","1632":"SemanticWER. A Unified Metric for the Evaluation of ASR Transcript for End Usability","1633":"Machine Translation into Lowresource Language Varieties","1634":"Balancing Methods for Multilabel Text Classification with LongTailed Class Distribution","1635":"Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks","1636":"Tricks for Training Sparse Translation Models","1637":"Intentbased Product Collections for Ecommerce using Pretrained Language Models","1638":"CrossDomain Data Integration for Named Entity Disambiguation in Biomedical Text","1639":"An Argumentative Dialogue System for COVID19 Vaccine Information","1640":"Towards Identity Preserving Normal to Dysarthric Voice Conversion","1641":"The World of an Octopus. How Reporting Bias Influences a Language Models Perception of Color","1642":"MixQG. Neural Question Generation with Mixed Answer Types","1643":"Kronecker Decomposition for GPT Compression","1644":"FewShot Bot. PromptBased Learning for Dialogue Systems","1645":"UltraHigh Dimensional Sparse Representations with Binarization for Efficient Text Retrieval","1646":"Generating Natural Language Adversarial Examples through An Improved Beam Search Algorithm","1647":"UniDS. A Unified Dialogue System for ChitChat and Taskoriented Dialogues","1648":"StreaMulT. Streaming Multimodal Transformer for Heterogeneous and Arbitrary Long Sequential Data","1649":"Multimodal EmotionCause Pair Extraction in Conversations","1650":"Crisis Domain Adaptation Using Sequencetosequence Transformers","1651":"Modeling Proficiency with Implicit User Representations","1652":"Transformerbased Multitask Learning for Disaster Tweet Categorisation","1653":"Leveraging OrderFree Tag Relations for ContextAware Recommendation","1654":"Scribosermo. Fast SpeechtoText models for German and other Languages","1655":"Interpretable agent communication from scratch with a generic visual processor emerging on the side","1656":"Identifying Causal Influences on Publication Trends and Behavior. A Case Study of the Computational Linguistics Community","1657":"SemEval2021 Task 11. NLPContributionGraph  Structuring Scholarly NLP Contributions for a Research Knowledge Graph","1658":"Estimating the Level and Direction of Phonetic Dialect Change in the Northern Netherlands","1659":"Multilingual Speech Recognition using Knowledge Transfer across Learning Processes","1660":"Moralitybased Assertion and Homophily on Social Media. A Cultural Comparison between English and Japanese Languages","1661":"Law Smells. Defining and Detecting Problematic Patterns in Legal Drafting","1662":"Exploring Lowdimensional Intrinsic Task Subspace via Prompt Tuning","1663":"EndtoEnd Segmentationbased News Summarization","1664":"Evaluating Biomedical BERT Models for Vocabulary Alignment at Scale in the UMLS Metathesaurus","1665":"Modeling Endorsement for MultiDocument Abstractive Summarization","1666":"ESPnet2TTS. Extending the Edge of TTS Research","1667":"CrossLingual FineGrained Entity Typing","1668":"Span Detection for AspectBased Sentiment Analysis in Vietnamese","1669":"RAP. RobustnessAware Perturbations for Defending against Backdoor Attacks on NLP Models","1670":"Named Entity Recognition in Unstructured Medical Text Documents","1671":"Trankit. A LightWeight Transformerbased Toolkit for Multilingual Natural Language Processing","1672":"DirectQuote. A Dataset for Direct Quotation Extraction and Attribution in News Articles","1673":"Speech Technology for Everyone. Automatic Speech Recognition for NonNative English with Transfer Learning","1674":"Multilingual Neural Machine Translation.Can Linguistic Hierarchies Help","1675":"Cascaded Fast and Slow Models for Efficient Semantic Code Search","1676":"Alternative Input Signals Ease Transfer in Multilingual Machine Translation","1677":"A Multilingual BagofEntities Model for ZeroShot CrossLingual Text Classification","1678":"LowRank Subspaces for Unsupervised Entity Linking","1679":"Emotion analysis and detection during COVID19","1680":"Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models","1681":"DWUG. A large Resource of Diachronic Word Usage Graphs in Four Languages","1682":"A Speakeraware Parallel Hierarchical Attentive EncoderDecoder Model for Multiturn Dialogue Generation","1683":"AutoTriggER. Named Entity Recognition with Auxiliary Trigger Extraction","1684":"Is Stance Detection TopicIndependent and Crosstopic Generalizable  A Reproduction Study","1685":"Crosslingual COVID19 Fake News Detection","1686":"Making DocumentLevel Information Extraction Right for the Right Reasons","1687":"A Brief Introduction to Automatic Differentiation for Machine Learning","1688":"Affective Decoding for Empathetic Response Generation","1689":"Sparks. Inspiration for Science Writing using Language Models","1690":"Compressibility of Distributed Document Representations","1691":"ZeroShot Dense Retrieval with Momentum Adversarial Domain Invariant Representations","1692":"Spoken ObjectNet. A BiasControlled Spoken Caption Dataset","1693":"Delphi. Towards Machine Ethics and Norms","1694":"LAGr. Labeling Aligned Graphs for Improving Systematic Generalization in Semantic Parsing","1695":"Practical Benefits of Feature Feedback Under Distribution Shift","1696":"Composable Sparse FineTuning for CrossLingual Transfer","1697":"The Irrationality of Neural Rationale Models","1698":"RobeCzech. Czech RoBERTa a monolingual contextualized language representation model","1699":"NonAutoregressive Translation with LayerWise Prediction and Deep Supervision","1700":"AES Systems Are Both Overstable And Oversensitive. Explaining Why And Proposing Defenses","1701":"Finetuning LargeScale Pretrained Language Models for Conversational Recommendation with Knowledge Graph","1702":"ConveRT for FAQ Answering","1703":"Designing Language Technologies for Social Good. The Road not Taken","1704":"Towards More Effective and Economic SparselyActivated Model","1705":"Automatic Modeling of Social Concepts Evoked by Art Images as Multimodal Frames","1706":"Evaluating OfftheShelf Machine Listening and Natural Language Models for Automated Audio Captioning","1707":"The Neglected Sibling. Isotropic Gaussian Posterior for VAE","1708":"Transferring Semantic Knowledge Into Language Encoders","1709":"BAS. An Answer Selection Method Using BERT Language Model","1710":"RocketQAv2. A Joint Training Method for Dense Passage Retrieval and Passage Reranking","1711":"PlugTagger. A Pluggable Sequence Labeling Framework Using Language Models","1712":"WMDecompose. A Framework for Leveraging the Interpretable Properties of Word Movers Distance in Sociocultural Analysis","1713":"Solving Aspect Category Sentiment Analysis as a Text Generation Task","1714":"Political Text Scaling Meets Computational Semantics","1715":"Beyond Voice Activity Detection. Hybrid Audio Segmentation for Direct Speech Translation","1716":"An Empirical Investigation of Multibridge Multilingual NMT models","1717":"AspectSentimentMultipleOpinion Triplet Extraction","1718":"Synthetic Data Augmentation for ZeroShot CrossLingual Question Answering","1719":"NOAHQA. Numerical Reasoning with Interpretable Graph Question Answering Dataset","1720":"Causal Transformers Perform Below Chance on Recursive Nested Constructions Unlike Humans","1721":"LaoPLM. Pretrained Language Models for Lao","1722":"Mengzi. Towards Lightweight yet Ingenious Pretrained Models for Chinese","1723":"Improve Crosslingual Voice Cloning Using Lowquality Codeswitched Data","1724":"A DualAttention Neural Network for Pun Location and Using PunGloss Pairs for Interpretation","1725":"Learning Semantics. An Opportunity for Effective 6G Communications","1726":"Symbolic Knowledge Distillation. from General Language Models to Commonsense Models","1727":"Contextgloss Augmentation for Improving Word Sense Disambiguation","1728":"MoFE. Mixture of Factual Experts for Controlling Hallucinations in Abstractive Summarization","1729":"Neural AttentionAware Hierarchical Topic Model","1730":"Transformer over Pretrained Transformer for Neural Text Segmentation with Enhanced Topic Coherence","1731":"CrossLingual GenQA. A LanguageAgnostic Generative Question Answering Approach for OpenDomain Question Answering","1732":"bert2BERT. Towards Reusable Pretrained Language Models","1733":"Mind the Style of Text Adversarial and Backdoor Attacks Based on Text Style Transfer","1734":"A CLIPEnhanced Method for VideoLanguage Understanding","1735":"Multilingual AMR Parsing with Noisy Knowledge Distillation","1736":"Continual learning using latticefree MMI for speech recognition","1737":"Improving the Robustness to Variations of Objects and Instructions with a NeuroSymbolic Approach for Interactive Instruction Following","1738":"Characterizing Partisan Political Narrative Frameworks about COVID19 on Twitter","1739":"Comparison of SVD and factorized TDNN approaches for speech to text","1740":"PhraseBERT. Improved Phrase Embeddings from BERT with an Application to Corpus Exploration","1741":"Explaining Deep Neural Networks","1742":"BagofVectors Autoencoders for Unsupervised Conditional Text Generation","1743":"OntheFly Attention Modulation for Neural Generation","1744":"Bandits Dont Follow Rules. Balancing MultiFacet Machine Translation with MultiArmed Bandits","1745":"OpenDomain QuestionAnswering for COVID19 and Other Emergent Domains","1746":"Semanticsaware Attention Improves Neural Machine Translation","1747":"Back to Square One. Artifact Detection Training and Commonsense Disentanglement in the Winograd Schema","1748":"Teaching Models new APIs. DomainAgnostic Simulators for Task Oriented Dialogue","1749":"AudioVisual SceneAware Dialog and Reasoning using AudioVisual Transformers with Joint StudentTeacher Learning","1750":"ConditionalQA. A Complex Reading Comprehension Dataset with Conditional Answers","1751":"Automated Essay Scoring Using Transformer Models","1752":"Semantic Role Labeling as Dependency Parsing. Exploring Latent Tree Structures Inside Arguments","1753":"Smart Proofs via Smart Contracts. Succinct and Informative Mathematical Derivations via Decentralized Markets","1754":"Ousiometrics and Telegnomics. The essence of meaning conforms to a twodimensional powerfulweak and dangeroussafe framework with diverse corpora presenting a safety bias","1755":"Leveraging redundancy in attention with Reuse Transformers","1756":"Masader. Metadata Sourcing for Arabic Text and Speech Data Resources","1757":"Systematic Inequalities in Language Technology Performance across the Worlds Languages","1758":"Truthful AI. Developing and governing AI that does not lie","1759":"SemanticBased SelfCritical Training For Question Generation","1760":"Maximizing Efficiency of Language Model Pretraining for Learning Representation","1761":"ECommerce Dispute Resolution Prediction","1762":"SGG. Learning to Select Guide and Generate for Keyphrase Generation","1763":"Decision Attentive Regularization to Improve Simultaneous Speech Translation Systems","1764":"Simple or Complex ComplexityControllable Question Generation with Soft Templates and Deep Mixture of Experts Model","1765":"Inconsistent FewShot Relation Classification via CrossAttentional Prototype Networks with Contrastive Learning","1766":"Does External Knowledge Help Explainable Natural Language Inference Automatic Evaluation vs. Human Ratings","1767":"Negation in Cognitive Reasoning","1768":"EventBERT. A PreTrained Model for Event Correlation Reasoning","1769":"DeepPSL. Endtoend perception and reasoning with applications to zero shot learning","1770":"The Dawn of Quantum Natural Language Processing","1771":"Perception Point. Identifying Critical Learning Periods in Speech for Bilingual Networks","1772":"Differentially Private Finetuning of Language Models","1773":"EndtoEnd Natural Language Understanding Pipeline for Bangla Conversational Agents","1774":"Understanding of Emotion Perception from Art","1775":"ActiveEA. Active Learning for Neural Entity Alignment","1776":"Fake News Detection in Spanish Using Deep Learning Techniques","1777":"Improving Graphbased Sentence Ordering with Iteratively Predicted Pairwise Orderings","1778":"SEPP. Similarity Estimation of Predicted Probabilities for Defending and Detecting Adversarial Text","1779":"Federated Natural Language Generation for Personalized Dialogue System","1780":"NumGPT. Improving Numeracy Ability of Generative Pretrained Models","1781":"An Overview of Ontologies and Tool Support for COVID19 Analytics","1782":"Attentionguided Generative Models for Extractive Question Answering","1783":"AutoNLU. Detecting rootcausing and fixing NLU model errors","1784":"ALL Dolphins Are Intelligent and SOME Are Friendly. Probing BERT for Nouns Semantic Properties and their Prototypicality","1785":"Learning Compact Metrics for MT","1786":"DecisionTheoretic Question Generation for Situated Reference Resolution. An Empirical Study and Computational Model","1787":"S3PRLVC. Opensource Voice Conversion Framework with Selfsupervised Speech Representations","1788":"LiST. Lite Selftraining Makes Efficient Fewshot Learners","1789":"Investigating the Effect of Natural Language Explanations on OutofDistribution Generalization in Fewshot NLI","1790":"A Survey on Legal Question Answering Systems","1791":"Extracting Feelings of People Regarding COVID19 by Social Network Mining","1792":"Modelbased analysis of brain activity reveals the hierarchy of language in 305 subjects","1793":"Minimal Supervision for Morphological Inflection","1794":"Deep Learning for Bias Detection. From Inception to Deployment","1795":"DiscoDVT. Generating Long Text with DiscourseAware Discrete Variational Transformer","1796":"SequencetoSequence Lexical Normalization with Multilingual Transformers","1797":"Investigation on Data Adaptation Techniques for Neural Named Entity Recognition","1798":"OpenHands. Making Sign Language Recognition Accessible with Posebased Pretrained Models across Languages","1799":"ViSeRet. A simple yet effective approach to moment retrieval via finegrained video segmentation","1800":"MetricGANU. Unsupervised speech enhancement dereverberation based only on noisy reverberated speech","1801":"FEVEROUS. Fact Extraction and VERification Over Unstructured and Structured information","1802":"Pretrained Language Models in Biomedical Domain. A Systematic Survey","1803":"Evaluation of Abstractive Summarisation Models with Machine Translation in Deliberative Processes","1804":"Balancing Average and Worstcase Accuracy in Multitask Learning","1805":"Prosodic segmentation for parsing spoken dialogue","1806":"Rethinking the Objectives of Extractive Question Answering","1807":"Weve had this conversation before. A Novel Approach to Measuring Dialog Similarity","1808":"Quantifying Cognitive Factors in Lexical Decline","1809":"Advances in Multiturn Dialogue Comprehension. A Survey","1810":"Advances in Multiturn Dialogue Comprehension. A Survey","1811":"UniSpeechSAT. Universal Speech Representation Learning with Speaker Aware PreTraining","1812":"SportsSum2.0. Generating HighQuality Sports News from Live Text Commentary","1813":"Anatomy of OntoGUMAdapting GUM to the OntoNotes Scheme to Evaluate Robustness of SOTA Coreference Algorithms","1814":"Prediction of Political Leanings of Chinese Speaking Twitter Users","1815":"Dealing with Disagreements. Looking Beyond the Majority Vote in Subjective Annotations","1816":"FewshotQA. A simple framework for fewshot learning of question answering tasks using pretrained texttotext models","1817":"On Releasing AnnotatorLevel Labels and Information in Datasets","1818":"Yuan 1.0. LargeScale Pretrained Language Model in ZeroShot and FewShot Learning","1819":"DoublyTrained Adversarial Data Augmentation for Neural Machine Translation","1820":"Large Language Models Can Be Strong Differentially Private Learners","1821":"Are you doing what I say On modalities alignment in ALFRED","1822":"MDETR  Modulated Detection for EndtoEnd MultiModal Understanding","1823":"Learned Construction Grammars Converge Across Registers Given Increased Exposure","1824":"TCube. DomainAgnostic Neural Timeseries Narration","1825":"Spatial Data Mining of Public Transport Incidents reported in Social Media","1826":"SRU. Pioneering Fast Recurrence with Attention for Speech Recognition","1827":"We Need to Talk About Data. The Importance of Data Readiness in Natural Language Processing","1828":"Rome was built in 1776. A Case Study on Factual Correctness in KnowledgeGrounded Response Generation","1829":"Unsupervised Neural Machine Translation with Generative Language Models Only","1830":"Using Document Similarity Methods to create Parallel Datasets for Code Translation","1831":"Calibrate your listeners Robust communicationbased training for pragmatic speakers","1832":"Model Bias in NLP  Application to Hate Speech Classification using transfer learning techniques","1833":"Evaluating User Perception of Speech Recognition System Quality with Semantic Distance Metric","1834":"Explainable Factchecking through Question Answering","1835":"Improving Gender Fairness of PreTrained Language Models without Catastrophic Forgetting","1836":"Focus on what matters. Applying Discourse Coherence Theory to Cross Document Coreference","1837":"Grounding SpatioTemporal Language with Transformers","1838":"On a Benefit of Mask Language Modeling. Robustness to Simplicity Bias","1839":"TEET Tunisian Dataset for Toxic Speech Detection","1840":"A Comparative Study on NonAutoregressive Modelings for SpeechtoText Generation","1841":"MultiTask Learning for Situated MultiDomain EndtoEnd Dialogue Systems","1842":"It is Not as Good as You Think Evaluating Simultaneous Machine Translation on Interpretation Data","1843":"KWav2vec 2.0. Automatic Speech Recognition based on Joint Decoding of Graphemes and Syllables","1844":"WRENCH. A Comprehensive Benchmark for Weak Supervision","1845":"Black or White but never neutral. How readers perceive identity from yellow or skintoned emoji","1846":"Topic Modeling Cladeassisted Sentiment Analysis and Vaccine Brand Reputation Analysis of COVID19 Vaccinerelated Facebook Comments in the Philippines","1847":"Attention in Natural Language Processing","1848":"Offensive Language Detection with BERTbased models By Customizing Attention Probabilities","1849":"Measuring SentenceLevel and AspectLevel Uncertainty in Science Communications","1850":"A Comprehensive Comparison of Word Embeddings in Event  Entity Coreference Resolution","1851":"Dynamic Forecasting of Conversation Derailment","1852":"MLQEPE. A Multilingual Quality Estimation and PostEditing Dataset","1853":"Dense Relational Image Captioning via Multitask TripleStream Networks","1854":"DocumentLevel Text Simplification. Dataset Criteria and Baseline","1855":"Calling to CNNLSTM for Rumor Detection. A Deep Multichannel Model for Message Veracity Classification in Microblogs","1856":"Representation of professions in entertainment media. Insights into frequency and sentiment trends through computational text analysis","1857":"Cross Domain Emotion Recognition using Few Shot Knowledge Transfer","1858":"A Review on PartofSpeech Technologies","1859":"An Analysis of COVID19 Knowledge Graph Construction and Applications","1860":"DistantlySupervised Evidence Retrieval Enables Question Answering without Evidence Annotation","1861":"Language Models As or For Knowledge Bases","1862":"Contextual LexiconBased Approach for Hate Speech and Offensive Language Detection","1863":"Identifying Offensive Expressions of Opinion in Context","1864":"Doc2Dict. Information Extraction as Text Generation","1865":"ContextMatters. Advantages and Limitations of Using Machine Learning to Support Women in Politics","1866":"On Automatic Text Extractive Summarization Based on Graph and pretrained Language Model Attention","1867":"Injecting Text and Crosslingual Supervision in Fewshot Learning from SelfSupervised Models","1868":"WhatTheWikiFact. FactChecking Claims Against Wikipedia","1869":"BatchSoftmax Contrastive Loss for Pairwise Sentence Scoring Tasks","1870":"What Makes Sentences Semantically Related. A Textual Relatedness Dataset and Empirical Study","1871":"Vision Guided Generative Pretrained Language Models for Multimodal Abstractive Summarization","1872":"Learning to Learn EndtoEnd GoalOriented Dialog From Related Dialog Tasks","1873":"DCT. Dynamic Compressive Transformer for Modeling Unbounded Sequence","1874":"SPGPT2. Semantics Improvement in Vietnamese Poetry Generation","1875":"PASTE. A TaggingFree Decoding Framework Using Pointer Networks for Aspect Sentiment Triplet Extraction","1876":"TransferNet. An Effective and Transparent Framework for Multihop Question Answering over Relation Graph","1877":"Applying Phonological Features in Multilingual TextToSpeech","1878":"Towards Highfidelity Singing Voice Conversion with Acoustic Reference and Contrastive Predictive Coding","1879":"Enhance Long Text Understanding via Distilled Gist Detector from Abstractive Summarization","1880":"SuperShaper. TaskAgnostic Super Pretraining of BERT Models with Variable Hidden Dimensions","1881":"Learn Continually Generalize Rapidly. Lifelong Knowledge Accumulation for Fewshot Learning","1882":"Learning to Follow Language Instructions with Compositional Policies","1883":"On the Relation between Syntactic Divergence and ZeroShot Performance","1884":"A Framework for Rationale Extraction for Deep QA models","1885":"Empathetic Response Generation through Graphbased Multihop Reasoning on Emotional Causality","1886":"Personalized Automatic Speech Recognition Trained on Small Disordered Speech Datasets","1887":"IndoNLG. Benchmark and Resources for Evaluating Indonesian Natural Language Generation","1888":"An Exploration of SelfSupervised Pretrained Representations for EndtoEnd Speech Recognition","1889":"WavBERT. Cooperative Acoustic and Linguistic Representation Learning for LowResource Speech Recognition","1890":"CLIPAdapter. Better VisionLanguage Models with Feature Adapters","1891":"Improving MultiParty Dialogue Discourse Parsing via Domain Integration","1892":"SemMT. A Semanticbased Testing Approach for Machine Translation Systems","1893":"DMRST. A Joint Framework for DocumentLevel Multilingual RST Discourse Segmentation and Parsing","1894":"Extending MultiText Sentence Fusion Resources via Pyramid Annotations","1895":"Wav2vecS. SemiSupervised PreTraining for Speech Recognition","1896":"Towards Lifelong Learning of Multilingual TextToSpeech Synthesis","1897":"Bayesian Active Summarization","1898":"Leveraging recent advances in PreTrained Language Models forEyeTracking Prediction","1899":"Sequence Model with SelfAdaptive Sliding Window for Efficient Spoken Document Segmentation","1900":"RoFormer. Enhanced Transformer with Rotary Position Embedding","1901":"Natural Language for HumanRobot Collaboration. Problems Beyond Language Grounding","1902":"Twostage Visual Cues Enhancement Network for Referring Image Segmentation","1903":"Layerwise Analysis of a Selfsupervised Speech Representation Model","1904":"Improving DistantlySupervised Named Entity Recognition with SelfCollaborative Denoising Learning","1905":"Detecting Community Sensitive Norm Violations in Online Conversations","1906":"Endtoend Keyword Spotting using Xception1d","1907":"Accessible Visualization via Natural Language Descriptions. A FourLevel Model of Semantic Content","1908":"Sentiment Analysis and Topic Modeling for COVID19 Vaccine Discussions","1909":"The Eval4NLP Shared Task on Explainable Quality Estimation. Overview and Results","1910":"Evaluation of Summarization Systems across Gender Age and Race","1911":"A Few More Examples May Be Worth Billions of Parameters","1912":"HowSumm. A MultiDocument Summarization Dataset Derived from WikiHow Articles","1913":"KGFiD. Infusing Knowledge Graph in FusioninDecoder for OpenDomain Question Answering","1914":"DPUV3INT8. A Compiler View to programmable FPGA Inference Engines","1915":"A Weakly Supervised Dataset of FineGrained Emotions in Portuguese","1916":"Local and Global ContextBased Pairwise Models for Sentence Ordering","1917":"VieSum. How Robust Are Transformerbased Models on Vietnamese Summarization","1918":"lambeq. An Efficient HighLevel Python Library for Quantum NLP","1919":"Development of an Extractive Title Generation System Using Titles of Papers of Top Conferences for Intermediate English Students","1920":"From SCAN to Real Data. Systematic Generalization via Meaningful Learning","1921":"Text analysis and deep learning. A network approach","1922":"I Do Not Understand What I Cannot Define. Automatic Question Generation With PedagogicallyDriven Content Selection","1923":"CPT. A PreTrained Unbalanced Transformer for Both Chinese Language Understanding and Generation","1924":"How to Do Things without Words. Modeling Semantic Drift of Emoji","1925":"Towards MathAware Automated Classification and Similarity Search of Scientific Publications. Methods of Mathematical Content Representations","1926":"FoodChem. A foodchemical relation extraction model","1927":"A guided journey through noninteractive automatic story generation","1928":"Relaxing the Conditional Independence Assumption of CTCbased ASR by Conditioning on Intermediate Predictions","1929":"Perceived and Intended Sarcasm Detection with Graph Attention Networks","1930":"English Machine Reading Comprehension Datasets. A Survey","1931":"CPT. Colorful Prompt Tuning for Pretrained VisionLanguage Models","1932":"CheerBots. Chatbots toward Empathy and Emotionusing Reinforcement Learning","1933":"Transformerbased endtoend speech recognition with residual Gaussianbased selfattention","1934":"ALLINONE. MultiTask Learning BERT models for Evaluating Peer Assessments","1935":"Explaining the Attention Mechanism of EndtoEnd Speech Recognition Using Decision Trees","1936":"Unsupervised CrossLingual Transfer of Structured Predictors without Source Data","1937":"A study on the efficacy of model pretraining in developing neural texttospeech system","1938":"Speeding up Deep Model Training by Sharing Weights and Then Unsharing","1939":"Machine Translation Verbosity Control for Automatic Dubbing","1940":"LMCritic. Language Models for Unsupervised Grammatical Error Correction","1941":"Rulebased Morphological Inflection Improves Neural Terminology Translation","1942":"Streaming Transformer Transducer Based Speech Recognition Using NonCausal Convolution","1943":"Exploring Conditional Text Generation for AspectBased Sentiment Analysis","1944":"Sonorant spectra and coarticulation distinguish speakers with different dialects","1945":"UoB at SemEval2021 Task 5. Extending PreTrained Language Models to Include Task and DomainSpecific Information for Toxic Span Prediction","1946":"Enriching a Models Notion of Belief using a Persistent Memory","1947":"Bridge to Target Domain by Prototypical Contrastive Learning and Label Confusion. Reexplore ZeroShot Learning for Slot Filling","1948":"GeSERA. Generaldomain Summary Evaluation by Relevance Analysis","1949":"Magic dust for crosslingual adaptation of monolingual wav2vec2.0","1950":"MandarinEnglish Codeswitching Speech Recognition with Selfsupervised Speech Representation Models","1951":"Beam Search with Bidirectional Strategies for Neural Response Generation","1952":"ContextAdaptive DocumentLevel Neural Machine Translation","1953":"Noisy Text Data. Achilles Heel of popular transformer based NLP models","1954":"Back from the future. bidirectional CTC decoding using future information in speech recognition","1955":"On the Latent Holes of VAEs for Text Generation","1956":"XTREMER. Towards More Challenging and Nuanced Multilingual Evaluation","1957":"EndtoEnd Supermask Pruning. Learning to Prune Image Captioning Models","1958":"Detecting Autism Spectrum Disorders with Machine Learning Models Using Speech Transcripts","1959":"Multitasking Dialogue Comprehension with Discourse Parsing","1960":"Layerwise Pruning of Transformer Attention Heads for Efficient Language Modeling","1961":"Influence Tuning. Demoting Spurious Correlations via Instance Attribution and InstanceDriven Updates","1962":"GNN is a Counter Revisiting GNN for Question Answering","1963":"OPAD. An Optimized Policybased Active Learning Framework for Document Content Analysis","1964":"A Comparative Study of TransformerBased Language Models on Extractive Question Answering","1965":"Fast Contextual Adaptation with Neural Associative Memory for OnDevice Personalized Speech Recognition","1966":"Improving Similar Language Translation With Transfer Learning","1967":"Arabic aspect based sentiment analysis using bidirectional GRU based models","1968":"An Empirical Exploration in Quality Filtering of Text Data","1969":"DRAFTWhat you always wanted to know but could not find about blockbased environments","1970":"DeBERTa. Decodingenhanced BERT with Disentangled Attention","1971":"Integrating Categorical Features in EndtoEnd ASR","1972":"The LowResource Double Bind. An Empirical Study of Pruning for LowResource Machine Translation","1973":"LIDSNet. A Lightweight ondevice Intent Detection model using Deep Siamese Network","1974":"NUSIDS at FinCausal 2021. Dependency Tree in Graph Neural Network for Better CauseEffect Span Detection","1975":"Text Generation with Efficient Soft QLearning","1976":"Using Optimal Transport as Alignment Objective for finetuning Multilingual Contextualized Embeddings","1977":"HumanintheLoop Refinement of Word Embeddings","1978":"Parallel Composition of Weighted FiniteState Transducers","1979":"Relation Prediction as an Auxiliary Training Objective for Improving MultiRelational Graph Representations","1980":"Spell my name. keyword boosted speech recognition","1981":"Sparse Attention with Linear Units","1982":"Visually grounded models of spoken language. A survey of datasets architectures and evaluation techniques","1983":"An automated domainindependent text reading interpreting and extracting approach for reviewing the scientific literature","1984":"Application of the interactive Leipzig Corpus Miner as a generic research platform for the use in the social sciences","1985":"Learning SenseSpecific Static Embeddings using Contextualised Word Embeddings as a Proxy","1986":"Weaklysupervised Text Classification Based on Keyword Graph","1987":"Efficient MultiModal Embeddings from Structured Data","1988":"Searching for an Effective Defender. Benchmarking Defense against Adversarial Word Substitution","1989":"KNNBERT. FineTuning PreTrained Models with KNN Classifier","1990":"HittER. Hierarchical Transformers for Knowledge Graph Embeddings","1991":"ABC. Attention with Boundedmemory Control","1992":"Tipping the Scales. A CorpusBased Reconstruction of Adjective Scales in the McGill Pain Questionnaire","1993":"BadPre. Taskagnostic Backdoor Attacks to Pretrained NLP Foundation Models","1994":"MUFASA. Multimodal Fusion Architecture Search for Electronic Health Records","1995":"MPG. A Multiingredient Pizza Image Generator with Conditional StyleGANs","1996":"Federated Distillation of Natural Language Understanding with Confident Sinkhorns","1997":"Voice Aging with AudioVisual Style Transfer","1998":"Word Acquisition in Neural Language Models","1999":"Language Modeling using LMUs. 10x Better Data Efficiency or Improved Scaling Compared to Transformers","2000":"Building the Language Resource for a CebuanoFilipino Neural Machine Translation System","2001":"Analyzing the Effects of Reasoning Types on CrossLingual Transfer Performance","2002":"Fast WordPiece Tokenization","2003":"Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning","2004":"Itihasa. A largescale corpus for Sanskrit to English translation","2005":"AdapterDrop. On the Efficiency of Adapters in Transformers","2006":"Waypoint Models for Instructionguided Navigation in Continuous Environments","2007":"Using Psuedolabels for training Sentiment Classifiers makes the model generalize better across datasets","2008":"Compositional generalization in semantic parsing with pretrained transformers","2009":"Analyzing the Impact of COVID19 on Economy from the Perspective of Users Reviews","2010":"TLDR9. A Large Scale Resource for Extreme Summarization of Social Media Posts","2011":"A Legal Approach to Hate Speech. Operationalizing the EUs Legal Framework against the Expression of Hatred as an NLP Task","2012":"Is Attention always needed A Case Study on Language Identification from Speech","2013":"Book Success Prediction with Pretrained Sentence Embeddings and Readability Scores","2014":"NaRLE. Natural Language Models using Reinforcement Learning with Emotion Feedback","2015":"Enriched Pretrained Transformers for Joint Slot Filling and Intent Detection","2016":"On Architectures and Training for Raw Waveform Feature Extraction in ASR","2017":"MFAQ. a Multilingual FAQ Dataset","2018":"Teach Me What to Say and I Will Learn What to Pick. Unsupervised Knowledge Selection Through Response Generation with Pretrained Generative Models","2019":"TENT. Text Classification Based on ENcoding Tree Learning","2020":"uriwhnt at GermEval 2021. An Ensembling Strategy with Multiple BERT Models","2021":"FooDIML. a large multilanguage dataset of food drinks and groceries images and descriptions","2022":"Dataset for Automatic Summarization of Russian News","2023":"Exploiting Twitter as Source of Large Corpora of Weakly Similar Pairs for Semantic Sentence Embeddings","2024":"MultiObjective Fewshot Learning for Fair Classification","2025":"AraCOVID19SSD. Arabic COVID19 Sentiment and Sarcasm Detection Dataset","2026":"Sicilian Translator. A Recipe for LowResource NMT","2027":"ASR Rescoring and Confidence Estimation with ELECTRA","2028":"COVIDRead. A Largescale Question Answering Dataset on COVID19","2029":"TruthConditional Captioning of Time Series Data","2030":"SentimentAware Measure SAM for Evaluating Sentiment Transfer by Machine Translation Systems","2031":"LegalNLP  Natural Language Processing methods for the Brazilian Legal Language","2032":"On the Complementarity between PreTraining and BackTranslation for Neural Machine Translation","2033":"A Survey On Neural Word Embeddings","2034":"ContractNLI. A Dataset for Documentlevel Natural Language Inference for Contracts","2035":"Automated Quality Assessment of Cognitive Behavioral Therapy Sessions Through Highly Contextualized Language Representations","2036":"Classification of hierarchical text using geometric deep learning. the case of clinical trials corpus","2037":"Empathetic Dialog Generation with FineGrained Intents","2038":"The optimality of syntactic dependency distances","2039":"Privacy enabled Financial Text Classification using Differential Privacy and Federated Learning","2040":"Encoder Adaptation of Dense Passage Retrieval for OpenDomain Question Answering","2041":"Using SingleTrial Representational Similarity Analysis with EEG to track semantic similarity in emotional word processing","2042":"Perhaps PTLMs Should Go to School  A Task to Assess Open Book and Closed Book QA","2043":"Towards Theme Detection in Personal Finance Questions","2044":"Generalization in NLI. Ways Not To Go Beyond Simple Heuristics","2045":"Generating Datasets with Pretrained Language Models","2046":"FewShot Text Generation with PatternExploiting Training","2047":"Building a Noisy Audio Dataset to Evaluate Machine Learning Approaches for Automatic Speech Recognition Systems","2048":"HumanImitating Metrics for Training and Evaluating Privacy Preserving Emotion Recognition Models Using Sociolinguistic Knowledge","2049":"Quantifying the Suicidal Tendency on Social Media. A Survey","2050":"Putting Words in BERTs Mouth. Navigating Contextualized Vector Spaces with Pseudowords","2051":"Neural Named Entity Recognition for Kazakh","2052":"Protagonists Tagger in Literary Domain  New Datasets and a Method for Person Entity Linkage","2053":"Identifying nonnatural language artifacts in bug reports","2054":"Beyond Preserved Accuracy. Evaluating Loyalty and Robustness of BERT Compression","2055":"Dont Search for a Search Method  Simple Heuristics Suffice for Adversarial Text Attacks","2056":"SPaR.txt a cheap Shallow Parsing approach for Regulatory texts","2057":"Leveraging Information Bottleneck for Scientific Document Summarization","2058":"A Aelfsupervised Tibetanchinese Vocabulary Alignment Method Based On Adversarial Learning","2059":"Revisiting SelfTraining for FewShot Learning of Language Model","2060":"TBCOV. Two Billion Multilingual COVID19 Tweets with Sentiment Entity Geo and Gender Labels","2061":"The stateoftheart in textbased automatic personality prediction","2062":"A Novel Metric for Evaluating Semantics Preservation","2063":"Beyond Topics. Discovering Latent Healthcare Objectives from Event Sequences","2064":"Structured abbreviation expansion in context","2065":"Probing Language Models for Understanding of Temporal Expressions","2066":"Adversarial Examples Generation for Reducing Implicit Gender Bias in Pretrained Models","2067":"From None to Severe. Predicting Severity in Movie Scripts","2068":"Towards Understanding Persuasion in Computational Argumentation","2069":"MultiDocument Keyphrase Extraction. A Literature Review and the First Dataset"},"summary":{"0":"neural machine translation (nmt) systems aim to map text from one language into another. while there are a wide variety of applications of nmt, one of the most important is translation of natural language. a distinguishing factor of natural language is that words are typically ordered according to the rules of the grammar of a given language. although many advances have been made in developing nmt systems for translating natural language, little research has been done on understanding how the word ordering of and lexical similarity between the source and target language affect translation performance. here, we investigate these relationships on a variety of low-resource language pairs from the opensubtitles2016 database, where the source language is english, and find that the more similar the target language is to english, the greater the translation performance. in addition, we study the impact of providing nmt models with part of speech of words (pos) in the english sequence and find that, for transformer-based models, the more dissimilar the target language is from english, the greater the benefit provided by pos. ","1":"in recent times, a large number of people have been involved in establishing their own businesses. unlike humans, chatbots can serve multiple customers at a time, are available 24\/7 and reply in less than a fraction of a second. though chatbots perform well in task-oriented activities, in most cases they fail to understand personalized opinions, statements or even queries which later impact the organization for poor service management. lack of understanding capabilities in bots disinterest humans to continue conversations with them. usually, chatbots give absurd responses when they are unable to interpret a user's text accurately. extracting the client reviews from conversations by using chatbots, organizations can reduce the major gap of understanding between the users and the chatbot and improve their quality of products and services.thus, in our research we incorporated all the key elements that are necessary for a chatbot to analyse and understand an input text precisely and accurately. we performed sentiment analysis, emotion detection, intent classification and named-entity recognition using deep learning to develop chatbots with humanistic understanding and intelligence. the efficiency of our approach can be demonstrated accordingly by the detailed analysis. ","2":"interest in artificial intelligence (ai) and its applications has seen unprecedented growth in the last few years. this success can be partly attributed to the advancements made in the sub-fields of ai such as machine learning, computer vision, and natural language processing. much of the growth in these fields has been made possible with deep learning, a sub-area of machine learning that uses artificial neural networks. this has created significant interest in the integration of vision and language. in this survey, we focus on ten prominent tasks that integrate language and vision by discussing their problem formulation, methods, existing datasets, evaluation measures, and compare the results obtained with corresponding state-of-the-art methods. our efforts go beyond earlier surveys which are either task-specific or concentrate only on one type of visual content, i.e., image or video. furthermore, we also provide some potential future directions in this field of research with an anticipation that this survey stimulates innovative thoughts and ideas to address the existing challenges and build new applications. ","3":"pre-trained language models have been successful on text classification tasks, but are prone to learning spurious correlations from biased datasets, and are thus vulnerable when making inferences in a new domain. prior work reveals such spurious patterns via post-hoc explanation algorithms which compute the importance of input features. further, the model is regularized to align the importance scores with human knowledge, so that the unintended model behaviors are eliminated. however, such a regularization technique lacks flexibility and coverage, since only importance scores towards a pre-defined list of features are adjusted, while more complex human knowledge such as feature interaction and pattern generalization can hardly be incorporated. in this work, we propose to refine a learned language model for a target domain by collecting human-provided compositional explanations regarding observed biases. by parsing these explanations into executable logic rules, the human-specified refinement advice from a small set of explanations can be generalized to more training examples. we additionally introduce a regularization term allowing adjustments for both importance and interaction of features to better rectify model behavior. we demonstrate the effectiveness of the proposed approach on two text classification tasks by showing improved performance in target domain as well as improved model fairness after refinement. ","4":"the inputs and\/or outputs of some neural nets are weight matrices of other neural nets. indirect encodings or end-to-end compression of weight matrices could help to scale such approaches. our goal is to open a discussion on this topic, starting with recurrent neural networks for character-level language modelling whose weight matrices are encoded by the discrete cosine transform. our fast weight version thereof uses a recurrent neural network to parameterise the compressed weights. we present experimental results on the enwik8 dataset. ","5":"efficient discovery of a speaker's emotional states in a multi-party conversation is significant to design human-like conversational agents. during a conversation, the cognitive state of a speaker often alters due to certain past utterances, which may lead to a flip in their emotional state. therefore, discovering the reasons (triggers) behind the speaker's emotion-flip during a conversation is essential to explain the emotion labels of individual utterances. in this paper, along with addressing the task of emotion recognition in conversations (erc), we introduce a novel task - emotion-flip reasoning (efr), that aims to identify past utterances which have triggered one's emotional state to flip at a certain time. we propose a masked memory network to address the former and a transformer-based network for the latter task. to this end, we consider meld, a benchmark emotion recognition dataset in multi-party conversations for the task of erc, and augment it with new ground-truth labels for efr. an extensive comparison with five state-of-the-art models suggests improved performances of our models for both tasks. we further present anecdotal evidence and both qualitative and quantitative error analyses to support the superiority of our models compared to the baselines. ","6":"search engines based on keyword retrieval can no longer adapt to the way of information acquisition in the era of intelligent internet of things due to the return of keyword related internet pages. how to quickly, accurately and effectively obtain the information needed by users from massive internet data has become one of the key issues urgently needed to be solved. we propose an intelligent question-answering system based on structured kb and unstructured data, called openqa, in which users can give query questions and the model can quickly give accurate answers back to users. we integrate kbqa structured question answering based on semantic parsing and deep representation learning, and two-stage unstructured question answering based on retrieval and neural machine reading comprehension into openqa, and return the final answer with the highest probability through the transformer answer selection module in openqa. we carry out preliminary experiments on our constructed dataset, and the experimental results prove the effectiveness of the proposed intelligent question answering system. at the same time, the core technology of each module of openqa platform is still in the forefront of academic hot spots, and the theoretical essence and enrichment of openqa will be further explored based on these academic hot spots. ","7":"persuasion games are fundamental in economics and ai research and serve as the basis for important applications. however, work on this setup assumes communication with stylized messages that do not consist of rich human language. in this paper we consider a repeated sender (expert) -- receiver (decision maker) game, where the sender is fully informed about the state of the world and aims to persuade the receiver to accept a deal by sending one of several possible natural language reviews. we design an automatic expert that plays this repeated game, aiming to achieve the maximal payoff. our expert is implemented within the monte carlo tree search (mcts) algorithm, with deep learning models that exploit behavioral and linguistic signals in order to predict the next action of the decision maker, and the future payoff of the expert given the state of the game and a candidate review. we demonstrate the superiority of our expert over strong baselines, its adaptability to different decision makers, and that its selected reviews are nicely adapted to the proposed deal. ","8":"we focus on the confounding bias between language and location in the visual grounding pipeline, where we find that the bias is the major visual reasoning bottleneck. for example, the grounding process is usually a trivial language-location association without visual reasoning, e.g., grounding any language query containing sheep to the nearly central regions, due to that most queries about sheep have ground-truth locations at the image center. first, we frame the visual grounding pipeline into a causal graph, which shows the causalities among image, query, target location and underlying confounder. through the causal graph, we know how to break the grounding bottleneck: deconfounded visual grounding. second, to tackle the challenge that the confounder is unobserved in general, we propose a confounder-agnostic approach called: referring expression deconfounder (red), to remove the confounding bias. third, we implement red as a simple language attention, which can be applied in any grounding method. on popular benchmarks, red improves various state-of-the-art grounding methods by a significant margin. code will soon be available at: https:\/\/github.com\/jianqiangh\/deconfounded_vg. ","9":"domain adaptation tasks such as cross-domain sentiment classification aim to utilize existing labeled data in the source domain and unlabeled or few labeled data in the target domain to improve the performance in the target domain via reducing the shift between the data distributions. existing cross-domain sentiment classification methods need to distinguish pivots, i.e., the domain-shared sentiment words, and non-pivots, i.e., the domain-specific sentiment words, for excellent adaptation performance. in this paper, we first design a category attention network (can), and then propose a model named can-cnn to integrate can and a convolutional neural network (cnn). on the one hand, the model regards pivots and non-pivots as unified category attribute words and can automatically capture them to improve the domain adaptation performance; on the other hand, the model makes an attempt at interpretability to learn the transferred category attribute words. specifically, the optimization objective of our model has three different components: 1) the supervised classification loss; 2) the distributions loss of category feature weights; 3) the domain invariance loss. finally, the proposed model is evaluated on three public sentiment analysis datasets and the results demonstrate that can-cnn can outperform other various baseline methods. ","10":"conventional methods for the image-text generation tasks mainly tackle the naturally bidirectional generation tasks separately, focusing on designing task-specific frameworks to improve the quality and fidelity of the generated samples. recently, vision-language pre-training models have greatly improved the performance of the image-to-text generation tasks, but large-scale pre-training models for text-to-image synthesis task are still under-developed. in this paper, we propose ernie-vilg, a unified generative pre-training framework for bidirectional image-text generation with transformer model. based on the image quantization models, we formulate both image generation and text generation as autoregressive generative tasks conditioned on the text\/image input. the bidirectional image-text generative modeling eases the semantic alignments across vision and language. for the text-to-image generation process, we further propose an end-to-end training method to jointly learn the visual sequence generator and the image reconstructor. to explore the landscape of large-scale pre-training for bidirectional text-image generation, we train a 10-billion parameter ernie-vilg model on a large-scale dataset of 145 million (chinese) image-text pairs which achieves state-of-the-art performance for both text-to-image and image-to-text tasks, obtaining an fid of 7.9 on ms-coco for text-to-image synthesis and best results on coco-cn and aic-icc for image captioning. ","11":"besides entity-centric knowledge, usually organized as knowledge graph (kg), events are also an essential kind of knowledge in the world, which trigger the spring up of event-centric knowledge representation form like event kg (ekg). it plays an increasingly important role in many machine learning and artificial intelligence applications, such as intelligent search, question-answering, recommendation, and text generation. this paper provides a comprehensive survey of ekg from history, ontology, instance, and application views. specifically, to characterize ekg thoroughly, we focus on its history, definitions, schema induction, acquisition, related representative graphs\/systems, and applications. the development processes and trends are studied therein. we further summarize perspective directions to facilitate future research on ekg. ","12":"autoregressive (ar) and non-autoregressive (nar) models have their own superiority on the performance and latency, combining them into one model may take advantage of both. current combination frameworks focus more on the integration of multiple decoding paradigms with a unified generative model, e.g. masked language model. however, the generalization can be harmful to the performance due to the gap between training objective and inference. in this paper, we aim to close the gap by preserving the original objective of ar and nar under a unified framework. specifically, we propose the directional transformer (diformer) by jointly modelling ar and nar into three generation directions (left-to-right, right-to-left and straight) with a newly introduced direction variable, which works by controlling the prediction of each token to have specific dependencies under that direction. the unification achieved by direction successfully preserves the original dependency assumption used in ar and nar, retaining both generalization and performance. experiments on 4 wmt benchmarks demonstrate that diformer outperforms current united-modelling works with more than 1.5 bleu points for both ar and nar decoding, and is also competitive to the state-of-the-art independent ar and nar models. ","13":"we study relationship between first order multiplicative linear logic (mll1), which has been known to provide representations to different categorial grammars, and the recently introduced extended tensor type calculus (ettc). we identify a fragment of mll1, which seems sufficient for many grammar representations, and establish a correspondence between ettc and this fragment. the system ettc, thus, can be seen as an alternative syntax and intrinsic deductive system together with a geometric representation for the latter. we also give a natural deduction formulation of ettc, which might be convenient. ","14":"automatic cognate detection (acd) is a challenging task which has been utilized to help nlp applications like machine translation, information retrieval and computational phylogenetics. unidentified cognate pairs can pose a challenge to these applications and result in a degradation of performance. in this paper, we detect cognate word pairs among ten indian languages with hindi and use deep learning methodologies to predict whether a word pair is cognate or not. we identify indowordnet as a potential resource to detect cognate word pairs based on orthographic similarity-based methods and train neural network models using the data obtained from it. we identify parallel corpora as another potential resource and perform the same experiments for them. we also validate the contribution of wordnets through further experimentation and report improved performance of up to 26%. we discuss the nuances of cognate detection among closely related indian languages and release the lists of detected cognates as a dataset. we also observe the behaviour of, to an extent, unrelated indian language pairs and release the lists of detected cognates among them as well. ","15":"in this paper we present kind, an italian dataset for named-entity recognition. it contains more than one million tokens with the annotation covering three classes: persons, locations, and organizations. most of the dataset (around 600k tokens) contains manual gold annotations in three different domains: news, literature, and political discourses. texts and annotations are downloadable for free from the github repository. ","16":"recently, text classification model based on graph neural network (gnn) has attracted more and more attention. most of these models adopt a similar network paradigm, that is, using pre-training node embedding initialization and two-layer graph convolution. in this work, we propose textrgnn, an improved gnn structure that introduces residual connection to deepen the convolution network depth. our structure can obtain a wider node receptive field and effectively suppress the over-smoothing of node features. in addition, we integrate the probabilistic language model into the initialization of graph node embedding, so that the non-graph semantic information of can be better extracted. the experimental results show that our model is general and efficient. it can significantly improve the classification accuracy whether in corpus level or text level, and achieve sota performance on a wide range of text classification datasets. ","17":"fine-tuning pre-trained language models for downstream tasks has become a norm for nlp. recently it is found that intermediate training based on high-level inference tasks such as question answering (qa) can improve the performance of some language models for target tasks. however it is not clear if intermediate training generally benefits various language models. in this paper, using the squad-2.0 qa task for intermediate training for target text classification tasks, we experimented on eight tasks for single-sequence classification and eight tasks for sequence-pair classification using two base and two compact language models. our experiments show that qa-based intermediate training generates varying transfer performance across different language models, except for similar qa tasks. ","18":"learner corpus collects language data produced by l2 learners, that is second or foreign-language learners. this resource is of great relevance for second language acquisition research, foreign-language teaching, and automatic grammatical error correction. however, there is little focus on learner corpus for chinese as foreign language (cfl) learners. therefore, we propose to construct a large-scale, multidimensional annotated chinese learner corpus. to construct the corpus, we first obtain a large number of topic-rich texts generated by cfl learners. then we design an annotation scheme including a sentence acceptability score as well as grammatical error and fluency-based corrections. we build a crowdsourcing platform to perform the annotation effectively (https:\/\/yaclc.wenmind.net). we name the corpus yaclc (yet another chinese learner corpus) and release it as part of the cuge benchmark (http:\/\/cuge.baai.ac.cn). by analyzing the original sentences and annotations in the corpus, we found that yaclc has a considerable size and very high annotation quality. we hope this corpus can further enhance the studies on chinese international education and chinese automatic grammatical error correction. ","19":"in clinics, a radiology report is crucial for guiding a patient's treatment. unfortunately, report writing imposes a heavy burden on radiologists. to effectively reduce such a burden, we hereby present an automatic, multi-modal approach for report generation from chest x-ray. our approach, motivated by the observation that the descriptions in radiology reports are highly correlated with the x-ray images, features two distinct modules: (i) learned knowledge base. to absorb the knowledge embedded in the above-mentioned correlation, we automatically build a knowledge base based on textual embedding. (ii) multi-modal alignment. to promote the semantic alignment among reports, disease labels and images, we explicitly utilize textual embedding to guide the learning of the visual feature space. we evaluate the performance of the proposed model using metrics from both natural language generation and clinic efficacy on the public iu and mimic-cxr datasets. our ablation study shows that each module contributes to improving the quality of generated reports. furthermore, with the aid of both modules, our approach clearly outperforms state-of-the-art methods. ","20":"automatic radiology report generation is critical in clinics which can relieve experienced radiologists from the heavy workload and remind inexperienced radiologists of misdiagnosis or missed diagnose. existing approaches mainly formulate radiology report generation as an image captioning task and adopt the encoder-decoder framework. however, in the medical domain, such pure data-driven approaches suffer from the following problems: 1) visual and textual bias problem; 2) lack of expert knowledge. in this paper, we propose a knowledge-enhanced radiology report generation approach introduces two types of medical knowledge: 1) general knowledge, which is input independent and provides the broad knowledge for report generation; 2) specific knowledge, which is input dependent and provides the fine-grained knowledge for report generation. to fully utilize both the general and specific knowledge, we also propose a knowledge-enhanced multi-head attention mechanism. by merging the visual features of the radiology image with general knowledge and specific knowledge, the proposed model can improve the quality of generated reports. experimental results on two publicly available datasets iu-xray and mimic-cxr show that the proposed knowledge enhanced approach outperforms state-of-the-art image captioning based methods. ablation studies also demonstrate that both general and specific knowledge can help to improve the performance of radiology report generation. ","21":"pre-trained language models such as bert have shown remarkable effectiveness in various natural language processing tasks. however, these models usually contain millions of parameters, which prevents them from practical deployment on resource-constrained devices. knowledge distillation, weight pruning, and quantization are known to be the main directions in model compression. however, compact models obtained through knowledge distillation may suffer from significant accuracy drop even for a relatively small compression ratio. on the other hand, there are only a few quantization attempts that are specifically designed for natural language processing tasks. they suffer from a small compression ratio or a large error rate since manual setting on hyper-parameters is required and fine-grained subgroup-wise quantization is not supported. in this paper, we proposed an automatic mixed-precision quantization framework designed for bert that can simultaneously conduct quantization and pruning in a subgroup-wise level. specifically, our proposed method leverages differentiable neural architecture search to assign scale and precision for parameters in each sub-group automatically, and at the same time pruning out redundant groups of parameters. extensive evaluations on bert downstream tasks reveal that our proposed method outperforms baselines by providing the same performance with much smaller model size. we also show the feasibility of obtaining the extremely light-weight model by combining our solution with orthogonal methods such as distilbert. ","22":"rhetorical frames in ai can be thought of as expressions that describe ai development as a competition between two or more actors, such as governments or companies. examples of such frames include robotic arms race, ai rivalry, technological supremacy, cyberwarfare dominance and 5g race. detection of rhetorical frames from open sources can help us track the attitudes of governments or companies towards ai, specifically whether attitudes are becoming more cooperative or competitive over time. given the rapidly increasing volumes of open sources (online news media, twitter, blogs), it is difficult for subject matter experts to identify rhetorical frames in (near) real-time. moreover, these sources are in general unstructured (noisy) and therefore, detecting frames from these sources will require state-of-the-art text classification techniques. in this paper, we develop rheframedetect, a text classification system for (near) real-time capture of rhetorical frames from open sources. given an input document, rheframedetect employs text classification techniques at multiple levels (document level and paragraph level) to identify all occurrences of frames used in the discussion of ai. we performed extensive evaluation of the text classification techniques used in rheframedetect against human annotated frames from multiple news sources. to further demonstrate the effectiveness of rheframedetect, we show multiple case studies depicting the frames identified by rheframedetect compared against human annotated frames. ","23":"recently, end-to-end (e2e) frameworks have achieved remarkable results on various automatic speech recognition (asr) tasks. however, lattice-free maximum mutual information (lf-mmi), as one of the discriminative training criteria that show superior performance in hybrid asr systems, is rarely adopted in e2e asr frameworks. in this work, we propose a novel approach to integrate lf-mmi criterion into e2e asr frameworks in both training and decoding stages. the proposed approach shows its effectiveness on two of the most widely used e2e frameworks including attention-based encoder-decoders (aeds) and neural transducers (nts). experiments suggest that the introduction of the lf-mmi criterion consistently leads to significant performance improvements on various datasets and different e2e asr frameworks. the best of our models achieves competitive cer of 4.1\\% \/ 4.4\\% on aishell-1 dev\/test set; we also achieve significant error reduction on aishell-2 and librispeech datasets over strong baselines. ","24":"simultaneous translation, which starts translating each sentence after receiving only a few words in source sentence, has a vital role in many scenarios. although the previous prefix-to-prefix framework is considered suitable for simultaneous translation and achieves good performance, it still has two inevitable drawbacks: the high computational resource costs caused by the need to train a separate model for each latency $k$ and the insufficient ability to encode information because each target token can only attend to a specific source prefix. we propose a novel framework that adopts a simple but effective decoding strategy which is designed for full-sentence models. within this framework, training a single full-sentence model can achieve arbitrary given latency and save computational resources. besides, with the competence of the full-sentence model to encode the whole sentence, our decoding strategy can enhance the information maintained in the decoded states in real time. experimental results show that our method achieves better translation quality than baselines on 4 directions: zh$\\rightarrow$en, en$\\rightarrow$ro and en$\\leftrightarrow$de. ","25":"quality estimation, as a crucial step of quality control for machine translation, has been explored for years. the goal is to investigate automatic methods for estimating the quality of machine translation results without reference translations. in this year's wmt qe shared task, we utilize the large-scale xlm-roberta pre-trained model and additionally propose several useful features to evaluate the uncertainty of the translations to build our qe system, named \\textit{qemind}. the system has been applied to the sentence-level scoring task of direct assessment and the binary score prediction task of critical error detection. in this paper, we present our submissions to the wmt 2021 qe shared task and an extensive set of experimental results have shown us that our multilingual systems outperform the best system in the direct assessment qe task of wmt 2020. ","26":"the unified streaming and non-streaming two-pass (u2) end-to-end model for speech recognition has shown great performance in terms of streaming capability, accuracy, real-time factor (rtf), and latency. in this paper, we present u2++, an enhanced version of u2 to further improve the accuracy. the core idea of u2++ is to use the forward and the backward information of the labeling sequences at the same time at training to learn richer information, and combine the forward and backward prediction at decoding to give more accurate recognition results. we also proposed a new data augmentation method called specsub to help the u2++ model to be more accurate and robust. our experiments show that, compared with u2, u2++ shows faster convergence at training, better robustness to the decoding method, as well as consistent 5\\% - 8\\% word error rate reduction gain over u2. on the experiment of aishell-1, we achieve a 4.63\\% character error rate (cer) with a non-streaming setup and 5.05\\% with a streaming setup with 320ms latency by u2++. to the best of our knowledge, 5.05\\% is the best-published streaming result on the aishell-1 test set. ","27":"the current work intends to study the performance of the hierarchical temporal memory(htm) theory for automated classification of text as well as documents. htm is a biologically inspired theory based on the working principles of the human neocortex. the current study intends to provide an alternative framework for document categorization using the spatial pooler learning algorithm in the htm theory. as htm accepts only a stream of binary data as input, latent semantic indexing(lsi) technique is used for extracting the top features from the input and converting them into binary format. the spatial pooler algorithm converts the binary input into sparse patterns with similar input text having overlapping spatial patterns making it easy for classifying the patterns into categories. the results obtained prove that htm theory, although is in its nascent stages, performs at par with most of the popular machine learning based classifiers. ","28":"we introduce bertphone, a transformer encoder trained on large speech corpora that outputs phonetically-aware contextual representation vectors that can be used for both speaker and language recognition. this is accomplished by training on two objectives: the first, inspired by adapting bert to the continuous domain, involves masking spans of input frames and reconstructing the whole sequence for acoustic representation learning; the second, inspired by the success of bottleneck features from asr, is a sequence-level ctc loss applied to phoneme labels for phonetic representation learning. we pretrain two bertphone models (one on fisher and one on ted-lium) and use them as feature extractors into x-vector-style dnns for both tasks. we attain a state-of-the-art $c_{\\text{avg}}$ of 6.16 on the challenging lre07 3sec closed-set language recognition task. on fisher and voxceleb speaker recognition tasks, we see an 18% relative reduction in speaker eer when training on bertphone vectors instead of mfccs. in general, bertphone outperforms previous phonetic pretraining approaches on the same data. we release our code and models at https:\/\/github.com\/awslabs\/speech-representations. ","29":"online reviews play a vital role in e commerce for decision making. much of the population makes the decision of which places, restaurant to visit, what to buy and from where to buy based on the reviews posted on the respective platforms. a fraudulent review or opinion spam is categorized as an untruthful or deceptive review. positive reviews of a product or a restaurant helps attract customers and thereby lead to an increase in sales whereas negative reviews may hamper the progress of a restaurant or sales of a product and thereby lead to defamed reputation and loss. fraudulent reviews are deliberately posted on various online review platforms to trick customers to buy, visit or distract against a product or a restaurant. they are also written to commend or discredit the product's repute. the work aims at detecting and classifying the reviews as deceptive or truthful. it involves use of various deep learning techniques for classifying the reviews and an overview of proposed approach involving attention based bidirectional lstm to tackle issues related to semantic information in reviews and a comparative study over baseline machine learning techniques for review classification. ","30":"the task of legal statute identification (lsi) aims to identify the legal statutes that are relevant to a given description of facts or evidence of a legal case. existing methods only utilize the textual content of facts and legal articles to guide such a task. however, the citation network among case documents and legal statutes is a rich source of additional information, which is not considered by existing models. in this work, we take the first step towards utilising both the text and the legal citation network for the lsi task. we curate a large novel dataset for this task, including facts of cases from several major indian courts of law, and statutes from the indian penal code (ipc). modeling the statutes and training documents as a heterogeneous graph, our proposed model lesicin can learn rich textual and graphical features, and can also tune itself to correlate these features. thereafter, the model can be used to inductively predict links between test documents (new nodes whose graphical features are not available to the model) and statutes (existing nodes). extensive experiments on the dataset show that our model comfortably outperforms several state-of-the-art baselines, by exploiting the graphical structure along with textual features. the dataset and our codes are available at https:\/\/github.com\/law-ai\/lesicin. ","31":"most unsupervised nlp models represent each word with a single point or single region in semantic space, while the existing multi-sense word embeddings cannot represent longer word sequences like phrases or sentences. we propose a novel embedding method for a text sequence (a phrase or a sentence) where each sequence is represented by a distinct set of multi-mode codebook embeddings to capture different semantic facets of its meaning. the codebook embeddings can be viewed as the cluster centers which summarize the distribution of possibly co-occurring words in a pre-trained word embedding space. we introduce an end-to-end trainable neural model that directly predicts the set of cluster centers from the input text sequence during test time. our experiments show that the per-sentence codebook embeddings significantly improve the performances in unsupervised sentence similarity and extractive summarization benchmarks. in phrase similarity experiments, we discover that the multi-facet embeddings provide an interpretable semantic representation but do not outperform the single-facet baseline. ","32":"despite the success of the neural sequence-to-sequence model for abstractive text summarization, it has a few shortcomings, such as repeating inaccurate factual details and tending to repeat themselves. we propose a hybrid pointer generator network to solve the shortcomings of reproducing factual details inadequately and phrase repetition. we augment the attention-based sequence-to-sequence using a hybrid pointer generator network that can generate out-of-vocabulary words and enhance accuracy in reproducing authentic details and a coverage mechanism that discourages repetition. it produces a reasonable-sized output text that preserves the conceptual integrity and factual information of the input article. for evaluation, we primarily employed \"bansdata\" - a highly adopted publicly available bengali dataset. additionally, we prepared a large-scale dataset called \"bans-133\" which consists of 133k bangla news articles associated with human-generated summaries. experimenting with the proposed model, we achieved rouge-1 and rouge-2 scores of 0.66, 0.41 for the \"bansdata\" dataset and 0.67, 0.42 for the bans-133k\" dataset, respectively. we demonstrated that the proposed system surpasses previous state-of-the-art bengali abstractive summarization techniques and its stability on a larger dataset. \"bans-133\" datasets and code-base will be publicly available for research. ","33":"we introduce hocalarim (myprofessors), the largest student review dataset available for the turkish language. it consists of over 5000 professor reviews left online by students, with different aspects of education rated on a scale of 1 to 5 stars. we investigate the properties of the dataset and present its statistics. we examine the impact of students' institution type on their ratings and the correlation of students' bias to give positive or negative feedback. ","34":"transformers are responsible for the vast majority of recent advances in natural language processing. the majority of practical natural language processing applications of these models is typically enabled through transfer learning. this paper studies if corpus-specific tokenization used for fine-tuning improves the resulting performance of the model. through a series of experiments, we demonstrate that such tokenization combined with the initialization and fine-tuning strategy for the vocabulary tokens speeds up the transfer and boosts the performance of the fine-tuned model. we call this aspect of transfer facilitation vocabulary transfer. ","35":"lack of external knowledge makes empathetic dialogue systems difficult to perceive implicit emotions and learn emotional interactions from limited dialogue history. to address the above problems, we propose to leverage external knowledge, including commonsense knowledge and emotional lexical knowledge, to explicitly understand and express emotions in empathetic dialogue generation. we first enrich the dialogue history by jointly interacting with external knowledge and construct an emotional context graph. then we learn emotional context representations from the knowledge-enriched emotional context graph and distill emotional signals, which are the prerequisites to predicate emotions expressed in responses. finally, to generate the empathetic response, we propose an emotional cross-attention mechanism to learn the emotional dependencies from the emotional context graph. extensive experiments conducted on a benchmark dataset verify the effectiveness of the proposed method. in addition, we find the performance of our method can be further improved by integrating with a pre-trained model that works orthogonally. ","36":"in this paper, we present a novel two-pass approach to unify streaming and non-streaming end-to-end (e2e) speech recognition in a single model. our model adopts the hybrid ctc\/attention architecture, in which the conformer layers in the encoder are modified. we propose a dynamic chunk-based attention strategy to allow arbitrary right context length. at inference time, the ctc decoder generates n-best hypotheses in a streaming way. the inference latency could be easily controlled by only changing the chunk size. the ctc hypotheses are then rescored by the attention decoder to get the final result. this efficient rescoring process causes very little sentence-level latency. our experiments on the open 170-hour aishell-1 dataset show that, the proposed method can unify the streaming and non-streaming model simply and efficiently. on the aishell-1 test set, our unified model achieves 5.60% relative character error rate (cer) reduction in non-streaming asr compared to a standard non-streaming transformer. the same model achieves 5.42% cer with 640ms latency in a streaming asr system. ","37":"in this paper, we propose an open source, production first, and production ready speech recognition toolkit called wenet in which a new two-pass approach is implemented to unify streaming and non-streaming end-to-end (e2e) speech recognition in a single model. the main motivation of wenet is to close the gap between the research and the production of e2e speechrecognition models. wenet provides an efficient way to ship asr applications in several real-world scenarios, which is the main difference and advantage to other open source e2e speech recognition toolkits. in our toolkit, a new two-pass method is implemented. our method propose a dynamic chunk-based attention strategy of the the transformer layers to allow arbitrary right context length modifies in hybrid ctc\/attention architecture. the inference latency could be easily controlled by only changing the chunk size. the ctc hypotheses are then rescored by the attention decoder to get the final result. our experiments on the aishell-1 dataset using wenet show that, our model achieves 5.03\\% relative character error rate (cer) reduction in non-streaming asr compared to a standard non-streaming transformer. after model quantification, our model perform reasonable rtf and latency. ","38":"low-frequency word prediction remains a challenge in modern neural machine translation (nmt) systems. recent adaptive training methods promote the output of infrequent words by emphasizing their weights in the overall training objectives. despite the improved recall of low-frequency words, their prediction precision is unexpectedly hindered by the adaptive objectives. inspired by the observation that low-frequency words form a more compact embedding space, we tackle this challenge from a representation learning perspective. specifically, we propose a frequency-aware token-level contrastive learning method, in which the hidden state of each decoding step is pushed away from the counterparts of other target words, in a soft contrastive way based on the corresponding word frequencies. we conduct experiments on widely used nist chinese-english and wmt14 english-german translation tasks. empirical results show that our proposed methods can not only significantly improve the translation quality but also enhance lexical diversity and optimize word representation space. further investigation reveals that, comparing with related adaptive training strategies, the superiority of our method on low-frequency word prediction lies in the robustness of token-level recall across different frequencies without sacrificing precision. ","39":"the severity of the coronavirus pandemic necessitates the need of effective administrative decisions. over 4 lakh people in india succumbed to covid-19, with over 3 crore confirmed cases, and still counting. the threat of a plausible third wave continues to haunt millions. in this ever changing dynamic of the virus, predictive modeling methods can serve as an integral tool. the pandemic has further triggered an unprecedented usage of social media. this paper aims to propose a method for harnessing social media, specifically twitter, to predict the upcoming scenarios related to covid-19 cases. in this study, we seek to understand how the surges in covid-19 related tweets can indicate rise in the cases. this prospective analysis can be utilised to aid administrators about timely resource allocation to lessen the severity of the damage. using word embeddings to capture the semantic meaning of tweets, we identify significant dimensions (sds).our methodology predicts the rise in cases with a lead time of 15 days and 30 days with r2 scores of 0.80 and 0.62 respectively. finally, we explain the thematic utility of the sds. ","40":"it is known that neural networks are subject to attacks through adversarial perturbations, i.e., inputs which are maliciously crafted through perturbations to induce wrong predictions. furthermore, such attacks are impossible to eliminate, i.e., the adversarial perturbation is still possible after applying mitigation methods such as adversarial training. multiple approaches have been developed to detect and reject such adversarial inputs, mostly in the image domain. rejecting suspicious inputs however may not be always feasible or ideal. first, normal inputs may be rejected due to false alarms generated by the detection algorithm. second, denial-of-service attacks may be conducted by feeding such systems with adversarial inputs. to address the gap, in this work, we propose an approach to automatically repair adversarial texts at runtime. given a text which is suspected to be adversarial, we novelly apply multiple adversarial perturbation methods in a positive way to identify a repair, i.e., a slightly mutated but semantically equivalent text that the neural network correctly classifies. our approach has been experimented with multiple models trained for natural language processing tasks and the results show that our approach is effective, i.e., it successfully repairs about 80\\% of the adversarial texts. furthermore, depending on the applied perturbation method, an adversarial text could be repaired in as short as one second on average. ","41":"the finite invert beta-liouville mixture model (iblmm) has recently gained some attention due to its positive data modeling capability. under the conventional variational inference (vi) framework, the analytically tractable solution to the optimization of the variational posterior distribution cannot be obtained, since the variational object function involves evaluation of intractable moments. with the recently proposed extended variational inference (evi) framework, a new function is proposed to replace the original variational object function in order to avoid intractable moment computation, so that the analytically tractable solution of the iblmm can be derived in an elegant way. the good performance of the proposed approach is demonstrated by experiments with both synthesized data and a real-world application namely text categorization. ","42":"robots operating in human spaces must be able to engage in natural language interaction with people, both understanding and executing instructions, and using conversation to resolve ambiguity and recover from mistakes. to study this, we introduce teach, a dataset of over 3,000 human--human, interactive dialogues to complete household tasks in simulation. a commander with access to oracle information about a task communicates in natural language with a follower. the follower navigates through and interacts with the environment to complete tasks varying in complexity from \"make coffee\" to \"prepare breakfast\", asking questions and getting additional information from the commander. we propose three benchmarks using teach to study embodied intelligence challenges, and we evaluate initial models' abilities in dialogue understanding, language grounding, and task execution. ","43":"online reviews have a significant influence on customers' purchasing decisions for any products or services. however, fake reviews can mislead both consumers and companies. several models have been developed to detect fake reviews using machine learning approaches. many of these models have some limitations resulting in low accuracy in distinguishing between fake and genuine reviews. these models focused only on linguistic features to detect fake reviews and failed to capture the semantic meaning of the reviews. to deal with this, this paper proposes a new ensemble model that employs transformer architecture to discover the hidden patterns in a sequence of fake reviews and detect them precisely. the proposed approach combines three transformer models to improve the robustness of fake and genuine behaviour profiling and modelling to detect fake reviews. the experimental results using semi-real benchmark datasets showed the superiority of the proposed model over state-of-the-art models. ","44":"the problem of comparing two bodies of text and searching for words that differ in their usage between them arises often in digital humanities and computational social science. this is commonly approached by training word embeddings on each corpus, aligning the vector spaces, and looking for words whose cosine distance in the aligned space is large. however, these methods often require extensive filtering of the vocabulary to perform well, and - as we show in this work - result in unstable, and hence less reliable, results. we propose an alternative approach that does not use vector space alignment, and instead considers the neighbors of each word. the method is simple, interpretable and stable. we demonstrate its effectiveness in 9 different setups, considering different corpus splitting criteria (age, gender and profession of tweet authors, time of tweet) and different languages (english, french and hebrew). ","45":"when medical researchers conduct a systematic review (sr), screening studies is the most time-consuming process: researchers read several thousands of medical literature and manually label them relevant or irrelevant. screening prioritization (ie., document ranking) is an approach for assisting researchers by providing document rankings where relevant documents are ranked higher than irrelevant ones. seed-driven document ranking (sdr) uses a known relevant document (ie., seed) as a query and generates such rankings. previous work on sdr seeks ways to identify different term weights in a query document and utilizes them in a retrieval model to compute ranking scores. alternatively, we formulate the sdr task as finding similar documents to a query document and produce rankings based on similarity scores. we propose a document matching measure named mirror matching, which calculates matching scores between medical abstract texts by incorporating common writing patterns, such as background, method, result, and conclusion in order. we conduct experiments on clef 2019 ehealth task 2 tar dataset, and the empirical results show this simple approach achieves the higher performance than traditional and neural retrieval models on average precision and precision-focused metrics. ","46":"can recurrent neural nets, inspired by human sequential data processing, learn to understand language? we construct simplified datasets reflecting core properties of natural language as modeled in formal syntax and semantics: recursive syntactic structure and compositionality. we find lstm and gru networks to generalise to compositional interpretation well, but only in the most favorable learning settings, with a well-paced curriculum, extensive training data, and left-to-right (but not right-to-left) composition. ","47":"much recent work in nlp has documented dataset artifacts, bias, and spurious correlations between input features and output labels. however, how to tell which features have \"spurious\" instead of legitimate correlations is typically left unspecified. in this work we argue that for complex language understanding tasks, all simple feature correlations are spurious, and we formalize this notion into a class of problems which we call competency problems. for example, the word \"amazing\" on its own should not give information about a sentiment label independent of the context in which it appears, which could include negation, metaphor, sarcasm, etc. we theoretically analyze the difficulty of creating data for competency problems when human bias is taken into account, showing that realistic datasets will increasingly deviate from competency problems as dataset size increases. this analysis gives us a simple statistical test for dataset artifacts, which we use to show more subtle biases than were described in prior work, including demonstrating that models are inappropriately affected by these less extreme biases. our theoretical treatment of this problem also allows us to analyze proposed solutions, such as making local edits to dataset instances, and to give recommendations for future data collection and model design efforts that target competency problems. ","48":"many socio-linguistic cues are used in the conversational analysis, such as emotion, sentiment, and dialogue acts. one of the fundamental social cues is politeness, which linguistically possesses properties useful in conversational analysis. this short article presents some of the brief findings of polite emotional dialogue acts, where we can correlate the relational bonds between these socio-linguistics cues. we found that the utterances with emotion classes anger and disgust are more likely to be impolite while happiness and sadness to be polite. similar phenomenon occurs with dialogue acts, inform and commissive contain many polite utterances than question and directive. finally, we will conclude on the future work of these findings. ","49":"this paper outlines a conceptual framework for understanding recent developments in information retrieval and natural language processing that attempts to integrate dense and sparse retrieval methods. i propose a representational approach that breaks the core text retrieval problem into a logical scoring model and a physical retrieval model. the scoring model is defined in terms of encoders, which map queries and documents into a representational space, and a comparison function that computes query-document scores. the physical retrieval model defines how a system produces the top-$k$ scoring documents from an arbitrarily large corpus with respect to a query. the scoring model can be further analyzed along two dimensions: dense vs. sparse representations and supervised (learned) vs. unsupervised approaches. i show that many recently proposed retrieval methods, including multi-stage ranking designs, can be seen as different parameterizations in this framework, and that a unified view suggests a number of open research questions, providing a roadmap for future work. as a bonus, this conceptual framework establishes connections to sentence similarity tasks in natural language processing and information access \"technologies\" prior to the dawn of computing. ","50":"this paper presents first successful steps in designing agents that learn meta-strategies for iterative query refinement. our approach uses machine reading to guide the selection of refinement terms from aggregated search results. agents are then empowered with simple but effective search operators to exert fine-grained and transparent control over queries and search results. we develop a novel way of generating synthetic search sessions, which leverages the power of transformer-based language models through (self-)supervised learning. we also present a reinforcement learning agent with dynamically constrained actions that learns interactive search strategies from scratch. we obtain retrieval and answer quality performance comparable to recent neural methods using a traditional term-based bm25 ranking function. we provide an in-depth analysis of the search policies. ","51":"driven by b5g and 6g technologies, multi-network fusion is an indispensable tendency for future communications. in this paper, we focus on and analyze the \\emph{security performance} (sp) of the \\emph{satellite-terrestrial downlink transmission} (stdt). here, the stdt is composed of a satellite network and a vehicular network with a legitimate mobile receiver and an mobile eavesdropper distributing. to theoretically analyze the sp of this system from the perspective of mobile terminals better, the random geometry theory is adopted, which assumes that both terrestrial vehicles are distributed stochastically in one beam of the satellite. furthermore, based on this theory, the closed-form analytical expressions for two crucial and specific indicators in the stdt are derived, respectively, the secrecy outage probability and the ergodic secrecy capacity. additionally, several related variables restricting the sp of the stdt are discussed, and specific schemes are presented to enhance the sp. then, the asymptotic property is investigated in the high signal-to-noise ratio scenario, and accurate and asymptotic closed-form expressions are given. finally, simulation results show that, under the precondition of guaranteeing the reliability of the stdt, the asymptotic solutions outperform the corresponding accurate results significantly in the effectiveness. ","52":"language can be used as a means of reproducing and enforcing harmful stereotypes and biases and has been analysed as such in numerous research. in this paper, we present a survey of 304 papers on gender bias in natural language processing. we analyse definitions of gender and its categories within social sciences and connect them to formal definitions of gender bias in nlp research. we survey lexica and datasets applied in research on gender bias and then compare and contrast approaches to detecting and mitigating gender bias. we find that research on gender bias suffers from four core limitations. 1) most research treats gender as a binary variable neglecting its fluidity and continuity. 2) most of the work has been conducted in monolingual setups for english or other high-resource languages. 3) despite a myriad of papers on gender bias in nlp methods, we find that most of the newly developed algorithms do not test their models for bias and disregard possible ethical considerations of their work. 4) finally, methodologies developed in this line of research are fundamentally flawed covering very limited definitions of gender bias and lacking evaluation baselines and pipelines. we suggest recommendations towards overcoming these limitations as a guide for future research. ","53":"the study forms a technical report of various tasks that have been performed on the materials collected and published by finnish ethnographer and linguist, matthias alexander castr\\'en (1813-1852). the finno-ugrian society is publishing castr\\'en's manuscripts as new critical and digital editions, and at the same time different research groups have also paid attention to these materials. we discuss the workflows and technical infrastructure used, and consider how datasets that benefit different computational tasks could be created to further improve the usability of these materials, and also to aid the further processing of similar archived collections. we specifically focus on the parts of the collections that are processed in a way that improves their usability in more technical applications, complementing the earlier work on the cultural and linguistic aspects of these materials. most of these datasets are openly available in zenodo. the study points to specific areas where further research is needed, and provides benchmarks for text recognition tasks. ","54":"in this paper, the challenges of maintaining a healthy it operational environment have been addressed by proactively analyzing it service desk tickets, customer satisfaction surveys, and social media data. a cognitive solution goes beyond the traditional structured data analysis by deep analyses of both structured and unstructured text. the salient features of the proposed platform include language identification, translation, hierarchical extraction of the most frequently occurring topics, entities and their relationships, text summarization, sentiments, and knowledge extraction from the unstructured text using natural language processing techniques. moreover, the insights from unstructured text combined with structured data allow the development of various classification, segmentation, and time-series forecasting use-cases on the incident, problem, and change datasets. further, the text and predictive insights together with raw data are used for visualization and exploration of actionable insights on a rich and interactive dashboard. however, it is hard not only to find these insights using traditional structured data analysis but it might also take a very long time to discover them, especially while dealing with a massive amount of unstructured data. by taking action on these insights, organizations can benefit from a significant reduction of ticket volume, reduced operational costs, and increased customer satisfaction. in various experiments, on average, upto 18-25% of yearly ticket volume has been reduced using the proposed approach. ","55":"this paper is concerned with categorical structures for reversible computation. in particular, we focus on a typed, functional reversible language based on theseus. we discuss how join inverse rig categories do not in general capture pattern-matching, the core construct theseus uses to enforce reversibility. we then derive a categorical structure to add to join inverse rig categories in order to capture pattern-matching. we show how such a structure makes an adequate model for reversible pattern-matching. ","56":"when learning a second language (l2), one of the most important but tedious components that often demoralizes students with its ineffectiveness and inefficiency is vocabulary acquisition, or more simply put, memorizing words. in light of such, a personalized and educational vocabulary recommendation system that traces a learner's vocabulary knowledge state would have an immense learning impact as it could resolve both issues. therefore, in this paper, we propose and release data for a novel task called pedagogical word recommendation (pwr). the main goal of pwr is to predict whether a given learner knows a given word based on other words the learner has already seen. to elaborate, we collect this data via an intelligent tutoring system (its) that is serviced to ~1m l2 learners who study for the standardized english exam, toeic. as a feature of this its, students can directly indicate words they do not know from the questions they solved to create wordbooks. finally, we report the evaluation results of a neural collaborative filtering approach along with an exploratory data analysis and discuss the impact and efficacy of this dataset as a baseline for future studies on this task. ","57":"an important aspect of human conversation difficult for machines is conversing with empathy, which is to understand the user's emotion and respond appropriately. recent neural conversation models that attempted to generate empathetic responses either focused on conditioning the output to a given emotion, or incorporating the current user emotional state. however, these approaches do not factor in how the user would feel towards the generated response. hence, in this paper, we propose sentiment look-ahead, which is a novel perspective for empathy that models the future user emotional state. in short, sentiment look-ahead is a reward function under a reinforcement learning framework that provides a higher reward to the generative model when the generated utterance improves the user's sentiment. we implement and evaluate three different possible implementations of sentiment look-ahead and empirically show that our proposed approach can generate significantly more empathetic, relevant, and fluent responses than other competitive baselines such as multitask learning. ","58":"despite the success of mixup in data augmentation, its applicability to natural language processing (nlp) tasks has been limited due to the discrete and variable-length nature of natural languages. recent studies have thus relied on domain-specific heuristics and manually crafted resources, such as dictionaries, in order to apply mixup in nlp. in this paper, we instead propose an unsupervised learning approach to text interpolation for the purpose of data augmentation, to which we refer as \"learning to interpolate for data augmentation\" (linda), that does not require any heuristics nor manually crafted resources but learns to interpolate between any pair of natural language sentences over a natural language manifold. after empirically demonstrating the linda's interpolation capability, we show that linda indeed allows us to seamlessly apply mixup in nlp and leads to better generalization in text classification both in-domain and out-of-domain. ","59":"neural machine translation (nmt) models are strong enough to convey semantic and syntactic information from the source language to the target language. however, these models are suffering from the need for a large amount of data to learn the parameters. as a result, for languages with scarce data, these models are at risk of underperforming. we propose to augment attention based neural network with reordering information to alleviate the lack of data. this augmentation improves the translation quality for both english to persian and persian to english by up to 6% bleu absolute over the baseline models. ","60":"the epidemic question answering (epic-qa) track at the text analysis conference (tac) is an evaluation of methodologies for answering ad-hoc questions about the covid-19 disease. this paper describes our participation in both tasks of epic-qa, targeting: (1) expert qa and (2) consumer qa. our methods used a multi-phase neural information retrieval (ir) system based on combining bm25, bert, and t5 as well as the idea of considering entailment relations between the original question and questions automatically generated from answer candidate sentences. moreover, because entailment relations were also considered between all generated questions, we were able to re-rank the answer sentences based on the number of novel answer nuggets they contained, as indicated by the processing of a question entailment graph. our system, called searching for entailed questions revealing novel nuggets of answers (ser4equnova), produced promising results in both epic-qa tasks, excelling in the expert qa task. ","61":"contrastive language--image pre-training (clip) has shown remarkable success in learning with cross-modal supervision from extensive amounts of image--text pairs collected online. thus far, the effectiveness of clip has been investigated primarily in general-domain multimodal problems. this work evaluates the effectiveness of clip for the task of medical visual question answering (medvqa). to this end, we present pubmedclip, a fine-tuned version of clip for the medical domain based on pubmed articles. our experiments are conducted on two medvqa benchmark datasets and investigate two medvqa methods, mevf (mixture of enhanced visual features) and qcr (question answering via conditional reasoning). for each of these, we assess the merits of visual representation learning using pubmedclip, the original clip, and state-of-the-art maml (model-agnostic meta-learning) networks pre-trained only on visual data. we open source the code for our medvqa pipeline and pre-training pubmedclip. clip and pubmedclip achieve improvements in comparison to maml's visual encoder. pubmedclip achieves the best results with gains in the overall accuracy of up to 3%. individual examples illustrate the strengths of pubmedclip in comparison to the previously widely used maml networks. visual representation learning with language supervision in pubmedclip leads to noticeable improvements for medvqa. our experiments reveal distributional differences in the two medvqa benchmark datasets that have not been imparted in previous work and cause different back-end visual encoders in pubmedclip to exhibit different behavior on these datasets. moreover, we witness fundamental performance differences of vqa in general versus medical domains. ","62":"personal social ontology (pso), it is proposed, is how an individual perceives the ontological properties of terms. for example, an absolute fatalist would arguably use terms that remove any form of agency from a person. such fatalism has the impact of ontologically defining acts such as winning, victory and success, for example, in a manner that is contrary to how a non-fatalist would ontologically define them. while both a fatalist and non-fatalist would agree on the dictionary definition of these terms, they would differ on what and how they can be caused. this difference between the two individuals, it is argued, can be induced from the co-occurrence of terms used by each individual. that such co-occurrence carries an implied social ontology, one that is specific to that person. the use of principal social perceptions -as evidenced by the social psychology and social neuroscience literature, is put forward as a viable method to feature engineer such texts. with the natural language characterisation of these features, they are then usable in machine learning pipelines. ","63":"script knowledge (schank and abelson, 1975) has long been recognized as crucial for language understanding as it can help in filling in unstated information in a narrative. however, such knowledge is expensive to produce manually and difficult to induce from text due to reporting bias (gordon and van durme, 2013). in this work, we are interested in the scientific question of whether explicit script knowledge is present and accessible through pre-trained generative language models (lms). to this end, we introduce the task of generating full event sequence descriptions (esds) given a scenario in the form of natural language prompts. in zero-shot probing experiments, we find that generative lms produce poor esds with mostly omitted, irrelevant, repeated or misordered events. to address this, we propose a pipeline-based script induction framework (sif) which can generate good quality esds for unseen scenarios (e.g., bake a cake). sif is a two-staged framework that fine-tunes lm on a small set of esd examples in the first stage. in the second stage, esd generated for an unseen scenario is post-processed using roberta-based models to filter irrelevant events, remove repetitions, and reorder the temporally misordered events. through automatic and manual evaluations, we demonstrate that sif yields substantial improvements ($1$-$3$ blue points) over a fine-tuned lm. however, manual analysis shows that there is great room for improvement, offering a new research direction for inducing script knowledge. ","64":"traditional automatic evaluation metrics for machine translation have been widely criticized by linguists due to their low accuracy, lack of transparency, focus on language mechanics rather than semantics, and low agreement with human quality evaluation. human evaluations in the form of mqm-like scorecards have always been carried out in real industry setting by both clients and translation service providers (tsps). however, traditional human translation quality evaluations are costly to perform and go into great linguistic detail, raise issues as to inter-rater reliability (irr) and are not designed to measure quality of worse than premium quality translations. in this work, we introduce hope, a task-oriented and human-centric evaluation framework for machine translation output based on professional post-editing annotations. it contains only a limited number of commonly occurring error types, and use a scoring model with geometric progression of error penalty points (epps) reflecting error severity level to each translation unit. the initial experimental work carried out on english-russian language pair mt outputs on marketing content type of text from highly technical domain reveals that our evaluation framework is quite effective in reflecting the mt output quality regarding both overall system-level performance and segment-level transparency, and it increases the irr for error type interpretation. the approach has several key advantages, such as ability to measure and compare less than perfect mt output from different systems, ability to indicate human perception of quality, immediate estimation of the labor effort required to bring mt output to premium quality, low-cost and faster application, as well as higher irr. our experimental data is available at \\url{https:\/\/github.com\/lhan87\/hope}. ","65":"dense word vectors or 'word embeddings' which encode semantic properties of words, have now become integral to nlp tasks like machine translation (mt), question answering (qa), word sense disambiguation (wsd), and information retrieval (ir). in this paper, we use various existing approaches to create multiple word embeddings for 14 indian languages. we place these embeddings for all these languages, viz., assamese, bengali, gujarati, hindi, kannada, konkani, malayalam, marathi, nepali, odiya, punjabi, sanskrit, tamil, and telugu in a single repository. relatively newer approaches that emphasize catering to context (bert, elmo, etc.) have shown significant improvements, but require a large amount of resources to generate usable models. we release pre-trained embeddings generated using both contextual and non-contextual approaches. we also use muse and xlm to train cross-lingual embeddings for all pairs of the aforementioned languages. to show the efficacy of our embeddings, we evaluate our embedding models on xpos, upos and ner tasks for all these languages. we release a total of 436 models using 8 different approaches. we hope they are useful for the resource-constrained indian language nlp. the title of this paper refers to the famous novel 'a passage to india' by e.m. forster, published initially in 1924. ","66":"this paper presents a technique, named stlcg, to compute the quantitative semantics of signal temporal logic (stl) formulas using computation graphs. stlcg provides a platform which enables the incorporation of logical specifications into robotics problems that benefit from gradient-based solutions. specifically, stl is a powerful and expressive formal language that can specify spatial and temporal properties of signals generated by both continuous and hybrid systems. the quantitative semantics of stl provide a robustness metric, i.e., how much a signal satisfies or violates an stl specification. in this work, we devise a systematic methodology for translating stl robustness formulas into computation graphs. with this representation, and by leveraging off-the-shelf automatic differentiation tools, we are able to efficiently backpropagate through stl robustness formulas and hence enable a natural and easy-to-use integration of stl specifications with many gradient-based approaches used in robotics. through a number of examples stemming from various robotics applications, we demonstrate that stlcg is versatile, computationally efficient, and capable of incorporating human-domain knowledge into the problem formulation. ","67":"newsletters and social networks can reflect the opinion about the market and specific stocks from the perspective of analysts and the general public on products and\/or services provided by a company. therefore, sentiment analysis of these texts can provide useful information to help investors trade in the market. in this paper, a hierarchical stack of transformers model is proposed to identify the sentiment associated with companies and stocks, by predicting a score (of data type real) in a range between -1 and +1. specifically, we fine-tuned a roberta model to process headlines and microblogs and combined it with additional transformer layers to process the sentence analysis with sentiment dictionaries to improve the sentiment analysis. we evaluated it on financial data released by semeval-2017 task 5 and our proposition outperformed the best systems of semeval-2017 task 5 and strong baselines. indeed, the combination of contextual sentence analysis with the financial and general sentiment dictionaries provided useful information to our model and allowed it to generate more reliable sentiment scores. ","68":"transformers are state-of-the-art in a wide range of nlp tasks and have also been applied to many real-world products. understanding the reliability and certainty of transformer model predictions is crucial for building trustable machine learning applications, e.g., medical diagnosis. although many recent transformer extensions have been proposed, the study of the uncertainty estimation of transformer models is under-explored. in this work, we propose a novel way to enable transformers to have the capability of uncertainty estimation and, meanwhile, retain the original predictive performance. this is achieved by learning a hierarchical stochastic self-attention that attends to values and a set of learnable centroids, respectively. then new attention heads are formed with a mixture of sampled centroids using the gumbel-softmax trick. we theoretically show that the self-attention approximation by sampling from a gumbel distribution is upper bounded. we empirically evaluate our model on two text classification tasks with both in-domain (id) and out-of-domain (ood) datasets. the experimental results demonstrate that our approach: (1) achieves the best predictive performance and uncertainty trade-off among compared methods; (2) exhibits very competitive (in most cases, improved) predictive performance on id datasets; (3) is on par with monte carlo dropout and ensemble methods in uncertainty estimation on ood datasets. ","69":"learning to understand grounded language, which connects natural language to percepts, is a critical research area. prior work in grounded language acquisition has focused primarily on textual inputs. in this work we demonstrate the feasibility of performing grounded language acquisition on paired visual percepts and raw speech inputs. this will allow interactions in which language about novel tasks and environments is learned from end users, reducing dependence on textual inputs and potentially mitigating the effects of demographic bias found in widely available speech recognition systems. we leverage recent work in self-supervised speech representation models and show that learned representations of speech can make language grounding systems more inclusive towards specific groups while maintaining or even increasing general performance. ","70":"clinical information systems have become large repositories for semi-structured annotated healthcare data, which have reached a critical mass that makes them interesting for supervised data-driven neural network approaches. we explored automated coding of 50 character long clinical problem list entries using the international classification of diseases (icd-10) and evaluated three different types of network architectures on the top 100 icd-10 three-digit codes. a fasttext baseline reached a macro-averaged f1-measure of 0.83, followed by a character-level lstm with a macro-averaged f1-measure of 0.84. top performing was a downstreamed roberta model using a custom language model with a macro-averaged f1-measure of 0.88. a neural network activation analysis together with an investigation of the false positives and false negatives unveiled inconsistent manual coding as a main limiting factor. ","71":"in recent years, due to the high availability of electronic documents through the web, the plagiarism has become a serious challenge, especially among scholars. various plagiarism detection systems have been developed to prevent text re-use and to confront plagiarism. although it is almost easy to detect duplicate text in academic manuscripts, finding patterns of text re-use that has been semantically changed is of great importance. another important issue is to deal with less resourced languages, which there are low volume of text for training purposes and also low performance in tools for nlp applications. in this paper, we introduce hamtajoo, a persian plagiarism detection system for academic manuscripts. moreover, we describe the overall structure of the system along with the algorithms used in each stage. in order to evaluate the performance of the proposed system, we used a plagiarism detection corpus comply with the pan standards. ","72":"we adapt the higher criticism (hc) goodness-of-fit test to measure the closeness between word-frequency tables. we apply this measure to authorship attribution challenges, where the goal is to identify the author of a document using other documents whose authorship is known. the method is simple yet performs well without handcrafting and tuning; reporting accuracy at the state of the art level in various current challenges. as an inherent side effect, the hc calculation identifies a subset of discriminating words. in practice, the identified words have low variance across documents belonging to a corpus of homogeneous authorship. we conclude that in comparing the similarity of a new document and a corpus of a single author, hc is mostly affected by words characteristic of the author and is relatively unaffected by topic structure. ","73":"research in question answering datasets and models has gained a lot of attention in the research community. many of them release their own question answering datasets as well as the models. there is tremendous progress that we have seen in this area of research. the aim of this survey is to recognize, summarize and analyze the existing datasets that have been released by many researchers, especially in non-english datasets as well as resources such as research code, and evaluation metrics. in this paper, we review question answering datasets that are available in common languages other than english such as french, german, japanese, chinese, arabic, russian, as well as the multilingual and cross-lingual question-answering datasets. ","74":"multilingual neural machine translation (mnmt) aims to translate multiple languages with a single model and has been proved successful thanks to effective knowledge transfer among different languages with shared parameters. however, it is still an open question which parameters should be shared and which ones need to be task-specific. currently, the common practice is to heuristically design or search language-specific modules, which is difficult to find the optimal configuration. in this paper, we propose a novel parameter differentiation based method that allows the model to determine which parameters should be language-specific during training. inspired by cellular differentiation, each shared parameter in our method can dynamically differentiate into more specialized types. we further define the differentiation criterion as inter-task gradient similarity. therefore, parameters with conflicting inter-task gradients are more likely to be language-specific. extensive experiments on multilingual datasets have demonstrated that our method significantly outperforms various strong baselines with different parameter sharing configurations. further analyses reveal that the parameter sharing configuration obtained by our method correlates well with the linguistic proximities. ","75":"realizing general-purpose language intelligence has been a longstanding goal for natural language processing, where standard evaluation benchmarks play a fundamental and guiding role. we argue that for general-purpose language intelligence evaluation, the benchmark itself needs to be comprehensive and systematic. to this end, we propose cuge, a chinese language understanding and generation evaluation benchmark with the following features: (1) hierarchical benchmark framework, where datasets are principally selected and organized with a language capability-task-dataset hierarchy. (2) multi-level scoring strategy, where different levels of model performance are provided based on the hierarchical framework. to facilitate cuge, we provide a public leaderboard that can be customized to support flexible model judging criteria. evaluation results on representative pre-trained language models indicate ample room for improvement towards general-purpose language intelligence. cuge is publicly available at cuge.baai.ac.cn. ","76":"why is ordinary language vague? we argue that in contexts in which a cooperative speaker is not perfectly informed about the world, the use of vague expressions can offer an optimal tradeoff between truthfulness (gricean quality) and informativeness (gricean quantity). focusing on expressions of approximation such as \"around\", which are semantically vague, we show that they allow the speaker to convey indirect probabilistic information, in a way that can give the listener a more accurate representation of the information available to the speaker than any more precise expression would (intervals of the form \"between\"). that is, vague sentences can be more informative than their precise counterparts. we give a probabilistic treatment of the interpretation of \"around\", and offer a model for the interpretation and use of \"around\"-statements within the rational speech act (rsa) framework. in our account the shape of the speaker's distribution matters in ways not predicted by the lexical uncertainty model standardly used in the rsa framework for vague predicates. we use our approach to draw further lessons concerning the semantic flexibility of vague expressions and their irreducibility to more precise meanings. ","77":"community question answering (cqa) is a well-defined task that can be used in many scenarios, such as e-commerce and online user community for special interests.   in these communities, users can post articles, give comment, raise a question and answer it.   these data form the heterogeneous information sources where each information source have their own special structure and context (comments attached to an article or related question with answers).   most of the cqa methods only incorporate articles or wikipedia to extract knowledge and answer the user's question.   however, various types of information sources in the community are not fully explored by these cqa methods and these multiple information sources (mis) can provide more related knowledge to user's questions.   thus, we propose a question-aware heterogeneous graph transformer to incorporate the mis in the user community to automatically generate the answer.   to evaluate our proposed method, we conduct the experiments on two datasets: $\\text{msm}^{\\text{plus}}$ the modified version of benchmark dataset ms-marco and the antqa dataset which is the first large-scale cqa dataset with four types of mis.   extensive experiments on two datasets show that our model outperforms all the baselines in terms of all the metrics. ","78":"recently, product question answering (pqa) on e-commerce platforms has attracted increasing attention as it can act as an intelligent online shopping assistant and improve the customer shopping experience. its key function, automatic answer generation for product-related questions, has been studied by aiming to generate content-preserving while question-related answers. however, an important characteristic of pqa, i.e., personalization, is neglected by existing methods. it is insufficient to provide the same \"completely summarized\" answer to all customers, since many customers are more willing to see personalized answers with customized information only for themselves, by taking into consideration their own preferences towards product aspects or information needs. to tackle this challenge, we propose a novel personalized answer generation method (page) with multi-perspective preference modeling, which explores historical user-generated contents to model user preference for generating personalized answers in pqa. specifically, we first retrieve question-related user history as external knowledge to model knowledge-level user preference. then we leverage gaussian softmax distribution model to capture latent aspect-level user preference. finally, we develop a persona-aware pointer network to generate personalized answers in terms of both content and style by utilizing personal user preference and dynamic user vocabulary. experimental results on real-world e-commerce qa datasets demonstrate that the proposed method outperforms existing methods by generating informative and customized answers, and show that answer generation in e-commerce can benefit from personalization. ","79":"radiology reports contain a diverse and rich set of clinical abnormalities documented by radiologists during their interpretation of the images. comprehensive semantic representations of radiological findings would enable a wide range of secondary use applications to support diagnosis, triage, outcomes prediction, and clinical research. in this paper, we present a new corpus of radiology reports annotated with clinical findings. our annotation schema captures detailed representations of pathologic findings that are observable on imaging (\"lesions\") and other types of clinical problems (\"medical problems\"). the schema used an event-based representation to capture fine-grained details, including assertion, anatomy, characteristics, size, count, etc. our gold standard corpus contained a total of 500 annotated computed tomography (ct) reports. we extracted triggers and argument entities using two state-of-the-art deep learning architectures, including bert. we then predicted the linkages between trigger and argument entities (referred to as argument roles) using a bert-based relation extraction model. we achieved the best extraction performance using a bert model pre-trained on 3 million radiology reports from our institution: 90.9%-93.4% f1 for finding triggers 72.0%-85.6% f1 for arguments roles. to assess model generalizability, we used an external validation set randomly sampled from the mimic chest x-ray (mimic-cxr) database. the extraction performance on this validation set was 95.6% for finding triggers and 79.1%-89.7% for argument roles, demonstrating that the model generalized well to the cross-institutional data with a different imaging modality. we extracted the finding events from all the radiology reports in the mimic-cxr database and provided the extractions to the research community. ","80":"long-form question answering (lfqa) tasks require retrieving the documents pertinent to a query, using them to form a paragraph-length answer. despite considerable progress in lfqa modeling, fundamental issues impede its progress: i) train\/validation\/test dataset overlap, ii) absence of automatic metrics and iii) generated answers not being \"grounded\" in retrieved documents. this work addresses every one these critical bottlenecks, contributing natural language inference\/generation (nli\/nlg) methods and metrics that make significant strides to their alleviation. ","81":"without labeled question-answer pairs for necessary training, unsupervised commonsense question-answering (qa) appears to be extremely challenging due to its indispensable unique prerequisite on commonsense source like knowledge bases (kbs), which are usually highly resource consuming in construction. recently pre-trained language models (prlms) show effectiveness as an alternative for commonsense clues when they play a role of knowledge generator. however, existing work simply generates hundreds of pseudo-answers, or roughly performs knowledge generation according to templates once for all, which may result in much noise and thus hinders the quality of generated knowledge. motivated by human thinking experience, we propose an approach of all-round thinker (art) by fully taking association during knowledge generating. in detail, our model first focuses on key parts in the given context, and then generates highly related knowledge on such a basis in an association way like human thinking. besides, for casual reasoning, a reverse thinking mechanism is proposed to conduct bidirectional inferring between cause and effect. art is totally unsupervised and kbs-free. we evaluate it on three commonsense qa benchmarks: copa, socialiqa and sct. on all scales of prlm backbones, art shows its brilliant performance and outperforms previous advanced unsupervised models. ","82":"text classification problem is a very broad field of study in the field of natural language processing. in short, the text classification problem is to determine which of the previously determined classes the given text belongs to. successful studies have been carried out in this field in the past studies. in the study, bidirectional encoder representations for transformers (bert), which is a frequently preferred method for solving the classification problem in the field of natural language processing, is used. by solving classification problems through a single model to be used in a chatbot architecture, it is aimed to alleviate the load on the server that will be created by more than one model used for solving more than one classification problem. at this point, with the masking method applied during the estimation of a single bert model, which was created for classification in more than one subject, the estimation of the model was provided on a problem-based basis. three separate data sets covering different fields from each other are divided by various methods in order to complicate the problem, and classification problems that are very close to each other in terms of field are also included in this way. the dataset used in this way consists of five classification problems with 154 classes. a bert model containing all classification problems and other bert models trained specifically for the problems were compared with each other in terms of performance and the space they occupied on the server. ","83":"the collection and availability of big data, combined with advances in pre-trained models (e.g., bert, xlnet, etc), have revolutionized the predictive performance of modern natural language processing tasks, ranging from text classification to text generation. this allows corporations to provide machine learning as a service (mlaas) by encapsulating fine-tuned bert-based models as apis. however, bert-based apis have exhibited a series of security and privacy vulnerabilities. for example, prior work has exploited the security issues of the bert-based apis through the adversarial examples crafted by the extracted model. however, the privacy leakage problems of the bert-based apis through the extracted model have not been well studied. on the other hand, due to the high capacity of bert-based apis, the fine-tuned model is easy to be overlearned, but what kind of information can be leaked from the extracted model remains unknown. in this work, we bridge this gap by first presenting an effective model extraction attack, where the adversary can practically steal a bert-based api (the target\/victim model) by only querying a limited number of queries. we further develop an effective attribute inference attack which can infer the sensitive attribute of the training data used by the bert-based apis. our extensive experiments on benchmark datasets under various realistic settings validate the potential vulnerabilities of bert-based apis. moreover, we demonstrate that two promising defense methods become ineffective against our attacks, which calls for more effective defense methods. ","84":"recent work has shown evidence that the knowledge acquired by multilingual bert (mbert) has two components: a language-specific and a language-neutral one. this paper analyses the relationship between them, in the context of fine-tuning on two tasks -- pos tagging and natural language inference -- which require the model to bring to bear different degrees of language-specific knowledge. visualisations reveal that mbert loses the ability to cluster representations by language after fine-tuning, a result that is supported by evidence from language identification experiments. however, further experiments on 'unlearning' language-specific representations using gradient reversal and iterative adversarial learning are shown not to add further improvement to the language-independent component over and above the effect of fine-tuning. the results presented here suggest that the process of fine-tuning causes a reorganisation of the model's limited representational capacity, enhancing language-independent representations at the expense of language-specific ones. ","85":"lexicon information and pre-trained models, such as bert, have been combined to explore chinese sequence labelling tasks due to their respective strengths. however, existing methods solely fuse lexicon features via a shallow and random initialized sequence layer and do not integrate them into the bottom layers of bert. in this paper, we propose lexicon enhanced bert (lebert) for chinese sequence labelling, which integrates external lexicon knowledge into bert layers directly by a lexicon adapter layer. compared with the existing methods, our model facilitates deep lexicon knowledge fusion at the lower layers of bert. experiments on ten chinese datasets of three tasks including named entity recognition, word segmentation, and part-of-speech tagging, show that lebert achieves the state-of-the-art results. ","86":"online game forums are popular to most of game players. they use it to communicate and discuss the strategy of the game, or even to make friends. however, game forums also contain abusive and harassment speech, disturbing and threatening players. therefore, it is necessary to automatically detect and remove cyberbullying comments to keep the game forum clean and friendly. we use the cyberbullying dataset collected from world of warcraft (wow) and league of legends (lol) forums and train classification models to automatically detect whether a comment of a player is abusive or not. the result obtains 82.69% of macro f1-score for lol forum and 83.86% of macro f1-score for wow forum by the toxic-bert model on the cyberbullying dataset. ","87":"millions of packages are delivered successfully by online and local retail stores across the world every day. the proper delivery of packages is needed to ensure high customer satisfaction and repeat purchases. these deliveries suffer various problems despite the best efforts from the stores. these issues happen not only due to the large volume and high demand for low turnaround time but also due to mechanical operations and natural factors. these issues range from receiving wrong items in the package to delayed shipment to damaged packages because of mishandling during transportation. finding solutions to various delivery issues faced by both sending and receiving parties plays a vital role in increasing the efficiency of the entire process. this paper shows how to find these issues using customer feedback from the text comments and uploaded images. we used transfer learning for both text and image models to minimize the demand for thousands of labeled examples. the results show that the model can find different issues. furthermore, it can also be used for tasks like bottleneck identification, process improvement, automating refunds, etc. compared with the existing process, the ensemble of text and image models proposed in this paper ensures the identification of several types of delivery issues, which is more suitable for the real-life scenarios of delivery of items in retail businesses. this method can supply a new idea of issue detection for the delivery of packages in similar industries. ","88":"media coverage has a substantial effect on the public perception of events. nevertheless, media outlets are often biased. one way to bias news articles is by altering the word choice. the automatic identification of bias by word choice is challenging, primarily due to the lack of gold-standard data sets and high context dependencies. in this research project, i aim to devise data sets and methods to identify media bias. to achieve this, i plan to research methods using natural language processing and deep learning while employing models and using analysis concepts from psychology and linguistics. the first results indicate the effectiveness of an interdisciplinary research approach. my vision is to devise a system that helps news readers become aware of media coverage differences caused by bias. so far, my best performing bert-based model is pre-trained on a larger corpus consisting of distant labels, indicating that distant supervision has the potential to become a solution for the difficult task of bias detection. ","89":"in previous research, knowledge-selection tasks mostly rely on language model-based methods or knowledge ranking. however, while approaches that rely on the language models take all knowledge as sequential input, knowledge does not contain sequential information in most circumstances. on the other hand, the knowledge-ranking methods leverage dialog history and each given knowledge snippet separately, but they do not consider information between knowledge snippets. in the tenth dialog system technology challenges (dstc10), we participated in the second knowledge-grounded task-oriented dialogue modeling on spoken conversations. to deal with the problems mentioned above, we modified training methods based on state-of-the-art (sota) models for the first and third sub-tasks. as for the second sub-task of knowledge selection, we proposed graph-knowledge selector (gks), utilizing a graph-attention base model incorporated with the language model. gks makes knowledge-selection decisions in the dialog by simultaneously considering each knowledge embedding generated from the language model without sequential features. moreover, gks leverages considerable knowledge in decision-making and takes relations across knowledge as part of the selection process. as a result, gks outperforms several sota models proposed in the data-set on knowledge selection from the ninth dialog system technology challenges (dstc9). ","90":"large crowd-sourced datasets are often noisy and relation classification (rc) datasets are no exception. reannotating the entire dataset is one probable solution however it is not always viable due to time and budget constraints. this paper addresses the problem of efficient reannotation of a large noisy dataset for the rc. our goal is to catch more annotation errors in the dataset while reannotating fewer instances. existing work on rc dataset reannotation lacks the flexibility about how much data to reannotate. we introduce the concept of a reannotation budget to overcome this limitation. the immediate follow-up problem is: given a specific reannotation budget, which subset of the data should we reannotate? to address this problem, we present two strategies to selectively reannotate rc datasets. our strategies utilize the taxonomic hierarchy of relation labels. the intuition of our work is to rely on the graph distance between actual and predicted relation labels in the label hierarchy graph. we evaluate our reannotation strategies on the well-known tacred dataset. we design our experiments to answer three specific research questions. first, does our strategy select novel candidates for reannotation? second, for a given reannotation budget is our reannotation strategy more efficient at catching annotation errors? third, what is the impact of data reannotation on rc model performance measurement? experimental results show that our both reannotation strategies are novel and efficient. our analysis indicates that the current reported performance of rc models on noisy tacred data is inflated. ","91":"in this paper, we consider the ``shortest superstring problem''(ssp) or the ``shortest common superstring problem''(scs). the problem is as follows. for a positive integer $n$, a sequence of n strings $s=(s^1,\\dots,s^n)$ is given. we should construct the shortest string $t$ (we call it superstring) that contains each string from the given sequence as a substring. the problem is connected with the sequence assembly method for reconstructing a long dna sequence from small fragments. we present a quantum algorithm with running time $o^*(1.728^n)$. here $o^*$ notation does not consider polynomials of $n$ and the length of $t$. ","92":"we introduce a novel embedding model, named noge, which aims to integrate co-occurrence among entities and relations into graph neural networks to improve knowledge graph completion (i.e., link prediction). given a knowledge graph, noge constructs a single graph considering entities and relations as individual nodes. noge then computes weights for edges among nodes based on the co-occurrence of entities and relations. next, noge proposes dual quaternion graph neural networks (dualqgnn) and utilizes dualqgnn to update vector representations for entity and relation nodes. noge then adopts a score function to produce the triple scores. comprehensive experimental results show that noge obtains state-of-the-art results on three new and difficult benchmark datasets codex for knowledge graph completion. ","93":"while the highly multilingual universal dependencies (ud) project provides extensive guidelines for clausal structure as well as structure within canonical nominal phrases, a standard treatment is lacking for many \"mischievous\" nominal phenomena that break the mold. as a result, numerous inconsistencies within and across corpora can be found, even in languages with extensive ud treebanking work, such as english. this paper surveys the kinds of mischievous nominal expressions attested in english ud corpora and proposes solutions primarily with english in mind, but which may offer paths to solutions for a variety of ud languages. ","94":"stance detection is commonly defined as the automatic process of determining the positions of text producers, towards a target. in this paper, we define a research problem closely related to stance detection, namely, stance quantification, for the first time. we define stance quantification on a pair including (1) a set of natural language text items and (2) a target. at the end of the stance quantification process, a triple is obtained which consists of the percentages of the number of text items classified as favor, against, neither, respectively, towards the target in the input pair. also defined in the current paper is a significant subproblem of the stance quantification problem, namely, multi-target stance quantification. we believe that stance quantification at the aggregate level can lead to fruitful results in many application settings, and furthermore, stance quantification might be the sole stance related analysis alternative in settings where privacy concerns prevent researchers from applying generic stance detection. ","95":"the surging amount of biomedical literature & digital clinical records presents a growing need for text mining techniques that can not only identify but also semantically relate entities in unstructured data. in this paper we propose a text mining framework comprising of named entity recognition (ner) and relation extraction (re) models, which expands on previous work in three main ways. first, we introduce two new re model architectures -- an accuracy-optimized one based on biobert and a speed-optimized one utilizing crafted features over a fully connected neural network (fcnn). second, we evaluate both models on public benchmark datasets and obtain new state-of-the-art f1 scores on the 2012 i2b2 clinical temporal relations challenge (f1 of 73.6, +1.2% over the previous sota), the 2010 i2b2 clinical relations challenge (f1 of 69.1, +1.2%), the 2019 phenotype-gene relations dataset (f1 of 87.9, +8.5%), the 2012 adverse drug events drug-reaction dataset (f1 of 90.0, +6.3%), and the 2018 n2c2 posology relations dataset (f1 of 96.7, +0.6%). third, we show two practical applications of this framework -- for building a biomedical knowledge graph and for improving the accuracy of mapping entities to clinical codes. the system is built using the spark nlp library which provides a production-grade, natively scalable, hardware-optimized, trainable & tunable nlp framework. ","96":"in recent years, researchers in the area of computational creativity have studied the human creative process proposing different approaches to reproduce it with a formal procedure. in this paper, we introduce a model for the generation of literary rhymes in spanish, combining structures of language and neural network models %(\\textit{word2vec}).%, into a structure for semantic assimilation. the results obtained with a manual evaluation of the texts generated by our algorithm are encouraging. ","97":"community question answering (cqa) forums provide answers for many real-life questions. thanks to the large size, these forums are very popular among machine learning researchers. automatic answer selection, answer ranking, question retrieval, expert finding, and fact-checking are example learning tasks performed using cqa data. in this paper, we present percqa, the first persian dataset for cqa. this dataset contains the questions and answers crawled from the most well-known persian forum. after data acquisition, we provide rigorous annotation guidelines in an iterative process, and then the annotation of question-answer pairs in semevalcqa format. percqa contains 989 questions and 21,915 annotated answers. we make percqa publicly available to encourage more research in persian cqa. we also build strong benchmarks for the task of answer selection in percqa by using mono- and multi-lingual pre-trained language models ","98":"acronyms and long-forms are commonly found in research documents, more so in documents from scientific and legal domains. many acronyms used in such documents are domain-specific and are very rarely found in normal text corpora. owing to this, transformer-based nlp models often detect oov (out of vocabulary) for acronym tokens, especially for non-english languages, and their performance suffers while linking acronyms to their long forms during extraction. moreover, pretrained transformer models like bert are not specialized to handle scientific and legal documents. with these points being the overarching motivation behind this work, we propose a novel framework cabace: character-aware bert for acronym extraction, which takes into account character sequences in text and is adapted to scientific and legal domains by masked language modelling. we further use an objective with an augmented loss function, adding the max loss and mask loss terms to the standard cross-entropy loss for training cabace. we further leverage pseudo labelling and adversarial data generation to improve the generalizability of the framework. experimental results prove the superiority of the proposed framework in comparison to various baselines. additionally, we show that the proposed framework is better suited than baseline models for zero-shot generalization to non-english languages, thus reinforcing the effectiveness of our approach. our team backgprop secured the highest scores on the french dataset, second-highest on danish and vietnamese, and third-highest in the english-legal dataset on the global leaderboard for the acronym extraction (ae) shared task at sdu aaai-22. ","99":"fine-tuning pre-trained models have achieved impressive performance on standard natural language processing benchmarks. however, the resultant model generalizability remains poorly understood. we do not know, for example, how excellent performance can lead to the perfection of generalization models. in this study, we analyze a fine-tuned bert model from different perspectives using relation extraction. we also characterize the differences in generalization techniques according to our proposed improvements. from empirical experimentation, we find that bert suffers a bottleneck in terms of robustness by way of randomizations, adversarial and counterfactual tests, and biases (i.e., selection and semantic). these findings highlight opportunities for future improvements. our open-sourced testbed diagnosere is available in \\url{https:\/\/github.com\/zjunlp\/diagnosere}. ","100":"the dependency tree of a natural language sentence can capture the interactions between semantics and words. however, it is unclear whether those methods which exploit such dependency information for semantic parsing can be combined to achieve further improvement and the relationship of those methods when they combine. in this paper, we examine three methods to incorporate such dependency information in a transformer based semantic parser and empirically study their combinations. we first replace standard self-attention heads in the encoder with parent-scaled self-attention (pascal) heads, i.e., the ones that can attend to the dependency parent of each token. then we concatenate syntax-aware word representations (sawrs), i.e., the intermediate hidden representations of a neural dependency parser, with ordinary word embedding to enhance the encoder. later, we insert the constituent attention (ca) module to the encoder, which adds an extra constraint to attention heads that can better capture the inherent dependency structure of input sentences. transductive ensemble learning (tel) is used for model aggregation, and an ablation study is conducted to show the contribution of each method. our experiments show that ca is complementary to pascal or sawrs, and pascal + ca provides state-of-the-art performance among neural approaches on atis, geo, and jobs. ","101":"publicly available, large pretrained languagemodels (lms) generate text with remarkable quality, but only sequentially from left to right. as a result, they are not immediately applicable to generation tasks that break the unidirectional assumption, such as paraphrasing or text-infilling, necessitating task-specific supervision.   in this paper, we present reflective decoding, a novel unsupervised algorithm that allows for direct application of unidirectional lms to non-sequential tasks. our 2-step approach requires no supervision or even parallel corpora, only two off-the-shelf pretrained lms in opposite directions: forward and backward. first, in the contextualization step, we use lms to generate ensembles of past and future contexts which collectively capture the input (e.g. the source sentence for paraphrasing). second, in the reflection step, we condition on these \"context ensembles\", generating outputs that are compatible with them. comprehensive empirical results demonstrate that reflective decoding outperforms strong unsupervised baselines on both paraphrasing and abductive text infilling, significantly narrowing the gap between unsupervised and supervised methods. reflective decoding surpasses multiple supervised baselines on various metrics including human evaluation. ","102":"due to the lack of parallel data in current grammatical error correction (gec) task, models based on sequence to sequence framework cannot be adequately trained to obtain higher performance. we propose two data synthesis methods which can control the error rate and the ratio of error types on synthetic data. the first approach is to corrupt each word in the monolingual corpus with a fixed probability, including replacement, insertion and deletion. another approach is to train error generation models and further filtering the decoding results of the models. the experiments on different synthetic data show that the error rate is 40% and the ratio of error types is the same can improve the model performance better. finally, we synthesize about 100 million data and achieve comparable performance as the state of the art, which uses twice as much data as we use. ","103":"in clinical research and clinical decision-making, it is important to know if a study changes or only supports the current standards of care for specific disease management. we define such a change as transformative and a support as incremental research. it usually requires a huge amount of domain expertise and time for humans to finish such tasks. faculty opinions provides us with a well-annotated corpus on whether a research challenges or only confirms established research. in this study, a machine learning approach is proposed to distinguishing transformative from incremental clinical evidence. the texts from both abstract and a 2-year window of citing sentences are collected for a training set of clinical studies recommended and labeled by faculty opinions experts. we achieve the best performance with an average auc of 0.755 (0.705-0.875) using random forest as the classifier and citing sentences as the feature. the results showed that transformative research has typical language patterns in citing sentences unlike abstract sentences. we provide an efficient tool for identifying those clinical evidence challenging or only confirming established claims for clinicians and researchers. ","104":"the scientific world is changing at a rapid pace, with new technology being developed and new trends being set at an increasing frequency. this paper presents a framework for conducting scientific analyses of academic publications, which is crucial to monitor research trends and identify potential innovations. this framework adopts and combines various techniques of natural language processing, such as word embedding and topic modelling. word embedding is used to capture semantic meanings of domain-specific words. we propose two novel scientific publication embedding, i.e., pub-g and pub-w, which are capable of learning semantic meanings of general as well as domain-specific words in various research fields. thereafter, topic modelling is used to identify clusters of research topics within these larger research fields. we curated a publication dataset consisting of two conferences and two journals from 1995 to 2020 from two research domains. experimental results show that our pub-g and pub-w embeddings are superior in comparison to other baseline embeddings by a margin of ~0.18-1.03 based on topic coherence. ","105":"modern neural language models widely used in tasks across nlp risk memorizing sensitive information from their training data. as models continue to scale up in parameters, training data, and compute, understanding memorization in language models is both important from a learning-theoretical point of view, and is practically crucial in real world applications. an open question in previous studies of memorization in language models is how to filter out \"common\" memorization. in fact, most memorization criteria strongly correlate with the number of occurrences in the training set, capturing \"common\" memorization such as familiar phrases, public knowledge or templated texts. in this paper, we provide a principled perspective inspired by a taxonomy of human memory in psychology. from this perspective, we formulate a notion of counterfactual memorization, which characterizes how a model's predictions change if a particular document is omitted during training. we identify and study counterfactually-memorized training examples in standard text datasets. we further estimate the influence of each training example on the validation set and on generated texts, and show that this can provide direct evidence of the source of memorization at test time. ","106":"this paper presents our research regarding spoiler detection in reviews. in this use case, we describe the method of fine-tuning and organizing the available text-based model tasks with the latest deep learning achievements and techniques to interpret the models' results.   until now, spoiler research has been rarely described in the literature. we tested the transfer learning approach and different latest transformer architectures on two open datasets with annotated spoilers (roc auc above 81\\% on tv tropes movies dataset, and goodreads dataset above 88\\%). we also collected data and assembled a new dataset with fine-grained annotations. to that end, we employed interpretability techniques and measures to assess the models' reliability and explain their results. ","107":"the development of open-domain dialogue systems (ods)is a trending topic due to the large number of research challenges, large societal and business impact, and advances in the underlying technology. however, the development of these kinds of systems requires two important characteristics:1) automatic evaluation mechanisms that show high correlations with human judgements across multiple dialogue evaluation aspects (with explainable features for providing constructive and explicit feedback on the quality of generative models' responses for quick development and deployment)and 2) mechanisms that can help to control chatbot responses,while avoiding toxicity and employing intelligent ways to handle toxic user comments and keeping interaction flow and engagement. this track at the 10th dialogue system technology challenge (dstc10) is part of the ongoing effort to promote scalable and toxic-free ods. this paper describes the datasets and baselines provided to participants, as well as submission evaluation results for each of the two proposed subtasks. ","108":"with recent improvements in natural language generation (nlg) models for various applications, it has become imperative to have the means to identify and evaluate whether nlg output is only sharing verifiable information about the external world. in this work, we present a new evaluation framework entitled attributable to identified sources (ais) for assessing the output of natural language generation models, when such output pertains to the external world. we first define ais and introduce a two-stage annotation pipeline for allowing annotators to appropriately evaluate model output according to ais guidelines. we empirically validate this approach on three generation datasets (two in the conversational qa domain and one in summarization) via human evaluation studies that suggest that ais could serve as a common framework for measuring whether model-generated statements are supported by underlying sources. we release guidelines for the human evaluation studies. ","109":"classification of posts in social media such as twitter is difficult due to the noisy and short nature of texts. sequence classification models based on recurrent neural networks (rnn) are popular for classifying posts that are sequential in nature. rnns assume the hidden representation dynamics to evolve in a discrete manner and do not consider the exact time of the posting. in this work, we propose to use recurrent neural ordinary differential equations (rnode) for social media post classification which consider the time of posting and allow the computation of hidden representation to evolve in a time-sensitive continuous manner. in addition, we propose a novel model, bi-directional rnode (bi-rnode), which can consider the information flow in both the forward and backward directions of posting times to predict the post label. our experiments demonstrate that rnode and bi-rnode are effective for the problem of stance classification of rumours in social media. ","110":"pre-trained language models have achieved state-of-the-art results in various natural language processing (nlp) tasks. gpt-3 has shown that scaling up pre-trained language models can further exploit their enormous potential. a unified framework named ernie 3.0 was recently proposed for pre-training large-scale knowledge enhanced models and trained a model with 10 billion parameters. ernie 3.0 outperformed the state-of-the-art models on various nlp tasks. in order to explore the performance of scaling up ernie 3.0, we train a hundred-billion-parameter model called ernie 3.0 titan with up to 260 billion parameters on the paddlepaddle platform. furthermore, we design a self-supervised adversarial loss and a controllable language modeling loss to make ernie 3.0 titan generate credible and controllable texts. to reduce the computation overhead and carbon emission, we propose an online distillation framework for ernie 3.0 titan, where the teacher model will teach students and train itself simultaneously. ernie 3.0 titan is the largest chinese dense pre-trained model so far. empirical results show that the ernie 3.0 titan outperforms the state-of-the-art models on 68 nlp datasets. ","111":"clinical notes are an efficient way to record patient information but are notoriously hard to decipher for non-experts. automatically simplifying medical text can empower patients with valuable information about their health, while saving clinicians time. we present a novel approach to automated simplification of medical text based on word frequencies and language modelling, grounded on medical ontologies enriched with layman terms. we release a new dataset of pairs of publicly available medical sentences and a version of them simplified by clinicians. also, we define a novel text simplification metric and evaluation framework, which we use to conduct a large-scale human evaluation of our method against the state of the art. our method based on a language model trained on medical forum data generates simpler sentences while preserving both grammar and the original meaning, surpassing the current state of the art. ","112":"measuring the semantic similarity of different texts has many important applications in digital humanities research such as information retrieval, document clustering and text summarization. the performance of different methods depends on the length of the text, the domain and the language. this study focuses on experimenting with some of the current approaches to finnish, which is a morphologically rich language. at the same time, we propose a simple method, tfw2v, which shows high efficiency in handling both long text documents and limited amounts of data. furthermore, we design an objective evaluation method which can be used as a framework for benchmarking text similarity approaches. ","113":"the large size and complex decision mechanisms of state-of-the-art text classifiers make it difficult for humans to understand their predictions, leading to a potential lack of trust by the users. these issues have led to the adoption of methods like shap and integrated gradients to explain classification decisions by assigning importance scores to input tokens. however, prior work, using different randomization tests, has shown that interpretations generated by these methods may not be robust. for instance, models making the same predictions on the test set may still lead to different feature importance rankings. in order to address the lack of robustness of token-based interpretability, we explore explanations at higher semantic levels like sentences. we use computational metrics and human subject studies to compare the quality of sentence-based interpretations against token-based ones. our experiments show that higher-level feature attributions offer several advantages: 1) they are more robust as measured by the randomization tests, 2) they lead to lower variability when using approximation-based methods like shap, and 3) they are more intelligible to humans in situations where the linguistic coherence resides at a higher granularity level. based on these findings, we show that token-based interpretability, while being a convenient first choice given the input interfaces of the ml models, is not the most effective one in all situations. ","114":"task-oriented dialogue systems have been plagued by the difficulties of obtaining large-scale and high-quality annotated conversations. furthermore, most of the publicly available datasets only include written conversations, which are insufficient to reflect actual human behaviors in practical spoken dialogue systems. in this paper, we propose task-oriented dialogue data augmentation (tod-da), a novel model-agnostic data augmentation paradigm to boost the robustness of task-oriented dialogue modeling on spoken conversations. the tod-da consists of two modules: 1) dialogue enrichment to expand training data on task-oriented conversations for easing data sparsity and 2) spoken conversation simulator to imitate oral style expressions and speech recognition errors in diverse granularities for bridging the gap between written and spoken conversations. with such designs, our approach ranked first in both tasks of dstc10 track2, a benchmark for task-oriented dialogue modeling on spoken conversations, demonstrating the superiority and effectiveness of our proposed tod-da. ","115":"the softmax function is widely used in artificial neural networks for the multiclass classification problems, where the softmax transformation enforces the output to be positive and sum to one, and the corresponding loss function allows to use maximum likelihood principle to optimize the model. however, softmax leaves a large margin for loss function to conduct optimizing operation when it comes to high-dimensional classification, which results in low-performance to some extent. in this paper, we provide an empirical study on a simple and concise softmax variant, namely sparse-softmax, to alleviate the problem that occurred in traditional softmax in terms of high-dimensional classification problems. we evaluate our approach in several interdisciplinary tasks, the experimental results show that sparse-softmax is simpler, faster, and produces better results than the baseline models. ","116":"multilingual language models (\\mllms) such as mbert, xlm, xlm-r, \\textit{etc.} have emerged as a viable option for bringing the power of pretraining to a large number of languages. given their success in zero-shot transfer learning, there has emerged a large body of work in (i) building bigger \\mllms~covering a large number of languages (ii) creating exhaustive benchmarks covering a wider variety of tasks and languages for evaluating \\mllms~ (iii) analysing the performance of \\mllms~on monolingual, zero-shot cross-lingual and bilingual tasks (iv) understanding the universal language patterns (if any) learnt by \\mllms~ and (v) augmenting the (often) limited capacity of \\mllms~ to improve their performance on seen or even unseen languages. in this survey, we review the existing literature covering the above broad areas of research pertaining to \\mllms. based on our survey, we recommend some promising directions of future research. ","117":"recently, text world games have been proposed to enable artificial agents to understand and reason about real-world scenarios. these text-based games are challenging for artificial agents, as it requires an understanding of and interaction using natural language in a partially observable environment. agents observe the environment via textual descriptions designed to be challenging enough for even human players. past approaches have not paid enough attention to the language understanding capability of the proposed agents. typically, these approaches train from scratch, an agent that learns both textual representations and the gameplay online during training using a temporal loss function. given the sample-inefficiency of rl approaches, it is inefficient to learn rich enough textual representations to be able to understand and reason using the textual observation in such a complicated game environment setting. in this paper, we improve the semantic understanding of the agent by proposing a simple rl with lm framework where we use transformer-based language models with deep rl models. we perform a detailed study of our framework to demonstrate how our model outperforms all existing agents on the popular game, zork1, to achieve a score of 44.7, which is 1.6 higher than the state-of-the-art model. overall, our proposed approach outperforms 4 games out of the 14 text-based games, while performing comparable to the state-of-the-art models on the remaining games. ","118":"emotion recognition in conversation (erc) has attracted much attention in recent years for its necessity in widespread applications. existing erc methods mostly model the self and inter-speaker context separately, posing a major issue for lacking enough interaction between them. in this paper, we propose a novel speaker and position-aware graph neural network model for erc (s+page), which contains three stages to combine the benefits of both transformer and relational graph convolution network (r-gcn) for better contextual modeling. firstly, a two-stream conversational transformer is presented to extract the coarse self and inter-speaker contextual features for each utterance. then, a speaker and position-aware conversation graph is constructed, and we propose an enhanced r-gcn model, called pag, to refine the coarse features guided by a relative positional encoding. finally, both of the features from the former two stages are input into a conditional random field layer to model the emotion transfer. ","119":"non-recurrent and unpredictable traffic events directly influence road traffic conditions. there is a need for dynamic monitoring and prediction of these unpredictable events to improve road network management. the problem with the existing traditional methods (flow or speed studies) is that the coverage of many indian roads is very sparse and reproducible methods to identify and describe the events are not available. addition of some other form of data is essential to help with this problem. this could be real-time speed monitoring data like google maps, waze, etc. or social data like twitter, facebook, etc. in this paper, an unsupervised learning model is used to perform effective tweet classification for enhancing indian traffic data. the model uses word-embeddings to calculate semantic similarity and achieves a test score of 94.7%. ","120":"during the past several years, a surge of multi-lingual pre-trained language models (plms) has been proposed to achieve state-of-the-art performance in many cross-lingual downstream tasks. however, the understanding of why multi-lingual plms perform well is still an open domain. for example, it is unclear whether multi-lingual plms reveal consistent token attributions in different languages. to address this, in this paper, we propose a cross-lingual consistency of token attributions (ccta) evaluation framework. extensive experiments in three downstream tasks demonstrate that multi-lingual plms assign significantly different attributions to multi-lingual synonyms. moreover, we have the following observations: 1) the spanish achieves the most consistent token attributions in different languages when it is used for training plms; 2) the consistency of token attributions strongly correlates with performance in downstream tasks. ","121":"while the english virtual assistants have achieved exciting performance with an enormous amount of training resources, the needs of non-english-speakers have not been satisfied well. up to dec 2021, alexa, one of the most popular smart speakers around the world, is able to support 9 different languages [1], while there are thousands of languages in the world, 91 of which are spoken by more than 10 million people according to statistics published in 2019 [2]. however, training a virtual assistant in other languages than english is often more difficult, especially for those low-resource languages. the lack of high-quality training data restricts the performance of models, resulting in poor user satisfaction. therefore, we devise an efficient and effective training solution for multilingual task-orientated dialogue systems, using the same dataset generation pipeline and end-to-end dialogue system architecture as bitod[5], which adopted some key design choices for a minimalistic natural language design where formal dialogue states are used in place of natural language inputs. this reduces the room for error brought by weaker natural language models, and ensures the model can correctly extract the essential slot values needed to perform dialogue state tracking (dst). our goal is to reduce the amount of natural language encoded at each turn, and the key parameter we investigate is the number of turns (h) to feed as history to model. we first explore the turning point where increasing h begins to yield limiting returns on the overall performance. then we examine whether the examples a model with small h gets wrong can be categorized in a way for the model to do few-shot finetuning on. lastly, will explore the limitations of this approach, and whether there is a certain type of examples that this approach will not be able to resolve. ","122":"tokenization is fundamental to pretrained language models (plms). existing tokenization methods for chinese plms typically treat each character as an indivisible token. however, they ignore the unique feature of the chinese writing system where additional linguistic information exists below the character level, i.e., at the sub-character level. to utilize such information, we propose sub-character (subchar for short) tokenization. specifically, we first encode the input text by converting each chinese character into a short sequence based on its glyph or pronunciation, and then construct the vocabulary based on the encoded text with sub-word tokenization. experimental results show that subchar tokenizers have two main advantages over existing tokenizers: 1) they can tokenize inputs into much shorter sequences, thus improving the computational efficiency. 2) pronunciation-based subchar tokenizers can encode chinese homophones into the same transliteration sequences and produce the same tokenization output, hence being robust to all homophone typos. at the same time, models trained with subchar tokenizers perform competitively on downstream tasks. we release our code at https:\/\/github.com\/thunlp\/subchartokenization to facilitate future work. ","123":"function load (fl) quantifies the contributions by phonological contrasts to distinctions made across the lexicon. previous research has linked particularly low values of fl to sound change. here we broaden the scope of enquiry into fl, to its evolution at all values. we apply phylogenetic methods to examine the diachronic evolution of fl across 90 languages of the pama-nyungan (pn) family of australia. we find a high degree of phylogenetic signal in fl. though phylogenetic signal has been reported for phonological structures, such as phonotactics, its detection in measures of phonological function is novel. we also find a significant, negative correlation between the fl of vowel length and of the following consonant, that is, a deep-time historical trade-off dynamic, which we relate to known allophony in modern pn languages and compensatory sound changes in their past. the finding reveals a historical dynamic, similar to transphonologization, which we characterize as a flow of contrastiveness between subsystems of the phonology. recurring across a language family which spans a whole continent and many millennia of time depth, our finding provides one of the most compelling examples yet of sapir's 'drift' hypothesis, of non-accidentally parallel development in historically related languages. ","124":"most of the speech recognition systems recover only words in the speech and fail to capture emotions. users have to manually add emoji(s) in text for adding tone and making communication fun. though there is much work done on punctuation addition on transcribed speech, the area of emotion addition is untouched. in this paper, we propose a novel on-device pipeline to enrich the voice input experience. it involves, given a blob of transcribed text, intelligently processing and identifying structure where emoji insertion makes sense. moreover, it includes semantic text analysis to predict emoji for each of the sub-parts for which we propose a novel architecture attention-based char aware (aca) lstm which handles out-of-vocabulary (oov) words as well. all these tasks are executed completely on-device and hence can aid on-device dictation systems. to the best of our knowledge, this is the first work that shows how to add emoji(s) in the transcribed text. we demonstrate that our components achieve comparable results to previous neural approaches for punctuation addition and emoji prediction with 80% fewer parameters. overall, our proposed model has a very small memory footprint of a mere 4mb to suit on-device deployment. ","125":"we receive several essential updates on our smartphones in the form of sms, documents, voice messages, etc. that get buried beneath the clutter of content. we often do not realize the key information without going through the full content. sms notifications sometimes help by giving an idea of what the message is about, however, they merely offer a preview of the beginning content. one way to solve this is to have a single efficient model that can adapt and summarize data from varied sources. in this paper, we tackle this issue and for the first time, propose a novel adaptive beam search to improve the quality of on-device abstractive summarization that can be applied to sms, voice messages and can be extended to documents. to the best of our knowledge, this is the first on-device abstractive summarization pipeline to be proposed that can adapt to multiple data sources addressing privacy concerns of users as compared to the majority of existing summarization systems that send data to a server. we reduce the model size by 30.9% using knowledge distillation and show that this model with a 97.6% lesser memory footprint extracts the same or more key information as compared to bert. ","126":"despite attempts to increase gender parity in politics, global efforts have struggled to ensure equal female representation. this is likely tied to implicit gender biases against women in authority. in this work, we present a comprehensive study of gender biases that appear in online political discussion. to this end, we collect 10 million comments on reddit in conversations about male and female politicians, which enables an exhaustive study of automatic gender bias detection. we address not only misogynistic language, but also benevolent sexism in the form of seemingly positive attitudes examining both sentiment and dominance attributed to female politicians. finally, we conduct a multi-faceted study of gender bias towards politicians investigating both linguistic and extra-linguistic cues. we assess 5 different types of gender bias, evaluating coverage, combinatorial, nominal, sentimental and lexical biases extant in social media language and discourse. overall, we find that, contrary to previous research, coverage and sentiment biases suggest equal public interest in female politicians. however, the results of the nominal and lexical analyses suggest this interest is not as professional or respectful as that expressed about male politicians. female politicians are often named by their first names and are described in relation to their body, clothing, or family; this is a treatment that is not similarly extended to men. on the now banned far-right subreddits, this disparity is greatest, though differences in gender biases still appear in the right and left-leaning subreddits. we release the curated dataset to the public for future studies. ","127":"deep learning techniques have been shown to be efficient in various tasks, especially in the development of speech recognition systems, that is, systems that aim to transcribe an audio sentence in a sequence of written words. despite the progress in the area, speech recognition can still be considered difficult, especially for languages lacking available data, such as brazilian portuguese (bp). in this sense, this work presents the development of an public automatic speech recognition (asr) system using only open available audio data, from the fine-tuning of the wav2vec 2.0 xlsr-53 model pre-trained in many languages, over bp data. the final model presents an average word error rate of 12.4% over 7 different datasets (10.5% when applying a language model). according to our knowledge, the obtained error is the lowest among open end-to-end (e2e) asr models for bp. ","128":"neural autoregressive sequence models smear the probability among many possible sequences including degenerate ones, such as empty or repetitive sequences. in this work, we tackle one specific case where the model assigns a high probability to unreasonably short sequences. we define the oversmoothing rate to quantify this issue. after confirming the high degree of oversmoothing in neural machine translation, we propose to explicitly minimize the oversmoothing rate during training. we conduct a set of experiments to study the effect of the proposed regularization on both model distribution and decoding performance. we use a neural machine translation task as the testbed and consider three different datasets of varying size. our experiments reveal three major findings. first, we can control the oversmoothing rate of the model by tuning the strength of the regularization. second, by enhancing the oversmoothing loss contribution, the probability and the rank of <eos> token decrease heavily at positions where it is not supposed to be. third, the proposed regularization impacts the outcome of beam search especially when a large beam is used. the degradation of translation quality (measured in bleu) with a large beam significantly lessens with lower oversmoothing rate, but the degradation compared to smaller beam sizes remains to exist. from these observations, we conclude that the high degree of oversmoothing is the main reason behind the degenerate case of overly probable short sequences in a neural autoregressive model. ","129":"this paper presents methods for improving automated essay scoring with techniques that address the computational trade-offs of self-attention and document length. to make automated essay scoring (aes) more useful to practitioners, researchers must overcome the challenges of data and label availability, authentic and extended writing, domain scoring, prompt and source variety, and transfer learning. this paper addresses these challenges using neural network models by employing techniques that preserve essay length as an important feature without increasing model training costs. it introduces techniques for minimizing classification loss on ordinal labels using multi-objective learning, capturing semantic information across the entire essay using sentence embeddings to use transformer architecture across arbitrarily long documents, the use of such models for transfer learning, automated hyperparameter generation based on prompt-corpus metadata, and, most importantly, the use of semantic information to provide meaningful insights into student reading through analysis of passage-dependent writing resulting in state-of-the-art results for various essay tasks. ","130":"we introduce the crass (counterfactual reasoning assessment) data set and benchmark utilizing questionized counterfactual conditionals as a novel and powerful tool to evaluate large language models. we present the data set design and benchmark as well as the accompanying api that supports scoring against a crowd-validated human baseline. we test six state-of-the-art models against our benchmark. our results show that it poses a valid challenge for these models and opens up considerable room for their improvement. ","131":"memes are one of the most ubiquitous forms of social media communication. the study and processing of memes, which are intrinsically multimedia, is a popular topic right now. the study presented in this research is based on the memotion dataset, which involves categorising memes based on irony, comedy, motivation, and overall-sentiment. three separate innovative transformer-based techniques have been developed, and their outcomes have been thoroughly reviewed.the best algorithm achieved a macro f1 score of 0.633 for humour classification, 0.55 for motivation classification, 0.61 for sarcasm classification, and 0.575 for overall sentiment of the meme out of all our techniques. ","132":"text classification is the most fundamental and essential task in natural language processing. the last decade has seen a surge of research in this area due to the unprecedented success of deep learning. numerous methods, datasets, and evaluation metrics have been proposed in the literature, raising the need for a comprehensive and updated survey. this paper fills the gap by reviewing the state-of-the-art approaches from 1961 to 2021, focusing on models from traditional models to deep learning. we create a taxonomy for text classification according to the text involved and the models used for feature extraction and classification. we then discuss each of these categories in detail, dealing with both the technical developments and benchmark datasets that support tests of predictions. a comprehensive comparison between different techniques, as well as identifying the pros and cons of various evaluation metrics are also provided in this survey. finally, we conclude by summarizing key implications, future research directions, and the challenges facing the research area. ","133":"event extraction is a fundamental task for natural language processing. finding the roles of event arguments like event participants is essential for event extraction. however, doing so for real-life event descriptions is challenging because an argument's role often varies in different contexts. while the relationship and interactions between multiple arguments are useful for settling the argument roles, such information is largely ignored by existing approaches. this paper presents a better approach for event extraction by explicitly utilizing the relationships of event arguments. we achieve this through a carefully designed task-oriented dialogue system. to model the argument relation, we employ reinforcement learning and incremental learning to extract multiple arguments via a multi-turned, iterative process. our approach leverages knowledge of the already extracted arguments of the same sentence to determine the role of arguments that would be difficult to decide individually. it then uses the newly obtained information to improve the decisions of previously extracted arguments. this two-way feedback process allows us to exploit the argument relations to effectively settle argument roles, leading to better sentence understanding and event extraction. experimental results show that our approach consistently outperforms seven state-of-the-art event extraction methods for the classification of events and argument role and argument identification. ","134":"we present the webis-stereo-21 dataset, a massive collection of scientific text reuse in open-access publications. it contains more than 91 million cases of reused text passages found in 4.2 million unique open-access publications. featuring a high coverage of scientific disciplines and varieties of reuse, as well as comprehensive metadata to contextualize each case, our dataset addresses the most salient shortcomings of previous ones on scientific writing. webis-stereo-21 allows for tackling a wide range of research questions from different scientific backgrounds, facilitating both qualitative and quantitative analysis of the phenomenon as well as a first-time grounding on the base rate of text reuse in scientific publications. ","135":"the last advances in sequence modeling are mainly based on deep learning approaches. the current state of the art involves the use of variations of the standard lstm architecture, combined with several tricks that improve the final prediction rates of the trained neural networks. however, in some cases, these adaptations might be too much tuned to the particular problems being addressed. in this article, we show that a very simple idea, to add a direct connection between the input and the output, skipping the recurrent module, leads to an increase of the prediction accuracy in sequence modeling problems related to natural language processing. experiments carried out on different problems show that the addition of this kind of connection to a recurrent network always improves the results, regardless of the architecture and training-specific details. when this idea is introduced into the models that lead the field, the resulting networks achieve a new state-of-the-art perplexity in language modeling problems. ","136":"annotation studies often require annotators to familiarize themselves with the task, its annotation scheme, and the data domain. this can be overwhelming in the beginning, mentally taxing, and induce errors into the resulting annotations; especially in citizen science or crowd sourcing scenarios where domain expertise is not required and only annotation guidelines are provided. to alleviate these issues, we propose annotation curricula, a novel approach to implicitly train annotators. our goal is to gradually introduce annotators into the task by ordering instances that are annotated according to a learning curriculum. to do so, we first formalize annotation curricula for sentence- and paragraph-level annotation tasks, define an ordering strategy, and identify well-performing heuristics and interactively trained models on three existing english datasets. we then conduct a user study with 40 voluntary participants who are asked to identify the most fitting misconception for english tweets about the covid-19 pandemic. our results show that using a simple heuristic to order instances can already significantly reduce the total annotation time while preserving a high annotation quality. annotation curricula thus can provide a novel way to improve data collection. to facilitate future research, we further share our code and data consisting of 2,400 annotations. ","137":"theoretical complexity is a vital subfield of computer science that enables us to mathematically investigate computation and answer many interesting queries about the nature of computational problems. it provides theoretical tools to assess time and space requirements of computations along with assessing the difficultly of problems - classifying them accordingly. it also garners at its core one of the most important problems in mathematics, namely, the $\\textbf{p vs. np}$ millennium problem. in essence, this problem asks whether solution and verification reside on two different levels of difficulty. in this thesis, we introduce some of the most central concepts in the theory of computing, giving an overview of how computation can be abstracted using turing machines. further, we introduce the two most famous problem complexity classes $\\textbf{p}$ and $\\textbf{np}$ along with the relationship between them. in addition, we explicate the concept of problem reduction and how it is an essential tool for making hardness comparisons between different problems. later, we present the problem of boolean satisfiability (sat) which lies at the center of np-complete problems. we then explore some of its tractable as well as intractable variants such as horn-sat and 3-sat, respectively. last but not least, we establish polynomial-time reductions from 3-sat to some of the famous np-complete graph problems, namely, clique finding, hamiltonian cycle finding, and 3-coloring. ","138":"event extraction is a critical technique to apprehend the essential content of events promptly. with the rapid development of deep learning technology, event extraction technology based on deep learning has become a research hotspot. numerous methods, datasets, and evaluation metrics have been proposed in the literature, raising the need for a comprehensive and updated survey. this paper fills the gap by reviewing the state-of-the-art approaches, focusing on deep learning-based models. we summarize the task definition, paradigm, and models of event extraction and then discuss each of these in detail. we introduce benchmark datasets that support tests of predictions and evaluation metrics. a comprehensive comparison between different techniques is also provided in this survey. finally, we conclude by summarizing future research directions facing the research area. ","139":"implicit discourse relation recognition (idrr) is a challenging but crucial task in discourse analysis. most existing methods train multiple models to predict multi-level labels independently, while ignoring the dependence between hierarchically structured labels. in this paper, we consider multi-level idrr as a conditional label sequence generation task and propose a label dependence-aware sequence generation model (ldsgm) for it. specifically, we first design a label attentive encoder to learn the global representation of an input instance and its level-specific contexts, where the label dependence is integrated to obtain better label embeddings. then, we employ a label sequence decoder to output the predicted labels in a top-down manner, where the predicted higher-level labels are directly used to guide the label prediction at the current level. we further develop a mutual learning enhanced training method to exploit the label dependence in a bottomup direction, which is captured by an auxiliary decoder introduced during training. experimental results on the pdtb dataset show that our model achieves the state-of-the-art performance on multi-level idrr. we will release our code at https:\/\/github.com\/nlpersecjtu\/ldsgm. ","140":"this paper offers a comprehensive review of the research on natural language generation (nlg) over the past two decades, especially in relation to data-to-text generation and text-to-text generation deep learning methods, as well as new applications of nlg technology. this survey aims to (a) give the latest synthesis of deep learning research on the nlg core tasks, as well as the architectures adopted in the field; (b) detail meticulously and comprehensively various nlg tasks and datasets, and draw attention to the challenges in nlg evaluation, focusing on different evaluation methods and their relationships; (c) highlight some future emphasis and relatively recent research issues that arise due to the increasing synergy between nlg and other artificial intelligence areas, such as computer vision, text and computational creativity. ","141":"query embedding (qe) -- which aims to embed entities and first-order logical (fol) queries in low-dimensional spaces -- has shown great power in multi-hop reasoning over knowledge graphs. recently, embedding entities and queries with geometric shapes becomes a promising direction, as geometric shapes can naturally represent answer sets of queries and logical relationships among them. however, existing geometry-based models have difficulty in modeling queries with negation, which significantly limits their applicability. to address this challenge, we propose a novel query embedding model, namely cone embeddings (cone), which is the first geometry-based qe model that can handle all the fol operations, including conjunction, disjunction, and negation. specifically, cone represents entities and queries as cartesian products of two-dimensional cones, where the intersection and union of cones naturally model the conjunction and disjunction operations. by further noticing that the closure of complement of cones remains cones, we design geometric complement operators in the embedding space for the negation operations. experiments demonstrate that cone significantly outperforms existing state-of-the-art methods on benchmark datasets. ","142":"for the task of conversation emotion recognition, recent works focus on speaker relationship modeling but ignore the role of utterance's emotional tendency.in this paper, we propose a new expression paradigm of sentence-level emotion orientation vector to model the potential correlation of emotions between sentence vectors. based on it, we design an emotion recognition model, which extracts the sentence-level emotion orientation vectors from the language model and jointly learns from the dialogue sentiment analysis model and extracted sentence-level emotion orientation vectors to identify the speaker's emotional orientation during the conversation. we conduct experiments on two benchmark datasets and compare them with the five baseline models.the experimental results show that our model has better performance on all data sets. ","143":"recent methods in speech and language technology pretrain very large models which are fine-tuned for specific tasks. however, the benefits of such large models are often limited to a few resource rich languages of the world. in this work, we make multiple contributions towards building asr systems for low resource languages from the indian subcontinent. first, we curate 17,000 hours of raw speech data for 40 indian languages from a wide variety of domains including education, news, technology, and finance. second, using this raw speech data we pretrain several variants of wav2vec style models for 40 indian languages. third, we analyze the pretrained models to find key features: codebook vectors of similar sounding phonemes are shared across languages, representations across layers are discriminative of the language family, and attention heads often pay attention within small local windows. fourth, we fine-tune this model for downstream asr for 9 languages and obtain state-of-the-art results on 3 public datasets, including on very low-resource languages such as sinhala and nepali. our work establishes that multilingual pretraining is an effective strategy for building asr systems for the linguistically diverse speakers of the indian subcontinent. our code, data and models are available publicly at https:\/\/indicnlp.ai4bharat.org\/indicwav2vec\/ and we hope they will help advance research in asr for indic languages. ","144":"the query focused text summarization (qfts) task aims at building systems that generate the summary of the text document(s) based on the given query. a key challenge in addressing this task is the lack of large labeled data for training the summarization model. in this paper, we address this challenge by exploring a series of domain adaptation techniques. given the recent success of pre-trained transformer models in a wide range of natural language processing tasks, we utilize such models to generate abstractive summaries for the qfts task for both single-document and multi-document scenarios. for domain adaptation, we apply a variety of techniques using pre-trained transformer-based summarization models including transfer learning, weakly supervised learning, and distant supervision. extensive experiments on six datasets show that our proposed approach is very effective in generating abstractive summaries for the qfts task while setting a new state-of-the-art result in several datasets across a set of automatic and human evaluation metrics. ","145":"the fine-tuning of pre-trained language models has a great success in many nlp fields. yet, it is strikingly vulnerable to adversarial examples, e.g., word substitution attacks using only synonyms can easily fool a bert-based sentiment analysis model. in this paper, we demonstrate that adversarial training, the prevalent defense technique, does not directly fit a conventional fine-tuning scenario, because it suffers severely from catastrophic forgetting: failing to retain the generic and robust linguistic features that have already been captured by the pre-trained model. in this light, we propose robust informative fine-tuning (rift), a novel adversarial fine-tuning method from an information-theoretical perspective. in particular, rift encourages an objective model to retain the features learned from the pre-trained model throughout the entire fine-tuning process, whereas a conventional one only uses the pre-trained weights for initialization. experimental results show that rift consistently outperforms the state-of-the-arts on two popular nlp tasks: sentiment analysis and natural language inference, under different attacks across various pre-trained language models. ","146":"deep encoders have been proven to be effective in improving neural machine translation (nmt) systems, but it reaches the upper bound of translation quality when the number of encoder layers exceeds 18. worse still, deeper networks consume a lot of memory, making it impossible to train efficiently. in this paper, we present symbiosis networks, which include a full network as the symbiosis main network (m-net) and another shared sub-network with the same structure but less layers as the symbiotic sub network (s-net). we adopt symbiosis networks on transformer-deep (m-n) architecture and define a particular regularization loss $\\mathcal{l}_{\\tau}$ between the m-net and s-net in nmt. we apply joint-training on the symbiosis networks and aim to improve the m-net performance. our proposed training strategy improves transformer-deep (12-6) by 0.61, 0.49 and 0.69 bleu over the baselines under classic training on wmt'14 en->de, de->en and en->fr tasks. furthermore, our transformer-deep (12-6) even outperforms classic transformer-deep (18-6). ","147":"recently, non-autoregressive (nat) models predict outputs in parallel, achieving substantial improvements in generation speed compared to autoregressive (at) models. while performing worse on raw data, most nat models are trained as student models on distilled data generated by at teacher models, which is known as sequence-level knowledge distillation. an effective training strategy to improve the performance of at models is self-distillation mixup (sdm) training, which pre-trains a model on raw data, generates distilled data by the pre-trained model itself and finally re-trains a model on the combination of raw data and distilled data. in this work, we aim to view sdm for nat models, but find directly adopting sdm to nat models gains no improvements in terms of translation quality. through careful analysis, we observe the invalidation is correlated to modeling diversity and confirmation bias between the at teacher model and the nat student models. based on these findings, we propose an enhanced strategy named sdmrt by adding two stages to classic sdm: one is pre-rerank on self-distilled data, the other is fine-tune on filtered teacher-distilled data. our results outperform baselines by 0.6 to 1.2 bleu on multiple nat models. as another bonus, for iterative refinement nat models, our methods can outperform baselines within half iteration number, which means 2x acceleration. ","148":"state-of-the-art attacks on nlp models lack a shared definition of a what constitutes a successful attack. we distill ideas from past work into a unified framework: a successful natural language adversarial example is a perturbation that fools the model and follows some linguistic constraints. we then analyze the outputs of two state-of-the-art synonym substitution attacks. we find that their perturbations often do not preserve semantics, and 38% introduce grammatical errors. human surveys reveal that to successfully preserve semantics, we need to significantly increase the minimum cosine similarities between the embeddings of swapped words and between the sentence encodings of original and perturbed sentences.with constraints adjusted to better preserve semantics and grammaticality, the attack success rate drops by over 70 percentage points. ","149":"contemporary approaches to perception, planning, estimation, and control have allowed robots to operate robustly as our remote surrogates in uncertain, unstructured environments. this progress now creates an opportunity for robots to operate not only in isolation, but also with and alongside humans in our complex environments. realizing this opportunity requires an efficient and flexible medium through which humans can communicate with collaborative robots. natural language provides one such medium, and through significant progress in statistical methods for natural-language understanding, robots are now able to interpret a diverse array of free-form commands. however, most contemporary approaches require a detailed, prior spatial-semantic map of the robot's environment that models the space of possible referents of an utterance. consequently, these methods fail when robots are deployed in new, previously unknown, or partially-observed environments, particularly when mental models of the environment differ between the human operator and the robot. this paper provides a comprehensive description of a novel learning framework that allows field and service robots to interpret and correctly execute natural-language instructions in a priori unknown, unstructured environments. integral to our approach is its use of language as a \"sensor\" -- inferring spatial, topological, and semantic information implicit in the utterance and then exploiting this information to learn a distribution over a latent environment model. we incorporate this distribution in a probabilistic, language grounding model and infer a distribution over a symbolic representation of the robot's action space. we use imitation learning to identify a belief-space policy that reasons over the environment and behavior distributions. we evaluate our framework through a variety navigation and mobile-manipulation experiments. ","150":"human-performed annotation of sentences in legal documents is an important prerequisite to many machine learning based systems supporting legal tasks. typically, the annotation is done sequentially, sentence by sentence, which is often time consuming and, hence, expensive. in this paper, we introduce a proof-of-concept system for annotating sentences \"laterally.\" the approach is based on the observation that sentences that are similar in meaning often have the same label in terms of a particular type system. we use this observation in allowing annotators to quickly view and annotate sentences that are semantically similar to a given sentence, across an entire corpus of documents. here, we present the interface of the system and empirically evaluate the approach. the experiments show that lateral annotation has the potential to make the annotation process quicker and more consistent. ","151":"as ai systems demonstrate increasingly strong predictive performance, their adoption has grown in numerous domains. however, in high-stakes domains such as criminal justice and healthcare, full automation is often not desirable due to safety, ethical, and legal concerns, yet fully manual approaches can be inaccurate and time consuming. as a result, there is growing interest in the research community to augment human decision making with ai assistance. besides developing ai technologies for this purpose, the emerging field of human-ai decision making must embrace empirical approaches to form a foundational understanding of how humans interact and work with ai to make decisions. to invite and help structure research efforts towards a science of understanding and improving human-ai decision making, we survey recent literature of empirical human-subject studies on this topic. we summarize the study design choices made in over 100 papers in three important aspects: (1) decision tasks, (2) ai models and ai assistance elements, and (3) evaluation metrics. for each aspect, we summarize current trends, discuss gaps in current practices of the field, and make a list of recommendations for future research. our survey highlights the need to develop common frameworks to account for the design and research spaces of human-ai decision making, so that researchers can make rigorous choices in study design, and the research community can build on each other's work and produce generalizable scientific knowledge. we also hope this survey will serve as a bridge for hci and ai communities to work together to mutually shape the empirical science and computational technologies for human-ai decision making. ","152":"jitter and shimmer measurements have shown to be carriers of voice quality and prosodic information which enhance the performance of tasks like speaker recognition, diarization or automatic speech recognition (asr). however, such features have been seldom used in the context of neural-based asr, where spectral features often prevail. in this work, we study the effects of incorporating voice quality and pitch features altogether and separately to a transformer-based asr model, with the intuition that the attention mechanisms might exploit latent prosodic traits. for doing so, we propose separated convolutional front-ends for prosodic and spectral features, showing that this architectural choice yields better results than simple concatenation of such pitch and voice quality features to mel-spectrogram filterbanks. furthermore, we find mean word error rate relative reductions of up to 5.6% with the librispeech benchmark. such findings motivate further research on the application of prosody knowledge for increasing the robustness of transformer-based asr. ","153":"contrastive pretraining techniques for text classification has been largely studied in an unsupervised setting. however, oftentimes labeled data from related tasks which share label semantics with current task is available. we hypothesize that using this labeled data effectively can lead to better generalization on current task. in this paper, we propose a novel way to effectively utilize labeled data from related tasks with a graph based supervised contrastive learning approach. we formulate a token-graph by extrapolating the supervised information from examples to tokens. our formulation results in an embedding space where tokens with high\/low probability of belonging to same class are near\/further-away from one another. we also develop detailed theoretical insights which serve as a motivation for our method. in our experiments with $13$ datasets, we show our method outperforms pretraining schemes by $2.5\\%$ and also example-level contrastive learning based formulation by $1.8\\%$ on average. in addition, we show cross-domain effectiveness of our method in a zero-shot setting by $3.91\\%$ on average. lastly, we also demonstrate our method can be used as a noisy teacher in a knowledge distillation setting to significantly improve performance of transformer based models in low labeled data regime by $4.57\\%$ on average. ","154":"this work proposes a new type of classifier called morphological classifier (mc). mcs aggregate concepts from mathematical morphology and supervised learning. the outcomes of this aggregation are classifiers that may preserve shape characteristics of classes, subject to the choice of a stopping criterion and structuring element. mcs are fundamentally based on set theory, and their classification model can be a mathematical set itself. two types of morphological classifiers are proposed in the current work, namely, morphological k-nn (mknn) and morphological dilation classifier (mdc), which demonstrate the feasibility of the approach. this work provides evidence regarding the advantages of mcs, e.g., very fast classification times as well as competitive accuracy rates. the performance of mknn and mdc was tested using p -dimensional datasets. mcs tied or outperformed 14 well established classifiers in 5 out of 8 datasets. in all occasions, the obtained accuracies were higher than the average accuracy obtained with all classifiers. moreover, the proposed implementations utilize the power of the graphics processing units (gpus) to speed up processing. ","155":"copy mechanism allows sequence-to-sequence models to choose words from the input and put them directly into the output, which is finding increasing use in abstractive summarization. however, since there is no explicit delimiter in chinese sentences, most existing models for chinese abstractive summarization can only perform character copy, resulting in inefficient. to solve this problem, we propose a lexicon-constrained copying network that models multi-granularity in both encoder and decoder. on the source side, words and characters are aggregated into the same input memory using a transformerbased encoder. on the target side, the decoder can copy either a character or a multi-character word at each time step, and the decoding process is guided by a word-enhanced search algorithm that facilitates the parallel computation and encourages the model to copy more words. moreover, we adopt a word selector to integrate keyword information. experiments results on a chinese social media dataset show that our model can work standalone or with the word selector. both forms can outperform previous character-based models and achieve competitive performances. ","156":"to enhance research on multimodal knowledge base and multimodal information processing, we propose a new task called multimodal entity tagging (met) with a multimodal knowledge base (mkb). we also develop a dataset for the problem using an existing mkb. in an mkb, there are entities and their associated texts and images. in met, given a text-image pair, one uses the information in the mkb to automatically identify the related entity in the text-image pair. we solve the task by using the information retrieval paradigm and implement several baselines using state-of-the-art methods in nlp and cv. we conduct extensive experiments and make analyses on the experimental results. the results show that the task is challenging, but current technologies can achieve relatively high performance. we will release the dataset, code, and models for future research. ","157":"string representation learning (srl) is an important task in the field of natural language processing, but it remains under-explored. the goal of srl is to learn dense and low-dimensional vectors (or embeddings) for encoding character sequences. the learned representation from this task can be used in many downstream application tasks such as string similarity matching or lexical normalization. in this paper, we propose a new method for to train a srl model by only using synthetic data. our approach makes use of contrastive learning in order to maximize similarity between related strings while minimizing it for unrelated strings. we demonstrate the effectiveness of our approach by evaluating the learned representation on the task of string similarity matching. codes, data and pretrained models will be made publicly available. ","158":"an approach based on answer set programming (asp) is proposed in this paper for representing knowledge generated from natural language texts. knowledge in a text is modeled using a neo davidsonian-like formalism, which is then represented as an answer set program. relevant commonsense knowledge is additionally imported from resources such as wordnet and represented in asp. the resulting knowledge-base can then be used to perform reasoning with the help of an asp system. this approach can facilitate many natural language tasks such as automated question answering, text summarization, and automated question generation. asp-based representation of techniques such as default reasoning, hierarchical knowledge organization, preferences over defaults, etc., are used to model commonsense reasoning methods required to accomplish these tasks. in this paper, we describe the caspr system that we have developed to automate the task of answering natural language questions given english text. caspr can be regarded as a system that answers questions by \"understanding\" the text and has been tested on the squad data set, with promising results. ","159":"task-oriented dialogue systems (tods) are continuing to rise in popularity as various industries find ways to effectively harness their capabilities, saving both time and money. however, even state-of-the-art tods are not yet reaching their full potential. tods typically have a primary design focus on completing the task at hand, so the metric of task-resolution should take priority. other conversational quality attributes that may point to the success, or otherwise, of the dialogue, may be ignored. this can cause interactions between human and dialogue system that leave the user dissatisfied or frustrated. this paper explores the literature on evaluative frameworks of dialogue systems and the role of conversational quality attributes in dialogue systems, looking at if, how, and where they are utilised, and examining their correlation with the performance of the dialogue system. ","160":"knowledge graphs (kg) act as a great tool for holding distilled information from large natural language text corpora. the problem of natural language querying over knowledge graphs is essential for the human consumption of this information. this problem is typically addressed by converting the natural language query to a structured query and then firing the structured query on the kg. direct answering models over knowledge graphs in literature are very few. the query conversion models and direct models both require specific training data pertaining to the domain of the knowledge graph. in this work, we convert the problem of natural language querying over knowledge graphs to an inference problem over premise-hypothesis pairs. using trained deep learning models for the converted proxy inferencing problem, we provide the solution for the original natural language querying problem. our method achieves over 90% accuracy on metaqa dataset, beating the existing state-of-the-art. we also propose a model for inferencing called hierarchical recurrent path encoder(hrpe). the inferencing models can be fine-tuned to be used across domains with less training data. our approach does not require large domain-specific training data for querying on new knowledge graphs from different domains. ","161":"the goal of stance detection is to determine the viewpoint expressed in a piece of text towards a target. these viewpoints or contexts are often expressed in many different languages depending on the user and the platform, which can be a local news outlet, a social media platform, a news forum, etc. most research in stance detection, however, has been limited to working with a single language and on a few limited targets, with little work on cross-lingual stance detection. moreover, non-english sources of labelled data are often scarce and present additional challenges. recently, large multilingual language models have substantially improved the performance on many non-english tasks, especially such with limited numbers of examples. this highlights the importance of model pre-training and its ability to learn from few examples. in this paper, we present the most comprehensive study of cross-lingual stance detection to date: we experiment with 15 diverse datasets in 12 languages from 6 language families, and with 6 low-resource evaluation settings each. for our experiments, we build on pattern-exploiting training, proposing the addition of a novel label encoder to simplify the verbalisation procedure. we further propose sentiment-based generation of stance data for pre-training, which shows sizeable improvement of more than 6% f1 absolute in low-shot settings compared to several strong baselines. ","162":"in this work we present a systematic empirical study focused on the suitability of the state-of-the-art multilingual encoders for cross-lingual document and sentence retrieval tasks across a number of diverse language pairs. we first treat these models as multilingual text encoders and benchmark their performance in unsupervised ad-hoc sentence- and document-level clir. in contrast to supervised language understanding, our results indicate that for unsupervised document-level clir -- a setup with no relevance judgments for ir-specific fine-tuning -- pretrained multilingual encoders on average fail to significantly outperform earlier models based on clwes. for sentence-level retrieval, we do obtain state-of-the-art performance: the peak scores, however, are met by multilingual encoders that have been further specialized, in a supervised fashion, for sentence understanding tasks, rather than using their vanilla 'off-the-shelf' variants. following these results, we introduce localized relevance matching for document-level clir, where we independently score a query against document sections. in the second part, we evaluate multilingual encoders fine-tuned in a supervised fashion (i.e., we learn to rank) on english relevance data in a series of zero-shot language and domain transfer clir experiments. our results show that supervised re-ranking rarely improves the performance of multilingual transformers as unsupervised base rankers. finally, only with in-domain contrastive fine-tuning (i.e., same domain, only language transfer), we manage to improve the ranking quality. we uncover substantial empirical differences between cross-lingual retrieval results and results of (zero-shot) cross-lingual transfer for monolingual retrieval in target languages, which point to \"monolingual overfitting\" of retrieval models trained on monolingual data. ","163":"end-to-end speech-to-text translation~(e2e-st) is becoming increasingly popular due to the potential of its less error propagation, lower latency, and fewer parameters. given the triplet training corpus $\\langle speech, transcription, translation\\rangle$, the conventional high-quality e2e-st system leverages the $\\langle speech, transcription\\rangle$ pair to pre-train the model and then utilizes the $\\langle speech, translation\\rangle$ pair to optimize it further. however, this process only involves two-tuple data at each stage, and this loose coupling fails to fully exploit the association between triplet data. in this paper, we attempt to model the joint probability of transcription and translation based on the speech input to directly leverage such triplet data. based on that, we propose a novel regularization method for model training to improve the agreement of dual-path decomposition within triplet data, which should be equal in theory. to achieve this goal, we introduce two kullback-leibler divergence regularization terms into the model training objective to reduce the mismatch between output probabilities of dual-path. then the well-trained model can be naturally transformed as the e2e-st models by the pre-defined early stop tag. experiments on the must-c benchmark demonstrate that our proposed approach significantly outperforms state-of-the-art e2e-st baselines on all 8 language pairs, while achieving better performance in the automatic speech recognition task. our code is open-sourced at https:\/\/github.com\/duyichao\/e2e-st-tda. ","164":"in previous research, we showed that 'texts that tell a story' exhibit a statistical structure that is not maxwell-boltzmann but bose-einstein. our explanation is that this is due to the presence of 'indistinguishability' in human language as a result of the same words in different parts of the story being indistinguishable from one another. in the current article, we set out to provide an explanation for this bose-einstein statistics. we show that it is the presence of 'meaning' in 'stories' that gives rise to the lack of independence characteristic of bose-einstein, and provides conclusive evidence that 'words can be considered the quanta of human language', structurally similar to how 'photons are the quanta of light'. using several studies on entanglement from our brussels research group, we also show that it is also the presence of 'meaning' in texts that makes the von neumann entropy of a total text smaller relative to the entropy of the words composing it. we explain how the new insights in this article fit in with the research domain called 'quantum cognition', where quantum probability models and quantum vector spaces are used in human cognition, and are also relevant to the use of quantum structures in information retrieval and natural language processing, and how they introduce 'quantization' and 'bose-einstein statistics' as relevant quantum effects there. inspired by the conceptuality interpretation of quantum mechanics, and relying on the new insights, we put forward hypotheses about the nature of physical reality. in doing so, we note how this new type of decrease in entropy, and its explanation, may be important for the development of quantum thermodynamics. we likewise note how it can also give rise to an original explanatory picture of the nature of physical reality on the surface of planet earth, in which human culture emerges as a reinforcing continuation of life. ","165":"the purpose of the study presented herein is to develop a machine learning algorithm based on natural language processing that automatically detects whether a patient has a cardiac failure or a healthy condition by using physician notes in research data warehouse at chu sainte justine hospital. first, a word representation learning technique was employed by using bag-of-word (bow), term frequency inverse document frequency (tfidf), and neural word embeddings (word2vec). each representation technique aims to retain the words semantic and syntactic analysis in critical care data. it helps to enrich the mutual information for the word representation and leads to an advantage for further appropriate analysis steps. second, a machine learning classifier was used to detect the patients condition for either cardiac failure or stable patient through the created word representation vector space from the previous step. this machine learning approach is based on a supervised binary classification algorithm, including logistic regression (lr), gaussian naive-bayes (gaussiannb), and multilayer perceptron neural network (mlpnn). technically, it mainly optimizes the empirical loss during training the classifiers. as a result, an automatic learning algorithm would be accomplished to draw a high classification performance, including accuracy (acc), precision (pre), recall (rec), and f1 score (f1). the results show that the combination of tfidf and mlpnn always outperformed other combinations with all overall performance. in the case without any feature selection, the proposed framework yielded an overall classification performance with acc, pre, rec, and f1 of 84% and 82%, 85%, and 83%, respectively. significantly, if the feature selection was well applied, the overall performance would finally improve up to 4% for each evaluation. ","166":"in today's era of digital misinformation, we are increasingly faced with new threats posed by video falsification techniques. such falsifications range from cheapfakes (e.g., lookalikes or audio dubbing) to deepfakes (e.g., sophisticated ai media synthesis methods), which are becoming perceptually indistinguishable from real videos. to tackle this challenge, we propose a multi-modal semantic forensic approach to discover clues that go beyond detecting discrepancies in visual quality, thereby handling both simpler cheapfakes and visually persuasive deepfakes. in this work, our goal is to verify that the purported person seen in the video is indeed themselves by detecting anomalous correspondences between their facial movements and the words they are saying. we leverage the idea of attribution to learn person-specific biometric patterns that distinguish a given speaker from others. we use interpretable action units (aus) to capture a persons' face and head movement as opposed to deep cnn visual features, and we are the first to use word-conditioned facial motion analysis. unlike existing person-specific approaches, our method is also effective against attacks that focus on lip manipulation. we further demonstrate our method's effectiveness on a range of fakes not seen in training including those without video manipulation, that were not addressed in prior work. ","167":"many real-world problems require the combined application of multiple reasoning abilities employing suitable abstractions, commonsense knowledge, and creative synthesis of problem-solving strategies. to help advance ai systems towards such capabilities, we propose a new reasoning challenge, namely fermi problems (fps), which are questions whose answers can only be approximately estimated because their precise computation is either impractical or impossible. for example, \"how much would the sea level rise if all ice in the world melted?\" fps are commonly used in quizzes and interviews to bring out and evaluate the creative reasoning abilities of humans. to do the same for ai systems, we present two datasets: 1) a collection of 1k real-world fps sourced from quizzes and olympiads; and 2) a bank of 10k synthetic fps of intermediate complexity to serve as a sandbox for the harder real-world challenge. in addition to question answer pairs, the datasets contain detailed solutions in the form of an executable program and supporting facts, helping in supervision and evaluation of intermediate steps. we demonstrate that even extensively fine-tuned large scale language models perform poorly on these datasets, on average making estimates that are off by two orders of magnitude. our contribution is thus the crystallization of several unsolved ai problems into a single, new challenge that we hope will spur further advances in building systems that can reason. ","168":"db-bert is a database tuning tool that exploits information gained via natural language analysis of manuals and other relevant text documents. it uses text to identify database system parameters to tune as well as recommended parameter values. db-bert applies large, pre-trained language models (specifically, the bert model) for text analysis. during an initial training phase, it fine-tunes model weights in order to translate natural language hints into recommended settings. at run time, db-bert learns to aggregate, adapt, and prioritize hints to achieve optimal performance for a specific database system and benchmark. both phases are iterative and use reinforcement learning to guide the selection of tuning settings to evaluate (penalizing settings that the database system rejects while rewarding settings that improve performance). in our experiments, we leverage hundreds of text documents about database tuning as input for db-bert. we compare db-bert against various baselines, considering different benchmarks (tpc-c and tpc-h), metrics (throughput and run time), as well as database systems (postgres and mysql). in all cases, db-bert finds the best parameter settings among all compared methods. the code of db-bert is available online at https:\/\/itrummer.github.io\/dbbert\/. ","169":"we introduce the probabilistic worldbuilding model (pwm), a new fully-symbolic bayesian model of semantic parsing and reasoning, as a first step in a research program toward more domain- and task-general nlu and ai. humans create internal mental models of their observations which greatly aid in their ability to understand and reason about a large variety of problems. in pwm, the meanings of sentences, acquired facts about the world, and intermediate steps in reasoning are all expressed in a human-readable formal language, with the design goal of interpretability. pwm is bayesian, designed specifically to be able to generalize to new domains and new tasks. we derive and implement an inference algorithm that reads sentences by parsing and abducing updates to its latent world model that capture the semantics of those sentences, and evaluate it on two out-of-domain question-answering datasets: (1) proofwriter and (2) a new dataset we call fictionalgeoqa, designed to be more representative of real language but still simple enough to focus on evaluating reasoning ability, while being robust against heuristics. our method outperforms baselines on both, thereby demonstrating its value as a proof-of-concept. ","170":"beyond their primary diagnostic purpose, radiology reports have been an invaluable source of information in medical research. given a corpus of radiology reports, researchers are often interested in identifying a subset of reports describing a particular medical finding. because the space of medical findings in radiology reports is vast and potentially unlimited, recent studies proposed mapping free-text statements in radiology reports to semi-structured strings of terms taken from a limited vocabulary. this paper aims to present an approach for the automatic generation of semi-structured representations of radiology reports. the approach consists of matching sentences from radiology reports to manually created semi-structured representations, followed by learning a sequence-to-sequence neural model that maps matched sentences to their semi-structured representations. we evaluated the proposed approach on the openi corpus of manually annotated chest x-ray radiology reports. the results indicate that the proposed approach is superior to several baselines, both in terms of (1) quantitative measures such as bleu, rouge, and meteor and (2) qualitative judgment of a radiologist. the results also demonstrate that the trained model produces reasonable semi-structured representations on an out-of-sample corpus of chest x-ray radiology reports from a different medical provider. ","171":"mixture of experts layers (moes) enable efficient scaling of language models through conditional computation. this paper presents a detailed empirical study of how autoregressive moe language models scale in comparison with dense models in a wide range of settings: in- and out-of-domain language modeling, zero- and few-shot priming, and full fine-tuning. with the exception of fine-tuning, we find moes to be substantially more compute efficient. at more modest training budgets, moes can match the performance of dense models using $\\sim$4 times less compute. this gap narrows at scale, but our largest moe model (1.1t parameters) consistently outperforms a compute-equivalent dense model (6.7b parameters). overall, this performance gap varies greatly across tasks and domains, suggesting that moe and dense models generalize differently in ways that are worthy of future study. we make our code and models publicly available for research use. ","172":"large-scale autoregressive language models such as gpt-3 are few-shot learners that can perform a wide range of language tasks without fine-tuning. while these models are known to be able to jointly represent many different languages, their training data is dominated by english, potentially limiting their cross-lingual generalization. in this work, we train multilingual autoregressive language models on a balanced corpus covering a diverse set of languages, and study their few- and zero-shot learning capabilities in a wide range of tasks. our largest model with 7.5 billion parameters sets new state of the art in few-shot learning in more than 20 representative languages, outperforming gpt-3 of comparable size in multilingual commonsense reasoning (with +7.4% absolute accuracy improvement in 0-shot settings and +9.4% in 4-shot settings) and natural language inference (+5.4% in each of 0-shot and 4-shot settings). on the flores-101 machine translation benchmark, our model outperforms gpt-3 on 171 out of 182 translation directions with 32 training examples, while surpassing the official supervised baseline in 45 directions. we present a detailed analysis of where the model succeeds and fails, showing in particular that it enables cross-lingual in-context learning on some tasks, while there is still room for improvement on surface form robustness and adaptation to tasks that do not have a natural cloze form. finally, we evaluate our models in social value tasks such as hate speech detection in five languages and find it has limitations similar to comparable sized gpt-3 models. ","173":"stance detection is an important task, supporting many downstream tasks such as discourse parsing and modeling the propagation of fake news, rumors, and science denial. in this paper, we propose a novel framework for stance detection. our framework is unsupervised and domain-independent. given a claim and a multi-participant discussion - we construct the interaction network from which we derive topological embedding for each speaker. these speaker embedding enjoy the following property: speakers with the same stance tend to be represented by similar vectors, while antipodal vectors represent speakers with opposing stances. these embedding are then used to divide the speakers into stance-partitions. we evaluate our method on three different datasets from different platforms. our method outperforms or is comparable with supervised models while providing confidence levels for its output. furthermore, we demonstrate how the structural embedding relate to the valence expressed by the speakers. finally, we discuss some limitations inherent to the framework. ","174":"in the present paper we use a range of modeling techniques to investigate whether an abstract phone could emerge from exposure to speech sounds. in effect, the study represents an attempt for operationalize a theoretical device of usage-based linguistics of emergence of an abstraction from language use. our quest focuses on the simplest of such hypothesized abstractions. we test two opposing principles regarding the development of language knowledge in linguistically untrained language users: memory-based learning (mbl) and error-correction learning (ecl). a process of generalization underlies the abstractions linguists operate with, and we probed whether mbl and ecl could give rise to a type of language knowledge that resembles linguistic abstractions. each model was presented with a significant amount of pre-processed speech produced by one speaker. we assessed the consistency or stability of what these simple models have learned and their ability to give rise to abstract categories. both types of models fare differently with regard to these tests. we show that ecl models can learn abstractions and that at least part of the phone inventory and grouping into traditional types can be reliably identified from the input. ","175":"voxceleb datasets are widely used in speaker recognition studies. our work serves two purposes. first, we provide speaker age labels and (an alternative) annotation of speaker gender. second, we demonstrate the use of this metadata by constructing age and gender recognition models with different features and classifiers. we query different celebrity databases and apply consensus rules to derive age and gender labels. we also compare the original voxceleb gender labels with our labels to identify records that might be mislabeled in the original voxceleb data. on modeling side, we design a comprehensive study of multiple features and models for recognizing gender and age. our best system, using i-vector features, achieved an f1-score of 0.9829 for gender recognition task using logistic regression, and the lowest mean absolute error (mae) in age regression, 9.443 years, is obtained with ridge regression. this indicates challenge in age estimation from in-the-wild style speech data. ","176":"large pretrained masked language models have become state-of-the-art solutions for many nlp problems. while studies have shown that monolingual models produce better results than multilingual models, the training datasets must be sufficiently large. we trained a trilingual litlat bert-like model for lithuanian, latvian, and english, and a monolingual est-roberta model for estonian. we evaluate their performance on four downstream tasks: named entity recognition, dependency parsing, part-of-speech tagging, and word analogy. to analyze the importance of focusing on a single language and the importance of a large training set, we compare created models with existing monolingual and multilingual bert models for estonian, latvian, and lithuanian. the results show that the newly created litlat bert and est-roberta models improve the results of existing models on all tested tasks in most situations. ","177":"in almost all text generation applications, word sequences are constructed in a left-to-right (l2r) or right-to-left (r2l) manner, as natural language sentences are written either l2r or r2l. however, we find that the natural language written order is not essential for text generation. in this paper, we propose spiral language modeling (slm), a general approach that enables one to construct natural language sentences beyond the l2r and r2l order. slm allows one to form natural language text by starting from an arbitrary token inside the result text and expanding the rest tokens around the selected ones. it makes the decoding order a new optimization objective besides the language model perplexity, which further improves the diversity and quality of the generated text. furthermore, slm makes it possible to manipulate the text construction process by selecting a proper starting token. slm also introduces generation orderings as additional regularization to improve model robustness in low-resource scenarios. experiments on 8 widely studied neural machine translation (nmt) tasks show that slm is constantly effective with up to 4.7 bleu increase comparing to the conventional l2r decoding approach. ","178":"what are the units of text that we want to model? from bytes to multi-word expressions, text can be analyzed and generated at many granularities. until recently, most natural language processing (nlp) models operated over words, treating those as discrete and atomic tokens, but starting with byte-pair encoding (bpe), subword-based approaches have become dominant in many areas, enabling small vocabularies while still allowing for fast inference. is the end of the road character-level model or byte-level processing? in this survey, we connect several lines of work from the pre-neural and neural era, by showing how hybrid approaches of words and characters as well as subword-based approaches based on learned segmentation have been proposed and evaluated. we conclude that there is and likely will never be a silver bullet singular solution for all applications and that thinking seriously about tokenization remains important for many applications. ","179":"quantum language models (qlms) in which words are modelled as quantum superposition of sememes have demonstrated a high level of model transparency and good post-hoc interpretability. nevertheless, in the current literature word sequences are basically modelled as a classical mixture of word states, which cannot fully exploit the potential of a quantum probabilistic description. a full quantum model is yet to be developed to explicitly capture the non-classical correlations within the word sequences. we propose a neural network model with a novel entanglement embedding (ee) module, whose function is to transform the word sequences into entangled pure states of many-body quantum systems. strong quantum entanglement, which is the central concept of quantum information and an indication of parallelized correlations among the words, is observed within the word sequences. numerical experiments show that the proposed qlm with ee (qlm-ee) achieves superior performance compared with the classical deep neural network models and other qlms on question answering (qa) datasets. in addition, the post-hoc interpretability of the model can be improved by quantizing the degree of entanglement among the words. ","180":"recent works have shown explainability and robustness are two crucial ingredients of trustworthy and reliable text classification. however, previous works usually address one of two aspects: i) how to extract accurate rationales for explainability while being beneficial to prediction; ii) how to make the predictive model robust to different types of adversarial attacks. intuitively, a model that produces helpful explanations should be more robust against adversarial attacks, because we cannot trust the model that outputs explanations but changes its prediction under small perturbations. to this end, we propose a joint classification and rationale extraction model named at-bmc. it includes two key mechanisms: mixed adversarial training (at) is designed to use various perturbations in discrete and embedding space to improve the model's robustness, and boundary match constraint (bmc) helps to locate rationales more precisely with the guidance of boundary information. performances on benchmark datasets demonstrate that the proposed at-bmc outperforms baselines on both classification and rationale extraction by a large margin. robustness analysis shows that the proposed at-bmc decreases the attack success rate effectively by up to 69%. the empirical results indicate that there are connections between robust models and better explanations. ","181":"recent neural sequence-to-sequence models with a copy mechanism have achieved remarkable progress in various text generation tasks. these models addressed out-of-vocabulary problems and facilitated the generation of rare words. however, the identification of the word which needs to be copied is difficult, as observed by prior copy models, which suffer from incorrect generation and lacking abstractness. in this paper, we propose a novel supervised approach of a copy network that helps the model decide which words need to be copied and which need to be generated. specifically, we re-define the objective function, which leverages source sequences and target vocabularies as guidance for copying. the experimental results on data-to-text generation and abstractive summarization tasks verify that our approach enhances the copying quality and improves the degree of abstractness. ","182":"false claims that have been previously fact-checked can still spread on social media. to mitigate their continual spread, detecting previously fact-checked claims is indispensable. given a claim, existing works focus on providing evidence for detection by reranking candidate fact-checking articles (fc-articles) retrieved by bm25. however, these performances may be limited because they ignore the following characteristics of fc-articles: (1) claims are often quoted to describe the checked events, providing lexical information besides semantics; (2) sentence templates to introduce or debunk claims are common across articles, providing pattern information. models that ignore the two aspects only leverage semantic relevance and may be misled by sentences that describe similar but irrelevant events. in this paper, we propose a novel reranker, mtm (memory-enhanced transformers for matching) to rank fc-articles using key sentences selected with event (lexical and semantic) and pattern information. for event information, we propose a rouge-guided transformer which is finetuned with regression of rouge. for pattern information, we generate pattern vectors for matching with sentences. by fusing event and pattern information, we select key sentences to represent an article and then predict if the article fact-checks the given claim using the claim, key sentences, and patterns. experiments on two real-world datasets show that mtm outperforms existing methods. human evaluation proves that mtm can capture key sentences for explanations. the code and the dataset are at https:\/\/github.com\/ictmcg\/mtm. ","183":"code-switching (cs) is a common linguistic phenomenon in multilingual communities that consists of switching between languages while speaking. this paper presents our investigations on end-to-end speech recognition for mandarin-english cs speech. we analyse different cs specific issues such as the properties mismatches between languages in a cs language pair, the unpredictable nature of switching points, and the data scarcity problem. we exploit and improve the state-of-the-art end-to-end system by merging nonlinguistic symbols, by integrating language identification using hierarchical softmax, by modeling sub-word units, by artificially lowering the speaking rate, and by augmenting data using speed perturbed technique and several monolingual datasets to improve the final performance not only on cs speech but also on monolingual benchmarks in order to make the system more applicable on real life settings. finally, we explore the effect of different language model integration methods on the performance of the proposed model. our experimental results reveal that all the proposed techniques improve the recognition performance. the best combined system improves the baseline system by up to 35% relatively in terms of mixed error rate and delivers acceptable performance on monolingual benchmarks. ","184":"this work aims to evaluate the ability that both probabilistic and state-of-the-art vector space modeling (vsm) methods provide to well known machine learning algorithms to identify social network documents to be classified as aggressive, gender biased or communally charged. to this end, an exploratory stage was performed first in order to find relevant settings to test, i.e. by using training and development samples, we trained multiple algorithms using multiple vector space modeling and probabilistic methods and discarded the less informative configurations. these systems were submitted to the competition of the comma@icon'21 workshop on multilingual gender biased and communal language identification. ","185":"bug reports are common artefacts in software development. they serve as the main channel for users to communicate to developers information about the issues that they encounter when using released versions of software programs. in the descriptions of issues, however, a user may, intentionally or not, expose a vulnerability. in a typical maintenance scenario, such security-relevant bug reports are prioritised by the development team when preparing corrective patches. nevertheless, when security relevance is not immediately expressed (e.g., via a tag) or rapidly identified by triaging teams, the open security-relevant bug report can become a critical leak of sensitive information that attackers can leverage to perform zero-day attacks. to support practitioners in triaging bug reports, the research community has proposed a number of approaches for the detection of security-relevant bug reports. in recent years, approaches in this respect based on machine learning have been reported with promising performance. our work focuses on such approaches, and revisits their building blocks to provide a comprehensive view on the current achievements. to that end, we built a large experimental dataset and performed extensive experiments with variations in feature sets and learning algorithms. eventually, our study highlights different approach configurations that yield best performing classifiers. ","186":"we investigate densely connected convolutional networks (densenets) and their extension with domain adversarial training for noise robust speech recognition. densenets are very deep, compact convolutional neural networks which have demonstrated incredible improvements over the state-of-the-art results in computer vision. our experimental results reveal that densenets are more robust against noise than other neural network based models such as deep feed forward neural networks and convolutional neural networks. moreover, domain adversarial learning can further improve the robustness of densenets against both, known and unknown noise conditions. ","187":"so far, named entity recognition (ner) has been involved with three major types, including flat, overlapped (aka. nested), and discontinuous ner, which have mostly been studied individually. recently, a growing interest has been built for unified ner, tackling the above three jobs concurrently with one single model. current best-performing methods mainly include span-based and sequence-to-sequence models, where unfortunately the former merely focus on boundary identification and the latter may suffer from exposure bias. in this work, we present a novel alternative by modeling the unified ner as word-word relation classification, namely w^2ner. the architecture resolves the kernel bottleneck of unified ner by effectively modeling the neighboring relations between entity words with next-neighboring-word (nnw) and tail-head-word-* (thw-*) relations. based on the w^2ner scheme we develop a neural framework, in which the unified ner is modeled as a 2d grid of word pairs. we then propose multi-granularity 2d convolutions for better refining the grid representations. finally, a co-predictor is used to sufficiently reason the word-word relations. we perform extensive experiments on 14 widely-used benchmark datasets for flat, overlapped, and discontinuous ner (8 english and 6 chinese datasets), where our model beats all the current top-performing baselines, pushing the state-of-the-art performances of unified ner. ","188":"the mental disorder of online users is determined using social media posts. the major challenge in this domain is to avail the ethical clearance for using the user generated text on social media platforms. academic re searchers identified the problem of insufficient and unlabeled data for mental health classification. to handle this issue, we have studied the effect of data augmentation techniques on domain specific user generated text for mental health classification. among the existing well established data augmentation techniques, we have identified easy data augmentation (eda), conditional bert, and back translation (bt) as the potential techniques for generating additional text to improve the performance of classifiers. further, three different classifiers random forest (rf), support vector machine (svm) and logistic regression (lr) are employed for analyzing the impact of data augmentation on two publicly available social media datasets. the experiments mental results show significant improvements in classifiers performance when trained on the augmented data. ","189":"unplanned intensive care unit (icu) readmission rate is an important metric for evaluating the quality of hospital care. efficient and accurate prediction of icu readmission risk can not only help prevent patients from inappropriate discharge and potential dangers, but also reduce associated costs of healthcare. in this paper, we propose a new method that uses medical text of electronic health records (ehrs) for prediction, which provides an alternative perspective to previous studies that heavily depend on numerical and time-series features of patients. more specifically, we extract discharge summaries of patients from their ehrs, and represent them with multiview graphs enhanced by an external knowledge graph. graph convolutional networks are then used for representation learning. experimental results prove the effectiveness of our method, yielding state-of-the-art performance for this task. ","190":"expert-layman text style transfer technologies have the potential to improve communication between members of scientific communities and the general public. high-quality information produced by experts is often filled with difficult jargon laypeople struggle to understand. this is a particularly notable issue in the medical domain, where layman are often confused by medical text online. at present, two bottlenecks interfere with the goal of building high-quality medical expert-layman style transfer systems: a dearth of pretrained medical-domain language models spanning both expert and layman terminologies and a lack of parallel corpora for training the transfer task itself. to mitigate the first issue, we propose a novel language model (lm) pretraining task, knowledge base assimilation, to synthesize pretraining data from the edges of a graph of expert- and layman-style medical terminology terms into an lm during self-supervised learning. to mitigate the second issue, we build a large-scale parallel corpus in the medical expert-layman domain using a margin-based criterion. our experiments show that transformer-based models pretrained on knowledge base assimilation and other well-established pretraining tasks fine-tuning on our new parallel corpus leads to considerable improvement against expert-layman transfer benchmarks, gaining an average relative improvement of our human evaluation, the overall success rate (osr), by 106%. we release our code and parallel corpus for future research. ","191":"this paper studies continual learning (cl) for sentiment classification (sc). in this setting, the cl system learns a sequence of sc tasks incrementally in a neural network, where each task builds a classifier to classify the sentiment of reviews of a particular product category or domain. two natural questions are: can the system transfer the knowledge learned in the past from the previous tasks to the new task to help it learn a better model for the new task? and, can old models for previous tasks be improved in the process as well? this paper proposes a novel technique called kan to achieve these objectives. kan can markedly improve the sc accuracy of both the new task and the old tasks via forward and backward knowledge transfer. the effectiveness of kan is demonstrated through extensive experiments. ","192":"in the current era of the internet, where social media platforms are easily accessible for everyone, people often have to deal with threats, identity attacks, hate, and bullying due to their association with a cast, creed, gender, religion, or even acceptance or rejection of a notion. existing works in hate speech detection primarily focus on individual comment classification as a sequence labeling task and often fail to consider the context of the conversation. the context of a conversation often plays a substantial role when determining the author's intent and sentiment behind the tweet. this paper describes the system proposed by team midas-iiitd for hasoc 2021 subtask 2, one of the first shared tasks focusing on detecting hate speech from hindi-english code-mixed conversations on twitter. we approach this problem using neural networks, leveraging the transformer's cross-lingual embeddings and further finetuning them for low-resource hate-speech classification in transliterated hindi text. our best performing system, a hard voting ensemble of indic-bert, xlm-roberta, and multilingual bert, achieved a macro f1 score of 0.7253, placing us first on the overall leaderboard standings. ","193":"with the rapid development of information technology, online platforms (e.g., news portals and social media) generate enormous web information every moment. therefore, it is crucial to extract structured representations of events from social streams. generally, existing event extraction research utilizes pattern matching, machine learning, or deep learning methods to perform event extraction tasks. however, the performance of chinese event extraction is not as good as english due to the unique characteristics of the chinese language. in this paper, we propose an integrated framework to perform chinese event extraction. the proposed approach is a multiple channel input neural framework that integrates semantic features and syntactic features. the semantic features are captured by bert architecture. the part of speech (pos) features and dependency parsing (dp) features are captured by profiling embeddings and graph convolutional network (gcn), respectively. we also evaluate our model on a real-world dataset. experimental results show that the proposed method outperforms the benchmark approaches significantly. ","194":"radiology reports play a critical role in communicating medical findings to physicians. in each report, the impression section summarizes essential radiology findings. in clinical practice, writing impression is highly demanded yet time-consuming and prone to errors for radiologists. therefore, automatic impression generation has emerged as an attractive research direction to facilitate such clinical practice. existing studies mainly focused on introducing salient word information to the general text summarization framework to guide the selection of the key content in radiology findings. however, for this task, a model needs not only capture the important words in findings but also accurately describe their relations so as to generate high-quality impressions. in this paper, we propose a novel method for automatic impression generation, where a word graph is constructed from the findings to record the critical words and their relations, then a word graph guided summarization model (wgsum) is designed to generate impressions with the help of the word graph. experimental results on two datasets, openi and mimic-cxr, confirm the validity and effectiveness of our proposed approach, where the state-of-the-art results are achieved on both datasets. further experiments are also conducted to analyze the impact of different graph designs to the performance of our method. ","195":"in order to address the increasing demands of real-world applications, the research for knowledge-intensive nlp (ki-nlp) should advance by capturing the challenges of a truly open-domain environment: web scale knowledge, lack of structure, inconsistent quality, and noise. to this end, we propose a new setup for evaluating existing ki-nlp tasks in which we generalize the background corpus to a universal web snapshot. we repurpose kilt, a standard ki-nlp benchmark initially developed for wikipedia, and ask systems to use a subset of ccnet - the sphere corpus - as a knowledge source. in contrast to wikipedia, sphere is orders of magnitude larger and better reflects the full diversity of knowledge on the internet. we find that despite potential gaps of coverage, challenges of scale, lack of structure and lower quality, retrieval from sphere enables a state-of-the-art retrieve-and-read system to match and even outperform wikipedia-based models on several kilt tasks - even if we aggressively filter content that looks like wikipedia. we also observe that while a single dense passage index over wikipedia can outperform a sparse bm25 version, on sphere this is not yet possible. to facilitate further research into this area, and minimise the community's reliance on proprietary black box search engines, we will share our indices, evaluation metrics and infrastructure. ","196":"this paper presents our work on the situated interactive multimodal conversations 2.0 challenge held at dialog state tracking challenge 10. simmc 2.0 includes 4 subtasks, and we introduce our multimodal approaches for the subtask \\#1, \\#2 and the generation of subtask \\#4. simmc 2.0 dataset is a multimodal dataset containing image and text information, which is more challenging than the problem of only text-based conversations because it must be solved by understanding the relationship between image and text. therefore, since there is a limit to solving only text models such as bert or gpt2, we propose a multimodal model combining image and text. we first pretrain the multimodal model to understand the relationship between image and text, then finetune our model for each task. we achieve the 3rd best performance in subtask \\#1, \\#2 and a runner-up in the generation of subtask \\#4. the source code is available at https:\/\/github.com\/rungjoo\/simmc2.0. ","197":"transformer based architectures have shown notable results on many down streaming tasks including question answering. the availability of data, on the other hand, impedes obtaining legitimate performance for low-resource languages. in this paper, we investigate the applicability of pre-trained multilingual models to improve the performance of question answering in low-resource languages. we tested four combinations of language and task adapters using multilingual transformer architectures on seven languages similar to mlqa dataset. additionally, we have also proposed zero-shot transfer learning of low-resource question answering using language and task adapters. we observed that stacking the language and the task adapters improves the multilingual transformer models' performance significantly for low-resource languages. ","198":"developing natural language processing resources for a low resource language is a challenging but essential task. in this paper, we present a morphological analyzer for gujarati. we have used a bi-directional lstm based approach to perform morpheme boundary detection and grammatical feature tagging. we have created a data set of gujarati words with lemma and grammatical features. the bi-lstm based model of morph analyzer discussed in the paper handles the language morphology effectively without the knowledge of any hand-crafted suffix rules. to the best of our knowledge, this is the first dataset and morph analyzer model for the gujarati language which performs both grammatical feature tagging and morpheme boundary detection tasks. ","199":"deep contextual language models (lms) like elmo, bert, and their successors dominate the landscape of natural language processing due to their ability to scale across multiple tasks rapidly by pre-training a single model, followed by task-specific fine-tuning. furthermore, multilingual versions of such models like xlm-r and mbert have given promising results in zero-shot cross-lingual transfer, potentially enabling nlp applications in many under-served and under-resourced languages. due to this initial success, pre-trained models are being used as `universal language models' as the starting point across diverse tasks, domains, and languages. this work explores the notion of `universality' by identifying seven dimensions across which a universal model should be able to scale, that is, perform equally well or reasonably well, to be useful across diverse settings. we outline the current theoretical and empirical results that support model performance across these dimensions, along with extensions that may help address some of their current limitations. through this survey, we lay the foundation for understanding the capabilities and limitations of massive contextual language models and help discern research gaps and directions for future work to make these lms inclusive and fair to diverse applications, users, and linguistic phenomena. ","200":"cross-lingual speech adaptation aims to solve the problem of leveraging multiple rich-resource languages to build models for a low-resource target language. since the low-resource language has limited training data, speech recognition models can easily overfit. in this paper, we propose to use adapters to investigate the performance of multiple adapters for parameter-efficient cross-lingual speech adaptation. based on our previous metaadapter that implicitly leverages adapters, we propose a novel algorithms called simadapter for explicitly learning knowledge from adapters. our algorithm leverages adapters which can be easily integrated into the transformer structure.metaadapter leverages meta-learning to transfer the general knowledge from training data to the test language. simadapter aims to learn the similarities between the source and target languages during fine-tuning using the adapters. we conduct extensive experiments on five-low-resource languages in common voice dataset. results demonstrate that our metaadapter and simadapter methods can reduce wer by 2.98% and 2.55% with only 2.5% and 15.5% of trainable parameters compared to the strong full-model fine-tuning baseline. moreover, we also show that these two novel algorithms can be integrated for better performance with up to 3.55% relative wer reduction. ","201":"we present findings from a first in-depth post-editing effort estimation study in the english-hindi direction along multiple effort indicators. we conduct a controlled experiment involving professional translators, who complete assigned tasks alternately, in a translation from scratch and a post-edit condition. we find that post-editing reduces translation time (by 63%), utilizes fewer keystrokes (by 59%), and decreases the number of pauses (by 63%) when compared to translating from scratch. we further verify the quality of translations thus produced via a human evaluation task in which we do not detect any discernible quality differences. ","202":"language-enabled ai systems can answer complex, multi-hop questions to high accuracy, but supporting answers with evidence is a more challenging task which is important for the transparency and trustworthiness to users. prior work in this area typically makes a trade-off between efficiency and accuracy; state-of-the-art deep neural network systems are too cumbersome to be useful in large-scale applications, while the fastest systems lack reliability. in this work, we integrate fast syntactic methods with powerful semantic methods for multi-hop explanation generation based on declarative facts. our best system, which learns a lightweight operation to simulate multi-hop reasoning over pieces of evidence and fine-tunes language models to re-rank generated explanation chains, outperforms a purely syntactic baseline from prior work by up to 7% in gold explanation retrieval rate. ","203":"the core of self-supervised learning for pre-training language models includes pre-training task design as well as appropriate data augmentation. most data augmentations in language model pre-training are context-independent. a seminal contextualized augmentation was recently proposed in electra and achieved state-of-the-art performance by introducing an auxiliary generation network (generator) to produce contextualized data augmentation for the training of a main discrimination network (discriminator). this design, however, introduces extra computation cost of the generator and a need to adjust the relative capability between the generator and the discriminator. in this paper, we propose a self-augmentation strategy (sas) where a single network is utilized for both regular pre-training and contextualized data augmentation for the training in later epochs. essentially, this strategy eliminates a separate generator and uses the single network to jointly conduct two pre-training tasks with mlm (masked language modeling) and rtd (replaced token detection) heads. it avoids the challenge to search for an appropriate size of the generator, which is critical to the performance as evidenced in electra and its subsequent variant models. in addition, sas is a general strategy that can be seamlessly combined with many new techniques emerging recently or in the future, such as the disentangled attention mechanism from deberta. our experiments show that sas is able to outperform electra and other state-of-the-art models in the glue tasks with similar or less computation cost. ","204":"current work on automatic coreference resolution has focused on the ontonotes benchmark dataset, due to both its size and consistency. however many aspects of the ontonotes annotation scheme are not well understood by nlp practitioners, including the treatment of generic nps, noun modifiers, indefinite anaphora, predication and more. these often lead to counterintuitive claims, results and system behaviors. this opinion piece aims to highlight some of the problems with the ontonotes rendition of coreference, and to propose a way forward relying on three principles: 1. a focus on semantics, not morphosyntax; 2. cross-linguistic generalizability; and 3. a separation of identity and scope, which can resolve old problems involving temporal and modal domain consistency. ","205":"in attempts to \"explain\" predictions of machine learning models, researchers have proposed hundreds of techniques for attributing predictions to features that are deemed important. while these attributions are often claimed to hold the potential to improve human \"understanding\" of the models, surprisingly little work explicitly evaluates progress towards this aspiration. in this paper, we conduct a crowdsourcing study, where participants interact with deception detection models that have been trained to distinguish between genuine and fake hotel reviews. they are challenged both to simulate the model on fresh reviews, and to edit reviews with the goal of lowering the probability of the originally predicted class. successful manipulations would lead to an adversarial example. during the training (but not the test) phase, input spans are highlighted to communicate salience. through our evaluation, we observe that for a linear bag-of-words model, participants with access to the feature coefficients during training are able to cause a larger reduction in model confidence in the testing phase when compared to the no-explanation control. for the bert-based classifier, popular local explanations do not improve their ability to reduce the model confidence over the no-explanation case. remarkably, when the explanation for the bert model is given by the (global) attributions of a linear model trained to imitate the bert model, people can effectively manipulate the model. ","206":"pre-trained language models such as bert have achieved great success in a broad range of natural language processing tasks. however, bert cannot well support e-commerce related tasks due to the lack of two levels of domain knowledge, i.e., phrase-level and product-level. on one hand, many e-commerce tasks require an accurate understanding of domain phrases, whereas such fine-grained phrase-level knowledge is not explicitly modeled by bert's training objective. on the other hand, product-level knowledge like product associations can enhance the language modeling of e-commerce, but they are not factual knowledge thus using them indiscriminately may introduce noise. to tackle the problem, we propose a unified pre-training framework, namely, e-bert. specifically, to preserve phrase-level knowledge, we introduce adaptive hybrid masking, which allows the model to adaptively switch from learning preliminary word knowledge to learning complex phrases, based on the fitting progress of two modes. to utilize product-level knowledge, we introduce neighbor product reconstruction, which trains e-bert to predict a product's associated neighbors with a denoising cross attention layer. our investigation reveals promising results in four downstream tasks, i.e., review-based question answering, aspect extraction, aspect sentiment classification, and product classification. ","207":"recent years have witnessed impressive advances in challenging multi-hop qa tasks. however, these qa models may fail when faced with some disturbance in the input text and their interpretability for conducting multi-hop reasoning remains uncertain. previous adversarial attack works usually edit the whole question sentence, which has limited effect on testing the entity-based multi-hop inference ability. in this paper, we propose a multi-hop reasoning chain based adversarial attack method. we formulate the multi-hop reasoning chains starting from the query entity to the answer entity in the constructed graph, which allows us to align the question to each reasoning hop and thus attack any hop. we categorize the questions into different reasoning types and adversarially modify part of the question corresponding to the selected reasoning hop to generate the distracting sentence. we test our adversarial scheme on three qa models on hotpotqa dataset. the results demonstrate significant performance reduction on both answer and supporting facts prediction, verifying the effectiveness of our reasoning chain based attack method for multi-hop reasoning models and the vulnerability of them. our adversarial re-training further improves the performance and robustness of these models. ","208":"since the introduction of the original bert (i.e., base bert), researchers have developed various customized bert models with improved performance for specific domains and tasks by exploiting the benefits of transfer learning. due to the nature of mathematical texts, which often use domain specific vocabulary along with equations and math symbols, we posit that the development of a new bert model for mathematics would be useful for many mathematical downstream tasks. in this resource paper, we introduce our multi-institutional effort (i.e., two learning platforms and three academic institutions in the us) toward this need: mathbert, a model created by pre-training the base bert model on a large mathematical corpus ranging from pre-kindergarten (pre-k), to high-school, to college graduate level mathematical content. in addition, we select three general nlp tasks that are often used in mathematics education: prediction of knowledge component, auto-grading open-ended q&a, and knowledge tracing, to demonstrate the superiority of mathbert over base bert. our experiments show that mathbert outperforms prior best methods by 1.2-22% and base bert by 2-8% on these tasks. in addition, we build a mathematics specific vocabulary 'mathvocab' to train with mathbert. we discover that mathbert pre-trained with 'mathvocab' outperforms mathbert trained with the base bert vocabulary (i.e., 'origvocab'). mathbert is currently being adopted at the participated leaning platforms: stride, inc, a commercial educational resource provider, and assistments.org, a free online educational platform. we release mathbert for public usage at: https:\/\/github.com\/tbs17\/mathbert. ","209":"sparse lexical representation learning has demonstrated much progress in improving passage retrieval effectiveness in recent models such as deepimpact, unicoil, and splade. this paper describes a straightforward yet effective approach for sparsifying lexical representations for passage retrieval, building on splade by introducing a top-$k$ masking scheme to control sparsity and a self-learning method to coax masked representations to mimic unmasked representations. a basic implementation of our model is competitive with more sophisticated approaches and achieves a good balance between effectiveness and efficiency. the simplicity of our methods opens the door for future explorations in lexical representation learning for passage retrieval. ","210":"this paper presents and makes publicly available the nilc-metrix, a computational system comprising 200 metrics proposed in studies on discourse, psycholinguistics, cognitive and computational linguistics, to assess textual complexity in brazilian portuguese (bp). these metrics are relevant for descriptive analysis and the creation of computational models and can be used to extract information from various linguistic levels of written and spoken language. the metrics in nilc-metrix were developed during the last 13 years, starting in 2008 with coh-metrix-port, a tool developed within the scope of the porsimples project. coh-metrix-port adapted some metrics to bp from the coh-metrix tool that computes metrics related to cohesion and coherence of texts in english. after the end of porsimples in 2010, new metrics were added to the initial 48 metrics of coh-metrix-port. given the large number of metrics, we present them following an organisation similar to the metrics of coh-metrix v3.0 to facilitate comparisons made with metrics in portuguese and english. in this paper, we illustrate the potential of nilc-metrix by presenting three applications: (i) a descriptive analysis of the differences between children's film subtitles and texts written for elementary school i and ii (final years); (ii) a new predictor of textual complexity for the corpus of original and simplified texts of the porsimples project; (iii) a complexity prediction model for school grades, using transcripts of children's story narratives told by teenagers. for each application, we evaluate which groups of metrics are more discriminative, showing their contribution for each task. ","211":"this work studies the task of glossification, of which the aim is to em transcribe natural spoken language sentences for the deaf (hard-of-hearing) community to ordered sign language glosses. previous sequence-to-sequence language models trained with paired sentence-gloss data often fail to capture the rich connections between the two distinct languages, leading to unsatisfactory transcriptions. we observe that despite different grammars, glosses effectively simplify sentences for the ease of deaf communication, while sharing a large portion of vocabulary with sentences. this has motivated us to implement glossification by executing a collection of editing actions, e.g. word addition, deletion, and copying, called editing programs, on their natural spoken language counterparts. specifically, we design a new neural agent that learns to synthesize and execute editing programs, conditioned on sentence contexts and partial editing results. the agent is trained to imitate minimal editing programs, while exploring more widely the program space via policy gradients to optimize sequence-wise transcription quality. results show that our approach outperforms previous glossification models by a large margin. ","212":"suicidal ideation detection from social media is an evolving research with great challenges. many of the people who have the tendency to suicide share their thoughts and opinions through social media platforms. as part of many researches it is observed that the publicly available posts from social media contain valuable criteria to effectively detect individuals with suicidal thoughts. the most difficult part to prevent suicide is to detect and understand the complex risk factors and warning signs that may lead to suicide. this can be achieved by identifying the sudden changes in a user behavior automatically. natural language processing techniques can be used to collect behavioral and textual features from social media interactions and these features can be passed to a specially designed framework to detect anomalies in human interactions that are indicators of suicidal intentions. we can achieve fast detection of suicidal ideation using deep learning and\/or machine learning based classification approaches. for such a purpose, we can employ the combination of lstm and cnn models to detect such emotions from posts of the users. in order to improve the accuracy, some approaches like using more data for training, using attention model to improve the efficiency of existing models etc. could be done. this paper proposes a lstm-attention-cnn combined model to analyze social media submissions to detect any underlying suicidal intentions. during evaluations, the proposed model demonstrated an accuracy of 90.3 percent and an f1-score of 92.6 percent, which is greater than the baseline models. ","213":"current news datasets merely focus on text features on the news and rarely leverage the feature of images, excluding numerous essential features for news classification. in this paper, we propose a new dataset, n24news, which is generated from new york times with 24 categories and contains both text and image information in each news. we use a multitask multimodal method and the experimental results show multimodal news classification performs better than text-only news classification. depending on the length of the text, the classification accuracy can be increased by up to 8.11%. our research reveals the relationship between the performance of a multimodal classifier and its sub-classifiers, and also the possible improvements when applying multimodal in news classification. n24news is shown to have great potential to prompt the multimodal news studies. ","214":"cognates are present in multiple variants of the same text across different languages (e.g., \"hund\" in german and \"hound\" in english language mean \"dog\"). they pose a challenge to various natural language processing (nlp) applications such as machine translation, cross-lingual sense disambiguation, computational phylogenetics, and information retrieval. a possible solution to address this challenge is to identify cognates across language pairs. in this paper, we describe the creation of two cognate datasets for twelve indian languages, namely sanskrit, hindi, assamese, oriya, kannada, gujarati, tamil, telugu, punjabi, bengali, marathi, and malayalam. we digitize the cognate data from an indian language cognate dictionary and utilize linked indian language wordnets to generate cognate sets. additionally, we use the wordnet data to create a false friends' dataset for eleven language pairs. we also evaluate the efficacy of our dataset using previously available baseline cognate detection approaches. we also perform a manual evaluation with the help of lexicographers and release the curated gold-standard dataset with this paper. ","215":"chinese word segmentation and part-of-speech tagging are necessary tasks in terms of computational linguistics and application of natural language processing. many re-searchers still debate the demand for chinese word segmentation and part-of-speech tagging in the deep learning era. nevertheless, resolving ambiguities and detecting unknown words are challenging problems in this field. previous studies on joint chinese word segmentation and part-of-speech tagging mainly follow the character-based tagging model focusing on modeling n-gram features. unlike previous works, we propose a neural model named spansegtag for joint chinese word segmentation and part-of-speech tagging following the span labeling in which the probability of each n-gram being the word and the part-of-speech tag is the main problem. we use the biaffine operation over the left and right boundary representations of consecutive characters to model the n-grams. our experiments show that our bert-based model spansegtag achieved competitive performances on the ctb5, ctb6, and ud, or significant improvements on ctb7 and ctb9 benchmark datasets compared with the current state-of-the-art method using bert or zen encoders. ","216":"bipolar disorder is a mental health disorder that causes mood swings that range from depression to mania. diagnosis of bipolar disorder is usually done based on patient interviews, and reports obtained from the caregivers of the patients. subsequently, the diagnosis depends on the experience of the expert, and it is possible to have confusions of the disorder with other mental disorders. automated processes in the diagnosis of bipolar disorder can help providing quantitative indicators, and allow easier observations of the patients for longer periods. furthermore, the need for remote treatment and diagnosis became especially important during the covid-19 pandemic. in this thesis, we create a multimodal decision system based on recordings of the patient in acoustic, linguistic, and visual modalities. the system is trained on the bipolar disorder corpus. comprehensive analysis of unimodal and multimodal systems, as well as various fusion techniques are performed. besides processing entire patient sessions using unimodal features, a task-level investigation of the clips is studied. using acoustic, linguistic, and visual features in a multimodal fusion system, we achieved a 64.8% unweighted average recall score, which improves the state-of-the-art performance achieved on this dataset. ","217":"the field of natural language processing (nlp) has recently seen a large change towards using pre-trained language models for solving almost any task. despite showing great improvements in benchmark datasets for various tasks, these models often perform sub-optimal in non-standard domains like the clinical domain where a large gap between pre-training documents and target documents is observed. in this paper, we aim at closing this gap with domain-specific training of the language model and we investigate its effect on a diverse set of downstream tasks and settings. we introduce the pre-trained clin-x (clinical xlm-r) language models and show how clin-x outperforms other pre-trained transformer models by a large margin for ten clinical concept extraction tasks from two languages. in addition, we demonstrate how the transformer model can be further improved with our proposed task- and language-agnostic model architecture based on ensembles over random splits and cross-sentence context. our studies in low-resource and transfer settings reveal stable model performance despite a lack of annotated data with improvements of up to 47 f1 points when only 250 labeled sentences are available. our results highlight the importance of specialized language models as clin-x for concept extraction in non-standard domains, but also show that our task-agnostic model architecture is robust across the tested tasks and languages so that domain- or task-specific adaptations are not required. ","218":"reference texts such as encyclopedias and news articles can manifest biased language when objective reporting is substituted by subjective writing. existing methods to detect bias mostly rely on annotated data to train machine learning models. however, low annotator agreement and comparability is a substantial drawback in available media bias corpora. to evaluate data collection options, we collect and compare labels obtained from two popular crowdsourcing platforms. our results demonstrate the existing crowdsourcing approaches' lack of data quality, underlining the need for a trained expert framework to gather a more reliable dataset. by creating such a framework and gathering a first dataset, we are able to improve krippendorff's $\\alpha$ = 0.144 (crowdsourcing labels) to $\\alpha$ = 0.419 (expert labels). we conclude that detailed annotator training increases data quality, improving the performance of existing bias detection systems. we will continue to extend our dataset in the future. ","219":"in this work, we unify several existing decoding strategies for punctuation prediction in one framework and introduce a novel strategy which utilises multiple predictions at each word across different windows. we show that significant improvements can be achieved by optimising these strategies after training a model, only leading to a potential increase in inference time, with no requirement for retraining. we further use our decoding strategy framework for the first comparison of tagging and classification approaches for punctuation prediction in a real-time setting. our results show that a classification approach for punctuation prediction can be beneficial when little or no right-side context is available. ","220":"a key challenge of online news recommendation is to help users find articles they are interested in. traditional news recommendation methods usually use single news information, which is insufficient to encode news and user representation. recent research uses multiple channel news information, e.g., title, category, and body, to enhance news and user representation. however, these methods only use various attention mechanisms to fuse multi-view embeddings without considering deep digging higher-level information contained in the context. these methods encode news content on the word level and jointly train the attention parameters in the recommendation network, leading to more corpora being required to train the model. we propose an event extraction-based news recommendation (eenr) framework to overcome these shortcomings, utilizing event extraction to abstract higher-level information. eenr also uses a two-stage strategy to reduce parameters in subsequent parts of the recommendation network. we train the event extraction module by external corpora in the first stage and apply the trained model to the news recommendation dataset to predict event-level information, including event types, roles, and arguments, in the second stage. then we fuse multiple channel information, including event information, news title, and category, to encode news and users. extensive experiments on a real-world dataset show that our eenr method can effectively improve the performance of news recommendations. finally, we also explore the reasonability of utilizing higher abstract level information to substitute news body content. ","221":"we present a system for bottom-up cumulative learning of myriad concepts corresponding to meaningful character strings, and their part-related and prediction edges. the learning is self-supervised in that the concepts discovered are used as predictors as well as targets of prediction. we devise an objective for segmenting with the learned concepts, derived from comparing to a baseline prediction system, that promotes making and using larger concepts, which in turn allows for predicting larger spans of text, and we describe a simple technique to promote exploration, i.e. trying out newly generated concepts in the segmentation process. we motivate and explain a layering of the concepts, to help separate the (conditional) distributions learnt among concepts. the layering of the concepts roughly corresponds to a part-whole concept hierarchy. with rudimentary segmentation and learning algorithms, the system is promising in that it acquires many concepts (tens of thousands in our small-scale experiments), and it learns to segment text well: when fed with english text with spaces removed, starting at the character level, much of what is learned respects word or phrase boundaries, and over time the average number of \"bad\" splits within segmentations, i.e. splits inside words, decreases as larger concepts are discovered and the system learns when to use them during segmentation. we report on promising experiments when the input text is converted to binary and the system begins with only two concepts, \"0\" and \"1\". the system is transparent, in the sense that it is easy to tell what the concepts learned correspond to, and which ones are active in a segmentation, or how the system \"sees\" its input. we expect this framework to be extensible and we discuss the current limitations and a number of directions for enhancing the learning and inference capabilities. ","222":"natural language data exhibit tree-like hierarchical structures such as the hypernym-hyponym relations in wordnet. fasttext, as the state-of-the-art text classifier based on shallow neural network in euclidean space, may not model such hierarchies precisely with limited representation capacity. considering that hyperbolic space is naturally suitable for modeling tree-like hierarchical data, we propose a new model named hypertext for efficient text classification by endowing fasttext with hyperbolic geometry. empirically, we show that hypertext outperforms fasttext on a range of text classification tasks with much reduced parameters. ","223":"knowledge base completion is formulated as a binary classification problem in this work, where an xgboost binary classifier is trained for each relation using relevant links in knowledge graphs (kgs). the new method, named kgboost, adopts a modularized design and attempts to find hard negative samples so as to train a powerful classifier for missing link prediction. we conduct experiments on multiple benchmark datasets, and demonstrate that kgboost outperforms state-of-the-art methods across most datasets. furthermore, as compared with models trained by end-to-end optimization, kgboost works well under the low-dimensional setting so as to allow a smaller model size. ","224":"while many methods purport to explain predictions by highlighting salient features, what aims these explanations serve and how they ought to be evaluated often go unstated. in this work, we introduce a framework to quantify the value of explanations via the accuracy gains that they confer on a student model trained to simulate a teacher model. crucially, the explanations are available to the student during training, but are not available at test time. compared to prior proposals, our approach is less easily gamed, enabling principled, automatic, model-agnostic evaluation of attributions. using our framework, we compare numerous attribution methods for text classification and question answering, and observe quantitative differences that are consistent (to a moderate to high degree) across different student model architectures and learning strategies. ","225":"the widespread of offensive content online such as hate speech poses a growing societal problem. ai tools are necessary for supporting the moderation process at online platforms. for the evaluation of these identification tools, continuous experimentation with data sets in different languages are necessary. the hasoc track (hate speech and offensive content identification) is dedicated to develop benchmark data for this purpose. this paper presents the hasoc subtrack for english, hindi, and marathi. the data set was assembled from twitter. this subtrack has two sub-tasks. task a is a binary classification problem (hate and not offensive) offered for all three languages. task b is a fine-grained classification problem for three classes (hate) hate speech, offensive and profanity offered for english and hindi. overall, 652 runs were submitted by 65 teams. the performance of the best classification algorithms for task a are f1 measures 0.91, 0.78 and 0.83 for marathi, hindi and english, respectively. this overview presents the tasks and the data development as well as the detailed results. the systems submitted to the competition applied a variety of technologies. the best performing algorithms were mainly variants of transformer architectures. ","226":"ontology alignment is an important research problem applied to various fields such as data integration, data transfer, data preparation, etc. state-of-the-art (sota) ontology alignment systems typically use naive domain-dependent approaches with handcrafted rules or domain-specific architectures, making them unscalable and inefficient. in this work, we propose veealign, a deep learning based model that uses a novel dual-attention mechanism to compute the contextualized representation of a concept which, in turn, is used to discover alignments. by doing this, not only is our approach able to exploit both syntactic and semantic information encoded in ontologies, it is also, by design, flexible and scalable to different domains with minimal effort. we evaluate our model on four different datasets from different domains and languages, and establish its superiority through these results as well as detailed ablation studies. the code and datasets used are available at https:\/\/github.com\/remorax\/veealign. ","227":"we introduce a family of deep-learning architectures for inter-sentence relation extraction, i.e., relations where the participants are not necessarily in the same sentence. we apply these architectures to an important use case in the biomedical domain: assigning biological context to biochemical events. in this work, biological context is defined as the type of biological system within which the biochemical event is observed. the neural architectures encode and aggregate multiple occurrences of the same candidate context mentions to determine whether it is the correct context for a particular event mention. we propose two broad types of architectures: the first type aggregates multiple instances that correspond to the same candidate context with respect to event mention before emitting a classification; the second type independently classifies each instance and uses the results to vote for the final class, akin to an ensemble approach. our experiments show that the proposed neural classifiers are competitive and some achieve better performance than previous state of the art traditional machine learning methods without the need for feature engineering. our analysis shows that the neural methods particularly improve precision compared to traditional machine learning classifiers and also demonstrates how the difficulty of inter-sentence relation extraction increases as the distance between the event and context mentions increase. ","228":"in this paper, we introduce a novel gnn-based knowledge graph embedding model, named wge, to capture entity-focused graph structure and relation-focused graph structure. in particular, given the knowledge graph, wge builds a single undirected entity-focused graph that views entities as nodes. in addition, wge also constructs another single undirected graph from relation-focused constraints, which views entities and relations as nodes. wge then proposes a new architecture of utilizing two vanilla gnns directly on these two single graphs to better update vector representations of entities and relations, followed by a weighted score function to return the triple scores. experimental results show that wge obtains state-of-the-art performances on three new and challenging benchmark datasets codex for knowledge graph completion. ","229":"text style transfer is an important task in natural language generation, which aims to control certain attributes in the generated text, such as politeness, emotion, humor, and many others. it has a long history in the field of natural language processing, and recently has re-gained significant attention thanks to the promising performance brought by deep neural models. in this paper, we present a systematic survey of the research on neural text style transfer, spanning over 100 representative articles since the first neural text style transfer work in 2017. we discuss the task formulation, existing datasets and subtasks, evaluation, as well as the rich methodologies in the presence of parallel and non-parallel data. we also provide discussions on a variety of important topics regarding the future development of this task. our curated paper list is at https:\/\/github.com\/zhijing-jin\/text_style_transfer_survey ","230":"automatic identification of salient aspects from user reviews is especially useful for opinion analysis. there has been significant progress in utilizing weakly supervised approaches, which require only a small set of seed words for training aspect classifiers. however, there is always room for improvement. first, no weakly supervised approaches fully utilize latent hierarchies between words. second, each seed words representation should have different latent semantics and be distinct when it represents a different aspect. in this paper, we propose hdae, a hyperbolic disentangled aspect extractor in which a hyperbolic aspect classifier captures words latent hierarchies, and aspect-disentangled representation models the distinct latent semantics of each seed word. compared to previous baselines, hdae achieves average f1 performance gains of 18.2% and 24.1% on amazon product review and restaurant review datasets, respectively. in addition, the em-bedding visualization experience demonstrates that hdae is a more effective approach to leveraging seed words. an ablation study and a case study further attest to the effectiveness of the proposed components ","231":"we present a three-level hierarchical transformer network (3-level-htn) for modeling long-term dependencies across clinical notes for the purpose of patient-level prediction. the network is equipped with three levels of transformer-based encoders to learn progressively from words to sentences, sentences to notes, and finally notes to patients. the first level from word to sentence directly applies a pre-trained bert model as a fully trainable component. while the second and third levels both implement a stack of transformer-based encoders, before the final patient representation is fed into a classification layer for clinical predictions. compared to conventional bert models, our model increases the maximum input length from 512 tokens to much longer sequences that are appropriate for modeling large numbers of clinical notes. we empirically examine different hyper-parameters to identify an optimal trade-off given computational resource limits. our experiment results on the mimic-iii dataset for different prediction tasks demonstrate that the proposed hierarchical transformer network outperforms previous state-of-the-art models, including but not limited to bigbird. ","232":"while non-suicidal self-injury (nssi) is not a new phenomenon, there is still a limited yet little is still known about understanding of the behavior, the intent behind the behavior and what the individuals themselves say about their behavior. this study collected pro-nssi public blog posts from reddit on pro-nssi and analyzed the content linguistically using liwc software, in order to examine the use of nssi specific words, linguistic properties and the psychological linguistic properties. were examined. the results inform current counseling practices by dispelling myths and providing insight into the inner world of people who engage in use nssii to cope. the most frequently appearing category of for nssi specific words categories, in the reddit blogs was the reasons in which one engagesfor engaging in nssi was the most frequently used in the reddit blogs. the linguistic properties found in the analysis reflected the predicted results; authors of pro-nssi posts used demonstrated expected results of first-person singular pronouns extensively, which indicatesing high levels of mental health distress and isolation. the psychological linguistic properties that could be observed of in these public reddit posts were dominantly in a negative emotional tone which demonstrates youth and impulsivity. the linguistic properties found when these posts were analyzed supports the work of earlier studies that dispelled common myths about nssi that were circulating in the mental health community. these findings suggest that the language of people who engage in nssi supports research findings in dispelling common myths about nssi. ","233":"media coverage possesses a substantial effect on the public perception of events. the way media frames events can significantly alter the beliefs and perceptions of our society. nevertheless, nearly all media outlets are known to report news in a biased way. while such bias can be introduced by altering the word choice or omitting information, the perception of bias also varies largely depending on a reader's personal background. therefore, media bias is a very complex construct to identify and analyze. even though media bias has been the subject of many studies, previous assessment strategies are oversimplified, lack overlap and empirical evaluation. thus, this study aims to develop a scale that can be used as a reliable standard to evaluate article bias. to name an example: intending to measure bias in a news article, should we ask, \"how biased is the article?\" or should we instead ask, \"how did the article treat the american president?\". we conducted a literature search to find 824 relevant questions about text perception in previous research on the topic. in a multi-iterative process, we summarized and condensed these questions semantically to conclude a complete and representative set of possible question types about bias. the final set consisted of 25 questions with varying answering formats, 17 questions using semantic differentials, and six ratings of feelings. we tested each of the questions on 190 articles with overall 663 participants to identify how well the questions measure an article's perceived bias. our results show that 21 final items are suitable and reliable for measuring the perception of media bias. we publish the final set of questions on http:\/\/bias-question-tree.gipplab.org\/. ","234":"we present a free and open-source tool for creating web-based surveys that include text annotation tasks. existing tools offer either text annotation or survey functionality but not both. combining the two input types is particularly relevant for investigating a reader's perception of a text which also depends on the reader's background, such as age, gender, and education. our tool caters primarily to the needs of researchers in the library and information sciences, the social sciences, and the humanities who apply content analysis to investigate, e.g., media bias, political communication, or fake news. ","235":"the lifelong learning paradigm in machine learning is an attractive alternative to the more prominent isolated learning scheme not only due to its resemblance to biological learning, but also its potential to reduce energy waste by obviating excessive model re-training. a key challenge to this paradigm is the phenomenon of catastrophic forgetting. with the increasing popularity and success of pre-trained models in machine learning, we pose the question: what role does pre-training play in lifelong learning, specifically with respect to catastrophic forgetting? we investigate existing methods in the context of large, pre-trained models and evaluate their performance on a variety of text and image classification tasks, including a large-scale study using a novel dataset of 15 diverse nlp tasks. across all settings, we observe that generic pre-training implicitly alleviates the effects of catastrophic forgetting when learning multiple tasks sequentially compared to randomly initialized models. we then further investigate why pre-training alleviates forgetting in this setting. we study this phenomenon by analyzing the loss landscape, finding that pre-trained weights appear to ease forgetting by leading to wider minima. based on this insight, we propose jointly optimizing for current task loss and loss basin sharpness in order to explicitly encourage wider basins during sequential fine-tuning. we show that this optimization approach leads to performance comparable to the state-of-the-art in task-sequential continual learning across multiple settings, without retaining a memory that scales in size with the number of tasks. ","236":"information retrieval is an important component in natural language processing, for knowledge intensive tasks such as question answering and fact checking. recently, information retrieval has seen the emergence of dense retrievers, based on neural networks, as an alternative to classical sparse methods based on term-frequency. these models have obtained state-of-the-art results on datasets and tasks where large training sets are available. however, they do not transfer well to new domains or applications with no training data, and are often outperformed by term-frequency methods such as bm25 which are not supervised. thus, a natural question is whether it is possible to train dense retrievers without supervision. in this work, we explore the limits of contrastive learning as a way to train unsupervised dense retrievers, and show that it leads to strong retrieval performance. more precisely, we show on the beir benchmark that our model outperforms bm25 on 11 out of 15 datasets. furthermore, when a few thousands examples are available, we show that fine-tuning our model on these leads to strong improvements compared to bm25. finally, when used as pre-training before fine-tuning on the ms-marco dataset, our technique obtains state-of-the-art results on the beir benchmark. ","237":"recent years have brought about a renewed interest in commonsense representation and reasoning in the field of natural language understanding. the development of new commonsense knowledge graphs (cskg) has been central to these advances as their diverse facts can be used and referenced by machine learning models for tackling new and challenging tasks. at the same time, there remain questions about the quality and coverage of these resources due to the massive scale required to comprehensively encompass general commonsense knowledge.   in this work, we posit that manually constructed cskgs will never achieve the coverage necessary to be applicable in all situations encountered by nlp agents. therefore, we propose a new evaluation framework for testing the utility of kgs based on how effectively implicit knowledge representations can be learned from them.   with this new goal, we propose atomic 2020, a new cskg of general-purpose commonsense knowledge containing knowledge that is not readily available in pretrained language models. we evaluate its properties in comparison with other leading cskgs, performing the first large-scale pairwise study of commonsense knowledge resources. next, we show that atomic 2020 is better suited for training knowledge models that can generate accurate, representative knowledge for new, unseen entities and events. finally, through human evaluation, we show that the few-shot performance of gpt-3 (175b parameters), while impressive, remains ~12 absolute points lower than a bart-based knowledge model trained on atomic 2020 despite using over 430x fewer parameters. ","238":"this paper presents xls-r, a large-scale model for cross-lingual speech representation learning based on wav2vec 2.0. we train models with up to 2b parameters on nearly half a million hours of publicly available speech audio in 128 languages, an order of magnitude more public data than the largest known prior work. our evaluation covers a wide range of tasks, domains, data regimes and languages, both high and low-resource. on the covost-2 speech translation benchmark, we improve the previous state of the art by an average of 7.4 bleu over 21 translation directions into english. for speech recognition, xls-r improves over the best known prior work on babel, mls, commonvoice as well as voxpopuli, lowering error rates by 14-34% relative on average. xls-r also sets a new state of the art on voxlingua107 language identification. moreover, we show that with sufficient model size, cross-lingual pretraining can outperform english-only pretraining when translating english speech into other languages, a setting which favors monolingual pretraining. we hope xls-r can help to improve speech processing tasks for many more languages of the world. ","239":"undirected neural sequence models have achieved performance competitive with the state-of-the-art directed sequence models that generate monotonically from left to right in machine translation tasks. in this work, we train a policy that learns the generation order for a pre-trained, undirected translation model via reinforcement learning. we show that the translations decoded by our learned orders achieve higher bleu scores than the outputs decoded from left to right or decoded by the learned order from mansimov et al. (2019) on the wmt'14 german-english translation task. on examples with a maximum source and target length of 30 from de-en, wmt'16 english-romanian, and wmt'21 english-chinese translation tasks, our learned order outperforms all heuristic generation orders on four out of six tasks. we next carefully analyze the learned order patterns via qualitative and quantitative analysis. we show that our policy generally follows an outer-to-inner order, predicting the left-most and right-most positions first, and then moving toward the middle while skipping less important words at the beginning. furthermore, the policy usually predicts positions for a single syntactic constituent structure in consecutive steps. we believe our findings could provide more insights on the mechanism of undirected generation models and encourage further research in this direction. our code is publicly available at https:\/\/github.com\/jiangyctarheel\/undirected-generation ","240":"in the decade since 2010, successes in artificial intelligence have been at the forefront of computer science and technology, and vector space models have solidified a position at the forefront of artificial intelligence. at the same time, quantum computers have become much more powerful, and announcements of major advances are frequently in the news.   the mathematical techniques underlying both these areas have more in common than is sometimes realized. vector spaces took a position at the axiomatic heart of quantum mechanics in the 1930s, and this adoption was a key motivation for the derivation of logic and probability from the linear geometry of vector spaces. quantum interactions between particles are modelled using the tensor product, which is also used to express objects and operations in artificial neural networks.   this paper describes some of these common mathematical areas, including examples of how they are used in artificial intelligence (ai), particularly in automated reasoning and natural language processing (nlp). techniques discussed include vector spaces, scalar products, subspaces and implication, orthogonal projection and negation, dual vectors, density matrices, positive operators, and tensor products. application areas include information retrieval, categorization and implication, modelling word-senses and disambiguation, inference in knowledge bases, and semantic composition.   some of these approaches can potentially be implemented on quantum hardware. many of the practical steps in this implementation are in early stages, and some are already realized. explaining some of the common mathematical tools can help researchers in both ai and quantum computing further exploit these overlaps, recognizing and exploring new directions along the way. ","241":"in dynamic adversarial data collection (dadc), human annotators are tasked with finding examples that models struggle to predict correctly. models trained on dadc-collected training data have been shown to be more robust in adversarial and out-of-domain settings, and are considerably harder for humans to fool. however, dadc is more time-consuming than traditional data collection and thus more costly per example. in this work, we examine if we can maintain the advantages of dadc, without suffering the additional cost. to that end, we introduce generative annotation assistants (gaas), generator-in-the-loop models that provide real-time suggestions that annotators can either approve, modify, or reject entirely. we collect training datasets in twenty experimental settings and perform a detailed analysis of this approach for the task of extractive question answering (qa) for both standard and adversarial data collection. we demonstrate that gaas provide significant efficiency benefits in terms of annotation speed, while leading to improved model fooling rates. in addition, we show that gaa-assisted data leads to higher downstream model performance on a variety of question answering tasks. ","242":"investigating the reasoning abilities of transformer models, and discovering new challenging tasks for them, has been a topic of much interest. recent studies have found these models to be surprisingly strong at performing deductive reasoning over formal logical theories expressed in natural language. a shortcoming of these studies, however, is that they do not take into account that logical theories, when sampled uniformly at random, do not necessarily lead to hard instances. we propose a new methodology for creating challenging algorithmic reasoning datasets that focus on natural language satisfiability (nlsat) problems. the key idea is to draw insights from empirical sampling of hard propositional sat problems and from complexity-theoretic studies of language. this methodology allows us to distinguish easy from hard instances, and to systematically increase the complexity of existing reasoning benchmarks such as ruletaker. we find that current transformers, given sufficient training data, are surprisingly robust at solving the resulting nlsat problems of substantially increased difficulty. they also exhibit some degree of scale-invariance - the ability to generalize to problems of larger size and scope. our results, however, reveal important limitations too: a careful sampling of training data is crucial for building models that generalize to larger problems, and transformer models' limited scale-invariance suggests they are far from learning robust deductive reasoning algorithms. ","243":"can a generative model be trained to produce images from a specific domain, guided by a text prompt only, without seeing any image? in other words: can an image generator be trained \"blindly\"? leveraging the semantic power of large scale contrastive-language-image-pre-training (clip) models, we present a text-driven method that allows shifting a generative model to new domains, without having to collect even a single image. we show that through natural language prompts and a few minutes of training, our method can adapt a generator across a multitude of domains characterized by diverse styles and shapes. notably, many of these modifications would be difficult or outright impossible to reach with existing methods. we conduct an extensive set of experiments and comparisons across a wide range of domains. these demonstrate the effectiveness of our approach and show that our shifted models maintain the latent-space properties that make generative models appealing for downstream tasks. ","244":"search is one of the key functionalities in digital platforms and applications such as an electronic dictionary, a search engine, and an e-commerce platform. while the search function in some languages is trivial, khmer word search is challenging given its complex writing system. multiple orders of characters and different spelling realizations of words impose a constraint on khmer word search functionality. additionally, spelling mistakes are common since robust spellcheckers are not commonly available across the input device platforms. these challenges hinder the use of khmer language in search-embedded applications. moreover, due to the absence of wordnet-like lexical databases for khmer language, it is impossible to establish semantic relation between words, enabling semantic search. in this paper, we propose a set of robust solutions to the above challenges associated with khmer word search. the proposed solutions include character order normalization, grapheme and phoneme-based spellcheckers, and khmer word semantic model. the semantic model is based on the word embedding model that is trained on a 30-million-word corpus and is used to capture the semantic similarities between words. ","245":"despite growing concerns around gender bias in nlp models used in algorithmic hiring, there is little empirical work studying the extent and nature of gendered language in resumes. using a corpus of 709k resumes from it firms, we train a series of models to classify the gender of the applicant, thereby measuring the extent of gendered information encoded in resumes. we also investigate whether it is possible to obfuscate gender from resumes by removing gender identifiers, hobbies, gender sub-space in embedding models, etc. we find that there is a significant amount of gendered information in resumes even after obfuscation. a simple tf-idf model can learn to classify gender with auroc=0.75, and more sophisticated transformer-based models achieve auroc=0.8. we further find that gender predictive values have low correlation with gender direction of embeddings -- meaning that, what is predictive of gender is much more than what is \"gendered\" in the masculine\/feminine sense. we discuss the algorithmic bias and fairness implications of these findings in the hiring context. ","246":"we focus on the task of creating a reinforcement learning agent that is inherently explainable -- with the ability to produce immediate local explanations by thinking out loud while performing a task and analyzing entire trajectories post-hoc to produce causal explanations. this hierarchically explainable reinforcement learning agent (hex-rl), operates in interactive fictions, text-based game environments in which an agent perceives and acts upon the world using textual natural language. these games are usually structured as puzzles or quests with long-term dependencies in which an agent must complete a sequence of actions to succeed -- providing ideal environments in which to test an agent's ability to explain its actions. our agent is designed to treat explainability as a first-class citizen, using an extracted symbolic knowledge graph-based state representation coupled with a hierarchical graph attention mechanism that points to the facts in the internal graph representation that most influenced the choice of actions. experiments show that this agent provides significantly improved explanations over strong baselines, as rated by human participants generally unfamiliar with the environment, while also matching state-of-the-art task performance. ","247":"knowledge built culturally across generations allows humans to learn far more than an individual could glean from their own experience in a lifetime. cultural knowledge in turn rests on language: language is the richest record of what previous generations believed, valued, and practiced, and how these evolved over time. the power and mechanisms of language as a means of cultural learning, however, are not well understood, and as a result, current ai systems do not leverage language as a means for cultural knowledge transmission. here, we take a first step towards reverse-engineering cultural learning through language. we developed a suite of complex tasks in the form of minimalist-style video games, which we deployed in an iterated learning paradigm. human participants were limited to only two attempts (two lives) to beat each game and were allowed to write a message to a future participant who read the message before playing. knowledge accumulated gradually across generations, allowing later generations to advance further in the games and perform more efficient actions. multigenerational learning followed a strikingly similar trajectory to individuals learning alone with an unlimited number of lives. successive generations of learners were able to succeed by expressing distinct types of knowledge in natural language: the dynamics of the environment, valuable goals, dangerous risks, and strategies for success. the video game paradigm we pioneer here is thus a rich test bed for developing ai systems capable of acquiring and transmitting cultural knowledge. ","248":"identifying cross-language plagiarism is challenging, especially for distant language pairs and sense-for-sense translations. we introduce the new multilingual retrieval model cross-language ontology-based similarity analysis (cl-osa) for this task. cl-osa represents documents as entity vectors obtained from the open knowledge graph wikidata. opposed to other methods, cl-osa does not require computationally expensive machine translation, nor pre-training using comparable or parallel corpora. it reliably disambiguates homonyms and scales to allow its application to web-scale document collections. we show that cl-osa outperforms state-of-the-art methods for retrieving candidate documents from five large, topically diverse test corpora that include distant language pairs like japanese-english. for identifying cross-language plagiarism at the character level, cl-osa primarily improves the detection of sense-for-sense translations. for these challenging cases, cl-osa's performance in terms of the well-established plagdet score exceeds that of the best competitor by more than factor two. the code and data of our study are openly available. ","249":"this paper summarizes our submission to task 2 of the second track of the 10th dialog system technology challenge (dstc10) \"knowledge-grounded task-oriented dialogue modeling on spoken conversations\". similar to the previous year's iteration, the task consists of three subtasks: detecting whether a turn is knowledge seeking, selecting the relevant knowledge document and finally generating a grounded response. this year, the focus lies on adapting the system to noisy asr transcripts. we explore different approaches to make the models more robust to this type of input and to adapt the generated responses to the style of spoken conversations. for the latter, we get the best results with a noisy channel model that additionally reduces the number of short and generic responses. our best system achieved the 1st rank in the automatic and the 3rd rank in the human evaluation of the challenge. ","250":"named entity recognition (ner) is a task of extracting named entities of specific types from text. current ner models often rely on human-annotated datasets requiring the vast engagement of professional knowledge on the target domain and entities. this work introduces an ask-to-generate approach, which automatically generates ner datasets by asking simple natural language questions that reflect the needs for entity types (e.g., which disease?) to an open-domain question answering system. without using any in-domain resources (i.e., training sentences, labels, or in-domain dictionaries), our models solely trained on our generated datasets largely outperform previous weakly supervised models on six ner benchmarks across four different domains. surprisingly, on ncbi-disease, our model achieves 75.5 f1 score and even outperforms the previous best weakly supervised model by 4.1 f1 score, which utilizes a rich in-domain dictionary provided by domain experts. formulating the needs of ner with natural language also allows us to build ner models for fine-grained entity types such as award, where our model even outperforms fully supervised models. on three few-shot ner benchmarks, our model achieves new state-of-the-art performance. ","251":"we present crosssum, a large-scale dataset comprising 1.65 million cross-lingual article-summary samples in 1500+ language-pairs constituting 45 languages. we use the multilingual xl-sum dataset and align identical articles written in different languages via cross-lingual retrieval using a language-agnostic representation model. we propose a multi-stage data sampling algorithm and fine-tune mt5, a multilingual pretrained model, with explicit cross-lingual supervision with crosssum and introduce a new metric for evaluating cross-lingual summarization. results on established and our proposed metrics indicate that models fine-tuned on crosssum outperforms summarization+translation baselines, even when the source and target language pairs are linguistically distant. to the best of our knowledge, crosssum is the largest cross-lingual summarization dataset and also the first-ever that does not rely on english as the pivot language. we are releasing the dataset, alignment and training scripts, and the models to spur future research on cross-lingual abstractive summarization. the resources can be found at \\url{https:\/\/github.com\/csebuetnlp\/crosssum}. ","252":"cognates are variants of the same lexical form across different languages; for example 'fonema' in spanish and 'phoneme' in english are cognates, both of which mean 'a unit of sound'. the task of automatic detection of cognates among any two languages can help downstream nlp tasks such as cross-lingual information retrieval, computational phylogenetics, and machine translation. in this paper, we demonstrate the use of cross-lingual word embeddings for detecting cognates among fourteen indian languages. our approach introduces the use of context from a knowledge graph to generate improved feature representations for cognate detection. we, then, evaluate the impact of our cognate detection mechanism on neural machine translation (nmt), as a downstream task. we evaluate our methods to detect cognates on a challenging dataset of twelve indian languages, namely, sanskrit, hindi, assamese, oriya, kannada, gujarati, tamil, telugu, punjabi, bengali, marathi, and malayalam. additionally, we create evaluation datasets for two more indian languages, konkani and nepali. we observe an improvement of up to 18% points, in terms of f-score, for cognate detection. furthermore, we observe that cognates extracted using our method help improve nmt quality by up to 2.76 bleu. we also release our code, newly constructed datasets and cross-lingual models publicly. ","253":"recently, pioneer work finds that speech pre-trained models can solve full-stack speech processing tasks, because the model utilizes bottom layers to learn speaker-related information and top layers to encode content-related information. since the network capacity is limited, we believe the speech recognition performance could be further improved if the model is dedicated to audio content information learning. to this end, we propose intermediate layer supervision for self-supervised learning (ils-ssl), which forces the model to concentrate on content information as much as possible by adding an additional ssl loss on the intermediate layers. experiments on librispeech test-other set show that our method outperforms hubert significantly, which achieves a 23.5%\/11.6% relative word error rate reduction in the w\/o language model setting for base\/large models. detailed analysis shows the bottom layers of our model have a better correlation with phonetic units, which is consistent with our intuition and explains the success of our method for asr. ","254":"text clustering methods were traditionally incorporated into multi-document summarization (mds) as a means for coping with considerable information repetition. clusters were leveraged to indicate information saliency and to avoid redundancy. these methods focused on clustering sentences, even though closely related sentences also usually contain non-aligning information. in this work, we revisit the clustering approach, grouping together propositions for more precise information alignment. specifically, our method detects salient propositions, clusters them into paraphrastic clusters, and generates a representative sentence for each cluster by fusing its propositions. our summarization method improves over the previous state-of-the-art mds method in the duc 2004 and tac 2011 datasets, both in automatic rouge scores and human preference. ","255":"data augmentation has been an important ingredient for boosting performances of learned models. prior data augmentation methods for few-shot text classification have led to great performance boosts. however, they have not been designed to capture the intricate compositional structure of natural language. as a result, they fail to generate samples with plausible and diverse sentence structures. motivated by this, we present the data augmentation using lexicalized probabilistic context-free grammars (alp) that generates augmented samples with diverse syntactic structures with plausible grammar. the lexicalized pcfg parse trees consider both the constituents and dependencies to produce a syntactic frame that maximizes a variety of word choices in a syntactically preservable manner without specific domain experts. experiments on few-shot text classification tasks demonstrate that alp enhances many state-of-the-art classification methods. as a second contribution, we delve into the train-val splitting methodologies when a data augmentation method comes into play. we argue empirically that the traditional splitting of training and validation sets is sub-optimal compared to our novel augmentation-based splitting strategies that further expand the training split with the same number of labeled data. taken together, our contributions on the data augmentation strategies yield a strong training recipe for few-shot text classification tasks. ","256":"conversational text-to-sql aims at converting multi-turn natural language queries into their corresponding sql representations. one of the most intractable problem of conversational text-to-sql is modeling the semantics of multi-turn queries and gathering proper information required for the current query. this paper shows that explicit modeling the semantic changes by adding each turn and the summarization of the whole context can bring better performance on converting conversational queries into sqls. in particular, we propose two conversational modeling tasks in both turn grain and conversation grain. these two tasks simply work as auxiliary training tasks to help with multi-turn conversational semantic parsing. we conducted empirical studies and achieve new state-of-the-art results on large-scale open-domain conversational text-to-sql dataset. the results demonstrate that the proposed mechanism significantly improves the performance of multi-turn semantic parsing. ","257":"the dominant paradigm for neural text generation is left-to-right decoding from autoregressive language models. constrained or controllable generation under complex lexical constraints, however, requires foresight to plan ahead feasible future paths.   drawing inspiration from the a* search algorithm, we propose neurologic a*esque, a decoding algorithm that incorporates heuristic estimates of future cost. we develop efficient lookahead heuristics that are efficient for large-scale language models, making our method a drop-in replacement for common techniques such as beam search and top-k sampling. to enable constrained generation, we build on neurologic decoding (lu et al., 2021), combining its flexibility in incorporating logical constraints with a*esque estimates of future constraint satisfaction.   our approach outperforms competitive baselines on five generation tasks, and achieves new state-of-the-art performance on table-to-text generation, constrained machine translation, and keyword-constrained generation. the improvements are particularly notable on tasks that require complex constraint satisfaction or in few-shot or zero-shot settings. neurologic a*esque illustrates the power of decoding for improving and enabling new capabilities of large-scale language models. ","258":"we propose a cross-modal attention distillation framework to train a dual-encoder model for vision-language understanding tasks, such as visual reasoning and visual question answering. dual-encoder models have a faster inference speed than fusion-encoder models and enable the pre-computation of images and text during inference. however, the shallow interaction module used in dual-encoder models is insufficient to handle complex vision-language understanding tasks. in order to learn deep interactions of images and text, we introduce cross-modal attention distillation, which uses the image-to-text and text-to-image attention distributions of a fusion-encoder model to guide the training of our dual-encoder model. in addition, we show that applying the cross-modal attention distillation for both pre-training and fine-tuning stages achieves further improvements. experimental results demonstrate that the distilled dual-encoder model achieves competitive performance for visual reasoning, visual entailment and visual question answering tasks while enjoying a much faster inference speed than fusion-encoder models. our code and models will be publicly available at https:\/\/github.com\/kugwzk\/distilled-dualencoder. ","259":"factual inconsistencies in generated summaries severely limit the practical applications of abstractive dialogue summarization. although significant progress has been achieved by using pre-trained models, substantial amounts of hallucinated content are found during the human evaluation. pre-trained models are most commonly fine-tuned with cross-entropy loss for text summarization, which may not be an optimal strategy. in this work, we provide a typology of factual errors with annotation data to highlight the types of errors and move away from a binary understanding of factuality. we further propose a training strategy that improves the factual consistency and overall quality of summaries via a novel contrastive fine-tuning, called confit. based on our linguistically-informed typology of errors, we design different modular objectives that each target a specific type. specifically, we utilize hard negative samples with errors to reduce the generation of factual inconsistency. in order to capture the key information between speakers, we also design a dialogue-specific loss. using human evaluation and automatic faithfulness metrics, we show that our model significantly reduces all kinds of factual errors on the dialogue summarization, samsum corpus. moreover, our model could be generalized to the meeting summarization, ami corpus, and it produces significantly higher scores than most of the baselines on both datasets regarding word-overlap metrics. ","260":"large language models, prompted with in-context examples, can perform semantic parsing with little training data. they do better when we formulate the problem as paraphrasing into canonical utterances, which cast the underlying meaning representations into a controlled natural language-like representation. intuitively, such models can more easily output canonical utterances as they are closer to the natural language used for pre-training. more recently, models also pre-trained on code, like openai codex, have risen in prominence. since accurately modeling code requires understanding of executable semantics. such models may prove more adept at semantic parsing. in this paper, we test this hypothesis and find that codex performs better at semantic parsing than equivalent gpt-3 models. we find that unlike gpt-3, codex performs similarly when targeting meaning representations directly, perhaps as meaning representations used in semantic parsing are structured similar to code. ","261":"we present a self-supervised pre-training approach for learning rich visual language representations for both handwritten and printed historical document transcription. after supervised fine-tuning of our pre-trained encoder representations for low-resource document transcription on two languages, (1) a heterogeneous set of handwritten islamicate manuscript images and (2) early modern english printed documents, we show a meaningful improvement in recognition accuracy over the same supervised model trained from scratch with as few as 30 line image transcriptions for training. our masked language model-style pre-training strategy, where the model is trained to be able to identify the true masked visual representation from distractors sampled from within the same line, encourages learning robust contextualized language representations invariant to scribal writing style and printing noise present across documents. ","262":"retrieval-augmented generation models have shown state-of-the-art performance across many knowledge-intensive nlp tasks such as open question answering and fact verification. these models are trained to generate the final output given the retrieved passages, which can be irrelevant to the original query, leading to learning spurious cues or answer memorization. this work introduces a method to incorporate evidentiality of passages -- whether a passage contains correct evidence to support the output -- into training the generator. we introduce a multi-task learning framework to jointly generate the final output and predict the evidentiality of each passage, leveraging a new task-agnostic method to obtain {\\it silver} evidentiality labels for supervision. our experiments on five datasets across three knowledge-intensive tasks show that our new evidentiality-guided generator significantly outperforms its direct counterpart with the same-size model and advances the state of the art on faviq-ambig. we attribute these improvements to both the auxiliary multi-task learning and silver evidentiality mining techniques. ","263":"noisy channel models have been especially effective in neural machine translation (nmt). however, recent approaches like \"beam search and rerank\" (bsr) incur significant computation overhead during inference, making real-world application infeasible. we aim to build an amortized noisy channel nmt model such that greedily decoding from it would generate translations that maximize the same reward as translations generated using bsr. we attempt three approaches: knowledge distillation, 1-step-deviation imitation learning, and q learning. the first approach obtains the noisy channel signal from a pseudo-corpus, and the latter two approaches aim to optimize toward a noisy-channel mt reward directly. all three approaches speed up inference by 1-2 orders of magnitude. for all three approaches, the generated translations fail to achieve rewards comparable to bsr, but the translation quality approximated by bleu is similar to the quality of bsr-produced translations. ","264":"attribute value extraction refers to the task of identifying values of an attribute of interest from product information. product attribute values are essential in many e-commerce scenarios, such as customer service robots, product ranking, retrieval and recommendations. while in the real world, the attribute values of a product are usually incomplete and vary over time, which greatly hinders the practical applications. in this paper, we introduce mave, a new dataset to better facilitate research on product attribute value extraction. mave is composed of a curated set of 2.2 million products from amazon pages, with 3 million attribute-value annotations across 1257 unique categories. mave has four main and unique advantages: first, mave is the largest product attribute value extraction dataset by the number of attribute-value examples. second, mave includes multi-source representations from the product, which captures the full product information with high attribute coverage. third, mave represents a more diverse set of attributes and values relative to what previous datasets cover. lastly, mave provides a very challenging zero-shot test set, as we empirically illustrate in the experiments. we further propose a novel approach that effectively extracts the attribute value from the multi-source product information. we conduct extensive experiments with several baselines and show that mave is an effective dataset for attribute value extraction task. it is also a very challenging task on zero-shot attribute extraction. data is available at {\\it \\url{https:\/\/github.com\/google-research-datasets\/mave}}. ","265":"the wave of pre-training language models has been continuously improving the quality of the machine-generated conversations, however, some of the generated responses still suffer from excessive repetition, sometimes repeating words from utterance, sometimes repeating words within self-generated responses, or both. inappropriate repetition of words can significantly degrade the quality of the generated texts. penalized sampling is one popular solution, reducing the sampling probability of existing words during inference, however, it is highly vulnerable to the inappropriate setting of the static weight. setting it too high can yield strange and unrealistic sentences while setting it too low makes the task of suppressing repetition trivial. to remedy the shortcomings of the above methods, we design a context-aware classifier to explicitly decide when to allow repetition and when to employ penalized sampling. such a classifier can be easily integrated with existing decoding methods, reducing repetitions where appropriate while preserving the diversity of the text. experimental results demonstrate that our method can generate higher quality and more authentic dialogues. ","266":"we present hidden-state optimization (hso), a gradient-based method for improving the performance of transformer language models at inference time. similar to dynamic evaluation (krause et al., 2018), hso computes the gradient of the log-probability the language model assigns to an evaluation text, but uses it to update the cached hidden states rather than the model parameters. we test hso with pretrained transformer-xl and gpt-2 language models, finding improvement on the wikitext103 and pg-19 datasets in terms of perplexity, especially when evaluating a model outside of its training distribution. we also demonstrate downstream applicability by showing gains in the recently developed prompt-based few-shot evaluation setting, again with no extra parameters or training data. ","267":"the extreme multi-label text classification (xmc) problem concerns finding most relevant labels for an input text instance from a large label set. however, the xmc setup faces two challenges: (1) it is not generalizable to predict unseen labels in dynamic environments, and (2) it requires a large amount of supervised (instance, label) pairs, which can be difficult to obtain for emerging domains. recently, the generalized zero-shot xmc (gz-xmc) setup has been studied and zestxml is proposed accordingly to handle the unseen labels, which still requires a large number of annotated (instance, label) pairs. in this paper, we consider a more practical scenario called extreme zero-shot xmc (ez-xmc), in which no supervision is needed and merely raw text of instances and labels are accessible. few-shot xmc (fs-xmc), an extension to ez-xmc with limited supervision is also investigated. to learn the semantic embeddings of instances and labels with raw text, we propose to pre-train transformer-based encoders with self-supervised contrastive losses. specifically, we develop a pre-training method maclr, which thoroughly leverages the raw text with techniques including multi-scale adaptive clustering, label regularization, and self-training with pseudo positive pairs. experimental results on four public ez-xmc datasets demonstrate that maclr achieves superior performance compared to all other leading baseline methods, in particular with approximately 5-10% improvement in precision and recall on average. moreover, we also show that our pre-trained encoder can be further improved on fs-xmc when there are a limited number of ground-truth positive pairs in training. by fine-tuning the encoder on such a few-shot subset, maclr still outperforms other extreme classifiers significantly. ","268":"neural information retrieval (ir) has greatly advanced search and other knowledge-intensive language tasks. while many neural ir methods encode queries and documents into single-vector representations, late interaction models produce multi-vector representations at the granularity of each token and decompose relevance modeling into scalable token-level computations. this decomposition has been shown to make late interaction more effective, but it inflates the space footprint of these models by an order of magnitude. in this work, we introduce colbertv2, a retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the quality and space footprint of late interaction. we evaluate colbertv2 across a wide range of benchmarks, establishing state-of-the-art quality within and outside the training domain while reducing the space footprint of late interaction models by 5--8$\\times$. ","269":"textual knowledge bases such as wikipedia require considerable effort to keep up to date and consistent. while automated writing assistants could potentially ease this burden, the problem of suggesting edits grounded in external knowledge has been under-explored. in this paper, we introduce the novel generation task of *faithfully reflecting updated information in text*(fruit) where the goal is to update an existing article given new evidence. we release the fruit-wiki dataset, a collection of over 170k distantly supervised data produced from pairs of wikipedia snapshots, along with our data generation pipeline and a gold evaluation set of 914 instances whose edits are guaranteed to be supported by the evidence. we provide benchmark results for popular generation systems as well as edit5 -- a t5-based approach tailored to editing we introduce that establishes the state of the art. our analysis shows that developing models that can update articles faithfully requires new capabilities for neural generation models, and opens doors to many new applications. ","270":"despite significant progress, state-of-the-art abstractive summarization methods are still prone to hallucinate content inconsistent with the source document. in this paper, we propose constrained abstractive summarization (cas), a general setup that preserves the factual consistency of abstractive summarization by specifying tokens as constraints that must be present in the summary. we adopt lexically constrained decoding, a technique generally applicable to autoregressive generative models, to fulfill cas and conduct experiments in two scenarios: (1) automatic summarization without human involvement, where keyphrases are extracted from the source document and used as constraints; (2) human-guided interactive summarization, where human feedback in the form of manual constraints are used to guide summary generation. automatic and human evaluations on two benchmark datasets demonstrate that cas improves both lexical overlap (rouge) and factual consistency of abstractive summarization. in particular, we observe up to 13.8 rouge-2 gains when only one manual constraint is used in interactive summarization. ","271":"physical measurements constitute a large portion of numbers in academic papers, engineering reports, and web tables. current benchmarks fall short of properly evaluating numeracy of pretrained language models on measurements, hindering research on developing new methods and applying them to numerical tasks. to that end, we introduce a novel task, masked measurement prediction (mmp), where a model learns to reconstruct a number together with its associated unit given masked text. mmp is useful for both training new numerically informed models as well as evaluating numeracy of existing systems. in order to address this task, we introduce a new generative masked measurement (gemm) model that jointly learns to predict numbers along with their units. we perform fine-grained analyses comparing our model with various ablations and baselines. we use linear probing of traditional pretrained transformer models (roberta) to show that they significantly underperform jointly trained number-unit models, highlighting the difficulty of this new task and the benefits of our proposed pretraining approach. we hope this framework accelerates the progress towards building more robust numerical reasoning systems in the future. ","272":"in this paper, we focus on studying robustness evaluation of chinese question matching. most of the previous work on analyzing robustness issue focus on just one or a few types of artificial adversarial examples. instead, we argue that it is necessary to formulate a comprehensive evaluation about the linguistic capabilities of models on natural texts. for this purpose, we create a chinese dataset namely duqm which contains natural questions with linguistic perturbations to evaluate the robustness of question matching models. duqm contains 3 categories and 13 subcategories with 32 linguistic perturbations. the extensive experiments demonstrate that duqm has a better ability to distinguish different models. importantly, the detailed breakdown of evaluation by linguistic phenomenon in duqm helps us easily diagnose the strength and weakness of different models. additionally, our experiment results show that the effect of artificial adversarial examples does not work on the natural texts. ","273":"to enable building and testing models on long-document comprehension, we introduce quality, a multiple-choice qa dataset with context passages in english that have an average length of about 5,000 tokens, much longer than typical current models can process. unlike in prior work with passages, our questions are written and validated by contributors who have read the entire passage, rather than relying on summaries or excerpts. in addition, only half of the questions are answerable by annotators working under tight time constraints, indicating that skimming and simple search are not enough to consistently perform well. current models perform poorly on this task (55.4%) and significantly lag behind human performance (93.5%). ","274":"automated storytelling has long captured the attention of researchers for the ubiquity of narratives in everyday life. however, it is challenging to maintain coherence and stay on-topic toward a specific ending when generating narratives with neural language models. in this paper, we introduce story generation with reader models (storm), a framework in which a reader model is used to reason about the story should progress. a reader model infers what a human reader believes about the concepts, entities, and relations about the fictional story world. we show how an explicit reader model represented as a knowledge graph affords story coherence and provides controllability in the form of achieving a given story world state goal. experiments show that our model produces significantly more coherent and on-topic stories, outperforming baselines in dimensions including plot plausibility and staying on topic. our system also outperforms outline-guided story generation baselines in composing given concepts without ordering. ","275":"for natural language processing systems, two kinds of evidence support the use of text representations from neural language models \"pretrained\" on large unannotated corpora: performance on application-inspired benchmarks (peters et al., 2018, inter alia), and the emergence of syntactic abstractions in those representations (tenney et al., 2019, inter alia). on the other hand, the lack of grounded supervision calls into question how well these representations can ever capture meaning (bender and koller, 2020). we apply novel probes to recent language models -- specifically focusing on predicate-argument structure as operationalized by semantic dependencies (ivanova et al., 2012) -- and find that, unlike syntax, semantics is not brought to the surface by today's pretrained models. we then use convolutional graph encoders to explicitly incorporate semantic parses into task-specific finetuning, yielding benefits to natural language understanding (nlu) tasks in the glue benchmark. this approach demonstrates the potential for general-purpose (rather than task-specific) linguistic supervision, above and beyond conventional pretraining and finetuning. several diagnostics help to localize the benefits of our approach. ","276":"the advent of large pre-trained generative language models has provided a common framework for ai story generation via sampling the model to create sequences that continue the story. however, sampling alone is insufficient for story generation. in particular, it is hard to direct a language model to create stories to reach a specific goal event. we present two automated techniques grounded in deep reinforcement learning and reward shaping to control the plot of computer-generated stories. the first utilizes proximal policy optimization to fine-tune an existing transformer-based language model to generate text continuations but also be goal-seeking. the second extracts a knowledge graph from the unfolding story, which is used by a policy network with graph attention to select a candidate continuation generated by a language model. we report on automated metrics pertaining to how often stories achieve a given goal event as well as human participant rankings of coherence and overall story quality compared to baselines and ablations. ","277":"idiomatic expressions (ies) play an essential role in natural language. in this paper, we study the task of idiomatic sentence paraphrasing (isp), which aims to paraphrase a sentence with an ie by replacing the ie with its literal paraphrase. the lack of large-scale corpora with idiomatic-literal parallel sentences is a primary challenge for this task, for which we consider two separate solutions. first, we propose an unsupervised approach to isp, which leverages an ie's contextual information and definition and does not require a parallel sentence training set. second, we propose a weakly supervised approach using back-translation to jointly perform paraphrasing and generation of sentences with ies to enlarge the small-scale parallel sentence training dataset. other significant derivatives of the study include a model that replaces a literal phrase in a sentence with an ie to generate an idiomatic expression and a large scale parallel dataset with idiomatic\/literal sentence pairs. the effectiveness of the proposed solutions compared to competitive baselines is seen in the relative gains of over 5.16 points in bleu, over 8.75 points in meteor, and over 19.57 points in sari when the generated sentences are empirically validated on a parallel dataset using automatic and manual evaluations. we demonstrate the practical utility of isp as a preprocessing step in en-de machine translation. ","278":"we introduce a machine-in-the-loop pipeline that aims to address root causes of unwanted bias in natural language based supervised machine learning tasks in the education domain. learning from the experiences of students is foundational for education researchers, and academic administrators. 21st-century skills learned from experience are becoming a core part of college and career readiness as well as the hiring process in the new knowledge economy. minoritized students demonstrate these skills in their daily lives, but documenting, assessing, and validating these skills is a huge problem for educational institutions. as an equity focused online platform, livedx translates minoritized students' lived experiences into the 21st century skills, issues micro-credentials, and creates personal 21st century skills portfolio. to automate the micro credential mining from the natural language texts received from the students' submitted essays, we employed a bag-of-word model to construct a multi-output classifier. despite our goal, our model initially exacerbated disparate impact on minoritized students. we used a machine-in-the-loop model development pipeline to address the problem and refine the aforementioned model to ensure fairness in its prediction. ","279":"answering complex questions about images is an ambitious goal for machine intelligence, which requires a joint understanding of images, text, and commonsense knowledge, as well as a strong reasoning ability. recently, multimodal transformers have made great progress in the task of visual commonsense reasoning (vcr), by jointly understanding visual objects and text tokens through layers of cross-modality attention. however, these approaches do not utilize the rich structure of the scene and the interactions between objects which are essential in answering complex commonsense questions. we propose a scene graph enhanced image-text learning (sgeitl) framework to incorporate visual scene graphs in commonsense reasoning. to exploit the scene graph structure, at the model structure level, we propose a multihop graph transformer for regularizing attention interaction among hops. as for pre-training, a scene-graph-aware pre-training method is proposed to leverage structure knowledge extracted in the visual scene graph. moreover, we introduce a method to train and generate domain-relevant visual scene graphs using textual annotations in a weakly-supervised manner. extensive experiments on vcr and other tasks show a significant performance boost compared with the state-of-the-art methods and prove the efficacy of each proposed component. ","280":"transformer models pre-trained with a masked-language-modeling objective (e.g., bert) encode commonsense knowledge as evidenced by behavioral probes; however, the extent to which this knowledge is acquired by systematic inference over the semantics of the pre-training corpora is an open question. to answer this question, we selectively inject verbalized knowledge into the minibatches of a bert model during pre-training and evaluate how well the model generalizes to supported inferences. we find generalization does not improve over the course of pre-training, suggesting that commonsense knowledge is acquired from surface-level, co-occurrence patterns rather than induced, systematic reasoning. ","281":"a classification scheme of a scientific subject gives an overview of its body of knowledge. it can also be used to facilitate access to research articles and other materials related to the subject. for example, the acm computing classification system (ccs) is used in the acm digital library search interface and also for indexing computer science papers. we observed that a comprehensive classification system like ccs or mathematics subject classification (msc) does not exist for computational linguistics (cl) and natural language processing (nlp). we propose a classification scheme -- clicker for cl\/nlp based on the analysis of online lectures from 77 university courses on this subject. the currently proposed taxonomy includes 334 topics and focuses on educational aspects of cl\/nlp; it is based primarily, but not exclusively, on lecture notes from nlp courses. we discuss how such a taxonomy can help in various real-world applications, including tutoring platforms, resource retrieval, resource recommendation, prerequisite chain learning, and survey generation. ","282":"non-autoregressive (nar) machine translation has recently achieved significant improvements, and now outperforms autoregressive (ar) models on some benchmarks, providing an efficient alternative to ar inference. however, while ar translation is often implemented using multilingual models that benefit from transfer between languages and from improved serving efficiency, multilingual nar models remain relatively unexplored. taking connectionist temporal classification (ctc) as an example nar model and imputer as a semi-nar model, we present a comprehensive empirical study of multilingual nar. we test its capabilities with respect to positive transfer between related languages and negative transfer under capacity constraints. as nar models require distilled training sets, we carefully study the impact of bilingual versus multilingual teachers. finally, we fit a scaling law for multilingual nar, which quantifies its performance relative to the ar model as model scale increases. ","283":"multimodal summarization with multimodal output (msmo) generates a summary with both textual and visual content. multimodal news report contains heterogeneous contents, which makes msmo nontrivial. moreover, it is observed that different modalities of data in the news report correlate hierarchically. traditional msmo methods indistinguishably handle different modalities of data by learning a representation for the whole data, which is not directly adaptable to the heterogeneous contents and hierarchical correlation. in this paper, we propose a hierarchical cross-modality semantic correlation learning model (hcscl) to learn the intra- and inter-modal correlation existing in the multimodal data. hcscl adopts a graph network to encode the intra-modal correlation. then, a hierarchical fusion framework is proposed to learn the hierarchical correlation between text and images. furthermore, we construct a new dataset with relevant image annotation and image object label information to provide the supervision information for the learning procedure. extensive experiments on the dataset show that hcscl significantly outperforms the baseline methods in automatic summarization metrics and fine-grained diversity tests. ","284":"transformer models have achieved promising results on natural language processing (nlp) tasks including extractive question answering (qa). common transformer encoders used in nlp tasks process the hidden states of all input tokens in the context paragraph throughout all layers. however, different from other tasks such as sequence classification, answering the raised question does not necessarily need all the tokens in the context paragraph. following this motivation, we propose block-skim, which learns to skim unnecessary context in higher hidden layers to improve and accelerate the transformer performance. the key idea of block-skim is to identify the context that must be further processed and those that could be safely discarded early on during inference. critically, we find that such information could be sufficiently derived from the self-attention weights inside the transformer model. we further prune the hidden states corresponding to the unnecessary positions early in lower layers, achieving significant inference-time speedup. to our surprise, we observe that models pruned in this way outperform their full-size counterparts. block-skim improves qa models' accuracy on different datasets and achieves 3 times speedup on bert-base model. ","285":"information security in the cyber world is a major cause for concern, with a significant increase in the number of attack surfaces. existing information on vulnerabilities, attacks, controls, and advisories available on the web provides an opportunity to represent knowledge and perform security analytics to mitigate some of the concerns. representing security knowledge in the form of ontology facilitates anomaly detection, threat intelligence, reasoning and relevance attribution of attacks, and many more. this necessitates dynamic and automated enrichment of information security ontologies. however, existing ontology enrichment algorithms based on natural language processing and ml models have issues with contextual extraction of concepts in words, phrases, and sentences. this motivates the need for sequential deep learning architectures that traverse through dependency paths in text and extract embedded vulnerabilities, threats, controls, products, and other security-related concepts and instances from learned path representations. in the proposed approach, bidirectional lstms trained on a large dbpedia dataset and wikipedia corpus of 2.8 gb along with universal sentence encoder is deployed to enrich iso 27001-based information security ontology. the model is trained and tested on a high-performance computing (hpc) environment to handle wiki text dimensionality. the approach yielded a test accuracy of over 80% when tested with knocked-out concepts from ontology and web page instances to validate the robustness. ","286":"the problem of poster generation for scientific papers is under-investigated. posters often present the most important information of papers, and the task can be considered as a special form of document summarization. previous studies focus mainly on poster layout and panel composition, while neglecting the importance of content extraction. besides, their datasets are not publicly available, which hinders further research. in this paper, we construct a benchmark dataset from scratch for this task. then we propose a three-step framework to tackle this task and focus on the content extraction step in this study. to get both textual and visual elements of a poster panel, a neural extractive model is proposed to extract text, figures and tables of a paper section simultaneously. we conduct experiments on the dataset and also perform ablation study. results demonstrate the efficacy of our proposed model. the dataset and code will be released. ","287":"we introduce the task of prosody-aware machine translation which aims at generating translations suitable for dubbing. dubbing of a spoken sentence requires transferring the content as well as the prosodic structure of the source into the target language to preserve timing information. practically, this implies correctly projecting pauses from the source to the target and ensuring that target speech segments have roughly the same duration of the corresponding source segments. in this work, we propose an implicit and explicit modeling approaches to integrate prosody information into neural machine translation. experiments on english-german\/french with automatic metrics show that the simplest of the considered approaches works best. results are confirmed by human evaluations of translations and dubbed videos. ","288":"in this work, we explore how to learn task-specific language models aimed towards learning rich representation of keyphrases from text documents. we experiment with different masking strategies for pre-training transformer language models (lms) in discriminative as well as generative settings. in the discriminative setting, we introduce a new pre-training objective - keyphrase boundary infilling with replacement (kbir), showing large gains in performance (upto 9.26 points in f1) over sota, when lm pre-trained using kbir is fine-tuned for the task of keyphrase extraction. in the generative setting, we introduce a new pre-training setup for bart - keybart, that reproduces the keyphrases related to the input text in the catseq format, instead of the denoised original input. this also led to gains in performance (upto 4.33 points in f1@m) over sota for keyphrase generation. additionally, we also fine-tune the pre-trained language models on named entity recognition (ner), question answering (qa), relation extraction (re), abstractive summarization and achieve comparable performance with that of the sota, showing that learning rich representation of keyphrases is indeed beneficial for many other fundamental nlp tasks. ","289":"the goal of a summary is to concisely state the most important information in a document. with this principle in mind, we introduce new reference-free summary evaluation metrics that use a pretrained language model to estimate the information content shared between a document and its summary. these metrics are a modern take on the shannon game, a method for summary quality scoring proposed decades ago, where we replace human annotators with language models. we also view these metrics as an extension of blanc, a recently proposed approach to summary quality measurement based on the performance of a language model with and without the help of a summary. using transformer based language models, we empirically verify that our metrics achieve state-of-the-art correlation with human judgement of the summary quality dimensions of both coherence and relevance, as well as competitive correlation with human judgement of consistency and fluency. ","290":"in the past decade, automatic product description generation for e-commerce have witnessed significant advancement. as the services provided by e-commerce platforms become diverse, it is necessary to dynamically adapt the patterns of descriptions generated. the selling point of products is an important type of product description for which the length should be as short as possible while still conveying key information. in addition, this kind of product description should be eye-catching to the readers. currently, product selling points are normally written by human experts. thus, the creation and maintenance of these contents incur high costs. these costs can be significantly reduced if product selling points can be automatically generated by machines. in this paper, we report our experience developing and deploying the intelligent online selling point extraction (iospe) system to serve the recommendation system in the jd.com e-commerce platform. since july 2020, iospe has become a core service for 62 key categories of products (covering more than 4 million products). so far, it has generated more than 0.1 billion selling points, thereby significantly scaling up the selling point creation operation and saving human labour. these iospe generated selling points have increased the click-through rate (ctr) by 1.89\\% and the average duration the customers spent on the products by more than 2.03\\% compared to the previous practice, which are significant improvements for such a large-scale e-commerce platform. ","291":"transformer networks are the de facto standard architecture in natural language processing. to date, there are no theoretical analyses of the transformer's ability to capture tree structures. we focus on the ability of transformer networks to learn tree structures that are important for tree transduction problems. we first analyze the theoretical capability of the standard transformer architecture to learn tree structures given enumeration of all possible tree backbones, which we define as trees without labels. we then prove that two linear layers with relu activation function can recover any tree backbone from any two nonzero, linearly independent starting backbones. this implies that a transformer can learn tree structures well in theory. we conduct experiments with synthetic data and find that the standard transformer achieves similar accuracy compared to a transformer where tree position information is explicitly encoded, albeit with slower convergence. this confirms empirically that transformers can learn tree structures. ","292":"we present the first parsing results on the penn-helsinki parsed corpus of early modern english (ppceme), a 1.9 million word treebank that is an important resource for research in syntactic change. we describe key features of ppceme that make it challenging for parsing, including a larger and more varied set of function tags than in the penn treebank. we present results for this corpus using a modified version of the berkeley neural parser and the approach to function tag recovery of gabbard et al (2006). despite its simplicity, this approach works surprisingly well, suggesting it is possible to recover the original structure with sufficient accuracy to support linguistic applications (e.g., searching for syntactic structures of interest). however, for a subset of function tags (e.g., the tag indicating direct speech), additional work is needed, and we discuss some further limits of this approach. the resulting parser will be used to parse early english books online, a 1.1 billion word corpus whose utility for the study of syntactic change will be greatly increased with the addition of accurate parse trees. ","293":"language is the primary medium through which human information is communicated and coordination is achieved. one of the most important language functions is to categorize the world so messages can be communicated through conversation. while we know a great deal about how human languages vary in their encoding of information within semantic domains such as color, sound, number, locomotion, time, space, human activities, gender, body parts and biology, little is known about the global structure of semantic information and its effect on human communication. using large-scale computation, artificial intelligence techniques, and massive, parallel corpora across 15 subject areas--including religion, economics, medicine, entertainment, politics, and technology--in 999 languages, here we show substantial variation in the information and semantic density of languages and their consequences for human communication and coordination. in contrast to prior work, we demonstrate that higher density languages communicate information much more quickly relative to lower density languages. then, using over 9,000 real-life conversations across 14 languages and 90,000 wikipedia articles across 140 languages, we show that because there are more ways to discuss any given topic in denser languages, conversations and articles retrace and cycle over a narrower conceptual terrain. these results demonstrate an important source of variation across the human communicative channel, suggesting that the structure of language shapes the nature and texture of conversation, with important consequences for the behavior of groups, organizations, markets, and societies. ","294":"to investigate the role of linguistic knowledge in data augmentation (da) for natural language processing (nlp), particularly, whether more linguistic knowledge leads to a better da approach, we designed two adapted da programs and applied them to lcqmc (a large-scale chinese question matching corpus) for a binary chinese question matching classification task. the two da programs produce augmented texts by five simple text editing operations (or da techniques), largely irrespective of language generation rules, but one is enhanced with a pre-trained n-gram language model to fuse it with prior linguistic knowledge. we then trained four neural network models (bow, cnn, lstm-rnn, and gru-rnn) and a pre-trained model (ernie-gram) on the lcqmc train sets of varying size as well as the related augmented train sets produced by the two da programs. the test set performances of the five classification models show that adding probabilistic linguistic knowledge as constrains does not make the base da program better, since there are no significant performance differences between the models trained on the two types of augmented train sets, both when the five da techniques are applied together or separately. moreover, due to the inability of the five da techniques to make strictly paraphrastic augmented texts, the results indicate the need of sufficient amounts of training examples for the classification models trained on them to mediate the negative impact of false matching augmented text pairs and improve performances, a limitation of random text editing perturbations used a da approach. ","295":"characters do not convey meaning, but sequences of characters do. we propose an unsupervised distributional method to learn the abstract meaning-bearing units in a sequence of characters. rather than segmenting the sequence, this model discovers continuous representations of the \"objects\" in the sequence, using a recently proposed architecture for object discovery in images called slot attention. we train our model on different languages and evaluate the quality of the obtained representations with probing classifiers. our experiments show promising results in the ability of our units to capture meaning at a higher level of abstraction. ","296":"recent research in neural machine translation has explored flexible generation orders, as an alternative to left-to-right generation. however, training non-monotonic models brings a new complication: how to search for a good ordering when there is a combinatorial explosion of orderings arriving at the same final result? also, how do these automatic orderings compare with the actual behaviour of human translators? current models rely on manually built biases or are left to explore all possibilities on their own. in this paper, we analyze the orderings produced by human post-editors and use them to train an automatic post-editing system. we compare the resulting system with those trained with left-to-right and random post-editing orderings. we observe that humans tend to follow a nearly left-to-right order, but with interesting deviations, such as preferring to start by correcting punctuation or verbs. ","297":"sharing of anti-vaccine posts on social media, including misinformation posts, has been shown to create confusion and reduce the publics confidence in vaccines, leading to vaccine hesitancy and resistance. recent years have witnessed the fast rise of such anti-vaccine posts in a variety of linguistic and visual forms in online networks, posing a great challenge for effective content moderation and tracking. extending previous work on leveraging textual information to understand vaccine information, this paper presents insta-vax, a new multi-modal dataset consisting of a sample of 64,957 instagram posts related to human vaccines. we applied a crowdsourced annotation procedure verified by two trained expert judges to this dataset. we then bench-marked several state-of-the-art nlp and computer vision classifiers to detect whether the posts show anti-vaccine attitude and whether they contain misinformation. extensive experiments and analyses demonstrate the multimodal models can classify the posts more accurately than the uni-modal models, but still need improvement especially on visual context understanding and external knowledge cooperation. the dataset and classifiers contribute to monitoring and tracking of vaccine discussions for social scientific and public health efforts in combating the problem of vaccine misinformation. ","298":"we introduce a new loss function tripleentropy, to improve classification performance for fine-tuning general knowledge pre-trained language models based on cross-entropy and softtriple loss. this loss function can improve the robust roberta baseline model fine-tuned with cross-entropy loss by about (0.02% - 2.29%). thorough tests on popular datasets indicate a steady gain. the fewer samples in the training dataset, the higher gain -- thus, for small-sized dataset it is 0.78%, for medium-sized -- 0.86% for large -- 0.20% and for extra-large 0.04%. ","299":"product copywriting is a critical component of e-commerce recommendation platforms. it aims to attract users' interest and improve user experience by highlighting product characteristics with textual descriptions. in this paper, we report our experience deploying the proposed automatic product copywriting generation (apcg) system into the jd.com e-commerce product recommendation platform. it consists of two main components: 1) natural language generation, which is built from a transformer-pointer network and a pre-trained sequence-to-sequence model based on millions of training data from our in-house platform; and 2) copywriting quality control, which is based on both automatic evaluation and human screening. for selected domains, the models are trained and updated daily with the updated training data. in addition, the model is also used as a real-time writing assistant tool on our live broadcast platform. the apcg system has been deployed in jd.com since feb 2021. by sep 2021, it has generated 2.53 million product descriptions, and improved the overall averaged click-through rate (ctr) and the conversion rate (cvr) by 4.22% and 3.61%, compared to baselines, respectively on a year-on-year basis. the accumulated gross merchandise volume (gmv) made by our system is improved by 213.42%, compared to the number in feb 2021. ","300":"we propose a novel domain-specific generative pre-training (ds-gpt) method for text generation and apply it to the product titleand review summarization problems on e-commerce mobile display.first, we adopt a decoder-only transformer architecture, which fitswell for fine-tuning tasks by combining input and output all to-gether. second, we demonstrate utilizing only small amount of pre-training data in related domains is powerful. pre-training a languagemodel from a general corpus such as wikipedia or the commoncrawl requires tremendous time and resource commitment, andcan be wasteful if the downstream tasks are limited in variety. ourdsgpt is pre-trained on a limited dataset, the chinese short textsummarization dataset (lcsts). third, our model does not requireproduct-related human-labeled data. for title summarization task,the state of art explicitly uses additional background knowledgein training and predicting stages. in contrast, our model implic-itly captures this knowledge and achieves significant improvementover other methods, after fine-tuning on the public taobao.comdataset. for review summarization task, we utilize jd.com in-housedataset, and observe similar improvement over standard machinetranslation methods which lack the flexibility of fine-tuning. ourproposed work can be simply extended to other domains for a widerange of text generation tasks. ","301":"many users turn to document retrieval systems (e.g. search engines) to seek answers to controversial questions. answering such user queries usually require identifying responses within web documents, and aggregating the responses based on their different perspectives.   classical document retrieval systems fall short at delivering a set of direct and diverse responses to the users. naturally, identifying such responses within a document is a natural language understanding task. in this paper, we examine the challenges of synthesizing such language understanding objectives with document retrieval, and study a new perspective-oriented document retrieval paradigm. we discuss and assess the inherent natural language understanding challenges in order to achieve the goal. following the design challenges and principles, we demonstrate and evaluate a practical prototype pipeline system. we use the prototype system to conduct a user survey in order to assess the utility of our paradigm, as well as understanding the user information needs for controversial queries. ","302":"as task-oriented dialog systems are becoming increasingly popular in our lives, more realistic tasks have been proposed and explored. however, new practical challenges arise. for instance, current dialog systems cannot effectively handle multiple search results when querying a database, due to the lack of such scenarios in existing public datasets. in this paper, we propose database search result (dsr) disambiguation, a novel task that focuses on disambiguating database search results, which enhances user experience by allowing them to choose from multiple options instead of just one. to study this task, we augment the popular task-oriented dialog datasets (multiwoz and sgd) with turns that resolve ambiguities by (a) synthetically generating turns through a pre-defined grammar, and (b) collecting human paraphrases for a subset. we find that training on our augmented dialog data improves the model's ability to deal with ambiguous scenarios, without sacrificing performance on unmodified turns. furthermore, pre-fine tuning and multi-task learning help our model to improve performance on dsr-disambiguation even in the absence of in-domain data, suggesting that it can be learned as a universal dialog skill. our data and code will be made publicly available. ","303":"large pre-trained language models are often trained on large volumes of internet data, some of which may contain toxic or abusive language. consequently, language models encode toxic information, which makes the real-world usage of these language models limited. current methods aim to prevent toxic features from appearing generated text. we hypothesize the existence of a low-dimensional toxic subspace in the latent space of pre-trained language models, the existence of which suggests that toxic features follow some underlying pattern and are thus removable. to construct this toxic subspace, we propose a method to generalize toxic directions in the latent space. we also provide a methodology for constructing parallel datasets using a context based word masking system. through our experiments, we show that when the toxic subspace is removed from a set of sentence representations, almost no toxic representations remain in the result. we demonstrate empirically that the subspace found using our method generalizes to multiple toxicity corpora, indicating the existence of a low-dimensional toxic subspace. ","304":"collecting data for training dialog systems can be extremely expensive due to the involvement of human participants and need for extensive annotation. especially in document-grounded dialog systems, human experts need to carefully read the unstructured documents to answer the users' questions. as a result, existing document-grounded dialog datasets are relatively small-scale and obstruct the effective training of dialogue systems. in this paper, we propose an automatic data augmentation technique grounded on documents through a generative dialogue model. the dialogue model consists of a user bot and agent bot that can synthesize diverse dialogues given an input document, which are then used to train a downstream model. when supplementing the original dataset, our method achieves significant improvement over traditional data augmentation methods. we also achieve great performance in the low-resource setting. ","305":"recent work on open domain question answering has shown that there is a large discrepancy in model performance between novel test questions and those that largely overlap with training questions. however, it is unclear which aspects of novel questions make them challenging. drawing upon studies on systematic generalization, we introduce and annotate questions according to three categories that measure different levels and kinds of generalization: training set overlap, compositional generalization (comp-gen), and novel-entity generalization (novel-entity). when evaluating six popular parametric and non-parametric models, we find that for the established natural questions and triviaqa datasets, even the strongest model performance for comp-gen\/novel-entity is 13.1\/5.4% and 9.6\/1.5% lower compared to that for the full test set -- indicating the challenge posed by these types of questions. furthermore, we show that whilst non-parametric models can handle questions containing novel entities relatively well, they struggle with those requiring compositional generalization. lastly, we find that key question difficulty factors are: cascading errors from the retrieval component, frequency of question pattern, and frequency of the entity. ","306":"a commonly observed problem of the state-of-the-art natural language technologies, such as amazon alexa and apple siri, is that their services do not extend to most developing countries' citizens due to language barriers. such populations suffer due to the lack of available resources in their languages to build nlp products. this paper presents allwoz, a multilingual multi-domain task-oriented customer service dialog dataset covering eight languages: english, mandarin, korean, vietnamese, hindi, french, portuguese, and thai. furthermore, we create a benchmark for our multilingual dataset by applying mt5 with meta-learning. ","307":"the wide applicability of pretrained transformer models (ptms) for natural language tasks is well demonstrated, but their ability to comprehend short phrases of text is less explored. to this end, we evaluate different ptms from the lens of unsupervised entity linking in task-oriented dialog across 5 characteristics -- syntactic, semantic, short-forms, numeric and phonetic. our results demonstrate that several of the ptms produce sub-par results when compared to traditional techniques, albeit competitive to other neural baselines. we find that some of their shortcomings can be addressed by using ptms fine-tuned for text-similarity tasks, which illustrate an improved ability in comprehending semantic and syntactic correspondences, as well as some improvements for short-forms, numeric and phonetic variations in entity mentions. we perform qualitative analysis to understand nuances in their predictions and discuss scope for further improvements. code can be found at https:\/\/github.com\/murali1996\/el_tod ","308":"recent neural models that extend the pretrain-then-finetune paradigm continue to achieve new state-of-the-art results on joint goal accuracy (jga) for dialogue state tracking (dst) benchmarks. however, we call into question their robustness as they show sharp drops in jga for conversations containing utterances or dialog flows with realistic perturbations. inspired by checklist (ribeiro et al., 2020), we design a collection of metrics called checkdst that facilitate comparisons of dst models on comprehensive dimensions of robustness by testing well-known weaknesses with augmented test sets. we evaluate recent dst models with checkdst and argue that models should be assessed more holistically rather than pursuing state-of-the-art on jga since a higher jga does not guarantee better overall robustness. we find that span-based classification models are resilient to unseen named entities but not robust to language variety, whereas those based on autoregressive language models generalize better to language variety but tend to memorize named entities and often hallucinate. due to their respective weaknesses, neither approach is yet suitable for real-world deployment. we believe checkdst is a useful guide for future research to develop task-oriented dialogue models that embody the strengths of various methods. ","309":"in the interest of interpreting neural nli models and their reasoning strategies, we carry out a systematic probing study which investigates whether these models capture the crucial semantic features central to natural logic: monotonicity and concept inclusion. correctly identifying valid inferences in downward-monotone contexts is a known stumbling block for nli performance, subsuming linguistic phenomena such as negation scope and generalized quantifiers. to understand this difficulty, we emphasize monotonicity as a property of a context and examine the extent to which models capture monotonicity information in the contextual embeddings which are intermediate to their decision making process. drawing on the recent advancement of the probing paradigm, we compare the presence of monotonicity features across various models. we find that monotonicity information is notably weak in the representations of popular nli models which achieve high scores on benchmarks, and observe that previous improvements to these models based on fine-tuning strategies have introduced stronger monotonicity features together with their improved performance on challenge sets. ","310":"generative commonsense reasoning requires machines to generate sentences describing an everyday scenario given several concepts, which has attracted much attention recently. however, existing models cannot perform as well as humans, since sentences they produce are often implausible and grammatically incorrect. in this paper, inspired by the process of humans creating sentences, we propose a novel knowledge-enhanced commonsense generation framework, termed kgr^4, consisting of four stages: retrieval, retrospect, refine, rethink. under this framework, we first perform retrieval to search for relevant sentences from external corpus as the prototypes. then, we train the generator that either edits or copies these prototypes to generate candidate sentences, of which potential errors will be fixed by an autoencoder-based refiner. finally, we select the output sentence from candidate sentences produced by generators with different hyper-parameters. experimental results and in-depth analysis on the commongen benchmark strongly demonstrate the effectiveness of our framework. particularly, kgr^4 obtains 33.56 spice points in the official leaderboard, outperforming the previously-reported best result by 2.49 spice points and achieving state-of-the-art performance. ","311":"a language agnostic approach to recognizing emotions from speech remains an incomplete and challenging task. in this paper, we used bangla and english languages to assess whether distinguishing emotions from speech is independent of language. the following emotions were categorized for this study: happiness, anger, neutral, sadness, disgust, and fear. we employed three emotional speech sets, of which the first two were developed by native bengali speakers from the islamic university of technology in bangla and english languages separately. the third was the toronto emotional speech set (tess), which was developed by native english speakers from canada. we carefully selected language-independent prosodic features, adopted a support vector machine (svm) model, and conducted three experiments to carry out our proposition. in the first experiment, we measured the performance of the three speech sets individually. this was followed by the second experiment, where we recorded the classification rate by combining the speech sets. finally, in the third experiment we measured the recognition rate by training and testing the model with different speech sets. although this study reveals that speech emotion recognition (ser) is mostly language-independent, there is some disparity while recognizing emotional states like disgust and fear in these two languages. moreover, our investigations inferred that non-native speakers convey emotions through speech, much like expressing themselves in their native tongue. ","312":"customer service chatbots are conversational systems designed to provide information to customers about products\/services offered by different companies. particularly, intent recognition is one of the core components in the natural language understating capabilities of a chatbot system. among the different intents that a chatbot is trained to recognize, there is a set of them that is universal to any customer service chatbot. universal intents may include salutation, switch the conversation to a human agent, farewells, among others. a system to recognize those universal intents will be very helpful to optimize the training process of specific customer service chatbots. we propose the development of a universal intent recognition system, which is trained to recognize a selected group of 11 intents that are common in 28 different chatbots. the proposed system is trained considering state-of-the-art word-embedding models such as word2vec and bert, and deep classifiers based on convolutional and recurrent neural networks. the proposed model is able to discriminate between those universal intents with a balanced accuracy up to 80.4\\%. in addition, the proposed system is equally accurate to recognize intents expressed both in short and long text requests. at the same time, misclassification errors often occurs between intents with very similar semantic fields such as farewells and positive comments. the proposed system will be very helpful to optimize the training process of a customer service chatbot because some of the intents will be already available and detected by our system. at the same time, the proposed approach will be a suitable base model to train more specific chatbots by applying transfer learning strategies. ","313":"cultural code-switching concerns how we adjust our overall behaviours, manners of speaking, and appearance in response to a perceived change in our social environment. we defend the need to investigate cultural code-switching capacities in artificial intelligence systems. we explore a series of ethical and epistemic issues that arise when bringing cultural code-switching to bear on artificial intelligence. building upon dotson's (2014) analysis of testimonial smothering, we discuss how emerging technologies in ai can give rise to epistemic oppression, and specifically, a form of self-silencing that we call 'cultural smothering'. by leaving the socio-dynamic features of cultural code-switching unaddressed, ai systems risk negatively impacting already-marginalised social groups by widening opportunity gaps and further entrenching social inequalities. ","314":"human reasoning can often be understood as an interplay between two systems: the intuitive and associative (\"system 1\") and the deliberative and logical (\"system 2\"). neural sequence models -- which have been increasingly successful at performing complex, structured tasks -- exhibit the advantages and failure modes of system 1: they are fast and learn patterns from data, but are often inconsistent and incoherent. in this work, we seek a lightweight, training-free means of improving existing system 1-like sequence models by adding system 2-inspired logical reasoning. we explore several variations on this theme in which candidate generations from a neural sequence model are examined for logical consistency by a symbolic reasoning module, which can either accept or reject the generations. our approach uses neural inference to mediate between the neural system 1 and the logical system 2. results in robust story generation and grounded instruction-following show that this approach can increase the coherence and accuracy of neurally-based generations. ","315":"nowadays, more and more applications are developed for running on a distributed ledger technology, namely dapps. the business logic of dapps is usually implemented within smart contracts developed through solidity, a programming language for writing smart contracts on different blockchain platforms, including the popular ethereum. in ethereum, the smart contracts run on the machines of miners and the gas corresponds to the execution fee compensating such computing resources. however, the deployment and execution costs of a smart contract depend on the implementation choices done by developers. unappropriated design choices could lead to higher gas consumption than necessary. in this paper, we (i) identify a set of 19 solidity code smells affecting the deployment and transaction costs of a smart contract, and (ii) assess the relevance of such smells through a survey involving 34 participants. on top of these smells, we propose gasmet, a suite of metrics for statically evaluating the code quality of a smart contract from the gas consumption perspective. an experiment involving 2,186 smart contracts demonstrates that the proposed metrics have direct associations with deployment costs. the metrics in our suite can be used for more easily identifying source code segments that need optimizations. ","316":"predicting stock prices from textual information is a challenging task due to the uncertainty of the market and the difficulty understanding the natural language from a machine's perspective. previous researches focus mostly on sentiment extraction based on single news. however, the stocks on the financial market can be highly correlated, one news regarding one stock can quickly impact the prices of other stocks. to take this effect into account, we propose a new stock movement prediction framework: multi-graph recurrent network for stock forecasting (mgrn). this architecture allows to combine the textual sentiment from financial news and multiple relational information extracted from other financial data. through an accuracy test and a trading simulation on the stocks in the stoxx europe 600 index, we demonstrate a better performance from our model than other benchmarks. ","317":"millions of people around the world can not access content on the web because most of the content is not readily available in their language. machine translation (mt) systems have the potential to change this for many languages. current mt systems provide very accurate results for high resource language pairs, e.g., german and english. however, for many low resource languages, mt is still under active research. the key challenge is lack of datasets to build these systems. we present lesan, an mt system for low resource languages. our pipeline solves the key bottleneck to low resource mt by leveraging online and offline sources, a custom ocr system for ethiopic and an automatic alignment module. the final step in the pipeline is a sequence to sequence model that takes parallel corpus as input and gives us a translation model. lesan's translation model is based on the transformer architecture. after constructing a base model, back translation, is used to leverage monolingual corpora. currently lesan supports translation to and from tigrinya, amharic and english. we perform extensive human evaluation and show that lesan outperforms state-of-the-art systems such as google translate and microsoft translator across all six pairs. lesan is freely available and has served more than 10 million translations so far. at the moment, there are only 217 tigrinya and 15,009 amharic wikipedia articles. we believe that lesan will contribute towards democratizing access to the web through mt for millions of people. ","318":"in general, speech processing models consist of a language model along with an acoustic model. regardless of the language model's complexity and variants, three critical pre-processing steps are needed in language models: cleaning, normalization, and tokenization. among mentioned steps, the normalization step is so essential to format unification in pure textual applications. however, for embedded language models in speech processing modules, normalization is not limited to format unification. moreover, it has to convert each readable symbol, number, etc., to how they are pronounced. to the best of our knowledge, there is no persian normalization toolkits for embedded language models in speech processing modules, so in this paper, we propose an open-source normalization toolkit for text processing in speech applications. briefly, we consider different readable persian text like symbols (common currencies, #, @, url, etc.), numbers (date, time, phone number, national code, etc.), and so on. comparison with other available persian textual normalization tools indicates the superiority of the proposed method in speech processing. also, comparing the model's performance for one of the proposed functions (sentence separation) with other common natural language libraries such as hazm and parsivar indicates the proper performance of the proposed method. besides, its evaluation of some persian wikipedia data confirms the proper performance of the proposed method. ","319":"preserving privacy in training modern nlp models comes at a cost. we know that stricter privacy guarantees in differentially-private stochastic gradient descent (dp-sgd) generally degrade model performance. however, previous research on the efficiency of dp-sgd in nlp is inconclusive or even counter-intuitive. in this short paper, we provide a thorough analysis of different privacy preserving strategies on seven downstream datasets in five different `typical' nlp tasks with varying complexity using modern neural models. we show that unlike standard non-private approaches to solving nlp tasks, where bigger is usually better, privacy-preserving strategies do not exhibit a winning pattern, and each task and privacy regime requires a special treatment to achieve adequate performance. ","320":"$k$nn based neural machine translation ($k$nn-mt) has achieved state-of-the-art results in a variety of mt tasks. one significant shortcoming of $k$nn-mt lies in its inefficiency in identifying the $k$ nearest neighbors of the query representation from the entire datastore, which is prohibitively time-intensive when the datastore size is large. in this work, we propose \\textbf{faster $k$nn-mt} to address this issue. the core idea of faster $k$nn-mt is to use a hierarchical clustering strategy to approximate the distance between the query and a data point in the datastore, which is decomposed into two parts: the distance between the query and the center of the cluster that the data point belongs to, and the distance between the data point and the cluster center. we propose practical ways to compute these two parts in a significantly faster manner. through extensive experiments on different mt benchmarks, we show that \\textbf{faster $k$nn-mt} is faster than fast $k$nn-mt \\citep{meng2021fast} and only slightly (1.2 times) slower than its vanilla counterpart while preserving model performance as $k$nn-mt. faster $k$nn-mt enables the deployment of $k$nn-mt models on real-world mt services. ","321":"conversational recommendation systems (crs) engage with users by inferring user preferences from dialog history, providing accurate recommendations, and generating appropriate responses. previous crss use knowledge graph (kg) based recommendation modules and integrate kg with language models for response generation. although kg-based approaches prove effective, two issues remain to be solved. first, kg-based approaches ignore the information in the conversational context but only rely on entity relations and bag of words to recommend items. second, it requires substantial engineering efforts to maintain kgs that model domain-specific relations, thus leading to less flexibility. in this paper, we propose a simple yet effective architecture comprising a pre-trained language model (plm) and an item metadata encoder. the encoder learns to map item metadata to embeddings that can reflect the semantic information in the dialog context. the plm then consumes the semantic-aligned item embeddings together with dialog context to generate high-quality recommendations and responses. instead of modeling entity relations with kgs, our model reduces engineering complexity by directly converting each item to an embedding. experimental results on the benchmark dataset redial show that our model obtains state-of-the-art results on both recommendation and response generation tasks. ","322":"large amounts of annotated data have become more important than ever, especially since the rise of deep learning techniques. however, manual annotations are costly. we propose a tool that enables researchers to create large, high-quality, annotated datasets with only a few manual annotations, thus strongly reducing annotation cost and effort. for this purpose, we combine an active learning (al) approach with a pre-trained language model to semi-automatically identify annotation categories in the given text documents. to highlight our research direction's potential, we evaluate the approach on the task of identifying frames in news articles. our preliminary results show that employing al strongly reduces the number of annotations for correct classification of even these complex and subtle frames. on the framing dataset, the al approach needs only 16.3\\% of the annotations to reach the same performance as a model trained on the full dataset. ","323":"fairness is a principal social value that can be observed in civilisations around the world. a manifestation of this is in social agreements, often described in texts, such as contracts. yet, despite the prevalence of such, a fairness metric for texts describing a social act remains wanting. to address this, we take a step back to consider the problem based on first principals. instead of using rules or templates, we utilise social psychology literature to determine the principal factors that humans use when making a fairness assessment. we then attempt to digitise these using word embeddings into a multi-dimensioned sentence level fairness perceptions vector to serve as an approximation for these fairness perceptions. the method leverages a pro-social bias within word embeddings, for which we obtain an f1= 81.0. a second approach, using pca and ml based on the said fairness approximation vector produces an f1 score of 86.2. we detail improvements that can be made in the methodology to incorporate the projection of sentence embedding on to a subspace representation of fairness. ","324":"to treat others as one would wish to be treated is a common formulation of the golden rule (gr). yet, despite its prevalence as an axiom throughout history, no transfer of this moral philosophy into computational systems exists. in this paper we consider how to algorithmically operationalise this rule so that it may be used to measure sentences such as the boy harmed the girl, and categorise them as fair or unfair. for the purposes of the paper, we define a fair act as one that one would be accepting of if it were done to oneself. a review and reply to criticisms of the gr is made. we share the code for the digitisation of the gr, and test it with a list of sentences. implementing it within two language models, the use, and albert, we find f1 scores of 78.0, 85.0, respectively. a suggestion of how the technology may be implemented to avoid unfair biases in word embeddings is made - given that individuals would typically not wish to be on the receiving end of an unfair act, such as racism, irrespective of whether the corpus being used deems such discrimination as praiseworthy. ","325":"automatic detection of cognates helps downstream nlp tasks of machine translation, cross-lingual information retrieval, computational phylogenetics and cross-lingual named entity recognition. previous approaches for the task of cognate detection use orthographic, phonetic and semantic similarity based features sets. in this paper, we propose a novel method for enriching the feature sets, with cognitive features extracted from human readers' gaze behaviour. we collect gaze behaviour data for a small sample of cognates and show that extracted cognitive features help the task of cognate detection. however, gaze data collection and annotation is a costly task. we use the collected gaze behaviour data to predict cognitive features for a larger sample and show that predicted cognitive features, also, significantly improve the task performance. we report improvements of 10% with the collected gaze features, and 12% using the predicted gaze features, over the previously proposed approaches. furthermore, we release the collected gaze behaviour data along with our code and cross-lingual models. ","326":"recently, attention-based encoder-decoder (aed) models have shown high performance for end-to-end automatic speech recognition (asr) across several tasks. addressing overconfidence in such models, in this paper we introduce the concept of relaxed attention, which is a simple gradual injection of a uniform distribution to the encoder-decoder attention weights during training that is easily implemented with two lines of code. we investigate the effect of relaxed attention across different aed model architectures and two prominent asr tasks, wall street journal (wsj) and librispeech. we found that transformers trained with relaxed attention outperform the standard baseline models consistently during decoding with external language models. on wsj, we set a new benchmark for transformer-based end-to-end speech recognition with a word error rate of 3.65%, outperforming state of the art (4.20%) by 13.1% relative, while introducing only a single hyperparameter. ","327":"named entity recognition (ner) is an information extraction technique that aims to locate and classify named entities (e.g., organizations, locations,...) within a document into predefined categories. correctly identifying these phrases plays a significant role in simplifying information access. however, it remains a difficult task because named entities (nes) have multiple forms and they are context-dependent. while the context can be represented by contextual features, global relations are often misrepresented by those models. in this paper, we propose the combination of contextual features from xlnet and global features from graph convolution network (gcn) to enhance ner performance. experiments over a widely-used dataset, conll 2003, show the benefits of our strategy, with results competitive with the state of the art (sota). ","328":"predicting the success of startup companies is of great importance for both startup companies and investors. it is difficult due to the lack of available data and appropriate general methods. with data platforms like crunchbase aggregating the information of startup companies, it is possible to predict with machine learning algorithms. existing research suffers from the data sparsity problem as most early-stage startup companies do not have much data available to the public. we try to leverage the recent algorithms to solve this problem. we investigate several machine learning algorithms with a large dataset from crunchbase. the results suggest that lightgbm and xgboost perform best and achieve 53.03% and 52.96% f1 scores. we interpret the predictions from the perspective of feature contribution. we construct portfolios based on the models and achieve high success rates. these findings have substantial implications on how machine learning methods can help startup companies and investors. ","329":"due to improvements in artificial intelligence, speaker identification (si) technologies have brought a great direction and are now widely used in a variety of sectors. one of the most important components of si is feature extraction, which has a substantial impact on the si process and performance. as a result, numerous feature extraction strategies are thoroughly investigated, contrasted, and analyzed. this article exploits five distinct feature extraction methods for speaker identification in disguised voices under emotional environments. to evaluate this work significantly, three effects are used: high-pitched, low-pitched, and electronic voice conversion (evc). experimental results reported that the concatenated mel-frequency cepstral coefficients (mfccs), mfccs-delta, and mfccs-delta-delta is the best feature extraction method. ","330":"dialogue systems in the form of chatbots and personal assistants are being increasingly integrated into people's lives. modern dialogue systems may consider adopting anthropomorphic personas, mimicking societal demographic groups to appear more approachable and trustworthy to users. however, the adoption of a persona can result in the adoption of biases. in this paper, we present the first large-scale study on persona biases in dialogue systems and conduct analyses on personas of different social classes, sexual orientations, races, and genders. we define persona biases as harmful differences in responses (e.g., varying levels of offensiveness, agreement with harmful statements) generated from adopting different demographic personas. furthermore, we introduce an open-source framework, unitpersonabias, to explore and aggregate persona biases in dialogue systems. by analyzing the blender and dialogpt dialogue systems, we observe that adopting personas can actually decrease harmful responses, compared to not using any personas. additionally, we find that persona choices can affect the degree of harms in generated responses and thus should be systematically evaluated before deployment. we also analyze how personas can result in different amounts of harm towards specific demographics. ","331":"knowledge-grounded dialogue systems are challenging to build due to the lack of training data and heterogeneous knowledge sources. existing systems perform poorly on unseen topics due to limited topics covered in the training data. in addition, heterogeneous knowledge sources make it challenging for systems to generalize to other tasks because knowledge sources in different knowledge representations require different knowledge encoders. to address these challenges, we present plug, a language model that homogenizes different knowledge sources to a unified knowledge representation for knowledge-grounded dialogue generation tasks. plug is pre-trained on a dialogue generation task conditioned on a unified essential knowledge representation. it can generalize to different downstream knowledge-grounded dialogue generation tasks with a few training examples. the empirical evaluation on two benchmarks shows that our model generalizes well across different knowledge-grounded tasks. it can achieve comparable performance with state-of-the-art methods under a fully-supervised setting and significantly outperforms other methods in zero-shot and few-shot settings. ","332":"most existing vision-language pre-training methods focus on understanding tasks and use bert-like objectives (masked language modeling and image-text matching) during pretraining. although they perform well in many understanding downstream tasks, e.g., visual question answering, image-text retrieval and visual entailment, they do not possess the ability to generate. to tackle this problem, we propose unified multimodal pre-training for both vision-language understanding and generation (univl). the proposed univl is capable of handling both understanding tasks and generative tasks. we augment existing pretraining paradigms that only use random masks with causal masks, i.e., triangular masks that mask out future tokens, such that the pre-trained models can have autoregressive generation abilities by design. we formulate several previous understanding tasks as a text generation task and propose to use prompt-based method for fine-tuning on different downstream tasks. our experiments show that there is a trade-off between understanding tasks and generation tasks while using the same model, and a feasible way to improve both tasks is to use more data. our univl framework attains comparable performance to recent vision-language pre-training methods on both understanding tasks and generation tasks. moreover, we demostrate that prompt-based finetuning is more data-efficient - it outperforms discriminative methods in few-shot scenarios. ","333":"it has been shown that dual encoders trained on one domain often fail to generalize to other domains for retrieval tasks. one widespread belief is that the bottleneck layer of a dual encoder, where the final score is simply a dot-product between a query vector and a passage vector, is too limited to make dual encoders an effective retrieval model for out-of-domain generalization. in this paper, we challenge this belief by scaling up the size of the dual encoder model {\\em while keeping the bottleneck embedding size fixed.} with multi-stage training, surprisingly, scaling up the model size brings significant improvement on a variety of retrieval tasks, especially for out-of-domain generalization. experimental results show that our dual encoders, \\textbf{g}eneralizable \\textbf{t}5-based dense \\textbf{r}etrievers (gtr), outperform %colbert~\\cite{khattab2020colbert} and existing sparse and dense retrievers on the beir dataset~\\cite{thakur2021beir} significantly. most surprisingly, our ablation study finds that gtr is very data efficient, as it only needs 10\\% of ms marco supervised data to achieve the best out-of-domain performance. all the gtr models are released at https:\/\/tfhub.dev\/google\/collections\/gtr\/1. ","334":"comprehending an article requires understanding its constituent events. however, the context where an event is mentioned often lacks the details of this event. then, where can we obtain more knowledge of this particular event in addition to its context? this work defines event linking, a new natural language understanding task at the event level. event linking tries to link an event mention, appearing in a news article for example, to the most appropriate wikipedia page. this page is expected to provide rich knowledge about what the event refers to. to standardize the research of this new problem, we contribute in three-fold. first, this is the first work in the community that formally defines event linking task. second, we collect a dataset for this new task. in specific, we first gather training set automatically from wikipedia, then create two evaluation sets: one from the wikipedia domain as well, reporting the in-domain performance; the other from the real-world news domain, testing the out-of-domain performance. third, we propose evelink, the first-ever event linking approach. overall, event linking is a considerably challenging task requiring more effort from the community. data and code are available here: https:\/\/github.com\/cogcomp\/event-linking. ","335":"entity linking faces significant challenges, such as prolific variations and prevalent ambiguities, especially in high-value domains with myriad entities. standard classification approaches suffer from the annotation bottleneck and cannot effectively handle unseen entities. zero-shot entity linking has emerged as a promising direction for generalizing to new entities, but it still requires example gold entity mentions during training and canonical descriptions for all entities, both of which are rarely available outside of wikipedia. in this paper, we explore knowledge-rich self-supervision ($\\tt kriss$) for entity linking, by leveraging readily available domain knowledge. in training, it generates self-supervised mention examples on unlabeled text using a domain ontology and trains a contextual encoder using contrastive learning. for inference, it samples self-supervised mentions as prototypes for each entity and conducts linking by mapping the test mention to the most similar prototype. our approach subsumes zero-shot and few-shot methods, and can easily incorporate entity descriptions and gold mention labels if available. using biomedicine as a case study, we conducted extensive experiments on seven standard datasets spanning biomedical literature and clinical notes. without using any labeled information, our method produces $\\tt krissbert$, a universal entity linker for four million umls entities, which attains new state of the art, outperforming prior self-supervised methods by as much as over 20 absolute points in accuracy. ","336":"in this paper, we examine the use of multi-lingual sentence embeddings to transfer predictive models for functional segmentation of adjudicatory decisions across jurisdictions, legal systems (common and civil law), languages, and domains (i.e. contexts). mechanisms for utilizing linguistic resources outside of their original context have significant potential benefits in ai & law because differences between legal systems, languages, or traditions often block wider adoption of research outcomes. we analyze the use of language-agnostic sentence representations in sequence labeling models using gated recurrent units (grus) that are transferable across languages. to investigate transfer between different contexts we developed an annotation scheme for functional segmentation of adjudicatory decisions. we found that models generalize beyond the contexts on which they were trained (e.g., a model trained on administrative decisions from the us can be applied to criminal law decisions from italy). further, we found that training the models on multiple contexts increases robustness and improves overall performance when evaluating on previously unseen contexts. finally, we found that pooling the training data from all the contexts enhances the models' in-context performance. ","337":"we propose a transition-based system to transpile abstract meaning representation (amr) into sparql for knowledge base question answering (kbqa). this allows to delegate part of the abstraction problem to a strongly pre-trained semantic parser, while learning transpiling with small amount of paired data. we departure from recent work relating amr and sparql constructs, but rather than applying a set of rules, we teach the bart model to selectively use these relations. further, we avoid explicitly encoding amr but rather encode the parser state in the attention mechanism of bart, following recent semantic parsing works. the resulting model is simple, provides supporting text for its decisions, and outperforms recent progress in amr-based kbqa in lc-quad (f1 53.4), matching it in qald (f1 30.8), while exploiting the same inductive biases. ","338":"we examine the extent to which, in principle, linguistic graph representations can complement and improve neural language modeling. with an ensemble setup consisting of a pretrained transformer and ground-truth graphs from one of 7 different formalisms, we find that, overall, semantic constituency structures are most useful to language modeling performance -- outpacing syntactic constituency structures as well as syntactic and semantic dependency structures. further, effects vary greatly depending on part-of-speech class. in sum, our findings point to promising tendencies in neuro-symbolic language modeling and invite future research quantifying the design choices made by different formalisms. ","339":"text content created by humans or language models is often stolen or misused by adversaries. tracing text provenance can help claim the ownership of text content or identify the malicious users who distribute misleading content like machine-generated fake news. there have been some attempts to achieve this, mainly based on watermarking techniques. specifically, traditional text watermarking methods embed watermarks by slightly altering text format like line spacing and font, which, however, are fragile to cross-media transmissions like ocr. considering this, natural language watermarking methods represent watermarks by replacing words in original sentences with synonyms from handcrafted lexical resources (e.g., wordnet), but they do not consider the substitution's impact on the overall sentence's meaning. recently, a transformer-based network was proposed to embed watermarks by modifying the unobtrusive words (e.g., function words), which also impair the sentence's logical and semantic coherence. besides, one well-trained network fails on other different types of text content. to address the limitations mentioned above, we propose a natural language watermarking scheme based on context-aware lexical substitution (ls). specifically, we employ bert to suggest ls candidates by inferring the semantic relatedness between the candidates and the original sentence. based on this, a selection strategy in terms of synchronicity and substitutability is further designed to test whether a word is exactly suitable for carrying the watermark signal. extensive experiments demonstrate that, under both objective and subjective metrics, our watermarking scheme can well preserve the semantic integrity of original sentences and has a better transferability than existing methods. besides, the proposed ls approach outperforms the state-of-the-art approach on the stanford word substitution benchmark. ","340":"we analyze the ability of pre-trained language models to transfer knowledge among datasets annotated with different type systems and to generalize beyond the domain and dataset they were trained on. we create a meta task, over multiple datasets focused on the prediction of rhetorical roles. prediction of the rhetorical role a sentence plays in a case decision is an important and often studied task in ai & law. typically, it requires the annotation of a large number of sentences to train a model, which can be time-consuming and expensive. further, the application of the models is restrained to the same dataset it was trained on. we fine-tune language models and evaluate their performance across datasets, to investigate the models' ability to generalize across domains. our results suggest that the approach could be helpful in overcoming the cold-start problem in active or interactvie learning, and shows the ability of the models to generalize across datasets and domains. ","341":"motivation: a perennial challenge for biomedical researchers and clinical practitioners is to stay abreast with the rapid growth of publications and medical notes. natural language processing (nlp) has emerged as a promising direction for taming information overload. in particular, large neural language models facilitate transfer learning by pretraining on unlabeled text, as exemplified by the successes of bert models in various nlp applications. however, fine-tuning such models for an end task remains challenging, especially with small labeled datasets, which are common in biomedical nlp.   results: we conduct a systematic study on fine-tuning stability in biomedical nlp. we show that finetuning performance may be sensitive to pretraining settings, especially in low-resource domains. large models have potential to attain better performance, but increasing model size also exacerbates finetuning instability. we thus conduct a comprehensive exploration of techniques for addressing fine-tuning instability. we show that these techniques can substantially improve fine-tuning performance for lowresource biomedical nlp applications. specifically, freezing lower layers is helpful for standard bert-base models, while layerwise decay is more effective for bert-large and electra models. for low-resource text similarity tasks such as biosses, reinitializing the top layer is the optimal strategy. overall, domainspecific vocabulary and pretraining facilitate more robust models for fine-tuning. based on these findings, we establish new state of the art on a wide range of biomedical nlp applications.   availability and implementation: to facilitate progress in biomedical nlp, we release our state-of-the-art pretrained and fine-tuned models: https:\/\/aka.ms\/blurb. ","342":"we created a fine-grained ai system for the detection of anti-semitism. this explainable ai will identify english and german anti-semitic expressions of dehumanization, verbal aggression and conspiracies in online social media messages across platforms, to support high-level decision making. ","343":"large-scale pre-training has recently revolutionized vision-and-language (vl) research. models such as lxmert and uniter have significantly lifted the state of the art over a wide range of vl tasks. however, the large number of parameters in such models hinders their application in practice. in parallel, work on the lottery ticket hypothesis (lth) has shown that deep neural networks contain small matching subnetworks that can achieve on par or even better performance than the dense networks when trained in isolation. in this work, we perform the first empirical study to assess whether such trainable subnetworks also exist in pre-trained vl models. we use uniter as the main testbed (also test on lxmert and vilt), and consolidate 7 representative vl tasks for experiments, including visual question answering, visual commonsense reasoning, visual entailment, referring expression comprehension, image-text retrieval, gqa, and nlvr$^2$. through comprehensive analysis, we summarize our main findings as follows. ($i$) it is difficult to find subnetworks that strictly match the performance of the full model. however, we can find \"relaxed\" winning tickets at 50%-70% sparsity that maintain 99% of the full accuracy. ($ii$) subnetworks found by task-specific pruning transfer reasonably well to the other tasks, while those found on the pre-training tasks at 60%\/70% sparsity transfer universally, matching 98%\/96% of the full accuracy on average over all the tasks. ($iii$) besides uniter, other models such as lxmert and vilt can also play lottery tickets. however, the highest sparsity we can achieve for vilt is far lower than lxmert and uniter (30% vs. 70%). ($iv$) lth also remains relevant when using other training methods (e.g., adversarial training). ","344":"existing datasets that contain boolean questions, such as boolq and tydi qa , provide the user with a yes\/no response to the question. however, a one word response is not sufficient for an explainable system. we promote explainability by releasing a new set of annotations marking the evidence in existing tydi qa and boolq datasets. we show that our annotations can be used to train a model that extracts improved evidence spans compared to models that rely on existing resources. we confirm our findings with a user study which shows that our extracted evidence spans enhance the user experience. we also provide further insight into the challenges of answering boolean questions, such as passages containing conflicting yes and no answers, and varying degrees of relevance of the predicted evidence. ","345":"we propose drboost, a dense retrieval ensemble inspired by boosting. drboost is trained in stages: each component model is learned sequentially and specialized by focusing only on retrieval mistakes made by the current ensemble. the final representation is the concatenation of the output vectors of all the component models, making it a drop-in replacement for standard dense retrievers at test time. drboost enjoys several advantages compared to standard dense retrieval models. it produces representations which are 4x more compact, while delivering comparable retrieval results. it also performs surprisingly well under approximate search with coarse quantization, reducing latency and bandwidth needs by another 4x. in practice, this can make the difference between serving indices from disk versus from memory, paving the way for much cheaper deployments. ","346":"cities have become primary actors on climate change and are increasingly setting goals aimed at net-zero emissions. the rapid proliferation of subnational governments \"racing to zero\" emissions and articulating their own climate mitigation plans warrants closer examination to understand how these actors intend to meet these goals. the scattered, incomplete and heterogeneous nature of city climate policy documents, however, has made their systemic analysis challenging. we analyze 318 climate action documents from cities that have pledged net-zero targets or joined a transnational climate initiative with this goal using machine learning-based natural language processing (nlp) techniques. we use these approaches to accomplish two primary goals: 1) determine text patterns that predict \"ambitious\" net-zero targets, where we define an ambitious target as one that encompasses a subnational government's economy-wide emissions; and 2) perform a sectoral analysis to identify patterns and trade-offs in climate action themes (i.e., land-use, industry, buildings, etc.). we find that cities that have defined ambitious climate actions tend to emphasize quantitative metrics and specific high-emitting sectors in their plans, supported by mentions of governance and citizen participation. cities predominantly emphasize energy-related actions in their plans, particularly in the buildings, transport and heating sectors, but often at the expense of other sectors, including land-use and climate impacts. the method presented in this paper provides a replicable, scalable approach to analyzing climate action plans and a first step towards facilitating cross-city learning. ","347":"it is an essential product requirement of yahoo mail to distinguish between personal and machine-generated emails. the old production classifier in yahoo mail was based on a simple logistic regression model. that model was trained by aggregating features at the smtp address level. we propose building deep learning models at the message level. we built and trained four individual cnn models: (1) a content model with subject and content as input; (2) a sender model with sender email address and name as input; (3) an action model by analyzing email recipients' action patterns and correspondingly generating target labels based on senders' opening\/deleting behaviors; (4) a salutation model by utilizing senders' \"explicit salutation\" signal as positive labels. next, we built a final full model after exploring different combinations of the above four models. experimental results on editorial data show that our full model improves the adjusted-recall from 70.5% to 78.8% compared to the old production model, while at the same time lifts the precision from 94.7% to 96.0%. our full model also significantly beats the state-of-the-art bert model at this task. this full model has been deployed into the current production system (yahoo mail 6). ","348":"we have recently begun a project to develop a more effective and efficient way to marshal inferences from background knowledge to facilitate deep natural language understanding. the meaning of a word is taken to be the entities, predications, presuppositions, and potential inferences that it adds to an ongoing situation. as words compose, the minimal model in the situation evolves to limit and direct inference. at this point we have developed our computational architecture and implemented it on real text. our focus has been on proving the feasibility of our design. ","349":"dense retrievers for open-domain question answering (odqa) have been shown to achieve impressive performance by training on large datasets of question-passage pairs. we investigate whether dense retrievers can be learned in a self-supervised fashion, and applied effectively without any annotations. we observe that existing pretrained models for retrieval struggle in this scenario, and propose a new pretraining scheme designed for retrieval: recurring span retrieval. we use recurring spans across passages in a document to create pseudo examples for contrastive learning. the resulting model -- spider -- performs surprisingly well without any examples on a wide range of odqa datasets, and is competitive with bm25, a strong sparse baseline. in addition, spider often outperforms strong baselines like dpr trained on natural questions, when evaluated on questions from other datasets. our hybrid retriever, which combines spider with bm25, improves over its components across all datasets, and is often competitive with in-domain dpr models, which are trained on tens of thousands of examples. ","350":"despite agreement on the importance of detecting out-of-distribution (ood) examples, there is little consensus on the formal definition of ood examples and how to best detect them. we categorize these examples by whether they exhibit a background shift or a semantic shift, and find that the two major approaches to ood detection, model calibration and density estimation (language modeling for text), have distinct behavior on these types of ood data. across 14 pairs of in-distribution and ood english natural language understanding datasets, we find that density estimation methods consistently beat calibration methods in background shift settings, while performing worse in semantic shift settings. in addition, we find that both methods generally fail to detect examples from challenge data, highlighting a weak spot for current methods. since no single method works well across all settings, our results call for an explicit definition of ood examples when evaluating different detection methods. ","351":"petroni et al. (2019) demonstrated that it is possible to retrieve world facts from a pre-trained language model by expressing them as cloze-style prompts and interpret the model's prediction accuracy as a lower bound on the amount of factual information it encodes. subsequent work has attempted to tighten the estimate by searching for better prompts, using a disjoint set of facts as training data. in this work, we make two complementary contributions to better understand these factual probing techniques. first, we propose optiprompt, a novel and efficient method which directly optimizes in continuous embedding space. we find this simple method is able to predict an additional 6.4% of facts in the lama benchmark. second, we raise a more important question: can we really interpret these probing results as a lower bound? is it possible that these prompt-search methods learn from the training data too? we find, somewhat surprisingly, that the training data used by these methods contains certain regularities of the underlying fact distribution, and all the existing prompt methods, including ours, are able to exploit them for better fact prediction. we conduct a set of control experiments to disentangle \"learning\" from \"learning to recall\", providing a more detailed picture of what different prompts can reveal about pre-trained language models. ","352":"spoken language understanding (slu) tasks involve mapping from speech audio signals to semantic labels. given the complexity of such tasks, good performance might be expected to require large labeled datasets, which are difficult to collect for each new task and domain. however, recent advances in self-supervised speech representations have made it feasible to consider learning slu models with limited labeled data. in this work we focus on low-resource spoken named entity recognition (ner) and address the question: beyond self-supervised pre-training, how can we use external speech and\/or text data that are not annotated for the task? we draw on a variety of approaches, including self-training, knowledge distillation, and transfer learning, and consider their applicability to both end-to-end models and pipeline (speech recognition followed by text ner model) approaches. we find that several of these approaches improve performance in resource-constrained settings beyond the benefits from pre-trained representations alone. compared to prior work, we find improved f1 scores of up to 16%. while the best baseline model is a pipeline approach, the best performance when using external data is ultimately achieved by an end-to-end model. we provide detailed comparisons and analyses, showing for example that end-to-end models are able to focus on the more ner-specific words. ","353":"interaction between caregivers and children plays a critical role in human language acquisition and development. given this observation, it is remarkable that explicit interaction plays little to no role in artificial language modeling -- which also targets the acquisition of human language, yet by artificial models. moreover, an interactive approach to language modeling has the potential to make language models substantially more versatile and to considerably impact downstream applications. motivated by these considerations, we pioneer the space of interactive language modeling. as a first contribution we present a road map in which we detail the steps that need to be taken towards interactive language modeling. we then lead by example and take the first steps on this road map, showing the initial feasibility of our approach. as such, this work aims to be the start of a larger research agenda on interactive language modeling. ","354":"recent breakthroughs in deep learning often rely on representation learning and knowledge transfer. in recent years, unsupervised and self-supervised techniques for learning speech representation were developed to foster automatic speech recognition. up to date, most of these approaches are task-specific and designed for within-task transfer learning between different datasets or setups of a particular task. in turn, learning task-independent representation of speech and cross-task applications of transfer learning remain less common. here, we introduce an encoder capturing word-level representations of speech for cross-task transfer learning. we demonstrate the application of the pre-trained encoder in four distinct speech and audio processing tasks: (i) speech enhancement, (ii) language identification, (iii) speech, noise, and music classification, and (iv) speaker identification. in each task, we compare the performance of our cross-task transfer learning approach to task-specific baselines. our results show that the speech representation captured by the encoder through the pre-training is transferable across distinct speech processing tasks and datasets. notably, even simple applications of our pre-trained encoder outperformed task-specific methods, or were comparable, depending on the task. ","355":"an effective method for cross-lingual transfer is to fine-tune a bilingual or multilingual model on a supervised dataset in one language and evaluating it on another language in a zero-shot manner. translating examples at training time or inference time are also viable alternatives. however, there are costs associated with these methods that are rarely addressed in the literature. in this work, we analyze cross-lingual methods in terms of their effectiveness (e.g., accuracy), development and deployment costs, as well as their latencies at inference time. our experiments on three tasks indicate that the best cross-lingual method is highly task-dependent. finally, by combining zero-shot and translation methods, we achieve the state-of-the-art in two of the three datasets used in this work. based on these results, we question the need for manually labeled training data in a target language. code and translated datasets are available at https:\/\/github.com\/unicamp-dl\/cross-lingual-analysis ","356":"query-focused summarization (qfs) requires generating a textual summary given a query using a set of relevant documents. however, in practice, such relevant documents are not readily available but should be first retrieved from a document collection. therefore, we show how to extend this task to make it more realistic. thereby the task setup also resembles the settings of the open-domain question answering task, where the answer is a summary of the top-retrieved documents. to address this extended task, we combine passage retrieval with text generation to produce the summary of the retrieved passages given the input query. we demonstrate the first evaluation results on the proposed task and show that a few samples are sufficient to fine-tune a large generative model with retrieved passages. ","357":"entity disambiguation (ed) is the last step of entity linking (el), when candidate entities are reranked according to the context they appear in. all datasets for training and evaluating models for el consist of convenience samples, such as news articles and tweets, that propagate the prior probability bias of the entity distribution towards more frequently occurring entities. it was previously shown that the performance of the el systems on such datasets is overestimated since it is possible to obtain higher accuracy scores by merely learning the prior. to provide a more adequate evaluation benchmark, we introduce the shadowlink dataset, which includes 16k short text snippets annotated with entity mentions. we evaluate and report the performance of popular el systems on the shadowlink benchmark. the results show a considerable difference in accuracy between more and less common entities for all of the el systems under evaluation, demonstrating the effects of prior probability bias and entity overshadowing. ","358":"bert-type structure has led to the revolution of vision-language pre-training and the achievement of state-of-the-art results on numerous vision-language downstream tasks. existing solutions dominantly capitalize on the multi-modal inputs with mask tokens to trigger mask-based proxy pre-training tasks (e.g., masked language modeling and masked object\/frame prediction). in this work, we argue that such masked inputs would inevitably introduce noise for cross-modal matching proxy task, and thus leave the inherent vision-language association under-explored. as an alternative, we derive a particular form of cross-modal proxy objective for video-language pre-training, i.e., contrastive cross-modal matching and denoising (coco). by viewing the masked frame\/word sequences as the noisy augmentation of primary unmasked ones, coco strengthens video-language association by simultaneously pursuing inter-modal matching and intra-modal denoising between masked and unmasked inputs in a contrastive manner. our coco proxy objective can be further integrated into any bert-type encoder-decoder structure for video-language pre-training, named as contrastive cross-modal bert (coco-bert). we pre-train coco-bert on tv dataset and a newly collected large-scale gif video dataset (action). through extensive experiments over a wide range of downstream tasks (e.g., cross-modal retrieval, video question answering, and video captioning), we demonstrate the superiority of coco-bert as a pre-trained structure. ","359":"we explore the correlation between the sentiment arcs of h. c. andersen's fairy tales and their popularity, measured as their average score on the platform goodreads. specifically, we do not conceive a story's overall sentimental trend as predictive \\textit{per se}, but we focus on its coherence and predictability over time as represented by the arc's hurst exponent. we find that degrading hurst values tend to imply degrading quality scores, while a hurst exponent between .55 and .65 might indicate a \"sweet spot\" for literary appreciation. ","360":"an increasing awareness of biased patterns in natural language processing resources, like bert, has motivated many metrics to quantify `bias' and `fairness'. but comparing the results of different metrics and the works that evaluate with such metrics remains difficult, if not outright impossible. we survey the existing literature on fairness metrics for pretrained language models and experimentally evaluate compatibility, including both biases in language models as in their downstream tasks. we do this by a mixture of traditional literature survey and correlation analysis, as well as by running empirical evaluations. we find that many metrics are not compatible and highly depend on (i) templates, (ii) attribute and target seeds and (iii) the choice of embeddings. these results indicate that fairness or bias evaluation remains challenging for contextualized language models, if not at least highly subjective. to improve future comparisons and fairness evaluations, we recommend avoiding embedding-based metrics and focusing on fairness evaluations in downstream tasks. ","361":"forms are a widespread type of template-based document used in a great variety of fields including, among others, administration, medicine, finance, or insurance. the automatic extraction of the information included in these documents is greatly demanded due to the increasing volume of forms that are generated in a daily basis. however, this is not a straightforward task when working with scanned forms because of the great diversity of templates with different location of form entities, and the quality of the scanned documents. in this context, there is a feature that is shared by all forms: they contain a collection of interlinked entities built as key-value (or label-value) pairs, together with other entities such as headers or images. in this work, we have tacked the problem of entity linking in forms by combining image processing techniques and a text classification model based on the bert architecture. this approach achieves state-of-the-art results with a f1-score of 0.80 on the funsd dataset, a 5% improvement regarding the best previous method. the code of this project is available at https:\/\/github.com\/mavillot\/funsd-entity-linking. ","362":"one of the core components of goal-oriented dialog systems is the task of intent detection. few-shot learning upon intent detection is challenging due to the scarcity of available annotated utterances. although recent works making use of metric-based and optimization-based methods have been proposed, the task is still challenging in large label spaces and much smaller number of shots. generalized few-shot learning is more difficult due to the presence of both novel and seen classes during the testing phase. in this work, we propose a simple and effective method based on natural language inference that not only tackles the problem of few shot intent detection, but also proves useful in zero-shot and generalized few shot learning problems. our extensive experiments on a number of natural language understanding (nlu) and spoken language understanding (slu) datasets show the effectiveness of our approach. in addition, we highlight the settings in which our nli based method outperforms the baselines by huge margins. ","363":"slanted news coverage, also called media bias, can heavily influence how news consumers interpret and react to the news. to automatically identify biased language, we present an exploratory approach that compares the context of related words. we train two word embedding models, one on texts of left-wing, the other on right-wing news outlets. our hypothesis is that a word's representations in both word embedding spaces are more similar for non-biased words than biased words. the underlying idea is that the context of biased words in different news outlets varies more strongly than the one of non-biased words, since the perception of a word as being biased differs depending on its context. while we do not find statistical significance to accept the hypothesis, the results show the effectiveness of the approach. for example, after a linear mapping of both word embeddings spaces, 31% of the words with the largest distances potentially induce bias. to improve the results, we find that the dataset needs to be significantly larger, and we derive further methodology as future research direction. to our knowledge, this paper presents the first in-depth look at the context of bias words measured by word embeddings. ","364":"recent works for open-domain question answering refer to an external knowledge base using a retriever model, optionally rerank the passages with a separate reranker model and generate an answer using an another reader model. despite performing related tasks, the models have separate parameters and are weakly-coupled during training. in this work, we propose casting the retriever and the reranker as hard-attention mechanisms applied sequentially within the transformer architecture and feeding the resulting computed representations to the reader. in this singular model architecture the hidden representations are progressively refined from the retriever to the reranker to the reader, which is more efficient use of model capacity and also leads to better gradient flow when we train it in an end-to-end manner. we also propose a pre-training methodology to effectively train this architecture. we evaluate our model on natural questions and triviaqa open datasets and for a fixed parameter budget, our model outperforms the previous state-of-the-art model by 1.0 and 0.7 exact match scores. ","365":"the recent explosion of question answering (qa) datasets and models has increased the interest in the generalization of models across multiple domains and formats by either training on multiple datasets or by combining multiple models. despite the promising results of multi-dataset models, some domains or qa formats may require specific architectures, and thus the adaptability of these models might be limited. in addition, current approaches for combining models disregard cues such as question-answer compatibility. in this work, we propose to combine expert agents with a novel, flexible, and training-efficient architecture that considers questions, answer predictions, and answer-prediction confidence scores to select the best answer among a list of answer candidates. through quantitative and qualitative experiments we show that our model i) creates a collaboration between agents that outperforms previous multi-agent and multi-dataset approaches in both in-domain and out-of-domain scenarios, ii) is highly data-efficient to train, and iii) can be adapted to any qa format. we release our code and a dataset of answer predictions from expert agents for 16 qa datasets to foster future developments of multi-agent systems on https:\/\/github.com\/ukplab\/metaqa. ","366":"answering natural language questions using information from tables (tableqa) is of considerable recent interest. in many applications, tables occur not in isolation, but embedded in, or linked to unstructured text. often, a question is best answered by matching its parts to either table cell contents or unstructured text spans, and extracting answers from either source. this leads to a new space of texttableqa problems that was introduced by the hybridqa dataset. existing adaptations of table representation to transformer-based reading comprehension (rc) architectures fail to tackle the diverse modalities of the two representations through a single system. training such systems is further challenged by the need for distant supervision. to reduce cognitive burden, training instances usually include just the question and answer, the latter matching multiple table rows and text passages. this leads to a noisy multi-instance training regime involving not only rows of the table, but also spans of linked text. we respond to these challenges by proposing mitqa, a new texttableqa system that explicitly models the different but closely-related probability spaces of table row selection and text span selection. our experiments indicate the superiority of our approach compared to recent baselines. the proposed method is currently at the top of the hybridqa leaderboard with a held out test set, achieving 21 % absolute improvement on both em and f1 scores over previous published results. ","367":"as many fine-tuned pre-trained language models~(plms) with promising performance are generously released, investigating better ways to reuse these models is vital as it can greatly reduce the retraining computational cost and the potential environmental side-effects. in this paper, we explore a novel model reuse paradigm, knowledge amalgamation~(ka) for plms. without human annotations available, ka aims to merge the knowledge from different teacher-plms, each of which specializes in a different classification problem, into a versatile student model. the achieve this, we design a model uncertainty--aware knowledge amalgamation~(muka) framework, which identifies the potential adequate teacher using monte-carlo dropout for approximating the golden supervision to guide the student. experimental results demonstrate that muka achieves substantial improvements over baselines on benchmark datasets. further analysis shows that muka can generalize well under several complicate settings with multiple teacher models, heterogeneous teachers, and even cross-dataset teachers. ","368":"we deal with a scenario of conversational search with mixed-initiative: namely user-asks system-answers, as well as system-asks (clarification questions) and user-answers. we focus on the task of selecting the next clarification question, given conversation context. our method leverages passage retrieval that is used both for an initial selection of relevant candidate clarification questions, as well as for fine-tuning two deep-learning models for re-ranking these candidates. we evaluated our method on two different use-cases. the first is an open domain conversational search in a large web collection. the second is a task-oriented customer-support setup. we show that our method performs well on both use-cases. ","369":"long story generation (lsg) is one of the coveted goals in natural language processing. different from most text generation tasks, lsg requires to output a long story of rich content based on a much shorter text input, and often suffers from information sparsity. in this paper, we propose \\emph{topnet} to alleviate this problem, by leveraging the recent advances in neural topic modeling to obtain high-quality skeleton words to complement the short input. in particular, instead of directly generating a story, we first learn to map the short text input to a low-dimensional topic distribution (which is pre-assigned by a topic model). based on this latent topic distribution, we can use the reconstruction decoder of the topic model to sample a sequence of inter-related words as a skeleton for the story. experiments on two benchmark datasets show that our proposed framework is highly effective in skeleton word selection and significantly outperforms the state-of-the-art models in both automatic evaluation and human evaluation. ","370":"recently, self-supervised pretraining has achieved impressive results in end-to-end (e2e) automatic speech recognition (asr). however, the dominant sequence-to-sequence (s2s) e2e model is still hard to fully utilize the self-supervised pre-training methods because its decoder is conditioned on acoustic representation thus cannot be pretrained separately. in this paper, we propose a pretrained transformer (preformer) s2s asr architecture based on hybrid ctc\/attention e2e models to fully utilize the pretrained acoustic models (ams) and language models (lms). in our framework, the encoder is initialized with a pretrained am (wav2vec2.0). the preformer leverages ctc as an auxiliary task during training and inference. furthermore, we design a one-cross decoder (ocd), which relaxes the dependence on acoustic representations so that it can be initialized with pretrained lm (distilgpt2). experiments are conducted on the aishell-1 corpus and achieve a $4.6\\%$ character error rate (cer) on the test set. compared with our vanilla hybrid ctc\/attention transformer baseline, our proposed ctc\/attention-based preformer yields $27\\%$ relative cer reduction. to the best of our knowledge, this is the first work to utilize both pretrained am and lm in a s2s asr system. ","371":"pre-trained language models (plms) have achieved great success in various natural language processing (nlp) tasks under the pre-training and fine-tuning paradigm. with large quantities of parameters, plms are computation-intensive and resource-hungry. hence, model pruning has been introduced to compress large-scale plms. however, most prior approaches only consider task-specific knowledge towards downstream tasks, but ignore the essential task-agnostic knowledge during pruning, which may cause catastrophic forgetting problem and lead to poor generalization ability. to maintain both task-agnostic and task-specific knowledge in our pruned model, we propose contrastive pruning (cap) under the paradigm of pre-training and fine-tuning. it is designed as a general framework, compatible with both structured and unstructured pruning. unified in contrastive learning, cap enables the pruned model to learn from the pre-trained model for task-agnostic knowledge, and fine-tuned model for task-specific knowledge. besides, to better retain the performance of the pruned model, the snapshots (i.e., the intermediate models at each pruning iteration) also serve as effective supervisions for pruning. our extensive experiments show that adopting cap consistently yields significant improvements, especially in extremely high sparsity scenarios. with only 3% model parameters reserved (i.e., 97% sparsity), cap successfully achieves 99.2% and 96.3% of the original bert performance in qqp and mnli tasks. in addition, our probing experiments demonstrate that the model pruned by cap tends to achieve better generalization ability. ","372":"we provide the first exploration of sentence embeddings from text-to-text transformers (t5). sentence embeddings are broadly useful for language processing tasks. while t5 achieves impressive performance on language tasks cast as sequence-to-sequence mapping problems, it is unclear how to produce sentence embeddings from encoder-decoder models. we investigate three methods for extracting t5 sentence embeddings: two utilize only the t5 encoder and one uses the full t5 encoder-decoder model. to support our investigation, we establish a new sentence representation transfer benchmark, sentglue, which extends the senteval toolkit to nine tasks from the glue benchmark. our encoder-only models outperforms sentence-bert and simcse sentence embeddings on both senteval and sentglue transfer tasks, including semantic textual similarity (sts). scaling up t5 from millions to billions of parameters is found to produce consistent further improvements. finally, our encoder-decoder method achieves a new state-of-the-art on sts when using sentence embeddings. our models are released at https:\/\/tfhub.dev\/google\/collections\/sentence-t5\/1. ","373":"compared with crosswoz (chinese) and multiwoz (english) dataset which have coarse-grained information, there is no dataset which handle fine-grained and hierarchical level information properly. in this paper, we publish a first cantonese knowledge-driven dialogue dataset for restaurant (kddres) in hong kong, which grounds the information in multi-turn conversations to one specific restaurant. our corpus contains 0.8k conversations which derive from 10 restaurants with various styles in different regions. in addition to that, we designed fine-grained slots and intents to better capture semantic information. the benchmark experiments and data statistic analysis show the diversity and rich annotations of our dataset. we believe the publish of kddres can be a necessary supplement of current dialogue datasets and more suitable and valuable for small and middle enterprises (smes) of society, such as build a customized dialogue system for each restaurant. the corpus and benchmark models are publicly available. ","374":"legal texts routinely use concepts that are difficult to understand. lawyers elaborate on the meaning of such concepts by, among other things, carefully investigating how have they been used in past. finding text snippets that mention a particular concept in a useful way is tedious, time-consuming, and, hence, expensive. we assembled a data set of 26,959 sentences, coming from legal case decisions, and labeled them in terms of their usefulness for explaining selected legal concepts. using the dataset we study the effectiveness of transformer-based models pre-trained on large language corpora to detect which of the sentences are useful. in light of models' predictions, we analyze various linguistic properties of the explanatory sentences as well as their relationship to the legal concept that needs to be explained. we show that the transformer-based models are capable of learning surprisingly sophisticated features and outperform the prior approaches to the task. ","375":"we present native chinese reader (ncr), a new machine reading comprehension (mrc) dataset with particularly long articles in both modern and classical chinese. ncr is collected from the exam questions for the chinese course in china's high schools, which are designed to evaluate the language proficiency of native chinese youth. existing chinese mrc datasets are either domain-specific or focusing on short contexts of a few hundreds of characters in modern chinese only. by contrast, ncr contains 8390 documents with an average length of 1024 characters covering a wide range of chinese writing styles, including modern articles, classical literature and classical poetry. a total of 20477 questions on these documents also require strong reasoning abilities and common sense to figure out the correct answers. we implemented multiple baseline models using popular chinese pre-trained models and additionally launched an online competition using our dataset to examine the limit of current methods. the best model achieves 59% test accuracy while human evaluation shows an average accuracy of 79%, which indicates a significant performance gap between current mrc models and native chinese speakers. we release the dataset at https:\/\/sites.google.com\/view\/native-chinese-reader\/. ","376":"we study the problem of online learning with human feedback in the human-in-the-loop machine translation, in which the human translators revise the machine-generated translations and then the corrected translations are used to improve the neural machine translation (nmt) system. however, previous methods require online model updating or additional translation memory networks to achieve high-quality performance, making them inflexible and inefficient in practice. in this paper, we propose a novel non-parametric online learning method without changing the model structure. this approach introduces two k-nearest-neighbor (knn) modules: one module memorizes the human feedback, which is the correct sentences provided by human translators, while the other balances the usage of the history human feedback and original nmt models adaptively. experiments conducted on emea and jrc-acquis benchmarks demonstrate that our proposed method obtains substantial improvements on translation accuracy and achieves better adaptation performance with less repeating human correction operations. ","377":"intent understanding plays an important role in dialog systems, and is typically formulated as a supervised learning problem. however, it is challenging and time-consuming to design the intents for a new domain from scratch, which usually requires a lot of manual effort of domain experts. this paper presents an unsupervised two-stage approach to discover intents and generate meaningful intent labels automatically from a collection of unlabeled utterances in a domain. in the first stage, we aim to generate a set of semantically coherent clusters where the utterances within each cluster convey the same intent. we obtain the utterance representation from various pre-trained sentence embeddings and present a metric of balanced score to determine the optimal number of clusters in k-means clustering for balanced datasets. in the second stage, the objective is to generate an intent label automatically for each cluster. we extract the action-object pair from each utterance using a dependency parser and take the most frequent pair within each cluster, e.g., book-restaurant, as the generated intent label. we empirically show that the proposed unsupervised approach can generate meaningful intent labels automatically and achieve high precision and recall in utterance clustering and intent discovery. ","378":"the problem of knowledge-based visual question answering involves answering questions that require external knowledge in addition to the content of the image. such knowledge typically comes in various forms, including visual, textual, and commonsense knowledge. using more knowledge sources increases the chance of retrieving more irrelevant or noisy facts, making it challenging to comprehend the facts and find the answer. to address this challenge, we propose multi-modal answer validation using external knowledge (mavex), where the idea is to validate a set of promising answer candidates based on answer-specific knowledge retrieval. instead of searching for the answer in a vast collection of often irrelevant facts as most existing approaches do, mavex aims to learn how to extract relevant knowledge from noisy sources, which knowledge source to trust for each answer candidate, and how to validate the candidate using that source. our multi-modal setting is the first to leverage external visual knowledge (images searched using google), in addition to textual knowledge in the form of wikipedia sentences and conceptnet concepts. our experiments with ok-vqa, a challenging knowledge-based vqa dataset, demonstrate that mavex achieves new state-of-the-art results. our code is available at https:\/\/github.com\/jialinwu17\/mavex ","379":"we propose to take on the problem ofword sense disambiguation (wsd). in language, words of the same form can take different meanings depending on context. while humans easily infer the meaning or gloss of such words by their context, machines stumble on this task.as such, we intend to replicated and expand upon the results of huang et al.glossbert, a model which they design to disambiguate these words (huang et al.,2019). specifically, we propose the following augmentations: data-set tweaking(alpha hyper-parameter), ensemble methods, and replacement of bert with bart andalbert. the following github repository contains all code used in this report, which extends on the code made available by huang et al. ","380":"user queries for a real-world dialog system may sometimes fall outside the scope of the system's capabilities, but appropriate system responses will enable smooth processing throughout the human-computer interaction. this paper is concerned with the user's intent, and focuses on out-of-scope intent classification in dialog systems. although user intents are highly correlated with the application domain, few studies have exploited such correlations for intent classification. rather than developing a two-stage approach that first classifies the domain and then the intent, we propose a hierarchical multi-task learning approach based on a joint model to classify domain and intent simultaneously. novelties in the proposed approach include: (1) sharing supervised out-of-scope signals in joint modeling of domain and intent classification to replace a two-stage pipeline; and (2) introducing a hierarchical model that learns the intent and domain representations in the higher and lower layers respectively. experiments show that the model outperforms existing methods in terms of accuracy, out-of-scope recall and f1. additionally, threshold-based post-processing further improves performance by balancing precision and recall in intent classification. ","381":"this paper describes bacon, a basic prototype of an automatic poetry generator with author linguistic style transfer. it combines concepts and techniques from finite state machinery, probabilistic models, artificial neural networks and deep learning, to write original poetry with rich aesthetic-qualities in the style of any given author. extrinsic evaluation of the output generated by bacon shows that participants were unable to tell the difference between human and ai-generated poems in any statistically significant way. ","382":"natural language processing (nlp) has become one of the leading application areas in the current artificial intelligence boom. transfer learning has enabled large deep learning neural networks trained on the language modeling task to vastly improve performance in almost all language tasks. interestingly, when the models are trained with data that includes software code, they demonstrate remarkable abilities in generating functioning computer code from natural language specifications. we argue that this creates a conundrum for claims that neural models provide an alternative theory to generative phrase structure grammars in explaining how language works. since the syntax of programming languages is determined by phrase structure grammars, successful neural models are apparently uninformative about the theoretical foundations of programming languages, and by extension, natural languages. we argue that the term language model is misleading because deep learning models are not theoretical models of language and propose the adoption of corpus model instead, which better reflects the genesis and contents of the model. ","383":"social networks have become one of the main information channels for human beings due to the immediate and social interactivity they offer, allowing in some cases to publish what each user considers relevant. this has brought with it the generation of false news or fake news, publications that only seek to generate uncertainty, misinformation or skew the opinion of readers. it has been shown that the human being is not capable of fully identifying whether an article is really a fact or a fake news, due to this it is that models arise that seek to characterize and identify articles based on data mining and machine learning. this article proposes a three-layer framework, the main objective of which is to characterize the emotions present in fake news and to be a tool for future work that identifies the emotional state and intentional state of the public. ","384":"in recent years tremendous efforts have been done to advance the state of the art for natural language processing (nlp) and audio recognition. however, these efforts often translated in increased power consumption and memory requirements for bigger and more complex models. these solutions falls short of the constraints of iot devices which need low power, low memory efficient computation, and therefore they fail to meet the growing demand of efficient edge computing. neuromorphic systems have proved to be excellent candidates for low-power low-latency computation in a multitude of applications. for this reason we present a neuromorphic architecture, capable of unsupervised auditory feature recognition. we then validate the network on a subset of google's speech commands dataset. ","385":"in this paper, we use a large-scale play scripts dataset to propose the novel task of theatrical cue generation from dialogues. using over one million lines of dialogue and cues, we approach the problem of cue generation as a controlled text generation task, and show how cues can be used to enhance the impact of dialogue using a language model conditioned on a dialogue\/cue discriminator. in addition, we explore the use of topic keywords and emotions for controlled text generation. extensive quantitative and qualitative experiments show that language models can be successfully used to generate plausible and attribute-controlled texts in highly specialised domains such as play scripts. supporting materials can be found at: https:\/\/catlab-team.github.io\/cuegen. ","386":"scaling language models with more data, compute and parameters has driven significant progress in natural language processing. for example, thanks to scaling, gpt-3 was able to achieve strong results on in-context learning tasks. however, training these large dense models requires significant amounts of computing resources. in this paper, we propose and develop a family of language models named glam (generalist language model), which uses a sparsely activated mixture-of-experts architecture to scale the model capacity while also incurring substantially less training cost compared to dense variants. the largest glam has 1.2 trillion parameters, which is approximately 7x larger than gpt-3. it consumes only 1\/3 of the energy used to train gpt-3 and requires half of the computation flops for inference, while still achieving better overall zero-shot and one-shot performance across 29 nlp tasks. ","387":"knowledge-based visual question answering (kbvqa) is a bi-modal task requiring external world knowledge in order to correctly answer a text question and associated image. recent single modality text work has shown knowledge injection into pre-trained language models, specifically entity enhanced knowledge graph embeddings, can improve performance on downstream entity-centric tasks. in this work, we empirically study how and whether such methods, applied in a bi-modal setting, can improve an existing vqa system's performance on the kbvqa task. we experiment with two large publicly available vqa datasets, (1) kvqa which contains mostly rare wikipedia entities and (2) okvqa which is less entity-centric and more aligned with common sense reasoning. both lack explicit entity spans and we study the effect of different weakly supervised and manual methods for obtaining them. additionally we analyze how recently proposed bi-modal and single modal attention explanations are affected by the incorporation of such entity enhanced representations. our results show substantial improved performance on the kbvqa task without the need for additional costly pre-training and we provide insights for when entity knowledge injection helps improve a model's understanding. we provide code and enhanced datasets for reproducibility. ","388":"the significance of social media has increased manifold in the past few decades as it helps people from even the most remote corners of the world to stay connected. with the advent of technology, digital media has become more relevant and widely used than ever before and along with this, there has been a resurgence in the circulation of fake news and tweets that demand immediate attention. in this paper, we describe a novel fake news detection system that automatically identifies whether a news item is \"real\" or \"fake\", as an extension of our work in the constraint covid-19 fake news detection in english challenge. we have used an ensemble model consisting of pre-trained models followed by a statistical feature fusion network , along with a novel heuristic algorithm by incorporating various attributes present in news items or tweets like source, username handles, url domains and authors as statistical feature. our proposed framework have also quantified reliable predictive uncertainty along with proper class output confidence level for the classification task. we have evaluated our results on the covid-19 fake news dataset and fakenewsnet dataset to show the effectiveness of the proposed algorithm on detecting fake news in short news content as well as in news articles. we obtained a best f1-score of 0.9892 on the covid-19 dataset, and an f1-score of 0.9073 on the fakenewsnet dataset. ","389":"there has been a lot of interest in understanding what information is captured by hidden representations of language models (lms). typically, interpretation methods i) do not guarantee that the model actually uses the encoded information, and ii) do not discover small subsets of neurons responsible for a considered phenomenon. inspired by causal mediation analysis, we propose a method that discovers within a neural lm a small subset of neurons responsible for a particular linguistic phenomenon, i.e., subsets causing a change in the corresponding token emission probabilities. we use a differentiable relaxation to approximately search through the combinatorial space. an $l_0$ regularization term ensures that the search converges to discrete and sparse solutions. we apply our method to analyze subject-verb number agreement and gender bias detection in lstms. we observe that it is fast and finds better solutions than the alternative (reinforce). our experiments confirm that each of these phenomenons is mediated through a small subset of neurons that do not play any other discernible role. ","390":"keyphrase generation aims at generating phrases (keyphrases) that best describe a given document. in scholarly domains, current approaches to this task are neural approaches and have largely worked with only the title and abstract of the articles. in this work, we explore whether the integration of additional data from semantically similar articles or from the full text of the given article can be helpful for a neural keyphrase generation model. we discover that adding sentences from the full text particularly in the form of summary of the article can significantly improve the generation of both types of keyphrases that are either present or absent from the title and abstract. the experimental results on the three acclaimed models along with one of the latest transformer models suitable for longer documents, longformer encoder-decoder (led) validate the observation. we also present a new large-scale scholarly dataset fulltextkp for keyphrase generation, which we use for our experiments. unlike prior large-scale datasets, fulltextkp includes the full text of the articles alongside title and abstract. we will release the source code to stimulate research on the proposed ideas. ","391":"text classification is one of the fundamental tasks in natural language processing to label an open-ended text and is useful for various applications such as sentiment analysis. in this paper, we discuss various classification approaches for khmer text, ranging from a classical tf-idf algorithm with support vector machine classifier to modern word embedding-based neural network classifiers including linear layer model, recurrent neural network and convolutional neural network. a khmer word embedding model is trained on a 30-million-khmer-word corpus to construct word vector representations that are used to train three different neural network classifiers. we evaluate the performance of different approaches on a news article dataset for both multi-class and multi-label text classification tasks. the result suggests that neural network classifiers using a word embedding model consistently outperform the traditional classifier using tf-idf. the recurrent neural network classifier provides a slightly better result compared to the convolutional network and the linear layer network. ","392":"recent years have seen significant advances in end-to-end (e2e) spoken language understanding (slu) systems, which directly predict intents and slots from spoken audio. while dialogue history has been exploited to improve conventional text-based natural language understanding systems, current e2e slu approaches have not yet incorporated such critical contextual signals in multi-turn and task-oriented dialogues. in this work, we propose a contextual e2e slu model architecture that uses a multi-head attention mechanism over encoded previous utterances and dialogue acts (actions taken by the voice assistant) of a multi-turn dialogue. we detail alternative methods to integrate these contexts into the state-ofthe-art recurrent and transformer-based models. when applied to a large de-identified dataset of utterances collected by a voice assistant, our method reduces average word and semantic error rates by 10.8% and 12.6%, respectively. we also present results on a publicly available dataset and show that our method significantly improves performance over a noncontextual baseline ","393":"recent work on enhancing bert-based language representation models with knowledge graphs (kgs) has promising results on multiple nlp tasks. state-of-the-art approaches typically integrate the original input sentences with triples in kgs, and feed the combined representation into a bert model. however, as the sequence length of a bert model is limited, the framework can not contain too much knowledge besides the original input sentences and is thus forced to discard some knowledge. the problem is especially severe for those downstream tasks that input is a long paragraph or even a document, such as qa or reading comprehension tasks. to address the problem, we propose roof-bert, a model with two underlying berts and a fusion layer on them. one of the underlying berts encodes the knowledge resources and the other one encodes the original input sentences, and the fusion layer like a roof integrates both berts' encodings. experiment results on qa task reveal the effectiveness of the proposed model. ","394":"fact-checking systems have become important tools to verify fake and misguiding news. these systems become more trustworthy when human-readable explanations accompany the veracity labels. however, manual collection of such explanations is expensive and time-consuming. recent works frame explanation generation as extractive summarization, and propose to automatically select a sufficient subset of the most important facts from the ruling comments (rcs) of a professional journalist to obtain fact-checking explanations. however, these explanations lack fluency and sentence coherence. in this work, we present an iterative edit-based algorithm that uses only phrase-level edits to perform unsupervised post-editing of disconnected rcs. to regulate our editing algorithm, we use a scoring function with components including fluency and semantic preservation. in addition, we show the applicability of our approach in a completely unsupervised setting. we experiment with two benchmark datasets, liar-plus and pubhealth. we show that our model generates explanations that are fluent, readable, non-redundant, and cover important information for the fact check. ","395":"named entity recognition (ner) is an important task that aims to resolve universal categories of named entities, e.g., persons, locations, organizations, and times. despite its common and viable use in many use cases, ner is barely applicable in domains where general categories are suboptimal, such as engineering or medicine. to facilitate ner of domain-specific types, we propose anea, an automated (named) entity annotator to assist human annotators in creating domain-specific ner corpora for german text collections when given a set of domain-specific texts. in our evaluation, we find that anea automatically identifies terms that best represent the texts' content, identifies groups of coherent terms, and extracts and assigns descriptive labels to these groups, i.e., annotates text datasets into the domain (named) entities. ","396":"exemplar-based generative models for open-domain conversation produce responses based on the exemplars provided by the retriever, taking advantage of generative models and retrieval models. however, they often ignore the retrieved exemplars while generating responses or produce responses over-fitted to the retrieved exemplars. in this paper, we argue that these drawbacks are derived from the one-to-many problem of the open-domain conversation. when the retrieved exemplar is relevant to the given context yet significantly different from the gold response, the exemplar-based generative models are trained to ignore the exemplar since the exemplar is not helpful for generating the gold response. on the other hand, when the retrieved exemplar is lexically similar to the gold response, the generative models are trained to rely on the exemplar highly. therefore, we propose a training method selecting exemplars that are semantically relevant to the gold response but lexically distanced from the gold response to mitigate the above disadvantages. in the training phase, our proposed training method first uses the gold response instead of dialogue context as a query to select exemplars that are semantically relevant to the gold response. and then, it eliminates the exemplars that lexically resemble the gold responses to alleviate the dependency of the generative models on that exemplars. the remaining exemplars could be irrelevant to the given context since they are searched depending on the gold response. thus, our proposed training method further utilizes the relevance scores between the given context and the exemplars to penalize the irrelevant exemplars. extensive experiments demonstrate that our proposed training method alleviates the drawbacks of the existing exemplar-based generative models and significantly improves the performance in terms of appropriateness and informativeness. ","397":"existing summarization systems mostly generate summaries purely relying on the content of the source document. however, even for humans, we usually need some references or exemplars to help us fully understand the source document and write summaries in a particular format. but how to find the high-quality exemplars and incorporate them into summarization systems is still challenging and worth exploring. in this paper, we propose retrievalsum, a novel retrieval enhanced abstractive summarization framework consisting of a dense retriever and a summarizer. at first, several closely related exemplars are retrieved as supplementary input to help the generation model understand the text more comprehensively. furthermore, retrieved exemplars can also play a role in guiding the model to capture the writing style of a specific corpus. we validate our method on a wide range of summarization datasets across multiple domains and two backbone models: bert and bart. results show that our framework obtains significant improvement by 1.38~4.66 in rouge-1 score when compared with the powerful pre-trained models, and achieve new state-of-the-art on billsum. human evaluation demonstrates that our retrieval enhanced model can better capture the domain-specific writing style. ","398":"personal narratives (pn) - spoken or written - are recollections of facts, people, events, and thoughts from one's own experience. emotion recognition and sentiment analysis tasks are usually defined at the utterance or document level. however, in this work, we focus on emotion carriers (ec) defined as the segments (speech or text) that best explain the emotional state of the narrator (\"loss of father\", \"made me choose\"). once extracted, such ec can provide a richer representation of the user state to improve natural language understanding and dialogue modeling. in previous work, it has been shown that ec can be identified using lexical features. however, spoken narratives should provide a richer description of the context and the users' emotional state. in this paper, we leverage word-based acoustic and textual embeddings as well as early and late fusion techniques for the detection of ecs in spoken narratives. for the acoustic word-level representations, we use residual neural networks (resnet) pretrained on separate speech emotion corpora and fine-tuned to detect ec. experiments with different fusion and system combination strategies show that late fusion leads to significant improvements for this task. ","399":"language is an essential factor of emancipation. unfortunately, most of the more than 2,000 african languages are low-resourced. the community has recently used machine translation to revive and strengthen several african languages. however, the trained models are often bilingual, resulting in a potentially exponential number of models to train and maintain to cover all possible translation directions. additionally, bilingual models do not leverage the similarity between some of the languages. consequently, multilingual neural machine translation (nmt) is gaining considerable interest, especially for low-resourced languages. nevertheless, its adoption by the community is still limited. this paper introduces english2gbe, a multilingual nmt model capable of translating from english to ewe or fon. using the bleu, chrf, and ter scores computed with the sacrebleu (post, 2018) package for reproducibility, we show that english2gbe outperforms bilingual models (english to ewe and english to fon) and gives state-of-the-art results on the jw300 benchmark for fon established by nekoto et al. (2020). we hope this work will contribute to the massive adoption of multilingual models inside the community. our code is made accessible from github. ","400":"the colbert model has recently been proposed as an effective bert based ranker. by adopting a late interaction mechanism, a major advantage of colbert is that document representations can be precomputed in advance. however, the big downside of the model is the index size, which scales linearly with the number of tokens in the collection. in this paper, we study various designs for colbert models in order to attack this problem. while compression techniques have been explored to reduce the index size, in this paper we study token pruning techniques for colbert. we compare simple heuristics, as well as a single layer of attention mechanism to select the tokens to keep at indexing time. our experiments show that colbert indexes can be pruned up to 30\\% on the ms marco passage collection without a significant drop in performance. finally, we experiment on ms marco documents, which reveal several challenges for such mechanism. ","401":"existing human mobility forecasting models follow the standard design of the time-series prediction model which takes a series of numerical values as input to generate a numerical value as a prediction. although treating this as a regression problem seems straightforward, incorporating various contextual information such as the semantic category information of each place-of-interest (poi) is a necessary step, and often the bottleneck, in designing an effective mobility prediction model. as opposed to the typical approach, we treat forecasting as a translation problem and propose a novel forecasting through a language generation pipeline. the paper aims to address the human mobility forecasting problem as a language translation task in a sequence-to-sequence manner. a mobility-to-language template is first introduced to describe the numerical mobility data as natural language sentences. the core intuition of the human mobility forecasting translation task is to convert the input mobility description sentences into a future mobility description from which the prediction target can be obtained. under this pipeline, a two-branch network, shift (translating human mobility forecasting), is designed. specifically, it consists of one main branch for language generation and one auxiliary branch to directly learn mobility patterns. during the training, we develop a momentum mode for better connecting and training the two branches. extensive experiments on three real-world datasets demonstrate that the proposed shift is effective and presents a new revolutionary approach to forecasting human mobility. ","402":"fake news, misinformation, and unverifiable facts on social media platforms propagate disharmony and affect society, especially when dealing with an epidemic like covid-19. the task of fake news detection aims to tackle the effects of such misinformation by classifying news items as fake or real. in this paper, we propose a novel approach that improves over the current automatic fake news detection approaches by automatically gathering evidence for each claim. our approach extracts supporting evidence from the web articles and then selects appropriate text to be treated as evidence sets. we use a pre-trained summarizer on these evidence sets and then use the extracted summary as supporting evidence to aid the classification task. our experiments, using both machine learning and deep learning-based methods, help perform an extensive evaluation of our approach. the results show that our approach outperforms the state-of-the-art methods in fake news detection to achieve an f1-score of 99.25 over the dataset provided for the constraint-2021 shared task. we also release the augmented dataset, our code and models for any further research. ","403":"unified opinion role labeling (orl) aims to detect all possible opinion structures of 'opinion-holder-target' in one shot, given a text. the existing transition-based unified method, unfortunately, is subject to longer opinion terms and fails to solve the term overlap issue. current top performance has been achieved by employing the span-based graph model, which however still suffers from both high model complexity and insufficient interaction among opinions and roles. in this work, we investigate a novel solution by revisiting the transition architecture, and augmenting it with a pointer network (pointnet). the framework parses out all opinion structures in linear-time complexity, meanwhile breaks through the limitation of any length of terms with pointnet. to achieve the explicit opinion-role interactions, we further propose a unified dependency-opinion graph (udog), co-modeling the syntactic dependency structure and the partial opinion-role structure. we then devise a relation-centered graph aggregator (rcga) to encode the multi-relational udog, where the resulting high-order representations are used to promote the predictions in the vanilla transition system. our model achieves new state-of-the-art results on the mpqa benchmark. analyses further demonstrate the superiority of our methods on both efficacy and efficiency. ","404":"neural information retrieval models hold the promise to replace lexical matching models, e.g. bm25, in modern search engines. while their capabilities have fully shone on in-domain datasets like ms marco, they have recently been challenged on out-of-domain zero-shot settings (beir benchmark), questioning their actual generalization capabilities compared to bag-of-words approaches. particularly, we wonder if these shortcomings could (partly) be the consequence of the inability of neural ir models to perform lexical matching off-the-shelf. in this work, we propose a measure of discrepancy between the lexical matching performed by any (neural) model and an 'ideal' one. based on this, we study the behavior of different state-of-the-art neural ir models, focusing on whether they are able to perform lexical matching when it's actually useful, i.e. for important terms. overall, we show that neural ir models fail to properly generalize term importance on out-of-domain collections or terms almost unseen during training ","405":"deep neural networks are effective feature extractors but they are prohibitively large for deployment scenarios. due to the huge number of parameters, interpretability of parameters in different layers is not straight-forward. this is why neural networks are sometimes considered black boxes. although simpler models are easier to explain, finding them is not easy. if found, a sparse network that can fit to a data from scratch would help to interpret parameters of a neural network. to this end, lottery ticket hypothesis states that typical dense neural networks contain a small sparse sub-network that can be trained to a reach similar test accuracy in an equal number of steps. the goal of this work is to assess whether such a trainable subnetwork exists for natural language models (nlm)s. to achieve this goal we will review state-of-the-art compression techniques such as quantization, knowledge distillation, and pruning. ","406":"multilingual speakers tend to alternate between languages within a conversation, a phenomenon referred to as \"code-switching\" (cs). cs is a complex phenomenon that not only encompasses linguistic challenges, but also contains a great deal of complexity in terms of its dynamic behaviour across speakers. this dynamic behaviour has been studied by sociologists and psychologists, identifying factors affecting cs. in this paper, we provide an empirical user study on arabic-english cs, where we show the correlation between users' cs frequency and character traits. we use machine learning (ml) to validate the findings, informing and confirming existing theories. the predictive models were able to predict users' cs frequency with an accuracy higher than 55%, where travel experiences and personality traits played the biggest role in the modeling process. ","407":"in this thesis we present a semantic representation formalism based on directed graphs and explore its linguistic adequacy and explanatory benefits in the semantics of plurality and quantification. our graph language covers the essentials of natural language semantics using only monadic second-order variables. we define its model-theoretical interpretation in terms of graph traversal, where the relative scope of variables arises from their order of valuation. we present a unification-based mechanism for constructing semantic graphs at a simple syntax-semantics interface, where syntax as a partition function on discourse referents is implemented with categorial grammars by establishing a partly deterministic relation between semantics and syntactic distribution. this mechanism is automated to facilitate future exploration. the present graph formalism is applied to linguistic issues in distributive predication, cross-categorial conjunction, and scope permutation of quantificational expressions, including the exceptional scoping behaviors of indefinites. ","408":"pre-trained language models (plm) have marked a huge leap in neural dialogue modeling. while plms are pre-trained on large-scale text corpora, they are usually fine-tuned on scarce dialogue data with specific domain knowledge and dialogue styles. however, tailoring the language models while fully utilizing prior knowledge in large pre-trained models remains a challenge. in this paper, we present a novel approach for pre-trained dialogue modeling that casts the dialogue generation problem as a prompt-learning task. instead of fine-tuning on limited dialogue data, our approach, dialogprompt, learns continuous prompt embeddings optimized for dialogue contexts, which appropriately elicit knowledge from the large pre-trained model. to encourage the model to better utilize the prompt embeddings, the prompt encoders are designed to be dynamically generated based on the dialogue context. experiments on popular conversation datasets show that our approach significantly outperforms the fine-tuning baseline and the generic prompt-learning methods. furthermore, human evaluations strongly support the superiority of dialogprompt in regard to response generation quality. ","409":"recent advances in pre-trained language models have significantly improved neural response generation. however, existing methods usually view the dialogue context as a linear sequence of tokens and learn to generate the next word through token-level self-attention. such token-level encoding hinders the exploration of discourse-level coherence among utterances. this paper presents dialogbert, a novel conversational response generation model that enhances previous plm-based dialogue models. dialogbert employs a hierarchical transformer architecture. to efficiently capture the discourse-level coherence among utterances, we propose two training objectives, including masked utterance regression and distributed utterance order ranking in analogy to the original bert training. experiments on three multi-turn conversation datasets show that our approach remarkably outperforms the baselines, such as bart and dialogpt, in terms of quantitative evaluation. the human evaluation suggests that dialogbert generates more coherent, informative, and human-like responses than the baselines with significant margins. ","410":"while in real life everyone behaves themselves at least to some extent, it is much more difficult to expect people to behave themselves on the internet, because there are few checks or consequences for posting something toxic to others. yet, for people on the other side, toxic texts often lead to serious psychological consequences. detecting such toxic texts is challenging. in this paper, we attempt to build a toxicity detector using machine learning methods including cnn, naive bayes model, as well as lstm. while there has been numerous groundwork laid by others, we aim to build models that provide higher accuracy than the predecessors. we produced very high accuracy models using lstm and cnn, and compared them to the go-to solutions in language processing, the naive bayes model. a word embedding approach is also applied to empower the accuracy of our models. ","411":"conversational information seeking (cis) is a relatively new research area within conversational ai that attempts to seek information from end-users in order to understand and satisfy users' needs. if realized, such a system has far-reaching benefits in the real world; for example, a cis system can assist clinicians in pre-screening or triaging patients in healthcare. a key open sub-problem in cis that remains unaddressed in the literature is generating information seeking questions (isqs) based on a short initial query from the end-user. to address this open problem, we propose information seeking question generator (iseeq), a novel approach for generating isqs from just a short user query, given a large text corpus relevant to the user query. firstly, iseeq uses a knowledge graph to enrich the user query. secondly, iseeq uses the knowledge-enriched query to retrieve relevant context passages to ask coherent isqs adhering to a conceptual flow. thirdly, iseeq introduces a new deep generative-adversarial reinforcement learning-based approach for generating isqs. we show that iseeq can generate high-quality isqs to promote the development of cis agents. iseeq significantly outperforms comparable baselines on five isq evaluation metrics across four datasets having user queries from diverse domains. further, we argue that iseeq is transferable across domains for generating isqs, as it shows the acceptable performance when trained and tested on different pairs of domains. the qualitative human evaluation confirms iseeq-generated isqs are comparable in quality to human-generated questions and outperform the best comparable baseline. ","412":"given the fact of a case, legal judgment prediction (ljp) involves a series of sub-tasks such as predicting violated law articles, charges and term of penalty. we propose leveraging a unified text-to-text transformer for ljp, where the dependencies among sub-tasks can be naturally established within the auto-regressive decoder. compared with previous works, it has three advantages: (1) it fits in the pretraining pattern of masked language models, and thereby can benefit from the semantic prompts of each sub-task rather than treating them as atomic labels, (2) it utilizes a single unified architecture, enabling full parameter sharing across all sub-tasks, and (3) it can incorporate both classification and generative sub-tasks. we show that this unified transformer, albeit pretrained on general-domain text, outperforms pretrained models tailored specifically for the legal domain. through an extensive set of experiments, we find that the best order to capture dependencies is different from human intuitions, and the most reasonable logical order for humans can be sub-optimal for the model. we further include two more auxiliary tasks: court view generation and article content prediction, showing they can not only improve the prediction accuracy, but also provide interpretable explanations for model outputs even when an error is made. with the best configuration, our model outperforms both previous sota and a single-tasked version of the unified transformer by a large margin. ","413":"building a socially intelligent agent involves many challenges, one of which is to teach the agent to speak guided by its value like a human. however, value-driven chatbots are still understudied in the area of dialogue systems. most existing datasets focus on commonsense reasoning or social norm modeling. in this work, we present a new large-scale human value dataset called valuenet, which contains human attitudes on 21,374 text scenarios. the dataset is organized in ten dimensions that conform to the basic human value theory in intercultural research. we further develop a transformer-based value regression model on valuenet to learn the utility distribution. comprehensive empirical results show that the learned value model could benefit a wide range of dialogue tasks. for example, by teaching a generative agent with reinforcement learning and the rewards from the value model, our method attains state-of-the-art performance on the personalized dialog generation dataset: persona-chat. with values as additional features, existing emotion recognition models enable capturing rich human emotions in the context, which further improves the empathetic response generation performance in the empatheticdialogues dataset. to the best of our knowledge, valuenet is the first large-scale text dataset for human value modeling, and we are the first one trying to incorporate a value model into emotionally intelligent dialogue systems. the dataset is available at https:\/\/liang-qiu.github.io\/valuenet\/. ","414":"here we study the problem of matched record clustering in unsupervised entity resolution. we build upon a state-of-the-art probabilistic framework named the data washing machine (dwm). we introduce a graph-based hierarchical 2-step record clustering method (gdwm) that first identifies large, connected components or, as we call them, soft clusters in the matched record pairs using a graph-based transitive closure algorithm utilized in the dwm. that is followed by breaking down the discovered soft clusters into more precise entity clusters in a hierarchical manner using an adapted graph-based modularity optimization method. our approach provides several advantages over the original implementation of the dwm, mainly a significant speed-up, increased precision, and overall increased f1 scores. we demonstrate the efficacy of our approach using experiments on multiple synthetic datasets. our results also provide evidence of the utility of graph theory-based algorithms despite their sparsity in the literature on unsupervised entity resolution. ","415":"this paper presents our latest effort on improving code-switching language models that suffer from data scarcity. we investigate methods to augment code-switching training text data by artificially generating them. concretely, we propose a cycle-consistent adversarial networks based framework to transfer monolingual text into code-switching text, considering code-switching as a speaking style. our experimental results on the seame corpus show that utilising artificially generated code-switching text data improves consistently the language model as well as the automatic speech recognition performance. ","416":"the zurich cognitive language processing corpus (zuco) provides eye-tracking and eeg signals from two reading paradigms, normal reading and task-specific reading. we analyze whether machine learning methods are able to classify these two tasks using eye-tracking and eeg features. we implement models with aggregated sentence-level features as well as fine-grained word-level features. we test the models in within-subject and cross-subject evaluation scenarios. all models are tested on the zuco 1.0 and zuco 2.0 data subsets, which are characterized by differing recording procedures and thus allow for different levels of generalizability. finally, we provide a series of control experiments to analyze the results in more detail. ","417":"this paper presents our latest investigations on improving automatic speech recognition for noisy speech via speech enhancement. we propose a novel method named multi-discriminators cyclegan to reduce noise of input speech and therefore improve the automatic speech recognition performance. our proposed method leverages the cyclegan framework for speech enhancement without any parallel data and improve it by introducing multiple discriminators that check different frequency areas. furthermore, we show that training multiple generators on homogeneous subset of the training data is better than training one generator on all the training data. we evaluate our method on chime-3 data set and observe up to 10.03% relatively wer improvement on the development set and up to 14.09% on the evaluation set. ","418":"auto-regressive neural sequence models have been shown to be effective across text generation tasks. however, their left-to-right decoding order prevents generation from being parallelized. insertion transformer (stern et al., 2019) is an attractive alternative that allows outputting multiple tokens in a single generation step. nevertheless, due to the incompatibility of absolute positional encoding and insertion-based generation schemes, it needs to refresh the encoding of every token in the generated partial hypotheses at each step, which could be costly. we design a novel incremental positional encoding scheme for insertion transformers called fractional positional encoding (fpe), which allows reusing representations calculated in previous steps. empirical studies on various language generation tasks demonstrate the effectiveness of fpe, which leads to reduction of floating point operations and latency improvements on batched decoding. ","419":"logical natural language generation, i.e., generating textual descriptions that can be logically entailed by a structured table, has been a challenge due to the low fidelity of the generation. \\citet{chen2020logic2text} have addressed this problem by annotating interim logical programs to control the generation contents and semantics, and presented the task of table-aware logical form to text (logic2text) generation. however, although table instances are abundant in the real world, logical forms paired with textual descriptions require costly human annotation work, which limits the performance of neural models. to mitigate this, we propose topic-conditioned data augmentation (topicda), which utilizes gpt-2 to generate unpaired logical forms and textual descriptions directly from tables. we further introduce logical form generation (lg), a dual task of logic2text that requires generating a valid logical form based on a text description of a table. we also propose a semi-supervised learning approach to jointly train a logic2text and an lg model with both labeled and augmented data. the two models benefit from each other by providing extra supervision signals through back-translation. experimental results on the logic2text dataset and the lg task demonstrate that our approach can effectively utilize the augmented data and outperform supervised baselines by a substantial margin. ","420":"recently, there has been an increasing interest in models that generate natural language explanations (nles) for their decisions. however, training a model to provide nles requires the acquisition of task-specific nles, which is time- and resource-consuming. a potential solution is the out-of-domain transfer of nles from a domain with a large number of nles to a domain with scarce nles but potentially a large number of labels, via few-shot transfer learning. in this work, we introduce three vanilla approaches for few-shot transfer learning of nles for the case of few nles but abundant labels, along with an adaptation of an existing vanilla fine-tuning approach. we transfer explainability from the natural language inference domain, where a large dataset of human-written nles exists (e-snli), to the domains of (1) hard cases of pronoun resolution, where we introduce a small dataset of nles on top of the winogrande dataset (small-e-winogrande), and (2) commonsense validation (comve). our results demonstrate that the transfer of nles outperforms the single-task methods, and establish the best strategies out of the four identified training regimes. we also investigate the scalability of the best methods, both in terms of training data and model size. ","421":"this paper describes foundational efforts with sautidb-naija, a novel corpus of non-native (l2) nigerian english speech. we describe how the corpus was created and curated as well as preliminary experiments with accent classification and learning nigerian accent embeddings. the initial version of the corpus includes over 900 recordings from l2 english speakers of nigerian languages, such as yoruba, igbo, edo, efik-ibibio, and igala. we further demonstrate how fine-tuning on a pre-trained model like wav2vec can yield representations suitable for related speech tasks such as accent classification. sautidb-naija has been published to zenodo for general use under a flexible creative commons license. ","422":"rst-style discourse parsing plays a vital role in many nlp tasks, revealing the underlying semantic\/pragmatic structure of potentially complex and diverse documents. despite its importance, one of the most prevailing limitations in modern day discourse parsing is the lack of large-scale datasets. to overcome the data sparsity issue, distantly supervised approaches from tasks like sentiment analysis and summarization have been recently proposed. here, we extend this line of research by exploiting distant supervision from topic segmentation, which can arguably provide a strong and oftentimes complementary signal for high-level discourse structures. experiments on two human-annotated discourse treebanks confirm that our proposal generates accurate tree structures on sentence and paragraph level, consistently outperforming previous distantly supervised models on the sentence-to-document task and occasionally reaching even higher scores on the sentence-to-paragraph level. ","423":"the time at which a message is communicated is a vital piece of metadata in many real-world natural language processing tasks such as topic detection and tracking (tdt). tdt systems aim to cluster a corpus of news articles by event, and in that context, stories that describe the same event are likely to have been written at around the same time. prior work on time modeling for tdt takes this into account, but does not well capture how time interacts with the semantic nature of the event. for example, stories about a tropical storm are likely to be written within a short time interval, while stories about a movie release may appear over weeks or months. in our work, we design a neural method that fuses temporal and textual information into a single representation of news documents for event detection. we fine-tune these time-aware document embeddings with a triplet loss architecture, integrate the model into downstream tdt systems, and evaluate the systems on two benchmark tdt data sets in english. in the retrospective setting, we apply clustering algorithms to the time-aware embeddings and show substantial improvements over baselines on the news2013 data set. in the online streaming setting, we add our document encoder to an existing state-of-the-art tdt pipeline and demonstrate that it can benefit the overall performance. we conduct ablation studies on the time representation and fusion algorithm strategies, showing that our proposed model outperforms alternative strategies. finally, we probe the model to examine how it handles recurring events more effectively than previous tdt systems. ","424":"training neural machine translation (nmt) models in federated learning (fl) settings could be inefficient both computationally and communication-wise, due to the large size of translation engines as well as the multiple rounds of updates required to train clients and a central server. in this paper, we explore how to efficiently build nmt models in an fl setup by proposing a novel solution. in order to reduce the communication overhead, out of all neural layers we only exchange what we term \"controller\" layers. controllers are a small number of additional neural components connected to our pre-trained architectures. these new components are placed in between original layers. they act as liaisons to communicate with the central server and learn minimal information that is sufficient enough to update clients.   we evaluated the performance of our models on five datasets from different domains to translate from german into english. we noted that the models equipped with controllers preform on par with those trained in a central and non-fl setting. in addition, we observed a substantial reduction in the communication traffic of the fl pipeline, which is a direct consequence of using controllers. based on our experiments, controller-based models are ~6 times less expensive than their other peers. this reduction is significantly important when we consider the number of parameters in large models and it becomes even more critical when such parameters need to be exchanged for multiple rounds in fl settings. ","425":"embedding-based methods are popular for knowledge base question answering (kbqa), but few current models have numerical reasoning skills and thus struggle to answer ordinal constrained questions. this paper proposes a new embedding-based kbqa framework which particularly takes numerical reasoning into account. we present numericaltransformer on top of nsm, a state-of-the-art embedding-based kbqa model, to create nt-nsm. to enable better training, we propose two pre-training tasks with explicit numerical-oriented loss functions on two generated training datasets and a template-based data augmentation method for enriching ordinal constrained qa dataset. extensive experiments on kbqa benchmarks demonstrate that with the help of our training algorithm, nt-nsm is empowered with numerical reasoning skills and substantially outperforms the baselines in answering ordinal constrained questions. ","426":"extractive rationales (i.e., subsets of input features) and natural language explanations (nles) are two predominant types of explanations for machine learning models. while nles can be more comprehensive than extractive rationales, machine-generated nles have been shown to fall short in terms of commonsense knowledge. in this paper, we show that commonsense knowledge can act as a bridge between extractive rationales and nles, rendering both types of explanations better. we introduce a self-rationalizing framework, called rexc, that (1) extracts rationales as most responsible features for the predictions, (2) expands the extractive rationales using commonsense resources, and (3) selects the best-suited commonsense knowledge to generate nles and give the final prediction. our framework surpasses by a large margin the previous state-of-the-art in generating nles across five tasks in both natural language and vision-language understanding. self-rationalization with commonsense also strongly improves the quality of the extractive rationale and task performances over the previous best performing models that also produce explanations. ","427":"identifying persuasive speakers in an adversarial environment is a critical task. in a national election, politicians would like to have persuasive speakers campaign on their behalf. when a company faces adverse publicity, they would like to engage persuasive advocates for their position in the presence of adversaries who are critical of them. debates represent a common platform for these forms of adversarial persuasion. this paper solves two problems: the debate outcome prediction (dop) problem predicts who wins a debate while the intensity of persuasion prediction (ipp) problem predicts the change in the number of votes before and after a speaker speaks. though dop has been previously studied, we are the first to study ipp. past studies on dop fail to leverage two important aspects of multimodal data: 1) multiple modalities are often semantically aligned, and 2) different modalities may provide diverse information for prediction. our m2p2 (multimodal persuasion prediction) framework is the first to use multimodal (acoustic, visual, language) data to solve the ipp problem. to leverage the alignment of different modalities while maintaining the diversity of the cues they provide, m2p2 devises a novel adaptive fusion learning framework which fuses embeddings obtained from two modules -- an alignment module that extracts shared information between modalities and a heterogeneity module that learns the weights of different modalities with guidance from three separately trained unimodal reference models. we test m2p2 on the popular iq2us dataset designed for dop. we also introduce a new dataset called qps (from qipashuo, a popular chinese debate tv show ) for ipp. m2p2 significantly outperforms 4 recent baselines on both datasets. ","428":"we present the first linguistically annotated treebank of ashokan prakrit, an early middle indo-aryan dialect continuum attested through emperor ashoka maurya's 3rd century bce rock and pillar edicts. for annotation, we used the multilingual universal dependencies (ud) formalism, following recent ud work on sanskrit and other indo-aryan languages. we touch on some interesting linguistic features that posed issues in annotation: regnal names and other nominal compounds, \"proto-ergative\" participial constructions, and possible grammaticalizations evidenced by sandhi (phonological assimilation across morpheme boundaries). eventually, we plan for a complete annotation of all attested ashokan texts, towards the larger goals of improving ud coverage of different diachronic stages of indo-aryan and studying language change in indo-aryan using computational methods. ","429":"zero-shot cross-lingual transfer is an important feature in modern nlp models and architectures to support low-resource languages. in this work, we study zero-shot cross-lingual transfer from english to french and german under multi-label text classification, where we train a classifier using english training set, and we test using french and german test sets. we extend eurlex57k dataset, the english dataset for topic classification of legal documents, with french and german official translation. we investigate the effect of using some training techniques, namely gradual unfreezing and language model finetuning, on the quality of zero-shot cross-lingual transfer. we find that language model finetuning of multi-lingual pre-trained model (m-distilbert, m-bert) leads to 32.0-34.94%, 76.15-87.54% relative improvement on french and german test sets correspondingly. also, gradual unfreezing of pre-trained model's layers during training results in relative improvement of 38-45% for french and 58-70% for german. compared to training a model in joint training scheme using english, french and german training sets, zero-shot bert-based classification model reaches 86% of the performance achieved by jointly-trained bert-based classification model. ","430":"there are two main challenges in document-level event extraction: 1) argument entities are scattered in different sentences, and 2) event triggers are often not available. to address these challenges, most previous studies mainly focus on building argument chains in an autoregressive way, which is inefficient in both training and inference. in contrast to the previous studies, we propose a fast and lightweight model named as ptpcg. we design a non-autoregressive decoding algorithm to perform event argument combination extraction on pruned complete graphs, which are constructed under the guidance of the automatically selected pseudo triggers. compared to the previous systems, our system achieves competitive results with lower resource consumption, taking only 3.6% gpu time (pfs-days) for training and up to 8.5 times faster for inference. besides, our approach shows superior compatibility for the datasets with (or without) triggers and the pseudo triggers can be the supplements for annotated triggers to make further improvements. ","431":"clinical question answering (qa) aims to automatically answer questions from medical professionals based on clinical texts. studies show that neural qa models trained on one corpus may not generalize well to new clinical texts from a different institute or a different patient group, where large-scale qa pairs are not readily available for model retraining. to address this challenge, we propose a simple yet effective framework, cliniqg4qa, which leverages question generation (qg) to synthesize qa pairs on new clinical contexts and boosts qa models without requiring manual annotations. in order to generate diverse types of questions that are essential for training qa models, we further introduce a seq2seq-based question phrase prediction (qpp) module that can be used together with most existing qg models to diversify the generation. our comprehensive experiment results show that the qa corpus generated by our framework can improve qa models on the new contexts (up to 8% absolute gain in terms of exact match), and that the qpp module plays a crucial role in achieving the gain. ","432":"this study aims to develop a semi-automatically labelled prosody database for hindi, for enhancing the intonation component in asr and tts systems, which is also helpful for building speech to speech machine translation systems. although no single standard for prosody labelling exists in hindi, researchers in the past have employed perceptual and statistical methods in literature to draw inferences about the behaviour of prosody patterns in hindi. based on such existing research and largely agreed upon theories of intonation in hindi, this study attempts to first develop a manually annotated prosodic corpus of hindi speech data, which is then used for training prediction models for generating automatic prosodic labels. a total of 5,000 sentences (23,500 words) for declarative and interrogative types have been labelled. the accuracy of the trained models for pitch accent, intermediate phrase boundaries and accentual phrase boundaries is 73.40%, 93.20%, and 43% respectively. ","433":"research shows that exposure to suicide-related news media content is associated with suicide rates, with some content characteristics likely having harmful and others potentially protective effects. although good evidence exists for a few selected characteristics, systematic large scale investigations are missing in general, and in particular for social media data. we apply machine learning methods to automatically label large quantities of twitter data. we developed a novel annotation scheme that classifies suicide-related tweets into different message types and problem- vs. solution-focused perspectives. we then trained a benchmark of machine learning models including a majority classifier, an approach based on word frequency (tf-idf with a linear svm) and two state-of-the-art deep learning models (bert, xlnet). the two deep learning models achieved the best performance in two classification tasks: first, we classified six main content categories, including personal stories about either suicidal ideation and attempts or coping, calls for action intending to spread either problem awareness or prevention-related information, reportings of suicide cases, and other suicide-related and off-topic tweets. the deep learning models reach accuracy scores above 73% on average across the six categories, and f1-scores in between 69% and 85% for all but the suicidal ideation and attempts category (55%). second, in separating postings referring to actual suicide from off-topic tweets, they correctly labelled around 88% of tweets, with bert achieving f1-scores of 93% and 74% for the two categories. these classification performances are comparable to the state-of-the-art on similar tasks. by making data labeling more efficient, this work enables future large-scale investigations on harmful and protective effects of various kinds of social media content on suicide rates and on help-seeking behavior. ","434":"relation extraction is a fundamental problem in natural language processing. most existing models are defined for relation extraction in the general domain. however, their performance on specific domains (e.g., biomedicine) is yet unclear. to fill this gap, this paper carries out an empirical study on relation extraction in biomedical research articles. specifically, we consider both sentence-level and document-level relation extraction, and run a few state-of-the-art methods on several benchmark datasets. our results show that (1) current document-level relation extraction methods have strong generalization ability; (2) existing methods require a large amount of labeled data for model fine-tuning in biomedicine. our observations may inspire people in this field to develop more effective models for biomedical relation extraction. ","435":"several years of research have shown that machine-learning systems are vulnerable to adversarial examples, both in theory and in practice. until now, such attacks have primarily targeted visual models, exploiting the gap between human and machine perception. although text-based models have also been attacked with adversarial examples, such attacks struggled to preserve semantic meaning and indistinguishability. in this paper, we explore a large class of adversarial examples that can be used to attack text-based models in a black-box setting without making any human-perceptible visual modification to inputs. we use encoding-specific perturbations that are imperceptible to the human eye to manipulate the outputs of a wide range of natural language processing (nlp) systems from neural machine-translation pipelines to web search engines. we find that with a single imperceptible encoding injection -- representing one invisible character, homoglyph, reordering, or deletion -- an attacker can significantly reduce the performance of vulnerable models, and with three injections most models can be functionally broken. our attacks work against currently-deployed commercial systems, including those produced by microsoft and google, in addition to open source models published by facebook, ibm, and huggingface. this novel series of attacks presents a significant threat to many language processing systems: an attacker can affect systems in a targeted manner without any assumptions about the underlying model. we conclude that text-based nlp systems require careful input sanitization, just like conventional applications, and that given such systems are now being deployed rapidly at scale, the urgent attention of architects and operators is required. ","436":"knowledge graph question answering (kgqa) involves retrieving facts from a knowledge graph (kg) using natural language queries. a kg is a curated set of facts consisting of entities linked by relations. certain facts include also temporal information forming a temporal kg (tkg). although many natural questions involve explicit or implicit time constraints, question answering (qa) over tkgs has been a relatively unexplored area. existing solutions are mainly designed for simple temporal questions that can be answered directly by a single tkg fact. this paper puts forth a comprehensive embedding-based framework for answering complex questions over tkgs. our method termed temporal question reasoning (tempoqr) exploits tkg embeddings to ground the question to the specific entities and time scope it refers to. it does so by augmenting the question embeddings with context, entity and time-aware information by employing three specialized modules. the first computes a textual representation of a given question, the second combines it with the entity embeddings for entities involved in the question, and the third generates question-specific time embeddings. finally, a transformer-based encoder learns to fuse the generated temporal information with the question representation, which is used for answer predictions. extensive experiments show that tempoqr improves accuracy by 25--45 percentage points on complex temporal questions over state-of-the-art approaches and it generalizes better to unseen question types. ","437":"state-of-the-art dialogue models still often stumble with regards to factual accuracy and self-contradiction. anecdotally, they have been observed to fail to maintain character identity throughout discourse; and more specifically, may take on the role of their interlocutor. in this work we formalize and quantify this deficiency, and show experimentally through human evaluations that this is indeed a problem. in contrast, we show that discriminative models trained specifically to recognize who is speaking can perform well; and further, these can be used as automated metrics. finally, we evaluate a wide variety of mitigation methods, including changes to model architecture, training protocol, and decoding strategy. our best models reduce mistaken identity issues by nearly 65% according to human annotators, while simultaneously improving engagingness. despite these results, we find that maintaining character identity still remains a challenging problem. ","438":"as more users across the world are interacting with dialog agents in their daily life, there is a need for better speech understanding that calls for renewed attention to the dynamics between research in automatic speech recognition (asr) and natural language understanding (nlu). we briefly review these research areas and lay out the current relationship between them. in light of the observations we make in this paper, we argue that (1) nlu should be cognizant of the presence of asr models being used upstream in a dialog system's pipeline, (2) asr should be able to learn from errors found in nlu, (3) there is a need for end-to-end datasets that provide semantic annotations on spoken input, (4) there should be stronger collaboration between asr and nlu research communities. ","439":"debugging a machine learning model is hard since the bug usually involves the training data and the learning process. this becomes even harder for an opaque deep learning model if we have no clue about how the model actually works. in this survey, we review papers that exploit explanations to enable humans to give feedback and debug nlp models. we call this problem explanation-based human debugging (ebhd). in particular, we categorize and discuss existing work along three dimensions of ebhd (the bug context, the workflow, and the experimental setting), compile findings on how ebhd components affect the feedback providers, and highlight open problems that could be future research directions. ","440":"in this work, we develop new self-learning techniques with an attention-based sequence-to-sequence (seq2seq) model for automatic speech recognition (asr). for untranscribed speech data, the hypothesis from an asr system must be used as a label. however, the imperfect asr result makes unsupervised learning difficult to consistently improve recognition performance especially in the case that multiple powerful teacher models are unavailable. in contrast to conventional unsupervised learning approaches, we adopt the \\emph{multi-task learning} (mtl) framework where the $n$-th best asr hypothesis is used as the label of each task. the seq2seq network is updated through the mtl framework so as to find the common representation that can cover multiple hypotheses. by doing so, the effect of the \\emph{hard-decision} errors can be alleviated.   we first demonstrate the effectiveness of our self-learning methods through asr experiments in an accent adaptation task between the us and british english speech. our experiment results show that our method can reduce the wer on the british speech data from 14.55\\% to 10.36\\% compared to the baseline model trained with the us english data only. moreover, we investigate the effect of our proposed methods in a federated learning scenario. ","441":"recent advancements in technology have led to a boost in social media usage which has ultimately led to large amounts of user-generated data which also includes hateful and offensive speech. the language used in social media is often a combination of english and the native language in the region. in india, hindi is used predominantly and is often code-switched with english, giving rise to the hinglish (hindi+english) language. various approaches have been made in the past to classify the code-mixed hinglish hate speech using different machine learning and deep learning-based techniques. however, these techniques make use of recurrence on convolution mechanisms which are computationally expensive and have high memory requirements. past techniques also make use of complex data processing making the existing techniques very complex and non-sustainable to change in data. we propose a much simpler approach which is not only at par with these complex networks but also exceeds performance with the use of subword tokenization algorithms like bpe and unigram along with multi-head attention-based technique giving an accuracy of 87.41% and f1 score of 0.851 on standard datasets. efficient use of bpe and unigram algorithms help handle the non-conventional hinglish vocabulary making our technique simple, efficient and sustainable to use in the real world. ","442":"this paper illustrates locality sensitive hasing (lsh) models for the identification and removal of nearly redundant data in a text dataset. to evaluate the different models, we create an artificial dataset for data deduplication using english wikipedia articles. area-under-curve (auc) over 0.9 were observed for most models, with the best model reaching 0.96. deduplication enables more effective model training by preventing the model from learning a distribution that differs from the real one as a result of the repeated data. ","443":"in this paper, we present a method of building strong, explainable classifiers in the form of boolean search rules. we developed an interactive environment called case (computer assisted semantic exploration) which exploits word co-occurrence to guide human annotators in selection of relevant search terms. the system seamlessly facilitates iterative evaluation and improvement of the classification rules. the process enables the human annotators to leverage the benefits of statistical information while incorporating their expert intuition into the creation of such rules. we evaluate classifiers created with our case system on 4 datasets, and compare the results to machine learning methods, including skope rules, random forest, support vector machine, and fasttext classifiers. the results drive the discussion on trade-offs between superior compactness, simplicity, and intuitiveness of the boolean search rules versus the better performance of state-of-the-art machine learning models for text classification. ","444":"we consider language modelling (lm) as a multi-label structured prediction task by re-framing training from solely predicting a single ground-truth word to ranking a set of words which could continue a given context. to avoid annotating top-$k$ ranks, we generate them using pre-trained lms: gpt-2, bert, and born-again models. this leads to a rank-based form of knowledge distillation (kd). we also develop a method using $n$-grams to create a non-probabilistic teacher which generates the ranks without the need of a pre-trained lm.   we confirm the hypotheses that we can treat lming as a ranking task and that we can do so without the use of a pre-trained lm. we show that rank-based kd generally improves perplexity (ppl), often with statistical significance, when compared to kullback-leibler-based kd. surprisingly, given the simplicity of the method, $n$-grams act as competitive teachers and achieve similar performance as using either bert or a born-again model teachers. gpt-2 always acts as the best teacher, though, and using it and a transformer-xl student on wiki-02, rank-based kd reduces a cross-entropy baseline from 65.27 to 55.94 and against a kl-based kd of 56.70. ","445":"current efficient fine-tuning methods (e.g., adapters, prefix-tuning, etc.) have optimized conditional text generation via training a small set of extra parameters of the neural language model, while freezing the rest for efficiency. while showing strong performance on some generation tasks, they don't generalize across all generation tasks. in this work, we show that prompt based conditional text generation can be improved with simple and efficient methods that simulate modeling the discourse structure of human written text. we introduce two key design choices: first we show that a higher-level discourse structure of human written text can be modelled with \\textit{hierarchical blocking} on prefix parameters that enable spanning different parts of the input and output text and yield more coherent output generations. second, we propose sparse prefix tuning by introducing \\textit{attention sparsity} on the prefix parameters at different layers of the network and learn sparse transformations on the softmax-function, respectively. we find that sparse attention enables the prefix-tuning to better control of the input contents (salient facts) yielding more efficient tuning of the prefix-parameters. experiments on a wide-variety of text generation tasks show that structured design of prefix parameters can achieve comparable results to fine-tuning all parameters while outperforming standard prefix-tuning on all generation tasks even in low-resource settings. ","446":"the sizes of pretrained language models make them challenging and expensive to use when there are multiple desired downstream tasks. in this work, we adopt recent strategies for model pruning during finetuning to explore the question of whether it is possible to prune a single encoder so that it can be used for multiple tasks. we allocate a fixed parameter budget and compare pruning a single model with a multitask objective against the best ensemble of single-task models. we find that under two pruning strategies (element-wise and rank pruning), the approach with the multitask objective outperforms training models separately when averaged across all tasks, and it is competitive on each individual one. additional analysis finds that using a multitask objective during pruning can also be an effective method for reducing model sizes for low-resource tasks. ","447":"energy-based models (ebms) allow for extremely flexible specifications of probability distributions. however, they do not provide a mechanism for obtaining exact samples from these distributions. monte carlo techniques can aid us in obtaining samples if some proposal distribution that we can easily sample from is available. for instance, rejection sampling can provide exact samples but is often difficult or impossible to apply due to the need to find a proposal distribution that upper-bounds the target distribution everywhere. approximate markov chain monte carlo sampling techniques like metropolis-hastings are usually easier to design, exploiting a local proposal distribution that performs local edits on an evolving sample. however, these techniques can be inefficient due to the local nature of the proposal distribution and do not provide an estimate of the quality of their samples. in this work, we propose a new approximate sampling technique, quasi rejection sampling (qrs), that allows for a trade-off between sampling efficiency and sampling quality, while providing explicit convergence bounds and diagnostics. qrs capitalizes on the availability of high-quality global proposal distributions obtained from deep learning models. we demonstrate the effectiveness of qrs sampling for discrete ebms over text for the tasks of controlled text generation with distributional constraints and paraphrase generation. we show that we can sample from such ebms with arbitrary precision at the cost of sampling efficiency. ","448":"the current state of adoption of well-structured electronic health records and integration of digital methods for storing medical patient data in structured formats can often considered as inferior compared to the use of traditional, unstructured text based patient data documentation. data mining in the field of medical data analysis often needs to rely solely on processing of unstructured data to retrieve relevant data. in natural language processing (nlp), statistical models have been shown successful in various tasks like part-of-speech tagging, relation extraction (re) and named entity recognition (ner). in this work, we present gernermed, the first open, neural nlp model for ner tasks dedicated to detect medical entity types in german text data. here, we avoid the conflicting goals of protection of sensitive patient data from training data extraction and the publication of the statistical model weights by training our model on a custom dataset that was translated from publicly available datasets in foreign language by a pretrained neural machine translation model. the sample code and the statistical model is available at: https:\/\/github.com\/frankkramer-lab\/gernermed ","449":"task embeddings are low-dimensional representations that are trained to capture task properties. in this paper, we propose metaeval, a collection of $101$ nlp tasks. we fit a single transformer to all metaeval tasks jointly while conditioning it on learned embeddings. the resulting task embeddings enable a novel analysis of the space of tasks. we then show that task aspects can be mapped to task embeddings for new tasks without using any annotated examples.   predicted embeddings can modulate the encoder for zero-shot inference and outperform a zero-shot baseline on glue tasks. the provided multitask setup can function as a benchmark for future transfer learning research. ","450":"evidence-based medicine, the practice in which healthcare professionals refer to the best available evidence when making decisions, forms the foundation of modern healthcare. however, it relies on labour-intensive systematic reviews, where domain specialists must aggregate and extract information from thousands of publications, primarily of randomised controlled trial (rct) results, into evidence tables. this paper investigates automating evidence table generation by decomposing the problem across two language processing tasks: \\textit{named entity recognition}, which identifies key entities within text, such as drug names, and \\textit{relation extraction}, which maps their relationships for separating them into ordered tuples. we focus on the automatic tabulation of sentences from published rct abstracts that report the results of the study outcomes. two deep neural net models were developed as part of a joint extraction pipeline, using the principles of transfer learning and transformer-based language representations. to train and test these models, a new gold-standard corpus was developed, comprising almost 600 result sentences from six disease areas. this approach demonstrated significant advantages, with our system performing well across multiple natural language processing tasks and disease areas, as well as in generalising to disease domains unseen during training. furthermore, we show these results were achievable through training our models on as few as 200 example sentences. the final system is a proof of concept that the generation of evidence tables can be semi-automated, representing a step towards fully automating systematic reviews. ","451":"we introduce shennong, a python toolbox and command-line utility for speech features extraction. it implements a wide range of well-established state of art algorithms including spectro-temporal filters such as mel-frequency cepstral filterbanks or predictive linear filters, pre-trained neural networks, pitch estimators as well as speaker normalization methods and post-processing algorithms. shennong is an open source, easy-to-use, reliable and extensible framework. the use of python makes the integration to others speech modeling and machine learning tools easy. it aims to replace or complement several heterogeneous software, such as kaldi or praat. after describing the shennong software architecture, its core components and implemented algorithms, this paper illustrates its use on three applications: a comparison of speech features performances on a phones discrimination task, an analysis of a vocal tract length normalization model as a function of the speech duration used for training and a comparison of pitch estimation algorithms under various noise conditions. ","452":"sentiment analysis is one of the most classical and primarily studied natural language processing tasks. this problem had a notable advance with the proposition of more complex and scalable machine learning models. despite this progress, the brazilian portuguese language still disposes only of limited linguistic resources, such as datasets dedicated to sentiment classification, especially when considering the existence of predefined partitions in training, testing, and validation sets that would allow a more fair comparison of different algorithm alternatives. motivated by these issues, this work analyzes the predictive performance of a range of document embedding strategies, assuming the polarity as the system outcome. this analysis includes five sentiment analysis datasets in brazilian portuguese, unified in a single dataset, and a reference partitioning in training, testing, and validation sets, both made publicly available through a digital repository. a cross-evaluation of dataset-specific models over different contexts is conducted to evaluate their generalization capabilities and the feasibility of adopting a unique model for addressing all scenarios. ","453":"software with natural-language user interfaces has an ever-increasing importance. however, the quality of the included question answering (qa) functionality is still not sufficient regarding the number of questions that are answered correctly. in our work, we address the research problem of how the qa quality of a given system can be improved just by evaluating the natural-language input (i.e., the user's question) and output (i.e., the system's answer). our main contribution is an approach capable of identifying wrong answers provided by a qa system. hence, filtering incorrect answers from a list of answer candidates is leading to a highly improved qa quality. in particular, our approach has shown its potential while removing in many cases the majority of incorrect answers, which increases the qa quality significantly in comparison to the non-filtered output of a system. ","454":"subjects change frequently in moderated debates with several participants, such as in parliamentary sessions, electoral debates, and trials. partitioning a debate into blocks with the same subject is essential for understanding. often a moderator is responsible for defining when a new block begins so that the task of automatically partitioning a moderated debate can focus solely on the moderator's behavior. in this paper, we (i) propose a new algorithm, debacer, which partitions moderated debates; (ii) carry out a comparative study between conventional and bertimbau pipelines; and (iii) validate debacer applying it to the minutes of the assembly of the republic of portugal. our results show the effectiveness of debacer. keywords: natural language processing, political documents, spoken text processing, speech split, dialogue partitioning. ","455":"in recent years, we have seen significant steps taken in the development of self-driving cars. multiple companies are starting to roll out impressive systems that work in a variety of settings. these systems can sometimes give the impression that full self-driving is just around the corner and that we would soon build cars without even a steering wheel. the increase in the level of autonomy and control given to an ai provides an opportunity for new modes of human-vehicle interaction. however, surveys have shown that giving more control to an ai in self-driving cars is accompanied by a degree of uneasiness by passengers. in an attempt to alleviate this issue, recent works have taken a natural language-oriented approach by allowing the passenger to give commands that refer to specific objects in the visual scene. nevertheless, this is only half the task as the car should also understand the physical destination of the command, which is what we focus on in this paper. we propose an extension in which we annotate the 3d destination that the car needs to reach after executing the given command and evaluate multiple different baselines on predicting this destination location. additionally, we introduce a model that outperforms the prior works adapted for this particular setting. ","456":"the transformer multi-head self-attention mechanism has been thoroughly investigated recently. on one hand, researchers are interested in understanding why and how transformers work. on the other hand, they propose new attention augmentation methods to make transformers more accurate, efficient and interpretable. in this paper, we synergize these two lines of research in a human-in-the-loop pipeline to first find important task-specific attention patterns. then those patterns are applied, not only to the original model, but also to smaller models, as a human-guided knowledge distillation process. the benefits of our pipeline are demonstrated in a case study with the extractive summarization task. after finding three meaningful attention patterns in the popular bertsum model, experiments indicate that when we inject such patterns, both the original and the smaller model show improvements in performance and arguably interpretability. ","457":"transformer-based models are not efficient in processing long sequences due to the quadratic space and time complexity of the self-attention modules. to address this limitation, linformer and informer are proposed to reduce the quadratic complexity to linear (modulo logarithmic factors) via low-dimensional projection and row selection respectively. these two models are intrinsically connected, and to understand their connection, we introduce a theoretical framework of matrix sketching. based on the theoretical analysis, we propose skeinformer to accelerate self-attention and further improve the accuracy of matrix approximation to self-attention with three carefully designed components: column sampling, adaptive row normalization and pilot sampling reutilization. experiments on the long range arena (lra) benchmark demonstrate that our methods outperform alternatives with a consistently smaller time\/space footprint. ","458":"text-to-sql aims to map natural language questions to sql queries. the sketch-based method combined with execution-guided (eg) decoding strategy has shown a strong performance on the wikisql benchmark. however, execution-guided decoding relies on database execution, which significantly slows down the inference process and is hence unsatisfactory for many real-world applications. in this paper, we present the schema dependency guided multi-task text-to-sql model (sdsql) to guide the network to effectively capture the interactions between questions and schemas. the proposed model outperforms all existing methods in both the settings with or without eg. we show the schema dependency learning partially cover the benefit from eg and alleviates the need for it. sdsql without eg significantly reduces time consumption during inference, sacrificing only a small amount of performance and provides more flexibility for downstream applications. ","459":"conversation disentanglement, the task to identify separate threads in conversations, is an important pre-processing step in multi-party conversational nlp applications such as conversational question answering and conversation summarization. framing it as a utterance-to-utterance classification problem -- i.e. given an utterance of interest (uoi), find which past utterance it replies to -- we explore a number of transformer-based models and found that bert in combination with handcrafted features remains a strong baseline. we then build a multi-task learning model that jointly learns utterance-to-utterance and utterance-to-thread classification. observing that the ground truth label (past utterance) is in the top candidates when our model makes an error, we experiment with using bipartite graphs as a post-processing step to learn how to best match a set of uois to past utterances. experiments on the ubuntu irc dataset show that this approach has the potential to outperform the conventional greedy approach of simply selecting the highest probability candidate for each uoi independently, indicating a promising future research direction. ","460":"in this paper, we discuss semantic construction grammar (scg), a system developed over the past several years to facilitate translation between natural language and logical representations. crucially, scg is designed to support a variety of different methods of representation, ranging from those that are fairly close to the nl structure (e.g. so-called 'logical forms'), to those that are quite different from the nl structure, with higher-order and high-arity relations. semantic constraints and checks on representations are integral to the process of nl understanding with scg, and are easily carried out due to the scg's integration with cyc's knowledge base and inference engine. ","461":"large-scale pretraining is fast becoming the norm in vision-language (vl) modeling. however, prevailing vl approaches are limited by the requirement for labeled data and the use of complex multi-step pretraining objectives. we present magma - a simple method for augmenting generative language models with additional modalities using adapter-based finetuning. building on frozen, we train a series of vl models that autoregressively generate text from arbitrary combinations of visual and textual input. the pretraining is entirely end-to-end using a single language modeling objective, simplifying optimization compared to previous approaches. importantly, the language model weights remain unchanged during training, allowing for transfer of encyclopedic knowledge and in-context learning abilities from language pretraining. magma outperforms frozen on open-ended generative tasks, achieving state of the art results on the okvqa benchmark and competitive results on a range of other popular vl benchmarks, while pretraining on 0.2% of the number of samples used to train simvlm. ","462":"as the volume of long-form spoken-word content such as podcasts explodes, many platforms desire to present short, meaningful, and logically coherent segments extracted from the full content. such segments can be consumed by users to sample content before diving in, as well as used by the platform to promote and recommend content. however, little published work is focused on the segmentation of spoken-word content, where the errors (noise) in transcripts generated by automatic speech recognition (asr) services poses many challenges. here we build a novel dataset of complete transcriptions of over 400 podcast episodes, in which we label the position of introductions in each episode. these introductions contain information about the episodes' topics, hosts, and guests, providing a valuable summary of the episode content, as it is created by the authors. we further augment our dataset with word substitutions to increase the amount of available training data. we train three transformer models based on the pre-trained bert and different augmentation strategies, which achieve significantly better performance compared with a static embedding model, showing that it is possible to capture generalized, larger-scale structural information from noisy, loosely-organized speech data. this is further demonstrated through an analysis of the models' inner architecture. our methods and dataset can be used to facilitate future work on the structure-based segmentation of spoken-word content. ","463":"in this paper, we explore how to use a small amount of new data to update a task-oriented semantic parsing model when the desired output for some examples has changed. when making updates in this way, one potential problem that arises is the presence of conflicting data, or out-of-date labels in the original training set. to evaluate the impact of this understudied problem, we propose an experimental setup for simulating changes to a neural semantic parser. we show that the presence of conflicting data greatly hinders learning of an update, then explore several methods to mitigate its effect. our multi-task and data selection methods lead to large improvements in model accuracy compared to a naive data-mixing strategy, and our best method closes 86% of the accuracy gap between this baseline and an oracle upper bound. ","464":"machine translation models have discrete vocabularies and commonly use subword segmentation techniques to achieve an 'open vocabulary.' this approach relies on consistent and correct underlying unicode sequences, and makes models susceptible to degradation from common types of noise and variation. motivated by the robustness of human language processing, we propose the use of visual text representations, which dispense with a finite set of text embeddings in favor of continuous vocabularies created by processing visually rendered text with sliding windows. we show that models using visual text representations approach or match performance of traditional text models on small and larger datasets. more importantly, models with visual embeddings demonstrate significant robustness to varied types of noise, achieving e.g., 25.9 bleu on a character permuted german-english task where subword models degrade to 1.9. ","465":"given the broad capabilities of large language models, it should be possible to work towards a general-purpose, text-based assistant that is aligned with human values, meaning that it is helpful, honest, and harmless. as an initial foray in this direction we study simple baseline techniques and evaluations, such as prompting. we find that the benefits from modest interventions increase with model size, generalize to a variety of alignment evaluations, and do not compromise the performance of large models. next we investigate scaling trends for several training objectives relevant to alignment, comparing imitation learning, binary discrimination, and ranked preference modeling. we find that ranked preference modeling performs much better than imitation learning, and often scales more favorably with model size. in contrast, binary discrimination typically performs and scales very similarly to imitation learning. finally we study a `preference model pre-training' stage of training, with the goal of improving sample efficiency when finetuning on human preferences. ","466":"this paper presents okapi, a new dataset for natural language to executable web application programming interfaces (nl2api). this dataset is in english and contains 22,508 questions and 9,019 unique api calls, covering three domains. we define new compositional generalization tasks for nl2api which explore the models' ability to extrapolate from simple api calls in the training set to new and more complex api calls in the inference phase. also, the models are required to generate api calls that execute correctly as opposed to the existing approaches which evaluate queries with placeholder values. our dataset is different than most of the existing compositional semantic parsing datasets because it is a non-synthetic dataset studying the compositional generalization in a low-resource setting. okapi is a step towards creating realistic datasets and benchmarks for studying compositional generalization alongside the existing datasets and tasks. we report the generalization capabilities of sequence-to-sequence baseline models trained on a variety of the scan and okapi datasets tasks. the best model achieves 15\\% exact match accuracy when generalizing from simple api calls to more complex api calls. this highlights some challenges for future research. okapi dataset and tasks are publicly available at https:\/\/aka.ms\/nl2api\/data. ","467":"deep learning models generalize well to in-distribution data but struggle to generalize compositionally, i.e., to combine a set of learned primitives to solve more complex tasks. in sequence-to-sequence (seq2seq) learning, transformers are often unable to predict correct outputs for longer examples than those seen at training. this paper introduces iterative decoding, an alternative to seq2seq that (i) improves transformer compositional generalization in the pcfg and cartesian product datasets and (ii) evidences that, in these datasets, seq2seq transformers do not learn iterations that are not unrolled. in iterative decoding, training examples are broken down into a sequence of intermediate steps that the transformer learns iteratively. at inference time, the intermediate outputs are fed back to the transformer as intermediate inputs until an end-of-iteration token is predicted. we conclude by illustrating some limitations of iterative decoding in the cfq dataset. ","468":"conversational recommender systems offer the promise of interactive, engaging ways for users to find items they enjoy. we seek to improve conversational recommendation via three dimensions: 1) we aim to mimic a common mode of human interaction for recommendation: experts justify their suggestions, a seeker explains why they don't like the item, and both parties iterate through the dialog to find a suitable item. 2) we leverage ideas from conversational critiquing to allow users to flexibly interact with natural language justifications by critiquing subjective aspects. 3) we adapt conversational recommendation to a wider range of domains where crowd-sourced ground truth dialogs are not available. we develop a new two-part framework for training conversational recommender systems. first, we train a recommender system to jointly suggest items and justify its reasoning with subjective aspects. we then fine-tune this model to incorporate iterative user feedback via self-supervised bot-play. experiments on three real-world datasets demonstrate that our system can be applied to different recommendation models across diverse domains to achieve superior performance in conversational recommendation compared to state-of-the-art methods. we also evaluate our model on human users, showing that systems trained under our framework provide more useful, helpful, and knowledgeable recommendations in warm- and cold-start settings. ","469":"with widening deployments of natural language processing (nlp) in daily life, inherited social biases from nlp models have become more severe and problematic. previous studies have shown that word embeddings trained on human-generated corpora have strong gender biases that can produce discriminative results in downstream tasks. previous debiasing methods focus mainly on modeling bias and only implicitly consider semantic information while completely overlooking the complex underlying causal structure among bias and semantic components. to address these issues, we propose a novel methodology that leverages a causal inference framework to effectively remove gender bias. the proposed method allows us to construct and analyze the complex causal mechanisms facilitating gender information flow while retaining oracle semantic information within word embeddings. our comprehensive experiments show that the proposed method achieves state-of-the-art results in gender-debiasing tasks. in addition, our methods yield better performance in word similarity evaluation and various extrinsic downstream nlp tasks. ","470":"a critical aspect of human visual perception is the ability to parse visual scenes into individual objects and further into object parts, forming part-whole hierarchies. such composite structures could induce a rich set of semantic concepts and relations, thus playing an important role in the interpretation and organization of visual signals as well as for the generalization of visual perception and reasoning. however, existing visual reasoning benchmarks mostly focus on objects rather than parts. visual reasoning based on the full part-whole hierarchy is much more challenging than object-centric reasoning due to finer-grained concepts, richer geometry relations, and more complex physics. therefore, to better serve for part-based conceptual, relational and physical reasoning, we introduce a new large-scale diagnostic visual reasoning dataset named ptr. ptr contains around 70k rgbd synthetic images with ground truth object and part level annotations regarding semantic instance segmentation, color attributes, spatial and geometric relationships, and certain physical properties such as stability. these images are paired with 700k machine-generated questions covering various types of reasoning types, making them a good testbed for visual reasoning models. we examine several state-of-the-art visual reasoning models on this dataset and observe that they still make many surprising mistakes in situations where humans can easily infer the correct answer. we believe this dataset will open up new opportunities for part-based reasoning. ","471":"the task of identifying the author of a text spans several decades and was tackled using linguistics, statistics, and, more recently, machine learning. inspired by the impressive performance gains across a broad range of natural language processing tasks and by the recent availability of the pan large-scale authorship dataset, we first study the effectiveness of several bert-like transformers for the task of authorship verification. such models prove to achieve very high scores consistently. next, we empirically show that they focus on topical clues rather than on author writing style characteristics, taking advantage of existing biases in the dataset. to address this problem, we provide new splits for pan-2020, where training and test data are sampled from disjoint topics or authors. finally, we introduce darkreddit, a dataset with a different input data distribution. we further use it to analyze the domain generalization performance of models in a low-data regime and how performance varies when using the proposed pan-2020 splits for fine-tuning. we show that those splits can enhance the models' capability to transfer knowledge over a new, significantly different dataset. ","472":"relationship extraction and named entity recognition have always been considered as two distinct tasks that require different input data, labels, and models. however, both are essential for structured sentiment analysis. we believe that both tasks can be combined into a single stacked model with the same input data. we performed different experiments to find the best model to extract multiple opinion tuples from a single sentence. the opinion tuples will consist of holders, targets, and expressions. with the opinion tuples, we will be able to extract the relationship we need. ","473":"data sparsity problem is a key challenge of natural language understanding (nlu), especially for a new target domain. by training an nlu model in source domains and applying the model to an arbitrary target domain directly (even without fine-tuning), few-shot nlu becomes crucial to mitigate the data scarcity issue. in this paper, we propose to improve prototypical networks with vector projection distance and abstract triangular conditional random field (crf) for the few-shot nlu. the vector projection distance exploits projections of contextual word embeddings on label vectors as word-label similarities, which is equivalent to a normalized linear model. the abstract triangular crf learns domain-agnostic label transitions for joint intent classification and slot filling tasks. extensive experiments demonstrate that our proposed methods can significantly surpass strong baselines. specifically, our approach can achieve a new state-of-the-art on two few-shot nlu benchmarks (few-joint and snips) in chinese and english without fine-tuning on target domains. ","474":"this work provides the first in-depth analysis of genre in universal dependencies (ud). in contrast to prior work on genre identification which uses small sets of well-defined labels in mono-\/bilingual setups, ud contains 18 genres with varying degrees of specificity spread across 114 languages. as most treebanks are labeled with multiple genres while lacking annotations about which instances belong to which genre, we propose four methods for predicting instance-level genre using weak supervision from treebank metadata. the proposed methods recover instance-level genre better than competitive baselines as measured on a subset of ud with labeled instances and adhere better to the global expected distribution. our analysis sheds light on prior work using ud genre metadata for treebank selection, finding that metadata alone are a noisy signal and must be disentangled within treebanks before it can be universally applied. ","475":"a comprehensive understanding of vision and language and their interrelation are crucial to realize the underlying similarities and differences between these modalities and to learn more generalized, meaningful representations. in recent years, most of the works related to text-to-image synthesis and image-to-text generation, focused on supervised generative deep architectures to solve the problems, where very little interest was placed on learning the similarities between the embedding spaces across modalities. in this paper, we propose a novel self-supervised deep learning based approach towards learning the cross-modal embedding spaces; for both image to text and text to image generations. in our approach, we first obtain dense vector representations of images using stackgan-based autoencoder model and also dense vector representations on sentence-level utilizing lstm based text-autoencoder; then we study the mapping from embedding space of one modality to embedding space of the other modality utilizing gan and maximum mean discrepancy based generative networks. we, also demonstrate that our model learns to generate textual description from image data as well as images from textual data both qualitatively and quantitatively. ","476":"machine-generated citation sentences can aid automated scientific literature review and assist article writing. current methods in generating citation text were limited to single citation generation using the citing document and a cited document as input. however, in real-world situations, writers often summarize several studies in one sentence or discuss relevant information across the entire paragraph. in addition, multiple citation intents have been previously identified, implying that writers may need control over the intents of generated sentences to cover different scenarios. therefore, this work focuses on generating multiple citations and releasing a newly collected dataset named citemi to drive the future research. we first build a novel generation model with the fusion-in-decoder approach to cope with multiple long inputs. second, we incorporate the predicted citation intents into training for intent control. the experiments demonstrate that the proposed approaches provide much more comprehensive features for generating citation sentences. ","477":"most existing video text spotting benchmarks focus on evaluating a single language and scenario with limited data. in this work, we introduce a large-scale, bilingual, open world video text benchmark dataset(bovtext). there are four features for bovtext. firstly, we provide 2,000+ videos with more than 1,750,000+ frames, 25 times larger than the existing largest dataset with incidental text in videos. secondly, our dataset covers 30+ open categories with a wide selection of various scenarios, e.g., life vlog, driving, movie, etc. thirdly, abundant text types annotation (i.e., title, caption or scene text) are provided for the different representational meanings in video. fourthly, the bovtext provides bilingual text annotation to promote multiple cultures live and communication. besides, we propose an end-to-end video text spotting framework with transformer, termed transvtspotter, which solves the multi-orient text spotting in video with a simple, but efficient attention-based query-key mechanism. it applies object features from the previous frame as a tracking query for the current frame and introduces a rotation angle prediction to fit the multiorient text instance. on icdar2015(video), transvtspotter achieves the state-of-the-art performance with 44.1% mota, 9 fps. the dataset and code of transvtspotter can be found at github:com=weijiawu=bovtext and github:com=weijiawu=transvtspotter, respectively. ","478":"in this paper, we approach the problem of semantic search by framing the search task as paraphrase span detection, i.e. given a segment of text as a query phrase, the task is to identify its paraphrase in a given document, the same modelling setup as typically used in extractive question answering. on the turku paraphrase corpus of 100,000 manually extracted finnish paraphrase pairs including their original document context, we find that our paraphrase span detection model outperforms two strong retrieval baselines (lexical similarity and bert sentence embeddings) by 31.9pp and 22.4pp respectively in terms of exact match, and by 22.3pp and 12.9pp in terms of token-level f-score. this demonstrates a strong advantage of modelling the task in terms of span retrieval, rather than sentence similarity. additionally, we introduce a method for creating artificial paraphrase data through back-translation, suitable for languages where manually annotated paraphrase resources for training the span detection model are not available. ","479":"sarcasm is a pervading linguistic phenomenon and highly challenging to explain due to its subjectivity, lack of context and deeply-felt opinion. in the multimodal setup, sarcasm is conveyed through the incongruity between the text and visual entities. although recent approaches deal with sarcasm as a classification problem, it is unclear why an online post is identified as sarcastic. without proper explanation, end users may not be able to perceive the underlying sense of irony. in this paper, we propose a novel problem -- multimodal sarcasm explanation (muse) -- given a multimodal sarcastic post containing an image and a caption, we aim to generate a natural language explanation to reveal the intended sarcasm. to this end, we develop more, a new dataset with explanation of 3510 sarcastic multimodal posts. each explanation is a natural language (english) sentence describing the hidden irony. we benchmark more by employing a multimodal transformer-based architecture. it incorporates a cross-modal attention in the transformer's encoder which attends to the distinguishing features between the two modalities. subsequently, a bart-based auto-regressive decoder is used as the generator. empirical results demonstrate convincing results over various baselines (adopted for muse) across five evaluation metrics. we also conduct human evaluation on predictions and obtain fleiss' kappa score of 0.4 as a fair agreement among 25 evaluators. ","480":"learning the embeddings of knowledge graphs is vital in artificial intelligence, and can benefit various downstream applications, such as recommendation and question answering. in recent years, many research efforts have been proposed for knowledge graph embedding. however, most previous knowledge graph embedding methods ignore the semantic similarity between the related entities and entity-relation couples in different triples since they separately optimize each triple with the scoring function. to address this problem, we propose a simple yet efficient contrastive learning framework for knowledge graph embeddings, which can shorten the semantic distance of the related entities and entity-relation couples in different triples and thus improve the expressiveness of knowledge graph embeddings. we evaluate our proposed method on three standard knowledge graph benchmarks. it is noteworthy that our method can yield some new state-of-the-art results, achieving 51.2% mrr, 46.8% hits@1 on the wn18rr dataset, and 59.1% mrr, 51.8% hits@1 on the yago3-10 dataset. ","481":"the raredis corpus contains more than 5,000 rare diseases and almost 6,000 clinical manifestations are annotated. moreover, the inter annotator agreement evaluation shows a relatively high agreement (f1-measure equal to 83.5% under exact match criteria for the entities and equal to 81.3% for the relations). based on these results, this corpus is of high quality, supposing a significant step for the field since there is a scarcity of available corpus annotated with rare diseases. this could open the door to further nlp applications, which would facilitate the diagnosis and treatment of these rare diseases and, therefore, would improve dramatically the quality of life of these patients. ","482":"over the last years, there has been an unprecedented proliferation of fake news. as a consequence, we are more susceptible to the pernicious impact that misinformation and disinformation spreading can have in different segments of our society. thus, the development of tools for automatic detection of fake news plays and important role in the prevention of its negative effects. most attempts to detect and classify false content focus only on using textual information. multimodal approaches are less frequent and they typically classify news either as true or fake. in this work, we perform a fine-grained classification of fake news on the fakeddit dataset, using both unimodal and multimodal approaches. our experiments show that the multimodal approach based on a convolutional neural network (cnn) architecture combining text and image data achieves the best results, with an accuracy of 87%. some fake news categories such as manipulated content, satire or false connection strongly benefit from the use of images. using images also improves the results of the other categories, but with less impact. regarding the unimodal approaches using only text, bidirectional encoder representations from transformers (bert) is the best model with an accuracy of 78%. therefore, exploiting both text and image data significantly improves the performance of fake news detection. ","483":"given a natural language statement, how to verify its veracity against a large-scale textual knowledge source like wikipedia? most existing neural models make predictions without giving clues about which part of a false claim goes wrong. in this paper, we propose loren, an approach for interpretable fact verification. we decompose the verification of the whole claim at phrase-level, where the veracity of the phrases serves as explanations and can be aggregated into the final verdict according to logical rules. the key insight of loren is to represent claim phrase veracity as three-valued latent variables, which are regularized by aggregation logical rules. the final claim verification is based on all latent variables. thus, loren enjoys the additional benefit of interpretability -- it is easy to explain how it reaches certain results with claim phrase veracity. experiments on a public fact verification benchmark show that loren is competitive against previous approaches while enjoying the merit of faithful and accurate interpretability. the resources of loren are available at: https:\/\/github.com\/jiangjiechen\/loren. ","484":"transformer is important for text modeling. however, it has difficulty in handling long documents due to the quadratic complexity with input text length. in order to handle this problem, we propose a hierarchical interactive transformer (hi-transformer) for efficient and effective long document modeling. hi-transformer models documents in a hierarchical way, i.e., first learns sentence representations and then learns document representations. it can effectively reduce the complexity and meanwhile capture global document context in the modeling of each sentence. more specifically, we first use a sentence transformer to learn the representations of each sentence. then we use a document transformer to model the global document context from these sentence representations. next, we use another sentence transformer to enhance sentence modeling using the global document context. finally, we use hierarchical pooling method to obtain document embedding. extensive experiments on three benchmark datasets validate the efficiency and effectiveness of hi-transformer in long document modeling. ","485":"hierarchical text classification consists in classifying text documents into a hierarchy of classes and sub-classes. although artificial neural networks have proved useful to perform this task, unfortunately they can leak training data information to adversaries due to training data memorization. using differential privacy during model training can mitigate leakage attacks against trained models, enabling the models to be shared safely at the cost of reduced model accuracy. this work investigates the privacy-utility trade-off in hierarchical text classification with differential privacy guarantees, and identifies neural network architectures that offer superior trade-offs. to this end, we use a white-box membership inference attack to empirically assess the information leakage of three widely used neural network architectures. we show that large differential privacy parameters already suffice to completely mitigate membership inference attacks, thus resulting only in a moderate decrease in model utility. more specifically, for large datasets with long texts we observed transformer-based models to achieve an overall favorable privacy-utility trade-off, while for smaller datasets with shorter texts convolutional neural networks are preferable. ","486":"the detection of offensive, hateful and profane language has become a critical challenge since many users in social networks are exposed to cyberbullying activities on a daily basis. in this paper, we present an analysis of combining different textual features for the detection of hateful or offensive posts on twitter. we provide a detailed experimental evaluation to understand the impact of each building block in a neural network architecture. the proposed architecture is evaluated on the english subtask 1a: identifying hate, offensive and profane content from the post datasets of hasoc-2021 dataset under the team name tib-va. we compared different variants of the contextual word embeddings combined with the character level embeddings and the encoding of collected hate terms. ","487":"acronym extraction aims to find acronyms (i.e., short-forms) and their meanings (i.e., long-forms) from the documents, which is important for scientific document understanding (sdu@aaai-22) tasks. previous works are devoted to modeling this task as a paragraph-level sequence labeling problem. however, it lacks the effective use of the external knowledge, especially when the datasets are in a low-resource setting. recently, the prompt-based method with the vast pre-trained language model can significantly enhance the performance of the low-resourced downstream tasks. in this paper, we propose a prompt-based sequence generation (psg) method for the acronym extraction task. specifically, we design a template for prompting the extracted acronym texts with auto-regression. a position extraction algorithm is designed for extracting the position of the generated answers. the results on the acronym extraction of vietnamese and persian in a low-resource setting show that the proposed method outperforms all other competitive state-of-the-art (sota) methods. ","488":"acronym disambiguation means finding the correct meaning of an ambiguous acronym from the dictionary in a given sentence, which is one of the key points for scientific document understanding (sdu@aaai-22). recently, many attempts have tried to solve this problem via fine-tuning the pre-trained masked language models (mlms) in order to obtain a better acronym representation. however, the acronym meaning is varied under different contexts, whose corresponding phrase representation mapped in different directions lacks discrimination in the entire vector space. thus, the original representations of the pre-trained mlms are not ideal for the acronym disambiguation task. in this paper, we propose a simple framework for contrastive learning of acronym disambiguation (simclad) method to better understand the acronym meanings. specifically, we design a continual contrastive pre-training method that enhances the pre-trained model's generalization ability by learning the phrase-level contrastive distributions between true meaning and ambiguous phrases. the results on the acronym disambiguation of the scientific domain in english show that the proposed method outperforms all other competitive state-of-the-art (sota) methods. ","489":"the automated speech recognition (asr) community experiences a major turning point with the rise of the fully-neural (end-to-end, e2e) approaches. at the same time, the conventional hybrid model remains the standard choice for the practical usage of asr. according to previous studies, the adoption of e2e asr in real-world applications was hindered by two main limitations: their ability to generalize on unseen domains and their high operational cost. in this paper, we investigate both above-mentioned drawbacks by performing a comprehensive multi-domain benchmark of several contemporary e2e models and a hybrid baseline. our experiments demonstrate that e2e models are viable alternatives for the hybrid approach, and even outperform the baseline both in accuracy and in operational efficiency. as a result, our study shows that the generalization and complexity issues are no longer the major obstacle for industrial integration, and draws the community's attention to other potential limitations of the e2e approaches in some specific use-cases. ","490":"modern web systems such as social media and e-commerce contain rich contents expressed in images and text. leveraging information from multi-modalities can improve the performance of machine learning tasks such as classification and recommendation. in this paper, we propose the cross-modality attention contrastive language-image pre-training (cma-clip), a new framework which unifies two types of cross-modality attentions, sequence-wise attention and modality-wise attention, to effectively fuse information from image and text pairs. the sequence-wise attention enables the framework to capture the fine-grained relationship between image patches and text tokens, while the modality-wise attention weighs each modality by its relevance to the downstream tasks. in addition, by adding task specific modality-wise attentions and multilayer perceptrons, our proposed framework is capable of performing multi-task classification with multi-modalities.   we conduct experiments on a major retail website product attribute (mrwpa) dataset and two public datasets, food101 and fashion-gen. the results show that cma-clip outperforms the pre-trained and fine-tuned clip by an average of 11.9% in recall at the same level of precision on the mrwpa dataset for multi-task classification. it also surpasses the state-of-the-art method on fashion-gen dataset by 5.5% in accuracy and achieves competitive performance on food101 dataset. through detailed ablation studies, we further demonstrate the effectiveness of both cross-modality attention modules and our method's robustness against noise in image and text inputs, which is a common challenge in practice. ","491":"the present paper explores a novel variant of random indexing (ri) based representations for encoding language data with a view to using them in a dynamic scenario where events are happening in a continuous fashion. as the size of the representations in the general method of onehot encoding grows linearly with the size of the vocabulary, they become non-scalable for online purposes with high volumes of dynamic data. on the other hand, existing pre-trained embedding models are not suitable for detecting happenings of new events due to the dynamic nature of the text data. the present work addresses this issue by using a novel ri representation by imposing a probability distribution on the number of randomized entries which leads to a class of ri representations. it also provides a rigorous analysis of the goodness of the representation methods to encode semantic information in terms of the probability of orthogonality. building on these ideas we propose an algorithm that is log-linear with the size of vocabulary to track the semantic relationship of a query word to other words for suggesting the events that are relevant to the word in question. we ran simulations using the proposed algorithm for tweet data specific to three different events and present our findings. the proposed probabilistic ri representations are found to be much faster and scalable than bag of words (bow) embeddings while maintaining accuracy in depicting semantic relationships. ","492":"the vision-language navigation (vln) task requires an agent to reach a target with the guidance of natural language instruction. previous works learn to navigate step-by-step following an instruction. however, these works may fail to discriminate the similarities and discrepancies across instruction-trajectory pairs and ignore the temporal continuity of sub-instructions. these problems hinder agents from learning distinctive vision-and-language representations, harming the robustness and generalizability of the navigation policy. in this paper, we propose a contrastive instruction-trajectory learning (citl) framework that explores invariance across similar data samples and variance across different ones to learn distinctive representations for robust navigation. specifically, we propose: (1) a coarse-grained contrastive learning objective to enhance vision-and-language representations by contrasting semantics of full trajectory observations and instructions, respectively; (2) a fine-grained contrastive learning objective to perceive instructions by leveraging the temporal information of the sub-instructions; (3) a pairwise sample-reweighting mechanism for contrastive learning to mine hard samples and hence mitigate the influence of data sampling bias in contrastive learning. our citl can be easily integrated with vln backbones to form a new learning paradigm and achieve better generalizability in unseen environments. extensive experiments show that the model with citl surpasses the previous state-of-the-art methods on r2r, r4r, and rxr. ","493":"this paper presents racebert -- a transformer-based model for predicting race and ethnicity from character sequences in names, and an accompanying python package. using a transformer-based model trained on a u.s. florida voter registration dataset, the model predicts the likelihood of a name belonging to 5 u.s. census race categories (white, black, hispanic, asian & pacific islander, american indian & alaskan native). i build on sood and laohaprapanon (2018) by replacing their lstm model with transformer-based models (pre-trained bert model, and a roberta model trained from scratch), and compare the results. to the best of my knowledge, racebert achieves state-of-the-art results in race prediction using names, with an average f1-score of 0.86 -- a 4.1% improvement over the previous state-of-the-art, and improvements between 15-17% for non-white names. ","494":"multi-document summarization (mds) is an effective tool for information aggregation that generates an informative and concise summary from a cluster of topic-related documents. our survey, the first of its kind, systematically overviews the recent deep learning based mds models. we propose a novel taxonomy to summarize the design strategies of neural networks and conduct a comprehensive summary of the state-of-the-art. we highlight the differences between various objective functions that are rarely discussed in the existing literature. finally, we propose several future directions pertaining to this new and exciting field. ","495":"with the growing impact of esg on businesses, research related to renewable energy is receiving great attention. solar cells are one of them, and accordingly, it can be said that the research value of solar cell patent analysis is very high. patent documents have high research value. being able to accurately analyze and classify patent documents can reveal several important technical relationships. it can also describe the business trends in that technology. and when it comes to investment, new industrial solutions will also be inspired and proposed to make important decisions. therefore, we must carefully analyze patent documents and utilize the value of patents. to solve the solar cell patent classification problem, we propose a keyword extraction method and a deep neural network-based solar cell patent classification method. first, solar cell patents are analyzed for pretreatment. it then uses the keybert algorithm to extract keywords and key phrases from the patent abstract to construct a lexical dictionary. we then build a solar cell patent classification model according to the deep neural network. finally, we use a deep neural network-based solar cell patent classification model to classify power patents, and the training accuracy is greater than 95%. also, the validation accuracy is about 87.5%. it can be seen that the deep neural network method can not only realize the classification of complex and difficult solar cell patents, but also have a good classification effect. ","496":"this paper explores the capabilities of current transformer-based language models for program evaluation of simple functional programming languages. we introduce a new program generation mechanism that allows control over syntactic sugar for semantically equivalent programs. t5 experiments reveal that neural functional program evaluation performs surprisingly well, achieving high 90% exact program match scores for most in-distribution and out-of-distribution tests. using pretrained t5 weights has significant advantages over random initialization. we present and evaluate on three datasets to study generalization abilities that are specific to functional programs based on: type, function composition, and reduction steps. code and data are publicly available at https:\/\/github.com\/elementai\/neural-interpreters. ","497":"despite the great success of high-level synthesis (hls) tools, we observe several unresolved challenges: 1) the high-level abstraction of programming styles in hls sometimes conceals optimization opportunities; 2) existing hls tools do not provide flexible trade-off (pareto) solutions among different objectives and constraints; 3) the actual quality of the resulting rtl designs is hard to predict. to address these challenges, we propose an end-to-end framework, namelyironman. the primary goal is to enable a flexible and automated design space exploration (dse), to provide either optimal solutions under user-specified constraints, or various trade-offs among different objectives (such as different types of resources, area, and latency). such dse either requires tedious manual efforts or is not achievable to attain these goals through existing hls tools. there are three components in ironman: 1) gpp, a highly accurate graph-neural-network-based performance and resource predictor; 2) rlmd, a reinforcement-learning-based multi-objective dse engine that explores the optimal resource allocation strategy, to provide pareto solutions between different objectives; 3) ct, a code transformer to assist rlmd and gpp, which extracts the data flow graph from original hls c\/c++ and automatically generates synthesizable code with hls directives. the experimental results show that: 1) gpp achieves high prediction accuracy, reducing prediction errors of hls tools by 10.9x in resource utilization and 5.7x in timing; 2) rlmd obtains optimal or pareto solutions that outperform the genetic algorithm and simulated annealing by 12.7% and 12.9%, respectively; 3) ironman is able to find optimized solutions perfectly matching various dsp constraints, with 2.54x fewer dsps and up to 6x shorter latency than those of hls tools while being up to 400x faster than the heuristic algorithms and hls tools. ","498":"this paper presents a new pre-trained language model, debertav3, which improves the original deberta model by replacing mask language modeling (mlm) with replaced token detection (rtd), a more sample-efficient pre-training task. our analysis shows that vanilla embedding sharing in electra hurts training efficiency and model performance. this is because the training losses of the discriminator and the generator pull token embeddings in different directions, creating the \"tug-of-war\" dynamics. we thus propose a new gradient-disentangled embedding sharing method that avoids the tug-of-war dynamics, improving both training efficiency and the quality of the pre-trained model. we have pre-trained debertav3 using the same settings as deberta to demonstrate its exceptional performance on a wide range of downstream natural language understanding (nlu) tasks. taking the glue benchmark with eight tasks as an example, the debertav3 large model achieves a 91.37% average score, which is 1.37% over deberta and 1.91% over electra, setting a new state-of-the-art (sota) among the models with a similar structure. furthermore, we have pre-trained a multi-lingual model mdeberta and observed a larger improvement over strong baselines compared to english models. for example, the mdeberta base achieves a 79.8% zero-shot cross-lingual accuracy on xnli and a 3.6% improvement over xlm-r base, creating a new sota on this benchmark. we have made our pre-trained models and inference code publicly available at https:\/\/github.com\/microsoft\/deberta. ","499":"keyphrase generation is the task of generating phrases (keyphrases) that summarize the main topics of a given document. the generated keyphrases can be either present or absent from the text of the given document. while the extraction of present keyphrases has received much attention in the past, only recently a stronger focus has been placed on the generation of absent keyphrases. however, generating absent keyphrases is very challenging; even the best methods show only a modest degree of success. in this paper, we propose an approach, called keyphrase dropout (or kpdrop), to improve absent keyphrase generation. we randomly drop present keyphrases from the document and turn them into artificial absent keyphrases during training. we test our approach extensively and show that it consistently improves the absent performance of strong baselines in keyphrase generation. ","500":"recognizing unseen relations with no training instances is a challenging task in the real world. in this paper, we propose a prompt-based model with semantic knowledge augmentation (zs-ska) to recognize unseen relations under the zero-shot setting. we generate augmented instances with unseen relations from instances with seen relations following a new word-level sentence translation rule. we design prompts based on an external knowledge graph to integrate semantic knowledge information learned from seen relations. instead of using the actual label sets in the prompt template, we construct weighted virtual label words. by generating the representations of both seen and unseen relations with augmented instances and prompts through prototypical networks, distance is calculated to predict unseen relations. extensive experiments conducted on three public datasets show that zs-ska outperforms state-of-the-art methods under the zero-shot scenarios. our experimental results also demonstrate the effectiveness and robustness of zs-ska. ","501":"visual-language pre-training has shown great success for learning joint visual-textual representations from large-scale web data, demonstrating remarkable ability for zero-shot generalisation. this paper presents a simple method to efficiently adapt one pre-trained visual-language model to novel tasks with minimal training, and here, we consider video understanding tasks. specifically, we propose to optimise a few random vectors, termed as continuous prompt vectors, that convert the novel tasks into the same format as the pre-training objectives. in addition, to bridge the gap between static images and videos, temporal information is encoded with lightweight transformers stacking on top of frame-wise visual features. experimentally, we conduct extensive ablation studies to analyse the critical components and necessities. on 9 public benchmarks of action recognition, action localisation, and text-video retrieval, across closed-set, few-shot, open-set scenarios, we achieve competitive or state-of-the-art performance to existing methods, despite training significantly fewer parameters. ","502":"we initiate the first empirical study on the use of mlp architectures for vision-and-language (vl) fusion. through extensive experiments on 5 vl tasks and 5 robust vqa benchmarks, we find that: (i) without pre-training, using mlps for multimodal fusion has a noticeable performance gap compared to transformers; (ii) however, vl pre-training can help close the performance gap; (iii) instead of heavy multi-head attention, adding tiny one-head attention to mlps is sufficient to achieve comparable performance to transformers. moreover, we also find that the performance gap between mlps and transformers is not widened when being evaluated on the harder robust vqa benchmarks, suggesting using mlps for vl fusion can generalize roughly to a similar degree as using transformers. these results hint that mlps can effectively learn to align vision and text features extracted from lower-level encoders without heavy reliance on self-attention. based on this, we ask an even bolder question: can we have an all-mlp architecture for vl modeling, where both vl fusion and the vision encoder are replaced with mlps? our result shows that an all-mlp vl model is sub-optimal compared to state-of-the-art full-featured vl models when both of them get pre-trained. however, pre-training an all-mlp can surprisingly achieve a better average score than full-featured transformer models without pre-training. this indicates the potential of large-scale pre-training of mlp-like architectures for vl modeling and inspires the future research direction on simplifying well-established vl modeling with less inductive design bias. our code is publicly available at: https:\/\/github.com\/easonnie\/mlp-vil ","503":"multi-modal learning from video data has seen increased attention recently as it allows to train semantically meaningful embeddings without human annotation enabling tasks like zero-shot retrieval and classification. in this work, we present a multi-modal, modality agnostic fusion transformer approach that learns to exchange information between multiple modalities, such as video, audio, and text, and integrate them into a joined multi-modal representation to obtain an embedding that aggregates multi-modal temporal information. we propose to train the system with a combinatorial loss on everything at once, single modalities as well as pairs of modalities, explicitly leaving out any add-ons such as position or modality encoding. at test time, the resulting model can process and fuse any number of input modalities. moreover, the implicit properties of the transformer allow to process inputs of different lengths. to evaluate the proposed approach, we train the model on the large scale howto100m dataset and evaluate the resulting embedding space on four challenging benchmark datasets obtaining state-of-the-art results in zero-shot video retrieval and zero-shot video action localization. ","504":"this paper aims to help structure the risk landscape associated with large-scale language models (lms). in order to foster advances in responsible innovation, an in-depth understanding of the potential risks posed by these models is needed. a wide range of established and anticipated risks are analysed in detail, drawing on multidisciplinary expertise and literature from computer science, linguistics, and social sciences.   we outline six specific risk areas: i. discrimination, exclusion and toxicity, ii. information hazards, iii. misinformation harms, v. malicious uses, v. human-computer interaction harms, vi. automation, access, and environmental harms. the first area concerns the perpetuation of stereotypes, unfair discrimination, exclusionary norms, toxic language, and lower performance by social group for lms. the second focuses on risks from private data leaks or lms correctly inferring sensitive information. the third addresses risks arising from poor, false or misleading information including in sensitive domains, and knock-on risks such as the erosion of trust in shared information. the fourth considers risks from actors who try to use lms to cause harm. the fifth focuses on risks specific to llms used to underpin conversational agents that interact with human users, including unsafe use, manipulation or deception. the sixth discusses the risk of environmental harm, job automation, and other challenges that may have a disparate effect on different social groups or communities.   in total, we review 21 risks in-depth. we discuss the points of origin of different risks and point to potential mitigation approaches. lastly, we discuss organisational responsibilities in implementing mitigations, and the role of collaboration and participation. we highlight directions for further research, particularly on expanding the toolkit for assessing and evaluating the outlined risks in lms. ","505":"in this work, our aim is to provide a structured answer in natural language to a complex information need. particularly, we envision using generative models from the perspective of data-to-text generation. we propose the use of a content selection and planning pipeline which aims at structuring the answer by generating intermediate plans. the experimental evaluation is performed using the trec complex answer retrieval (car) dataset. we evaluate both the generated answer and its corresponding structure and show the effectiveness of planning-based models in comparison to a text-to-text model. ","506":"numerous government initiatives (e.g. the eu with gdpr) are coming to the conclusion that the increasing complexity of modern software systems must be contrasted with some rights to explanation and metrics for the impact assessment of these tools, that allow humans to understand and oversee the output of automated decision making systems. explainable ai was born as a pathway to allow humans to explore and understand the inner working of complex systems. but establishing what is an explanation and objectively evaluating explainability, are not trivial tasks. with this paper, we present a new model-agnostic metric to measure the degree of explainability of (correct) information in an objective way, exploiting a specific theoretical model from ordinary language philosophy called the achinstein's theory of explanations, implemented with an algorithm relying on deep language models for knowledge graph extraction and information retrieval. in order to understand whether this metric is actually behaving as explainability is expected to, we have devised a few experiments and user-studies involving more than 160 participants evaluating two realistic ai-based systems for healthcare and finance using famous ai technology including artificial neural networks and treeshap. the results we obtained are very encouraging, suggesting that our proposed metric for measuring the degree of explainability is robust on several scenarios and it can be eventually exploited for a lawful impact assessment of an automated decision making system. ","507":"given a word binary relation $\\tau$ we define a $\\tau$-gray cycle over a finite language x to be a permutation w [i] 0$\\le$i$\\le$|x|--1 of x such that each word wi is an image of the previous word wi--1 by $\\tau$. in that framework, we introduce the complexity measure $\\lambda$(n), equal to the largest cardinality of a language x having words of length at most n, and such that a $\\tau$-gray cycle over x exists. the present paper is concerned with the relation $\\tau$ = $\\sigma$ k , the so-called k-character substitution, where (u, v) belongs to $\\sigma$ k if, and only if, the hamming distance of u and v is k. we compute the bound $\\lambda$(n) for all cases of the alphabet cardinality and the argument n. ","508":"the past decade has seen a substantial rise in the amount of mis- and disinformation online, from targeted disinformation campaigns to influence politics, to the unintentional spreading of misinformation about public health. this development has spurred research in the area of automatic fact checking, from approaches to detect check-worthy claims and determining the stance of tweets towards claims, to methods to determine the veracity of claims given evidence documents. these automatic methods are often content-based, using natural language processing methods, which in turn utilise deep neural networks to learn higher-order features from text in order to make predictions. as deep neural networks are black-box models, their inner workings cannot be easily explained. at the same time, it is desirable to explain how they arrive at certain decisions, especially if they are to be used for decision making. while this has been known for some time, the issues this raises have been exacerbated by models increasing in size, and by eu legislation requiring models to be used for decision making to provide explanations, and, very recently, by legislation requiring online platforms operating in the eu to provide transparent reporting on their services. despite this, current solutions for explainability are still lacking in the area of fact checking. this thesis presents my research on automatic fact checking, including claim check-worthiness detection, stance detection and veracity prediction. its contributions go beyond fact checking, with the thesis proposing more general machine learning solutions for natural language processing in the area of learning with limited labelled data. finally, the thesis presents some first solutions for explainable fact checking. ","509":"general-purpose robots coexisting with humans in their environment must learn to relate human language to their perceptions and actions to be useful in a range of daily tasks. moreover, they need to acquire a diverse repertoire of general-purpose skills that allow composing long-horizon tasks by following unconstrained language instructions. in this paper, we present calvin (composing actions from language and vision), an open-source simulated benchmark to learn long-horizon language-conditioned tasks. our aim is to make it possible to develop agents that can solve many robotic manipulation tasks over a long horizon, from onboard sensors, and specified only via human language. calvin tasks are more complex in terms of sequence length, action space, and language than existing vision-and-language task datasets and supports flexible specification of sensor suites. we evaluate the agents in zero-shot to novel language instructions and to novel environments and objects. we show that a baseline model based on multi-context imitation learning performs poorly on calvin, suggesting that there is significant room for developing innovative agents that learn to relate human language to their world models with this benchmark. ","510":"the extraction of relevant information carried out by named entities in handwriting documents is still a challenging task. unlike traditional information extraction approaches that usually face text transcription and named entity recognition as separate subsequent tasks, we propose in this paper an end-to-end transformer-based approach to jointly perform these two tasks. the proposed approach operates at the paragraph level, which brings two main benefits. first, it allows the model to avoid unrecoverable early errors due to line segmentation. second, it allows the model to exploit larger bi-dimensional context information to identify the semantic categories, reaching a higher final prediction accuracy. we also explore different training scenarios to show their effect on the performance and we demonstrate that a two-stage learning strategy can make the model reach a higher final prediction accuracy. as far as we know, this work presents the first approach that adopts the transformer networks for named entity recognition in handwritten documents. we achieve the new state-of-the-art performance in the icdar 2017 information extraction competition using the esposalles database, for the complete task, even though the proposed technique does not use any dictionaries, language modeling, or post-processing. ","511":"expectation-based minimalist grammars (e-mgs) are simplified versions of the (conflated) minimalist grammars, (c)mgs, formalized by stabler (stabler, 2011, 2013, 1997) and phase-based minimalist grammars, pmgs (chesi, 2005, 2007; stabler, 2011). the crucial simplification consists of driving structure building only by relying on lexically encoded categorial top-down expectations. the commitment on a top-down derivation (as in e-mgs and pmgs, as opposed to (c)mgs, chomsky, 1995; stabler, 2011) allows us to define a core derivation that should be the same in both parsing and generation (momma & phillips, 2018). ","512":"recommendation is the task of ranking items (e.g. movies or products) according to individual user needs. current systems rely on collaborative filtering and content-based techniques, which both require structured training data. we propose a framework for recommendation with off-the-shelf pretrained language models (lm) that only used unstructured text corpora as training data. if a user $u$ liked \\textit{matrix} and \\textit{inception}, we construct a textual prompt, e.g. \\textit{\"movies like matrix, inception, ${<}m{>}$\"} to estimate the affinity between $u$ and $m$ with lm likelihood. we motivate our idea with a corpus analysis, evaluate several prompt structures, and we compare lm-based recommendation with standard matrix factorization trained on different data regimes. the code for our experiments is publicly available (https:\/\/colab.research.google.com\/drive\/1f1mlz-fgalgdo5rpzxf3vemkllbh2est?usp=sharing). ","513":"natural language video localization (nlvl) is an important task in the vision-language understanding area, which calls for an in-depth understanding of not only computer vision and natural language side alone, but more importantly the interplay between both sides. adversarial vulnerability has been well-recognized as a critical security issue of deep neural network models, which requires prudent investigation. despite its extensive yet separated studies in video and language tasks, current understanding of the adversarial robustness in vision-language joint tasks like nlvl is less developed. this paper therefore aims to comprehensively investigate the adversarial robustness of nlvl models by examining three facets of vulnerabilities from both attack and defense aspects. to achieve the attack goal, we propose a new adversarial attack paradigm called synonymous sentences-aware adversarial attack on nlvl (sneak), which captures the cross-modality interplay between the vision and language sides. ","514":"in this study, listeners of varied indian nativities are asked to listen and recognize timit utterances spoken by american speakers. we have three kinds of responses from each listener while they recognize an utterance: 1. sentence difficulty ratings, 2. speaker difficulty ratings, and 3. transcription of the utterance. from these transcriptions, word error rate (wer) is calculated and used as a metric to evaluate the similarity between the recognized and the original sentences.the sentences selected in this study are categorized into three groups: easy, medium and hard, based on the frequency ofoccurrence of the words in them. we observe that the sentence, speaker difficulty ratings and the wers increase from easy to hard categories of sentences. we also compare the human speech recognition performance with that using three automatic speech recognition (asr) under following three combinations of acoustic model (am) and language model(lm): asr1) am trained with recordings from speakers of indian origin and lm built on timit text, asr2) am using recordings from native american speakers and lm built ontext from libri speech corpus, and asr3) am using recordings from native american speakers and lm build on libri speech and timit text. we observe that hsr performance is similar to that of asr1 whereas asr3 achieves the best performance. speaker nativity wise analysis shows that utterances from speakers of some nativity are more difficult to recognize by indian listeners compared to few other nativities ","515":"natural language processing researchers have identified limitations of evaluation methodology for generation tasks, with new questions raised about the validity of automatic metrics and of crowdworker judgments. meanwhile, efforts to improve generation models tend to focus on simple n-gram overlap metrics (e.g., bleu, rouge). we argue that new advances on models and metrics should each more directly benefit and inform the other. we therefore propose a generalization of leaderboards, bidimensional leaderboards (billboards), that simultaneously tracks progress in language generation tasks and metrics for their evaluation. unlike conventional unidimensional leaderboards that sort submitted systems by predetermined metrics, a billboard accepts both generators and evaluation metrics as competing entries. a billboard automatically creates an ensemble metric that selects and linearly combines a few metrics based on a global analysis across generators. further, metrics are ranked based on their correlations with human judgments. we release four billboards for machine translation, summarization, and image captioning. we demonstrate that a linear ensemble of a few diverse metrics sometimes substantially outperforms existing metrics in isolation. our mixed-effects model analysis shows that most automatic metrics, especially the reference-based ones, overrate machine over human generation, demonstrating the importance of updating metrics as generation models become stronger (and perhaps more similar to humans) in the future. ","516":"how to effectively adapt neural machine translation (nmt) models according to emerging cases without retraining? despite the great success of neural machine translation, updating the deployed models online remains a challenge. existing non-parametric approaches that retrieve similar examples from a database to guide the translation process are promising but are prone to overfit the retrieved examples. in this work, we propose to learn kernel-smoothed translation with example retrieval (kster), an effective approach to adapt neural machine translation models online. experiments on domain adaptation and multi-domain machine translation datasets show that even without expensive retraining, kster is able to achieve improvement of 1.1 to 1.5 bleu scores over the best existing online adaptation methods. the code and trained models are released at https:\/\/github.com\/jiangqn\/kster. ","517":"we propose a deep learning-based foreign language learning platform, named freetalky, for people who experience anxiety dealing with foreign languages, by employing a humanoid robot nao and various deep learning models. a persona-based dialogue system that is embedded in nao provides an interesting and consistent multi-turn dialogue for users. also, an grammar error correction system promotes improvement in grammar skills of the users. thus, our system enables personalized learning based on persona dialogue and facilitates grammar learning of a user using grammar error feedback. furthermore, we verified whether freetalky provides practical help in alleviating xenoglossophobia by replacing the real human in the conversation with a nao robot, through human evaluation. ","518":"entity linking aims to establish a link between entity mentions in a document and the corresponding entities in knowledge graphs (kgs). previous work has shown the effectiveness of global coherence for entity linking. however, most of the existing global linking methods based on sequential decisions focus on how to utilize previously linked entities to enhance the later decisions. in those methods, the order of mention is fixed, making the model unable to adjust the subsequent linking targets according to the previously linked results, which will cause the previous information to be unreasonably utilized. to address the problem, we propose a novel model, called dymen, to dynamically adjust the subsequent linking target based on the previously linked entities via reinforcement learning, enabling the model to select a link target that can fully use previously linked information. we sample mention by sliding window to reduce the action sampling space of reinforcement learning and maintain the semantic coherence of mention. experiments conducted on several benchmark datasets have shown the effectiveness of the proposed model. ","519":"the current state-of-the-art generative models for open-domain question answering (odqa) have focused on generating direct answers from unstructured textual information. however, a large amount of world's knowledge is stored in structured databases, and need to be accessed using query languages such as sql. furthermore, query languages can answer questions that require complex reasoning, as well as offering full explainability. in this paper, we propose a hybrid framework that takes both textual and tabular evidence as input and generates either direct answers or sql queries depending on which form could better answer the question. the generated sql queries can then be executed on the associated databases to obtain the final answers. to the best of our knowledge, this is the first paper that applies text2sql to odqa tasks. empirically, we demonstrate that on several odqa datasets, the hybrid methods consistently outperforms the baseline models that only take homogeneous input by a large margin. specifically we achieve state-of-the-art performance on opensquad dataset using a t5-base model. in a detailed analysis, we demonstrate that the being able to generate structural sql queries can always bring gains, especially for those questions that requires complex reasoning. ","520":"the creation of a quality summarization dataset is an expensive, time-consuming effort, requiring the production and evaluation of summaries by both trained humans and machines. if such effort is made in one language, it would be beneficial to be able to use it in other languages without repeating human annotations. to investigate how much we can trust machine translation of such a dataset, we translate the english dataset summeval to seven languages and compare performance across automatic evaluation measures. we explore equivalence testing as the appropriate statistical paradigm for evaluating correlations between human and automated scoring of summaries. while we find some potential for dataset reuse in languages similar to the source, most summary evaluation methods are not found to be statistically equivalent across translations. ","521":"objective: to provide a scoping review of papers on clinical natural language processing (nlp) tasks that use publicly available electronic health record data from a cohort of patients. materials and methods: we searched six databases, including biomedical research and computer science literature database. a round of title\/abstract screening and full-text screening were conducted by two reviewers. our method followed the preferred reporting items for systematic reviews and meta-analysis (prisma) guidelines. results: a total of 35 papers with 47 clinical nlp tasks met inclusion criteria between 2007 and 2021. we categorized the tasks by the type of nlp problems, including name entity recognition, summarization, and other nlp tasks. some tasks were introduced with a topic of clinical decision support applications, such as substance abuse, phenotyping, cohort selection for clinical trial. we summarized the tasks by publication and dataset information. discussion: the breadth of clinical nlp tasks keeps growing as the field of nlp evolves with advancements in language systems. however, gaps exist in divergent interests between general domain nlp community and clinical informatics community, and in generalizability of the data sources. we also identified issues in data selection and preparation including the lack of time-sensitive data, and invalidity of problem size and evaluation. conclusions: the existing clinical nlp tasks cover a wide range of topics and the field will continue to grow and attract more attention from both general domain nlp and clinical informatics community. we encourage future work to incorporate multi-disciplinary collaboration, reporting transparency, and standardization in data preparation. ","522":"address parsing consists of identifying the segments that make up an address, such as a street name or a postal code. because of its importance for tasks like record linkage, address parsing has been approached with many techniques, the latest relying on neural networks. while these models yield notable results, previous work on neural networks has only focused on parsing addresses from a single source country. this paper explores the possibility of transferring the address parsing knowledge acquired by training deep learning models on some countries' addresses to others with no further training in a zero-shot transfer learning setting. we also experiment using an attention mechanism and a domain adversarial training algorithm in the same zero-shot transfer setting to improve performance. both methods yield state-of-the-art performance for most of the tested countries while giving good results to the remaining countries. we also explore the effect of incomplete addresses on our best model, and we evaluate the impact of using incomplete addresses during training. in addition, we propose an open-source python implementation of some of our trained models. ","523":"emotion-cause pair extraction (ecpe) is a complex yet popular area in natural language processing due to its importance and potential applications in various domains. in this report , we aim to present our work in ecpe in the domain of online reviews. with a manually annotated dataset, we explore an algorithm to extract emotion cause pairs using a neural network. in addition, we propose a model using previous reference materials and combining emotion-cause pair extraction with research in the domain of emotion-aware word embeddings, where we send these embeddings into a bi-lstm layer which gives us the emotionally relevant clauses. with the constraint of a limited dataset, we achieved . the overall scope of our report comprises of a comprehensive literature review, implementation of referenced methods for dataset construction and initial model training, and modifying previous work in ecpe by proposing an improvement to the pipeline, as well as algorithm development and implementation for the specific domain of reviews. ","524":"explainable nlp (exnlp) has increasingly focused on collecting human-annotated textual explanations. these explanations are used downstream in three ways: as data augmentation to improve performance on a predictive task, as supervision to train models to produce explanations for their predictions, and as a ground-truth to evaluate model-generated explanations. in this review, we identify 65 datasets with three predominant classes of textual explanations (highlights, free-text, and structured), organize the literature on annotating each type, identify strengths and shortcomings of existing collection methodologies, and give recommendations for collecting exnlp datasets in the future. ","525":"we develop a tool that extracts emotions from social media text data. our methodology has three main advantages. first, it is tailored for financial context; second, it incorporates key aspects of social media data, such as non-standard phrases, emojis and emoticons; and third, it operates by sequentially learning a latent representation that includes features such as word order, word usage, and local context. this tool, along with a user guide is available at: https:\/\/github.com\/dvamossy\/emtract. using emtract, we explore the relationship between investor emotions expressed on social media and asset prices. we document a number of interesting insights. first, we confirm some of the findings of controlled laboratory experiments relating investor emotions to asset price movements. second, we show that investor emotions are predictive of daily price movements. these impacts are larger when volatility or short interest are higher, and when institutional ownership or liquidity are lower. third, increased investor enthusiasm prior to the ipo contributes to the large first-day return and long-run underperformance of ipo stocks. to corroborate our results, we provide a number of robustness checks, including using an alternative emotion model. our findings reinforce the intuition that emotions and market dynamics are closely related, and highlight the importance of considering investor emotions when assessing a stock's short-term value. ","526":"the ubiquity of offensive and hateful content on online fora necessitates the need for automatic solutions that detect such content competently across target groups. in this paper we show that text classification models trained on large publicly available datasets despite having a high overall performance, may significantly under-perform on several protected groups. on the \\citet{vidgen2020learning} dataset, we find the accuracy to be 37\\% lower on an under annotated black women target group and 12\\% lower on immigrants, where hate speech involves a distinct style. to address this, we propose to perform token-level hate sense disambiguation, and utilize tokens' hate sense representations for detection, modeling more general signals. on two publicly available datasets, we observe that the variance in model accuracy across target groups drops by at least 30\\%, improving the average target group performance by 4\\% and worst case performance by 13\\%. ","527":"this paper presents a grounded language-image pre-training (glip) model for learning object-level, language-aware, and semantic-rich visual representations. glip unifies object detection and phrase grounding for pre-training. the unification brings two benefits: 1) it allows glip to learn from both detection and grounding data to improve both tasks and bootstrap a good grounding model; 2) glip can leverage massive image-text pairs by generating grounding boxes in a self-training fashion, making the learned representation semantic-rich. in our experiments, we pre-train glip on 27m grounding data, including 3m human-annotated and 24m web-crawled image-text pairs. the learned representations demonstrate strong zero-shot and few-shot transferability to various object-level recognition tasks. 1) when directly evaluated on coco and lvis (without seeing any images in coco during pre-training), glip achieves 49.8 ap and 26.9 ap, respectively, surpassing many supervised baselines. 2) after fine-tuned on coco, glip achieves 60.8 ap on val and 61.5 ap on test-dev, surpassing prior sota. 3) when transferred to 13 downstream object detection tasks, a 1-shot glip rivals with a fully-supervised dynamic head. code will be released at https:\/\/github.com\/microsoft\/glip. ","528":"question answering systems these days typically use template-based language generation. though adequate for a domain-specific task, these systems are too restrictive and predefined for domain-independent systems. this paper proposes a system that outputs a full-length answer given a question and the extracted factoid answer (short spans such as named entities) as the input. our system uses constituency and dependency parse trees of questions. a transformer-based grammar error correction model gector (2020), is used as a post-processing step for better fluency. we compare our system with (i) modified pointer generator (sota) and (ii) fine-tuned dialogpt for factoid questions. we also test our approach on existential (yes-no) questions with better results. our model generates accurate and fluent answers than the state-of-the-art (sota) approaches. the evaluation is done on newsqa and squad datasets with an increment of 0.4 and 0.9 percentage points in rouge-1 score respectively. also the inference time is reduced by 85\\% as compared to the sota. the improved datasets used for our evaluation will be released as part of the research contribution. ","529":"neural language model-based approaches to automated story generation suffer from two important limitations. first, language model-based story generators generally do not work toward a given goal or ending. second, they often lose coherence as the story gets longer. we propose a novel approach to automated story generation that treats the problem as one of generative question-answering. our proposed story generation system starts with sentences encapsulating the final event of the story. the system then iteratively (1) analyzes the text describing the most recent event, (2) generates a question about \"why\" a character is doing the thing they are doing in the event, and then (3) attempts to generate another, preceding event that answers this question. ","530":"protein is linked to almost every life process. therefore, analyzing the biological structure and property of protein sequences is critical to the exploration of life, as well as disease detection and drug discovery. traditional protein analysis methods tend to be labor-intensive and time-consuming. the emergence of deep learning models makes modeling data patterns in large quantities of data possible. interdisciplinary researchers have begun to leverage deep learning methods to model large biological datasets, e.g. using long short-term memory and convolutional neural network for protein sequence classification. after millions of years of evolution, evolutionary information is encoded in protein sequences. inspired by the similarity between natural language and protein sequences, we use large-scale language models to model evolutionary-scale protein sequences, encoding protein biology information in representation. significant improvements are observed in both token-level and sequence-level tasks, demonstrating that our large-scale model can accurately capture evolution information from pretraining on evolutionary-scale individual sequences. our code and model are available at https:\/\/github.com\/thudm\/proteinlm. ","531":"language is not only used to inform. we often seek to persuade by arguing in favor of a particular view. persuasion raises a number of challenges for classical accounts of belief updating, as information cannot be taken at face value. how should listeners account for a speaker's \"hidden agenda\" when incorporating new information? here, we extend recent probabilistic models of recursive social reasoning to allow for persuasive goals and show that our model provides a new pragmatic explanation for why weakly favorable arguments may backfire, a phenomenon known as the weak evidence effect. critically, our model predicts a relationship between belief updating and speaker expectations: weak evidence should only backfire when speakers are expected to act under persuasive goals, implying the absence of stronger evidence. we introduce a simple experimental paradigm called the stick contest to measure the extent to which the weak evidence effect depends on speaker expectations, and show that a pragmatic listener model accounts for the empirical data better than alternative models. our findings suggest potential avenues for rational models of social reasoning to further illuminate decision-making phenomena. ","532":"in recent years, the task of mining important information from social media posts during crises has become a focus of research for the purposes of assisting emergency response (es). the trec incident streams (is) track is a research challenge organised for this purpose. the track asks participating systems to both classify a stream of crisis-related tweets into humanitarian aid related information types and estimate their importance regarding criticality. the former refers to a multi-label information type classification task and the latter refers to a priority estimation task. in this paper, we report on the participation of the university college dublin school of computer science (ucd-cs) in trec-is 2021. we explored a variety of approaches, including simple machine learning algorithms, multi-task learning techniques, text augmentation, and ensemble approaches. the official evaluation results indicate that our runs achieve the highest scores in many metrics. to aid reproducibility, our code is publicly available at https:\/\/github.com\/wangcongcong123\/crisis-mtl. ","533":"this paper describes the system submitted to dravidian-codemix-hasoc2021: hate speech and offensive language identification in dravidian languages (tamil-english and malayalam-english). this task aims to identify offensive content in code-mixed comments\/posts in dravidian languages collected from social media. our approach utilizes pooling the last layers of pretrained transformer multilingual bert for this task which helped us achieve rank nine on the leaderboard with a weighted average score of 0.61 for the tamil-english dataset in subtask b. after the task deadline, we sampled the dataset uniformly and used the muril pretrained model, which helped us achieve a weighted average score of 0.67, the top score in the leaderboard. furthermore, our approach to utilizing the pretrained models helps reuse our models for the same task with a different dataset. our code and models are available in https:\/\/github.com\/seanbenhur\/tanglish-offensive-language-identification ","534":"the amount of scholarly data has been increasing dramatically over the last years. for newcomers to a particular science domain (e.g., ir, physics, nlp) it is often difficult to spot larger trends and to position the latest research in the context of prior scientific achievements and breakthroughs. similarly, researchers in the history of science are interested in tools that allow them to analyze and visualize changes in particular scientific domains. temporal summarization and related methods should be then useful for making sense of large volumes of scientific discourse data aggregated over time. we demonstrate a novel approach to analyze the collections of research papers published over longer time periods to provide a high-level overview of important semantic changes that occurred over the progress of time. our approach is based on comparing word semantic representations over time and aims to support users in a better understanding of large domain-focused archives of scholarly publications. as an example dataset we use the acl anthology reference corpus that spans from 1979 to 2015 and contains 22,878 scholarly articles. ","535":"with an increase of dataset availability, the potential for learning from a variety of data sources has increased. one particular method to improve learning from multiple data sources is to embed the data source during training. this allows the model to learn generalizable features as well as distinguishing features between datasets. however, these dataset embeddings have mostly been used before contextualized transformer-based embeddings were introduced in the field of natural language processing. in this work, we compare two methods to embed datasets in a transformer-based multilingual dependency parser, and perform an extensive evaluation. we show that: 1) embedding the dataset is still beneficial with these models 2) performance increases are highest when embedding the dataset at the encoder level 3) unsurprisingly, we confirm that performance increases are highest for small datasets and datasets with a low baseline score. 4) we show that training on the combination of all datasets performs similarly to designing smaller clusters based on language-relatedness. ","536":"contextual word representations generated by language models (lms) learn spurious associations present in the training corpora. recent findings reveal that adversaries can exploit these associations to reverse-engineer the private attributes of entities mentioned within the corpora. these findings have led to efforts towards minimizing the privacy risks of language models. however, existing approaches lack interpretability, compromise on data utility and fail to provide privacy guarantees. thus, the goal of my doctoral research is to develop interpretable approaches towards privacy preservation of text representations that retain data utility while guaranteeing privacy. to this end, i aim to study and develop methods to incorporate steganographic modifications within the vector geometry to obfuscate underlying spurious associations and preserve the distributional semantic properties learnt during training. ","537":"we show that deep learning models, and especially architectures like the transformer, originally intended for natural language, can be trained on randomly generated datasets to predict to very high accuracy both the qualitative and quantitative features of metabolic networks. using standard mathematical techniques, we create large sets (40 million elements) of random networks that can be used to train our models. these trained models can predict network equilibrium on random graphs in more than 99% of cases. they can also generalize to graphs with different structure than those encountered at training. finally, they can predict almost perfectly the equilibria of a small set of known biological networks. our approach is both very economical in experimental data and uses only small and shallow deep-learning model, far from the large architectures commonly used in machine translation. such results pave the way for larger use of deep learning models for problems related to biological networks in key areas such as quantitative systems pharmacology, systems biology, and synthetic biology. ","538":"we propose a novel problem within end-to-end learning of task-oriented dialogs (tod), in which the dialog system mimics a troubleshooting agent who helps a user by diagnosing their problem (e.g., car not starting). such dialogs are grounded in domain-specific flowcharts, which the agent is supposed to follow during the conversation. our task exposes novel technical challenges for neural tod, such as grounding an utterance to the flowchart without explicit annotation, referring to additional manual pages when user asks a clarification question, and ability to follow unseen flowcharts at test time. we release a dataset (flodial) consisting of 2,738 dialogs grounded on 12 different troubleshooting flowcharts. we also design a neural model, flonet, which uses a retrieval-augmented generation architecture to train the dialog agent. our experiments find that flonet can do zero-shot transfer to unseen flowcharts, and sets a strong baseline for future research. ","539":"the usage and amount of information available on the internet increase over the past decade. this digitization leads to the need for automated answering system to extract fruitful information from redundant and transitional knowledge sources. such systems are designed to cater the most prominent answer from this giant knowledge source to the user query using natural language understanding (nlu) and thus eminently depends on the question-answering(qa) field.   question answering involves but not limited to the steps like mapping of user question to pertinent query, retrieval of relevant information, finding the best suitable answer from the retrieved information etc. the current improvement of deep learning models evince compelling performance improvement in all these tasks.   in this review work, the research directions of qa field are analyzed based on the type of question, answer type, source of evidence-answer, and modeling approach. this detailing followed by open challenges of the field like automatic question generation, similarity detection and, low resource availability for a language. in the end, a survey of available datasets and evaluation measures is presented. ","540":"multi-label few-shot image classification (ml-fsic) is the task of assigning descriptive labels to previously unseen images, based on a small number of training examples. a key feature of the multi-label setting is that images often have multiple labels, which typically refer to different regions of the image. when estimating prototypes, in a metric-based setting, it is thus important to determine which regions are relevant for which labels, but the limited amount of training data makes this highly challenging. as a solution, in this paper we propose to use word embeddings as a form of prior knowledge about the meaning of the labels. in particular, visual prototypes are obtained by aggregating the local feature maps of the support images, using an attention mechanism that relies on the label embeddings. as an important advantage, our model can infer prototypes for unseen labels without the need for fine-tuning any model parameters, which demonstrates its strong generalization abilities. experiments on coco and pascal voc furthermore show that our model substantially improves the current state-of-the-art. ","541":"we present a methodology to train our multi-speaker emotional text-to-speech synthesizer that can express speech for 10 speakers' 7 different emotions. all silences from audio samples are removed prior to learning. this results in fast learning by our model. curriculum learning is applied to train our model efficiently. our model is first trained with a large single-speaker neutral dataset, and then trained with neutral speech from all speakers. finally, our model is trained using datasets of emotional speech from all speakers. in each stage, training samples of each speaker-emotion pair have equal probability to appear in mini-batches. through this procedure, our model can synthesize speech for all targeted speakers and emotions. our synthesized audio sets are available on our web page. ","542":"transformers have achieved success in both language and vision domains. however, it is prohibitively expensive to scale them to long sequences such as long documents or high-resolution images, because self-attention mechanism has quadratic time and memory complexities with respect to the input sequence length. in this paper, we propose long-short transformer (transformer-ls), an efficient self-attention mechanism for modeling long sequences with linear complexity for both language and vision tasks. it aggregates a novel long-range attention with dynamic projection to model distant correlations and a short-term attention to capture fine-grained local correlations. we propose a dual normalization strategy to account for the scale mismatch between the two attention mechanisms. transformer-ls can be applied to both autoregressive and bidirectional models without additional complexity. our method outperforms the state-of-the-art models on multiple tasks in language and vision domains, including the long range arena benchmark, autoregressive language modeling, and imagenet classification. for instance, transformer-ls achieves 0.97 test bpc on enwik8 using half the number of parameters than previous method, while being faster and is able to handle 3x as long sequences compared to its full-attention version on the same hardware. on imagenet, it can obtain the state-of-the-art results (e.g., a moderate size of 55.8m model solely trained on 224x224 imagenet-1k can obtain top-1 accuracy 84.1%), while being more scalable on high-resolution images. the source code and models are released at https:\/\/github.com\/nvidia\/transformer-ls . ","543":"the use of machine learning (ml)-based language models (lms) to monitor content online is on the rise. for toxic text identification, task-specific fine-tuning of these models are performed using datasets labeled by annotators who provide ground-truth labels in an effort to distinguish between offensive and normal content. these projects have led to the development, improvement, and expansion of large datasets over time, and have contributed immensely to research on natural language. despite the achievements, existing evidence suggests that ml models built on these datasets do not always result in desirable outcomes. therefore, using a design science research (dsr) approach, this study examines selected toxic text datasets with the goal of shedding light on some of the inherent issues and contributing to discussions on navigating these challenges for existing and future projects. to achieve the goal of the study, we re-annotate samples from three toxic text datasets and find that a multi-label approach to annotating toxic text samples can help to improve dataset quality. while this approach may not improve the traditional metric of inter-annotator agreement, it may better capture dependence on context and diversity in annotators. we discuss the implications of these results for both theory and practice. ","544":"we present our work on the multimodal coreference resolution task of the situated and interactive multimodal conversation 2.0 (simmc 2.0) dataset as a part of the tenth dialog system technology challenge (dstc10). we propose a uniter-based model utilizing rich multimodal context such as textual dialog history, object knowledge base and visual dialog scenes to determine whether each object in the current scene is mentioned in the current dialog turn. results show that the proposed approach outperforms the official dstc10 baseline substantially, with the object f1 score boosted from 36.6% to 77.3% on the development set, demonstrating the effectiveness of the proposed object representations from rich multimodal input. our model ranks second in the official evaluation on the object coreference resolution task with an f1 score of 73.3% after model ensembling. ","545":"time delay neural network (tdnn) is a well-performing structure for dnn-based speaker recognition systems. in this paper we introduce a novel structure crossed-time delay neural network (ctdnn) to enhance the performance of current tdnn. inspired by the multi-filters setting of convolution layer from convolution neural network, we set multiple time delay units each with different context size at the bottom layer and construct a multilayer parallel network. the proposed ctdnn gives significant improvements over original tdnn on both speaker verification and identification tasks. it outperforms in voxceleb1 dataset in verification experiment with a 2.6% absolute equal error rate improvement. in few shots condition ctdnn reaches 90.4% identification accuracy, which doubles the identification accuracy of original tdnn. we also compare the proposed ctdnn with another new variant of tdnn, ftdnn, which shows that our model has a 36% absolute identification accuracy improvement under few shots condition and can better handle training of a larger batch in a shorter training time, which better utilize the calculation resources. the code of the new model is released at https:\/\/github.com\/chenllliang\/ctdnn ","546":"hate speech detection research has predominantly focused on purely content-based methods, without exploiting any additional context. we briefly critique pros and cons of this task formulation. we then investigate profiling users by their past utterances as an informative prior to better predict whether new utterances constitute hate speech. to evaluate this, we augment three twitter hate speech datasets with additional timeline data, then embed this additional context into a strong baseline model. promising results suggest merit for further investigation, though analysis is complicated by differences in annotation schemes and processes, as well as twitter api limitations and data sharing policies. ","547":"current state-of-the-art cross-lingual summarization models employ multi-task learning paradigm, which works on a shared vocabulary module and relies on the self-attention mechanism to attend among tokens in two languages. however, correlation learned by self-attention is often loose and implicit, inefficient in capturing crucial cross-lingual representations between languages. the matter worsens when performing on languages with separate morphological or structural features, making the cross-lingual alignment more challenging, resulting in the performance drop. to overcome this problem, we propose a novel knowledge-distillation-based framework for cross-lingual summarization, seeking to explicitly construct cross-lingual correlation by distilling the knowledge of the monolingual summarization teacher into the cross-lingual summarization student. since the representations of the teacher and the student lie on two different vector spaces, we further propose a knowledge distillation loss using sinkhorn divergence, an optimal-transport distance, to estimate the discrepancy between those teacher and student representations. due to the intuitively geometric nature of sinkhorn divergence, the student model can productively learn to align its produced cross-lingual hidden states with monolingual hidden states, hence leading to a strong correlation between distant languages. experiments on cross-lingual summarization datasets in pairs of distant languages demonstrate that our method outperforms state-of-the-art models under both high and low-resourced settings. ","548":"artificial intelligence is being utilized in many domains as of late, and the legal system is no exception. however, as it stands now, the number of well-annotated datasets pertaining to legal documents from the supreme court of the united states (scotus) is very limited for public use. even though the supreme court rulings are public domain knowledge, trying to do meaningful work with them becomes a much greater task due to the need to manually gather and process that data from scratch each time. hence, our goal is to create a high-quality dataset of scotus court cases so that they may be readily used in natural language processing (nlp) research and other data-driven applications. additionally, recent advances in nlp provide us with the tools to build predictive models that can be used to reveal patterns that influence court decisions. by using advanced nlp algorithms to analyze previous court cases, the trained models are able to predict and classify a court's judgment given the case's facts from the plaintiff and the defendant in textual format; in other words, the model is emulating a human jury by generating a final verdict. ","549":"metonymy is a figure of speech in which an entity is referred to by another related entity. the task of metonymy detection aims to distinguish metonymic tokens from literal ones. until now, metonymy detection methods attempt to disambiguate only a single noun phrase in a sentence, typically location names or organization names. in this paper, we disambiguate every word in a sentence by reformulating metonymy detection as a sequence labeling task. we also investigate the impact of target word and context on metonymy detection. we show that the target word is less useful for detecting metonymy in our dataset. on the other hand, the entity types that are associated with domain-specific words in their context are easier to solve. this shows that the context words are much more relevant for detecting metonymy. ","550":"state-of-the-art abstractive summarization systems often generate \\emph{hallucinations}; i.e., content that is not directly inferable from the source text. despite being assumed incorrect, we find that much hallucinated content is factual, namely consistent with world knowledge. these factual hallucinations can be beneficial in a summary by providing useful background information. in this work, we propose a novel detection approach that separates factual from non-factual hallucinations of entities. our method utilizes an entity's prior and posterior probabilities according to pre-trained and finetuned masked language models, respectively. empirical results suggest that our approach vastly outperforms two baselines %in both accuracy and f1 scores and strongly correlates with human judgments. % on factuality classification tasks. furthermore, we show that our detector, when used as a reward signal in an off-line reinforcement learning (rl) algorithm, significantly improves the factuality of summaries while maintaining the level of abstractiveness. ","551":"in this work, we develop intuitive controls for editing the style of 3d objects. our framework, text2mesh, stylizes a 3d mesh by predicting color and local geometric details which conform to a target text prompt. we consider a disentangled representation of a 3d object using a fixed mesh input (content) coupled with a learned neural network, which we term neural style field network. in order to modify style, we obtain a similarity score between a text prompt (describing style) and a stylized mesh by harnessing the representational power of clip. text2mesh requires neither a pre-trained generative model nor a specialized 3d mesh dataset. it can handle low-quality meshes (non-manifold, boundaries, etc.) with arbitrary genus, and does not require uv parameterization. we demonstrate the ability of our technique to synthesize a myriad of styles over a wide variety of 3d meshes. ","552":"while india has been one of the hotspots of covid-19, data about the pandemic from the country has proved to be largely inaccessible at scale. much of the data exists in unstructured form on the web, and limited aspects of such data are available through public apis maintained manually through volunteer effort. this has proved to be difficult both in terms of ease of access to detailed data and with regards to the maintenance of manual data-keeping over time. this paper reports on our effort at automating the extraction of such data from public health bulletins with the help of a combination of classical pdf parsers and state-of-the-art machine learning techniques. in this paper, we will describe the automated data-extraction technique, the nature of the generated data, and exciting avenues of ongoing work. ","553":"hashtag segmentation, also known as hashtag decomposition, is a common step in preprocessing pipelines for social media datasets. it usually precedes tasks such as sentiment analysis and hate speech detection. for sentiment analysis in medium to low-resourced languages, previous research has demonstrated that a multilingual approach that resorts to machine translation can be competitive or superior to previous approaches to the task. we develop a zero-shot hashtag segmentation framework and demonstrate how it can be used to improve the accuracy of multilingual sentiment analysis pipelines. our zero-shot framework establishes a new state-of-the-art for hashtag segmentation datasets, surpassing even previous approaches that relied on feature engineering and language models trained on in-domain data. ","554":"regenerating natural language explanations in the scientific domain has been proposed as a benchmark to evaluate complex multi-hop and explainable inference. in this context, large language models can achieve state-of-the-art performance when employed as cross-encoder architectures and fine-tuned on human-annotated explanations. however, while much attention has been devoted to the quality of the explanations, the problem of performing inference efficiently is largely under-studied. cross-encoders, in fact, are intrinsically not scalable, possessing limited applicability to real-world scenarios that require inference on massive facts banks. to enable complex multi-hop reasoning at scale, this paper focuses on bi-encoder architectures, investigating the problem of scientific explanation regeneration at the intersection of dense and sparse models. specifically, we present scar (for scalable autoregressive inference), a hybrid framework that iteratively combines a transformer-based bi-encoder with a sparse model of explanatory power, designed to leverage explicit inference patterns in the explanations. our experiments demonstrate that the hybrid framework significantly outperforms previous sparse models, achieving performance comparable with that of state-of-the-art cross-encoders while being approx 50 times faster and scalable to corpora of millions of facts. further analyses on semantic drift and multi-hop question answering reveal that the proposed hybridisation boosts the quality of the most challenging explanations, contributing to improved performance on downstream inference tasks. ","555":"latent text representations exhibit geometric regularities, such as the famous analogy: queen is to king what woman is to man. such structured semantic relations were not demonstrated on image representations. recent works aiming at bridging this semantic gap embed images and text into a multimodal space, enabling the transfer of text-defined transformations to the image modality.   we introduce the simat dataset to evaluate the task of text-driven image transformation. simat contains 6k images and 18k \"transformation queries\" that aim at either replacing scene elements or changing their pairwise relationships. the goal is to retrieve an image consistent with the (source image, transformation) query. we use an image\/text matching oracle (oscar) to assess whether the image transformation is successful. the simat dataset will be publicly available.   we use simat to show that vanilla clip multimodal embeddings are not very well suited for text-driven image transformation, but that a simple finetuning on the coco dataset can bring dramatic improvements. we also study whether it is beneficial to leverage the geometric properties of pretrained universal sentence encoders (fasttext, laser and labse). ","556":"text style transfer (tst) aims to alter the underlying style of the source text to another specific style while keeping the same content. due to the scarcity of high-quality parallel training data, unsupervised learning has become a trending direction for tst tasks. in this paper, we propose a novel vae based text style transfer with pivot words enhancement learning (vt-stower) method which utilizes variational autoencoder (vae) and external style embeddings to learn semantics and style distribution jointly. additionally, we introduce pivot words learning, which is applied to learn decisive words for a specific style and thereby further improve the overall performance of the style transfer. the proposed vt-stower can be scaled to different tst scenarios given very limited and non-parallel training data with a novel and flexible style strength control mechanism. experiments demonstrate that the vt-stower outperforms the state-of-the-art on sentiment, formality, and code-switching tst tasks. ","557":"recent research on model interpretability in natural language processing extensively uses feature scoring methods for identifying which parts of the input are the most important for a model to make a prediction (i.e. explanation or rationale). however, previous research has shown that there is no clear best scoring method across various text classification tasks while practitioners typically have to make several other ad-hoc choices regarding the length and the type of the rationale (e.g. short or long, contiguous or not). inspired by this, we propose a simple yet effective and flexible method that allows selecting optimally for each data instance: (1) a feature scoring method; (2) the length; and (3) the type of the rationale. our method is inspired by input erasure approaches to interpretability which assume that the most faithful rationale for a prediction should be the one with the highest difference between the model's output distribution using the full text and the text after removing the rationale as input respectively. evaluation on four standard text classification datasets shows that our proposed method provides more faithful, comprehensive and highly sufficient explanations compared to using a fixed feature scoring method, rationale length and type. more importantly, we demonstrate that a practitioner is not required to make any ad-hoc choices in order to extract faithful rationales using our approach. ","558":"neural vocoders, used for converting the spectral representations of an audio signal to the waveforms, are a commonly used component in speech synthesis pipelines. it focuses on synthesizing waveforms from low-dimensional representation, such as mel-spectrograms. in recent years, different approaches have been introduced to develop such vocoders. however, it becomes more challenging to assess these new vocoders and compare their performance to previous ones. to address this problem, we present vocbench, a framework that benchmark the performance of state-of-the art neural vocoders. vocbench uses a systematic study to evaluate different neural vocoders in a shared environment that enables a fair comparison between them. in our experiments, we use the same setup for datasets, training pipeline, and evaluation metrics for all neural vocoders. we perform a subjective and objective evaluation to compare the performance of each vocoder along a different axis. our results demonstrate that the framework is capable of showing the competitive efficacy and the quality of the synthesized samples for each vocoder. vocbench framework is available at https:\/\/github.com\/facebookresearch\/vocoder-benchmark. ","559":"in this paper, we present and implement a multi-dimensional, modular framework for performing deep argument analysis (deepa2) using current pre-trained language models (ptlms). argumentanalyst -- a t5 model (raffel et al. 2020) set up and trained within deepa2 -- reconstructs argumentative texts, which advance an informal argumentation, as valid arguments: it inserts, e.g., missing premises and conclusions, formalizes inferences, and coherently links the logical reconstruction to the source text. we create a synthetic corpus for deep argument analysis, and evaluate argumentanalyst on this new dataset as well as on existing data, specifically entailmentbank (dalvi et al. 2021). our empirical findings vindicate the overall framework and highlight the advantages of a modular design, in particular its ability to emulate established heuristics (such as hermeneutic cycles), to explore the model's uncertainty, to cope with the plurality of correct solutions (underdetermination), and to exploit higher-order evidence. ","560":"we address efficient calculation of influence functions for tracking predictions back to the training data. we propose and analyze a new approach to speeding up the inverse hessian calculation based on arnoldi iteration. with this improvement, we achieve, to the best of our knowledge, the first successful implementation of influence functions that scales to full-size (language and vision) transformer models with several hundreds of millions of parameters. we evaluate our approach on image classification and sequence-to-sequence tasks with tens to a hundred of millions of training examples. our code will be available at https:\/\/github.com\/google-research\/jax-influence. ","561":"a key trait of daily conversations between individuals is the ability to express empathy towards others, and exploring ways to implement empathy is a crucial step towards human-like dialogue systems. previous approaches on this topic mainly focus on detecting and utilizing the user's emotion for generating empathetic responses. however, since empathy includes both aspects of affection and cognition, we argue that in addition to identifying the user's emotion, cognitive understanding of the user's situation should also be considered. to this end, we propose a novel approach for empathetic response generation, which leverages commonsense to draw more information about the user's situation and uses this additional information to further enhance the empathy expression in generated responses. we evaluate our approach on empatheticdialogues, which is a widely-used benchmark dataset for empathetic response generation. empirical results demonstrate that our approach outperforms the baseline models in both automatic and human evaluations and can generate more informative and empathetic responses. ","562":"currently, bio-based and tuple-based approaches perform quite well on the span-based semantic role labeling (srl) task. however, the bio-based approach usually needs to encode a sentence once for each predicate when predicting its arguments, and the tuple-based approach has to deal with a huge search space of $o(n^3)$, greatly reducing the training and inference efficiency. the parsing speed is less than 50 sentences per second. moreover, both bio-based and tuple-based approaches usually consider only local structural information when making predictions. this paper proposes to cast end-to-end span-based srl as a graph parsing task. based on a novel graph representation schema, we present a fast and accurate srl parser on the shoulder of recent works on high-order semantic dependency graph parsing. moreover, we propose a constrained viterbi procedure to ensure the legality of the output graph. experiments on english conll05 and conll12 datasets show that our model achieves new state-of-the-art results under both settings of without and with pre-trained language models, and can parse over 600 sentences per second. ","563":"recent approaches to sign language production (slp) have adopted spoken language neural machine translation (nmt) architectures, applied without sign-specific modifications. in addition, these works represent sign language as a sequence of skeleton pose vectors, projected to an abstract representation with no inherent skeletal structure. in this paper, we represent sign language sequences as a skeletal graph structure, with joints as nodes and both spatial and temporal connections as edges. to operate on this graphical structure, we propose skeletal graph self-attention (sgsa), a novel graphical attention layer that embeds a skeleton inductive bias into the slp model. retaining the skeletal feature representation throughout, we directly apply a spatio-temporal adjacency matrix into the self-attention formulation. this provides structure and context to each skeletal joint that is not possible when using a non-graphical abstract representation, enabling fluid and expressive sign language production. we evaluate our skeletal graph self-attention architecture on the challenging rwth-phoenix-weather-2014t(phoenix14t) dataset, achieving state-of-the-art back translation performance with an 8% and 7% improvement over competing methods for the dev and test sets. ","564":"contrastive learning has proven effective for pre-training image models on unlabeled data with promising results for tasks such as medical image classification. using paired text and images (such as radiological reports and images) during pre-training improved the results even further. still, most existing methods target image classification as downstream tasks and may not be optimal for localized tasks like semantic segmentation or object detection. we therefore propose localized representation learning from vision and text (lovt), to our best knowledge, the first text-supervised pre-training method that targets localized medical imaging tasks. our method combines instance-level image-report contrastive learning with local contrastive learning on image region and report sentence representations. we evaluate lovt and commonly used pre-training methods on a novel evaluation framework consisting of 18 localized tasks on chest x-rays from five public datasets. while there is no single best method, lovt performs best on 11 out of the 18 studied tasks making it the preferred method of choice for localized tasks. ","565":"english based datasets are commonly available from kaggle, github, or recently published papers. although benchmark tests with english datasets are sufficient to show off the performances of new models and methods, still a researcher need to train and validate the models on korean based datasets to produce a technology or product, suitable for korean processing. this paper introduces 15 popular korean based nlp datasets with summarized details such as volume, license, repositories, and other research results inspired by the datasets. also, i provide high-resolution instructions with sample or statistics of datasets. the main characteristics of datasets are presented on a single table to provide a rapid summarization of datasets for researchers. ","566":"we suggest a model for metaphor interpretation using word embeddings trained over a relatively large corpus. our system handles nominal metaphors, like \"time is money\". it generates a ranked list of potential interpretations of given metaphors. candidate meanings are drawn from collocations of the topic (\"time\") and vehicle (\"money\") components, automatically extracted from a dependency-parsed corpus. we explore adding candidates derived from word association norms (common human responses to cues). our ranking procedure considers similarity between candidate interpretations and metaphor components, measured in a semantic vector space. lastly, a clustering algorithm removes semantically related duplicates, thereby allowing other candidate interpretations to attain higher rank. we evaluate using different sets of annotated metaphors, with encouraging preliminary results. ","567":"data-to-text generation systems aim to generate text descriptions based on input data (often represented in the tabular form). a typical system uses huge training samples for learning the correspondence between tables and texts. however, large training sets are expensive to obtain, limiting the applicability of these approaches in real-world scenarios. in this work, we focus on few-shot data-to-text generation. we observe that, while fine-tuned pretrained language models may generate plausible sentences, they suffer from the low semantic coverage problem in the few-shot setting. in other words, important input slots tend to be missing in the generated text. to this end, we propose a search-and-learning approach that leverages pretrained language models but inserts the missing slots to improve the semantic coverage. we further fine-tune our system based on the search results to smooth out the search noise, yielding better-quality text and improving inference efficiency to a large extent. experiments show that our model achieves high performance on e2e and wikibio datasets. especially, we cover 98.35% of input slots on e2e, largely alleviating the low coverage problem. ","568":"this paper studies continual learning (cl) of a sequence of aspect sentiment classification (asc) tasks. although some cl techniques have been proposed for document sentiment classification, we are not aware of any cl work on asc. a cl system that incrementally learns a sequence of asc tasks should address the following two issues: (1) transfer knowledge learned from previous tasks to the new task to help it learn a better model, and (2) maintain the performance of the models for previous tasks so that they are not forgotten. this paper proposes a novel capsule network based model called b-cl to address these issues. b-cl markedly improves the asc performance on both the new task and the old tasks via forward and backward knowledge transfer. the effectiveness of b-cl is demonstrated through extensive experiments. ","569":"this paper introduces the proposed automatic minuting system of the hitachi team for the first shared task on automatic minuting (automin-2021). we utilize a reference-free approach (i.e., without using training minutes) for automatic minuting (task a), which first splits a transcript into blocks on the basis of topics and subsequently summarizes those blocks with a pre-trained bart model fine-tuned on a summarization corpus of chat dialogue. in addition, we apply a technique of argument mining to the generated minutes, reorganizing them in a well-structured and coherent way. we utilize multiple relevance scores to determine whether or not a minute is derived from the same meeting when either a transcript or another minute is given (task b and c). on top of those scores, we train a conventional machine learning model to bind them and to make final decisions. consequently, our approach for task a achieve the best adequacy score among all submissions and close performance to the best system in terms of grammatical correctness and fluency. for task b and c, the proposed model successfully outperformed a majority vote baseline. ","570":"quantum computing has been a fascinating research field in quantum physics. recent progresses motivate us to study in depth the universal quantum computing models (uqcm), which lie at the foundation of quantum computing and have tight connections with fundamental physics. although being developed decades ago, a physically concise principle or picture to formalize and understand uqcm is still lacking. this is challenging given the diversity of still-emerging models, but important to understand the difference between classical and quantum computing. in this work, we carried out a primary attempt to unify uqcm by classifying a few of them as two categories, hence making a table of models. with such a table, some known models or schemes appear as hybridization or combination of models, and more importantly, it leads to new schemes that have not been explored yet. our study of uqcm also leads to some insights into quantum algorithms. this work reveals the importance and feasibility of systematic study of computing models. ","571":"data augmentation is an important component in the robustness evaluation of models in natural language processing (nlp) and in enhancing the diversity of the data they are trained on. in this paper, we present nl-augmenter, a new participatory python-based natural language augmentation framework which supports the creation of both transformations (modifications to the data) and filters (data splits according to specific features). we describe the framework and an initial set of 117 transformations and 23 filters for a variety of natural language tasks. we demonstrate the efficacy of nl-augmenter by using several of its transformations to analyze the robustness of popular natural language models. the infrastructure, datacards and robustness analysis results are available publicly on the nl-augmenter repository (\\url{https:\/\/github.com\/gem-benchmark\/nl-augmenter}). ","572":"this paper studies continual learning (cl) of a sequence of aspect sentiment classification(asc) tasks in a particular cl setting called domain incremental learning (dil). each task is from a different domain or product. the dil setting is particularly suited to asc because in testing the system needs not know the task\/domain to which the test data belongs. to our knowledge, this setting has not been studied before for asc. this paper proposes a novel model called classic. the key novelty is a contrastive continual learning method that enables both knowledge transfer across tasks and knowledge distillation from old tasks to the new task, which eliminates the need for task ids in testing. experimental results show the high effectiveness of classic. ","573":"continual learning (cl) learns a sequence of tasks incrementally with the goal of achieving two main objectives: overcoming catastrophic forgetting (cf) and encouraging knowledge transfer (kt) across tasks. however, most existing techniques focus only on overcoming cf and have no mechanism to encourage kt, and thus do not do well in kt. although several papers have tried to deal with both cf and kt, our experiments show that they suffer from serious cf when the tasks do not have much shared knowledge. another observation is that most current cl methods do not use pre-trained models, but it has been shown that such models can significantly improve the end task performance. for example, in natural language processing, fine-tuning a bert-like pre-trained language model is one of the most effective approaches. however, for cl, this approach suffers from serious cf. an interesting question is how to make the best use of pre-trained models for cl. this paper proposes a novel model called ctr to solve these problems. our experimental results demonstrate the effectiveness of ctr ","574":"nowadays, due to the breakthrough in natural language generation (nlg), including machine translation, document summarization, image captioning, etc nlg models have been encapsulated in cloud apis to serve over half a billion people worldwide and process over one hundred billion word generations per day. thus, nlg apis have already become essential profitable services in many commercial companies. due to the substantial financial and intellectual investments, service providers adopt a pay-as-you-use policy to promote sustainable market growth. however, recent works have shown that cloud platforms suffer from financial losses imposed by model extraction attacks, which aim to imitate the functionality and utility of the victim services, thus violating the intellectual property (ip) of cloud apis. this work targets at protecting ip of nlg apis by identifying the attackers who have utilized watermarked responses from the victim nlg apis. however, most existing watermarking techniques are not directly amenable for ip protection of nlg apis. to bridge this gap, we first present a novel watermarking method for text generation apis by conducting lexical modification to the original outputs. compared with the competitive baselines, our watermark approach achieves better identifiable performance in terms of p-value, with fewer semantic losses. in addition, our watermarks are more understandable and intuitive to humans than the baselines. finally, the empirical studies show our approach is also applicable to queries from different domains, and is effective on the attacker trained on a mixture of the corpus which includes less than 10\\% watermarked samples. ","575":"automatically recommending relevant law articles to a given legal case has attracted much attention as it can greatly release human labor from searching over the large database of laws. however, current researches only support coarse-grained recommendation where all relevant articles are predicted as a whole without explaining which specific fact each article is relevant with. since one case can be formed of many supporting facts, traversing over them to verify the correctness of recommendation results can be time-consuming. we believe that learning fine-grained correspondence between each single fact and law articles is crucial for an accurate and trustworthy ai system. with this motivation, we perform a pioneering study and create a corpus with manually annotated fact-article correspondences. we treat the learning as a text matching task and propose a multi-level matching network to address it. to help the model better digest the content of law articles, we parse articles in form of premise-conclusion pairs with random forest. experiments show that the parsed form yielded better performance and the resulting model surpassed other popular text matching baselines. furthermore, we compare with previous researches and find that establishing the fine-grained fact-article correspondences can improve the recommendation accuracy by a large margin. our best system reaches an f1 score of 96.3%, making it of great potential for practical use. it can also significantly boost the downstream task of legal decision prediction, increasing the f1 score by up to 12.7%. ","576":"variable names are critical for conveying intended program behavior. machine learning-based program analysis methods use variable name representations for a wide range of tasks, such as suggesting new variable names and bug detection. ideally, such methods could capture semantic relationships between names beyond syntactic similarity, e.g., the fact that the names average and mean are similar. unfortunately, previous work has found that even the best of previous representation approaches primarily capture relatedness (whether two variables are linked at all), rather than similarity (whether they actually have the same meaning).   we propose varclr, a new approach for learning semantic representations of variable names that effectively captures variable similarity in this stricter sense. we observe that this problem is an excellent fit for contrastive learning, which aims to minimize the distance between explicitly similar inputs, while maximizing the distance between dissimilar inputs. this requires labeled training data, and thus we construct a novel, weakly-supervised variable renaming dataset mined from github edits. we show that varclr enables the effective application of sophisticated, general-purpose language models like bert, to variable name representation and thus also to related downstream tasks like variable name similarity search or spelling correction. varclr produces models that significantly outperform the state-of-the-art on idbench, an existing benchmark that explicitly captures variable similarity (as distinct from relatedness). finally, we contribute a release of all data, code, and pre-trained models, aiming to provide a drop-in replacement for variable representations used in either existing or future program analyses that rely on variable names. ","577":"mining user-generated content--e.g., for the early detection of outbreaks or for extracting personal observations--often suffers from the lack of enough training data, short document length, and informal language model. we propose a novel multi-view active learning model, called context-aware co-testing with bagging (cocoba), to address these issues in the classification tasks tailored for a query word--e.g., detecting illness reports given the disease name. cocoba employs the context of user postings to construct two views. then it uses the distribution of the representations in each view to detect the regions that are assigned to the opposite classes. this effectively leads to detecting the contexts that the two base learners disagree on. our model also employs a query-by-committee model to address the usually noisy language of user postings. the experiments testify that our model is applicable to multiple important representative twitter tasks and also significantly outperforms the existing baselines. ","578":"there is growing interest in the role of sentiment in economic decision-making. however, most research on the subject has focused on positive and negative valence. conviction narrative theory (cnt) places approach and avoidance sentiment (that which drives action) at the heart of real-world decision-making, and argues that it better captures emotion in financial markets. this research, bringing together psychology and machine learning, introduces new techniques to differentiate approach and avoidance from positive and negative sentiment on a fundamental level of meaning. it does this by comparing word-lists, previously constructed to capture these concepts in text data, across a large range of semantic features. the results demonstrate that avoidance in particular is well defined as a separate type of emotion, which is evaluative\/cognitive and action-orientated in nature. refining the avoidance word-list according to these features improves macroeconomic models, suggesting that they capture the essence of avoidance and that it plays a crucial role in driving real-world economic decision-making. ","579":"numerous methods have been developed to monitor the spread of negativity in modern years by eliminating vulgar, offensive, and fierce comments from social media platforms. however, there are relatively lesser amounts of study that converges on embracing positivity, reinforcing supportive and reassuring content in online forums. consequently, we propose creating an english-kannada hope speech dataset, kanhope and comparing several experiments to benchmark the dataset. the dataset consists of 6,176 user-generated comments in code mixed kannada scraped from youtube and manually annotated as bearing hope speech or not-hope speech. in addition, we introduce dc-bert4hope, a dual-channel model that uses the english translation of kanhope for additional training to promote hope speech detection. the approach achieves a weighted f1-score of 0.756, bettering other models. henceforth, kanhope aims to instigate research in kannada while broadly promoting researchers to take a pragmatic approach towards online content that encourages, positive, and supportive. ","580":"the new and growing field of quantitative dependency syntax has emerged at the crossroads between dependency syntax and quantitative linguistics. one of the main concerns in this field is the statistical patterns of syntactic dependency structures. these structures, grouped in treebanks, are the source for statistical analyses in these and related areas; dozens of scores devised over the years are the tools of a new industry to search for patterns and perform other sorts of analyses. the plethora of such metrics and their increasing complexity require sharing the source code of the programs used to perform such analyses. however, such code is not often shared with the scientific community or is tested following unknown standards. here we present a new open-source tool, the linear arrangement library (lal), which caters to the needs of, especially, inexperienced programmers. this tool enables the calculation of these metrics on single syntactic dependency structures, treebanks, and collection of treebanks, grounded on ease of use and yet with great flexibility. lal has been designed to be efficient, easy to use (while satisfying the needs of all levels of programming expertise), reliable (thanks to thorough testing), and to unite research from different traditions, geographic areas, and research fields. ","581":"distillation efforts have led to language models that are more compact and efficient without serious drops in performance. the standard approach to distillation trains a student model against two objectives: a task-specific objective (e.g., language modeling) and an imitation objective that encourages the hidden states of the student model to be similar to those of the larger teacher model. in this paper, we show that it is beneficial to augment distillation with a third objective that encourages the student to imitate the causal computation process of the teacher through interchange intervention training(iit). iit pushes the student model to become a causal abstraction of the teacher model - a simpler model with the same causal structure. iit is fully differentiable, easily implemented, and combines flexibly with other objectives. compared with standard distillation of bert, distillation via iit results in lower perplexity on wikipedia (masked language modeling) and marked improvements on the glue benchmark (natural language understanding), squad (question answering), and conll-2003 (named entity recognition). ","582":"traditional symbolic reasoning engines, while attractive for their precision and explicability, have a few major drawbacks: the use of brittle inference procedures that rely on exact matching (unification) of logical terms, an inability to deal with uncertainty, and the need for a precompiled rule-base of knowledge (the \"knowledge acquisition\" problem). to address these issues, we devise a novel logical reasoner called braid, that supports probabilistic rules, and uses the notion of custom unification functions and dynamic rule generation to overcome the brittle matching and knowledge-gap problem prevalent in traditional reasoners. in this paper, we describe the reasoning algorithms used in braid, and their implementation in a distributed task-based framework that builds proof\/explanation graphs for an input query. we use a simple qa example from a children's story to motivate braid's design and explain how the various components work together to produce a coherent logical explanation. finally, we evaluate braid on the roc story cloze test and achieve close to state-of-the-art results while providing frame-based explanations. ","583":"social media content routinely incorporates multi-modal design to covey information and shape meanings, and sway interpretations toward desirable implications, but the choices and outcomes of using both texts and visual images have not been sufficiently studied. this work proposes a computational approach to analyze the outcome of persuasive information in multi-modal content, focusing on two aspects, popularity and reliability, in covid-19-related news articles shared on twitter. the two aspects are intertwined in the spread of misinformation: for example, an unreliable article that aims to misinform has to attain some popularity. this work has several contributions. first, we propose a multi-modal (image and text) approach to effectively identify popularity and reliability of information sources simultaneously. second, we identify textual and visual elements that are predictive to information popularity and reliability. third, by modeling cross-modal relations and similarity, we are able to uncover how unreliable articles construct multi-modal meaning in a distorted, biased fashion. our work demonstrates how to use multi-modal analysis for understanding influential content and has implications to social media literacy and engagement. ","584":"we draw insights from the social psychology literature to identify two facets of twitter deliberations about migrants, i.e., perceptions about migrants and behaviors towards mi-grants. our theoretical anchoring helped us in identifying two prevailing perceptions (i.e., sympathy and antipathy) and two dominant behaviors (i.e., solidarity and animosity) of social media users towards migrants. we have employed unsuper-vised and supervised approaches to identify these perceptions and behaviors. in the domain of applied nlp, our study of-fers a nuanced understanding of migrant-related twitter de-liberations. our proposed transformer-based model, i.e., bert + cnn, has reported an f1-score of 0.76 and outper-formed other models. additionally, we argue that tweets con-veying antipathy or animosity can be broadly considered hate speech towards migrants, but they are not the same. thus, our approach has fine-tuned the binary hate speech detection task by highlighting the granular differences between perceptual and behavioral aspects of hate speeches. ","585":"we present an end-to-end differentiable training method for retrieval-augmented open-domain question answering systems that combine information from multiple retrieved documents when generating answers. we model retrieval decisions as latent variables over sets of relevant documents. since marginalizing over sets of retrieved documents is computationally hard, we approximate this using an expectation-maximization algorithm. we iteratively estimate the value of our latent variable (the set of relevant documents for a given question) and then use this estimate to update the retriever and reader parameters. we hypothesize that such end-to-end training allows training signals to flow to the reader and then to the retriever better than staged-wise training. this results in a retriever that is able to select more relevant documents for a question and a reader that is trained on more accurate documents to generate an answer. experiments on three benchmark datasets demonstrate that our proposed method outperforms all existing approaches of comparable size by 2-3% absolute exact match points, achieving new state-of-the-art results. our results also demonstrate the feasibility of learning to retrieve to improve answer generation without explicit supervision of retrieval decisions. ","586":"contrastive vision-language pre-training (clip) has drown increasing attention recently for its transferable visual representation learning. supervised by large-scale image-text pairs, clip is able to align paired images and texts and thus conduct zero-shot recognition in open-vocabulary scenarios. however, there exists semantic gap between the specific application and generally pre-trained knowledge, which makes the matching sub-optimal on downstream tasks. in this paper, we propose vt-clip to enhance vision-language modeling via visual-guided texts. specifically, we guide the text feature to adaptively explore informative regions on the image and aggregate the visual feature by cross-attention machanism. in this way, the visual-guided text become more semantically correlated with the image, which greatly benefits the matching process. in few-shot settings, we evaluate our vt-clip on 11 well-known classification datasets and experiment extensive ablation studies to demonstrate the effectiveness of vt-clip. the code will be released soon. ","587":"dependency distance minimization (ddm) is a well-established principle of word order. it has been predicted theoretically that ddm implies compression, namely the minimization of word lengths. this is a second order prediction because it links a principle with another principle, rather than a principle and a manifestation as in a first order prediction. here we test that second order prediction with a parallel collection of treebanks controlling for annotation style with universal dependencies and surface-syntactic universal dependencies. to test it, we use a recently introduced score that has many mathematical and statistical advantages with respect to the widely used sum of dependency distances. we find that the prediction is confirmed by the new score when word lengths are measured in phonemes, independently of the annotation style, but not when word lengths are measured in syllables. in contrast, one of the most widely used scores, i.e. the sum of dependency distances, fails to confirm that prediction, showing the weakness of raw dependency distances for research on word order. finally, our findings expand the theory of natural communication by linking two distinct levels of organization, namely syntax (word order) and word internal structure. ","588":"question answering (qa) is one of the most common nlp tasks that relates to named entity recognition, fact extraction, semantic search and some other fields. in industry, it is much appreciated in chatbots and corporate information systems. it is also a challenging task that attracted the attention of a very general audience at the quiz show jeopardy! in this article we describe a jeopardy!-like russian qa data set collected from the official russian quiz database chgk (che ge ka). the data set includes 379,284 quiz-like questions with 29,375 from the russian analogue of jeopardy! - \"own game\". we observe its linguistic features and the related qa-task. we conclude about perspectives of a qa competition based on the data set collected from this database. ","589":"*content warning: this work displays examples of explicit and strongly offensive language. the covid-19 pandemic has fueled a surge in anti-asian xenophobia and prejudice. many have taken to social media to express these negative sentiments, necessitating the development of reliable systems to detect hate speech against this often under-represented demographic. in this paper, we create and annotate a corpus of twitter tweets using 2 experimental approaches to explore anti-asian abusive and hate speech at finer granularity. using the dataset with less biased annotation, we deploy multiple models and also examine the applicability of other relevant corpora to accomplish these multi-task classifications. in addition to demonstrating promising results, our experiments offer insights into the nuances of cultural and logistical factors in annotating hate speech for different demographics. our analyses together aim to contribute to the understanding of the area of hate speech detection, particularly towards low-resource groups. ","590":"conversational agents have become an integral part of the general population for simple task enabling situations. however, these systems are yet to have any social impact on the diverse and minority population, for example, helping people with neurological disorders, for example als, and people with speech, language and social communication disorders. language model technology can play a huge role to help these users carry out daily communication and social interactions. to enable this population, we build a dialog system that can be controlled by users using cues or keywords. we build models that can suggest relevant cues in the dialog response context which is used to control response generation and can speed up communication. we also introduce a keyword loss to lexically constrain the model output. we show both qualitatively and quantitatively that our models can effectively induce the keyword into the model response without degrading the quality of response. in the context of usage of such systems for people with degenerative disorders, we present human evaluation of our cue or keyword predictor and the controllable dialog system and show that our models perform significantly better than models without control. our study shows that keyword control on end to end response generation models is powerful and can enable and empower users with degenerative disorders to carry out their day to day communication. ","591":"semantic parsing datasets are expensive to collect. moreover, even the questions pertinent to a given domain, which are the input of a semantic parsing system, might not be readily available, especially in cross-domain semantic parsing. this makes data augmentation even more challenging. existing methods to synthesize new data use hand-crafted or induced rules, requiring substantial engineering effort and linguistic expertise to achieve good coverage and precision, which limits the scalability. in this work, we propose a purely neural approach of data augmentation for semantic parsing that completely removes the need for grammar engineering while achieving higher semantic parsing accuracy. furthermore, our method can synthesize in the zero-shot setting, where only a new domain schema is available without any input-output examples of the new domain. on the spider cross-domain text-to-sql semantic parsing benchmark, we achieve the state-of-the-art performance on the development set (77.2% accuracy) using our zero-shot augmentation. ","592":"humans communicate with graphical sketches apart from symbolic languages. while recent studies of emergent communication primarily focus on symbolic languages, their settings overlook the graphical sketches existing in human communication; they do not account for the evolution process through which symbolic sign systems emerge in the trade-off between iconicity and symbolicity. in this work, we take the very first step to model and simulate such an evolution process via two neural agents playing a visual communication game; the sender communicates with the receiver by sketching on a canvas. we devise a novel reinforcement learning method such that agents are evolved jointly towards successful communication and abstract graphical conventions. to inspect the emerged conventions, we carefully define three key properties -- iconicity, symbolicity, and semanticity -- and design evaluation methods accordingly. our experimental results under different controls are consistent with the observation in studies of human graphical conventions. of note, we find that evolved sketches can preserve the continuum of semantics under proper environmental pressures. more interestingly, co-evolved agents can switch between conventionalized and iconic communication based on their familiarity with referents. we hope the present research can pave the path for studying emergent communication with the unexplored modality of sketches. ","593":"the study presented here provides numerical insight into ghazal -- the most appreciated genre in urdu poetry. using 48,761 poetic works from 4,754 poets produced over a period of 800 years, this study explores the main features of urdu ghazal that make it popular and admired more than other forms. a detailed explanation is provided as to the types of words used for expressing love, nature, birds, and flowers etc. also considered is the way in which the poets addressed their loved ones in their poetry. the style of poetry is numerically analyzed using multi dimensional scaling to reveal the lexical diversity and similarities\/differences between the different poetic works that have drawn the attention of critics, such as iqbal and ghalib, mir taqi mir and mir dard. the analysis produced here is particularly helpful for research in computational stylistics, neurocognitive poetics, and sentiment analysis. ","594":"we present translatotron 2, a neural direct speech-to-speech translation model that can be trained end-to-end. translatotron 2 consists of a speech encoder, a phoneme decoder, a mel-spectrogram synthesizer, and an attention module that connects all the previous three components. experimental results suggest that translatotron 2 outperforms the original translatotron by a large margin in terms of translation quality and predicted speech naturalness, and drastically improves the robustness of the predicted speech by mitigating over-generation, such as babbling or long pause. we also propose a new method for retaining the source speaker's voice in the translated speech. the trained model is restricted to retain the source speaker's voice, but unlike the original translatotron, it is not able to generate speech in a different speaker's voice, making the model more robust for production deployment, by mitigating potential misuse for creating spoofing audio artifacts. when the new method is used together with a simple concatenation-based data augmentation, the trained translatotron 2 model is able to retain each speaker's voice for input with speaker turns. ","595":"text classification has long been a staple within natural language processing (nlp) with applications spanning across diverse areas such as sentiment analysis, recommender systems and spam detection. with such a powerful solution, it is often tempting to use it as the go-to tool for all nlp problems since when you are holding a hammer, everything looks like a nail. however, we argue here that many tasks which are currently addressed using classification are in fact being shoehorned into a classification mould and that if we instead address them as a ranking problem, we not only improve the model, but we achieve better performance. we propose a novel end-to-end ranking approach consisting of a transformer network responsible for producing representations for a pair of text sequences, which are in turn passed into a context aggregating network outputting ranking scores used to determine an ordering to the sequences based on some notion of relevance. we perform numerous experiments on publicly-available datasets and investigate the applications of ranking in problems often solved using classification. in an experiment on a heavily-skewed sentiment analysis dataset, converting ranking results to classification labels yields an approximately 22% improvement over state-of-the-art text classification, demonstrating the efficacy of text ranking over text classification in certain scenarios. ","596":"fitting complex patterns in the training data, such as reasoning and commonsense, is a key challenge for language pre-training. according to recent studies and our empirical observations, one possible reason is that some easy-to-fit patterns in the training data, such as frequently co-occurring word combinations, dominate and harm pre-training, making it hard for the model to fit more complex information. we argue that mis-predictions can help locate such dominating patterns that harm language understanding. when a mis-prediction occurs, there should be frequently co-occurring patterns with the mis-predicted word fitted by the model that lead to the mis-prediction. if we can add regularization to train the model to rely less on such dominating patterns when a mis-prediction occurs and focus more on the rest more subtle patterns, more information can be efficiently fitted at pre-training. following this motivation, we propose a new language pre-training method, mis-predictions as harm alerts (mpa). in mpa, when a mis-prediction occurs during pre-training, we use its co-occurrence information to guide several heads of the self-attention modules. some self-attention heads in the transformer modules are optimized to assign lower attention weights to the words in the input sentence that frequently co-occur with the mis-prediction while assigning higher weights to the other words. by doing so, the transformer model is trained to rely less on the dominating frequently co-occurring patterns with mis-predictions while focus more on the rest more complex information when mis-predictions occur. our experiments show that mpa expedites the pre-training of bert and electra and improves their performances on downstream tasks. ","597":"wikidata is a frequently updated, community-driven, and multilingual knowledge graph. hence, wikidata is an attractive basis for entity linking, which is evident by the recent increase in published papers. this survey focuses on four subjects: (1) which wikidata entity linking datasets exist, how widely used are they and how are they constructed? (2) do the characteristics of wikidata matter for the design of entity linking datasets and if so, how? (3) how do current entity linking approaches exploit the specific characteristics of wikidata? (4) which wikidata characteristics are unexploited by existing entity linking approaches? this survey reveals that current wikidata-specific entity linking datasets do not differ in their annotation scheme from schemes for other knowledge graphs like dbpedia. thus, the potential for multilingual and time-dependent datasets, naturally suited for wikidata, is not lifted. furthermore, we show that most entity linking approaches use wikidata in the same way as any other knowledge graph missing the chance to leverage wikidata-specific characteristics to increase quality. almost all approaches employ specific properties like labels and sometimes descriptions but ignore characteristics such as the hyper-relational structure. hence, there is still room for improvement, for example, by including hyper-relational graph embeddings or type information. many approaches also include information from wikipedia, which is easily combinable with wikidata and provides valuable textual information, which wikidata lacks. ","598":"this paper demonstrates that by fine-tuning an autoregressive language model (gpt-neo) on appropriately structured step-by-step demonstrations, it is possible to teach it to execute a mathematical task that has previously proved difficult for transformers - longhand modulo operations - with a relatively small number of examples. specifically, we fine-tune gpt-neo to solve the numbers__div_remainder task from the deepmind mathematics dataset; saxton et al. (arxiv:1904.01557) reported below 40% accuracy on this task with 2 million training examples. we show that after fine-tuning on 200 appropriately structured demonstrations of solving long division problems and reporting the remainders, the smallest available gpt-neo model achieves over 80% accuracy. this is achieved by constructing an appropriate dataset for fine-tuning, with no changes to the learning algorithm. these results suggest that fine-tuning autoregressive language models on small sets of well-crafted demonstrations may be a useful paradigm for enabling individuals without training in machine learning to coax such models to perform some kinds of complex multi-step tasks. ","599":"as online news has become increasingly popular and fake news increasingly prevalent, the ability to audit the veracity of online news content has become more important than ever. such a task represents a binary classification challenge, for which transformers have achieved state-of-the-art results. using the publicly available isot and combined corpus datasets, this study explores transformers' abilities to identify fake news, with particular attention given to investigating generalisation to unseen datasets with varying styles, topics and class distributions. moreover, we explore the idea that opinion-based news articles cannot be classified as real or fake due to their subjective nature and often sensationalised language, and propose a novel two-step classification pipeline to remove such articles from both model training and the final deployed inference system. experiments over the isot and combined corpus datasets show that transformers achieve an increase in f1 scores of up to 4.9% for out of distribution generalisation compared to baseline approaches, with a further increase of 10.1% following the implementation of our two-step classification pipeline. to the best of our knowledge, this study is the first to investigate generalisation of transformers in this context. ","600":"in this paper, we show how a portuguese bert model can be combined with structured data in order to deploy a chatbot based on a finite state machine to create a conversational ai system that helps a real-estate company to predict its client's contact motivation. the model achieves human level results in a dataset that contains 235 unbalanced labels. then, we also show its benefits considering the business impact comparing it against classical nlp methods. ","601":"emotion recognition in conversations (erc) is an important and active research problem. recent work has shown the benefits of using multiple modalities (e.g., text, audio, and video) for the erc task. in a conversation, participants tend to maintain a particular emotional state unless some external stimuli evokes a change. there is a continuous ebb and flow of emotions in a conversation. inspired by this observation, we propose a multimodal erc model and augment it with an emotion-shift component. the proposed emotion-shift component is modular and can be added to any existing multimodal erc model (with a few modifications), to improve emotion recognition. we experiment with different variants of the model, and results show that the inclusion of emotion shift signal helps the model to outperform existing multimodal models for erc and hence showing the state-of-the-art performance on mosei and iemocap datasets. ","602":"electronic medical records (emrs) contain clinical narrative text that is of great potential value to medical researchers. however, this information is mixed with personally identifiable information (pii) that presents risks to patient and clinician confidentiality. this paper presents an end-to-end de-identification framework to automatically remove pii from hospital discharge summaries. our corpus included 600 hospital discharge summaries which were extracted from the emrs of two principal referral hospitals in sydney, australia. our end-to-end de-identification framework consists of three components: 1) annotation: labelling of pii in the 600 hospital discharge summaries using five pre-defined categories: person, address, date of birth, identification number, phone number; 2) modelling: training six named entity recognition (ner) deep learning base-models on balanced and imbalanced datasets; and evaluating ensembles that combine all six base-models, the three base-models with the best f1 scores and the three base-models with the best recall scores respectively, using token-level majority voting and stacking methods; and 3) de-identification: removing pii from the hospital discharge summaries. our results showed that the ensemble model combined using the stacking support vector machine (svm) method on the three base-models with the best f1 scores achieved excellent results with a f1 score of 99.16% on the test set of our corpus. we also evaluated the robustness of our modelling component on the 2014 i2b2 de-identification dataset. our ensemble model, which uses the token-level majority voting method on all six base-models, achieved the highest f1 score of 96.24% at strict entity matching and the highest f1 score of 98.64% at binary token-level matching compared to two state-of-the-art methods. the framework provides a robust solution to de-identifying clinical narrative text safely. ","603":"in this paper, we present hs-ban, a binary class hate speech (hs) dataset in bangla language consisting of more than 50,000 labeled comments, including 40.17% hate and rest are non hate speech. while preparing the dataset a strict and detailed annotation guideline was followed to reduce human annotation bias. the hs dataset was also preprocessed linguistically to extract different types of slang currently people write using symbols, acronyms, or alternative spellings. these slang words were further categorized into traditional and non-traditional slang lists and included in the results of this paper. we explored traditional linguistic features and neural network-based methods to develop a benchmark system for hate speech detection for the bangla language. our experimental results show that existing word embedding models trained with informal texts perform better than those trained with formal text. our benchmark shows that a bi-lstm model on top of the fasttext informal word embedding achieved 86.78% f1-score. we will make the dataset available for public use. ","604":"most applications of transformers to mathematics, from integration to theorem proving, focus on symbolic computation. in this paper, we show that transformers can be trained to perform numerical calculations with high accuracy. we consider problems of linear algebra: matrix transposition, addition, multiplication, eigenvalues and vectors, singular value decomposition, and inversion. training small transformers (up to six layers) over datasets of random matrices, we achieve high accuracies (over 90%) on all problems. we also show that trained models can generalize out of their training distribution, and that out-of-domain accuracy can be greatly improved by working from more diverse datasets (in particular, by training from matrices with non-independent and identically distributed coefficients). finally, we show that few-shot learning can be leveraged to re-train models to solve larger problems. ","605":"we present a joint model for entity-level relation extraction from documents. in contrast to other approaches - which focus on local intra-sentence mention pairs and thus require annotations on mention level - our model operates on entity level. to do so, a multi-task approach is followed that builds upon coreference resolution and gathers relevant signals via multi-instance learning with multi-level representations combining global entity and local mention information. we achieve state-of-the-art relation extraction results on the docred dataset and report the first entity-level end-to-end relation extraction results for future reference. finally, our experimental results suggest that a joint approach is on par with task-specific learning, though more efficient due to shared parameters and training steps. ","606":"the catalan language understanding benchmark (club) encompasses various datasets representative of different nlu tasks that enable accurate evaluations of language models, following the general language understanding evaluation (glue) example. it is part of aina and plantl, two public funding initiatives to empower the catalan language in the artificial intelligence era. ","607":"cloze task is a widely used task to evaluate an nlp system's language understanding ability. however, most of the existing cloze tasks only require nlp systems to give the relative best prediction for each input data sample, rather than the absolute quality of all possible predictions, in a consistent way across the input domain. thus a new task is proposed: predicting if a filler word in a cloze task is a good, neutral, or bad candidate. complicated versions can be extended to predicting more discrete classes or continuous scores. we focus on subtask a in semeval 2022 task 7, explored some possible architectures to solve this new task, provided a detailed comparison of them, and proposed an ensemble method to improve traditional models in this new task. ","608":"the goal of this paper is to learn strong lip reading models that can recognise speech in silent videos. most prior works deal with the open-set visual speech recognition problem by adapting existing automatic speech recognition techniques on top of trivially pooled visual features. instead, in this paper we focus on the unique challenges encountered in lip reading and propose tailored solutions. to this end, we make the following contributions: (1) we propose an attention-based pooling mechanism to aggregate visual speech representations; (2) we use sub-word units for lip reading for the first time and show that this allows us to better model the ambiguities of the task; (3) we propose a model for visual speech detection (vsd), trained on top of the lip reading network. following the above, we obtain state-of-the-art results on the challenging lrs2 and lrs3 benchmarks when training on public datasets, and even surpass models trained on large-scale industrial datasets by using an order of magnitude less data. our best model achieves 22.6% word error rate on the lrs2 dataset, a performance unprecedented for lip reading models, significantly reducing the performance gap between lip reading and automatic speech recognition. moreover, on the ava-activespeaker benchmark, our vsd model surpasses all visual-only baselines and even outperforms several recent audio-visual methods. ","609":"legal documents are unstructured, use legal jargon, and have considerable length, making it difficult to process automatically via conventional text processing techniques. a legal document processing system would benefit substantially if the documents could be semantically segmented into coherent units of information. this paper proposes a rhetorical roles (rr) system for segmenting a legal document into semantically coherent units: facts, arguments, statute, issue, precedent, ruling, and ratio. with the help of legal experts, we propose a set of 13 fine-grained rhetorical role labels and create a new corpus of legal documents annotated with the proposed rr. we develop a system for segmenting a document into rhetorical role units. in particular, we develop a multitask learning-based deep learning model with document rhetorical role label shift as an auxiliary task for segmenting a legal document. we experiment extensively with various deep learning models for predicting rhetorical roles in a document, and the proposed model shows superior performance over the existing models. further, we apply rr for predicting the judgment of legal cases and show that the use of rr enhances the prediction compared to the transformer-based models. ","610":"in this paper, we present a corpus based study of politeness across two languages-english and hindi. it studies the politeness in a translated parallel corpus of hindi and english and sees how politeness in a hindi text is translated into english. we provide a detailed theoretical background in which the comparison is carried out, followed by a brief description of the translated data within this theoretical model. since politeness may become one of the major reasons of conflict and misunderstanding, it is a very important phenomenon to be studied and understood cross-culturally, particularly for such purposes as machine translation. ","611":"web search engines focus on serving highly relevant results within hundreds of milliseconds. pre-trained language transformer models such as bert are therefore hard to use in this scenario due to their high computational demands. we present our real-time approach to the document ranking problem leveraging a bert-based siamese architecture. the model is already deployed in a commercial search engine and it improves production performance by more than 3%. for further research and evaluation, we release dareczech, a unique data set of 1.6 million czech user query-document pairs with manually assigned relevance levels. we also release small-e-czech, an electra-small language model pre-trained on a large czech corpus. we believe this data will support endeavours both of search relevance and multilingual-focused research communities. ","612":"controversial content refers to any content that attracts both positive and negative feedback. its automatic identification, especially on social media, is a challenging task as it should be done on a large number of continuously evolving posts, covering a large variety of topics. most of the existing approaches rely on the graph structure of a topic-discussion and\/or the content of messages. this paper proposes a controversy detection approach based on both graph structure of a discussion and text features. our proposed approach relies on graph neural network (gnn) to encode the graph representation (including its texts) in an embedding vector before performing a graph classification task. the latter will classify the post as controversial or not. two controversy detection strategies are proposed. the first one is based on a hierarchical graph representation learning. graph user nodes are embedded hierarchically and iteratively to compute the whole graph embedding vector. the second one is based on the attention mechanism, which allows each user node to give more or less importance to its neighbors when computing node embeddings. we conduct experiments to evaluate our approach using different real-world datasets. conducted experiments show the positive impact of combining textual features and structural information in terms of performance. ","613":"existing works on multimodal affective computing tasks, such as emotion recognition, generally adopt a two-phase pipeline, first extracting feature representations for each single modality with hand-crafted algorithms and then performing end-to-end learning with the extracted features. however, the extracted features are fixed and cannot be further fine-tuned on different target tasks, and manually finding feature extraction algorithms does not generalize or scale well to different tasks, which can lead to sub-optimal performance. in this paper, we develop a fully end-to-end model that connects the two phases and optimizes them jointly. in addition, we restructure the current datasets to enable the fully end-to-end training. furthermore, to reduce the computational overhead brought by the end-to-end model, we introduce a sparse cross-modal attention mechanism for the feature extraction. experimental results show that our fully end-to-end model significantly surpasses the current state-of-the-art models based on the two-phase pipeline. moreover, by adding the sparse cross-modal attention, our model can maintain performance with around half the computation in the feature extraction part. ","614":"this paper presents the challenges in creating and managing large parallel corpora of 12 major indian languages (which is soon to be extended to 23 languages) as part of a major consortium project funded by the department of information technology (dit), govt. of india, and running parallel in 10 different universities of india. in order to efficiently manage the process of creation and dissemination of these huge corpora, the web-based (with a reduced stand-alone version also) annotation tool ilciann (indian languages corpora initiative annotation tool) has been developed. it was primarily developed for the pos annotation as well as the management of the corpus annotation by people with differing amount of competence and at locations physically situated far apart. in order to maintain consistency and standards in the creation of the corpora, it was necessary that everyone works on a common platform which was provided by this tool. ","615":"in our project, we focus on nlp-based hybrid recommendation systems. our data is from yelp data. for our hybrid recommendation system, we have two major components: the first part is to embed the reviews with the bert model and word2vec model; the second part is the implementation of an item-based collaborative filtering algorithm to compute the similarity of each review under different categories of restaurants. in the end, with the help of similarity scores, we are able to recommend users the most matched restaurant based on their recorded reviews. the coding work is split into several parts: selecting samples and data cleaning, processing, embedding, computing similarity, and computing prediction and error. due to the size of the data, each part will generate one or more json files as the milestone to reduce the pressure on memory and the communication between each part. ","616":"this paper introduces the system submitted by the yidun nisp team to the video keyword wakeup challenge. we propose a mandarin keyword spotting system (kws) with several novel and effective improvements, including a big backbone (b) model, a keyword biasing (b) mechanism and the introduction of syllable modeling units (s). by considering this, we term the total system bbs-kws as an abbreviation. the bbs-kws system consists of an end-to-end automatic speech recognition (asr) module and a kws module. the asr module converts speech features to text representations, which applies a big backbone network to the acoustic model and takes syllable modeling units into consideration as well. in addition, the keyword biasing mechanism is used to improve the recall rate of keywords in the asr inference stage. the kws module applies multiple criteria to determine the absence or presence of the keywords, such as multi-stage matching, fuzzy matching, and connectionist temporal classification (ctc) prefix score. to further improve our system, we conduct semi-supervised learning on the cn-celeb dataset for better generalization. in the vkw task, the bbs-kws system achieves significant gains over the baseline and won the first place in two tracks. ","617":"joint embedding (je) is a way to encode multi-modal data into a vector space where text remains as the grounding key and other modalities like image are to be anchored with such keys. meme is typically an image with embedded text onto it. although, memes are commonly used for fun, they could also be used to spread hate and fake information. that along with its growing ubiquity over several social platforms has caused automatic analysis of memes to become a widespread topic of research. in this paper, we report our initial experiments on memotion analysis problem through joint embeddings. results are marginally yielding sota. ","618":"transformer based language models have led to impressive results across all domains in natural language processing. pretraining these models on language modeling tasks and finetuning them on downstream tasks such as text classification, question answering and neural machine translation has consistently shown exemplary results. in this work, we propose a multitask finetuning methodology which combines the bilingual machine translation task with an auxiliary causal language modeling task to improve performance on the former task on indian languages. we conduct an empirical study on three language pairs, marathi-hindi, marathi-english and hindi-english, where we compare the multitask finetuning approach to the standard finetuning approach, for which we use the mbart50 model. our study indicates that the multitask finetuning method could be a better technique than standard finetuning, and could improve bilingual machine translation across language pairs. ","619":"benchmark datasets play a central role in the organization of machine learning research. they coordinate researchers around shared research problems and serve as a measure of progress towards shared goals. despite the foundational role of benchmarking practices in this field, relatively little attention has been paid to the dynamics of benchmark dataset use and reuse, within or across machine learning subcommunities. in this paper, we dig into these dynamics. we study how dataset usage patterns differ across machine learning subcommunities and across time from 2015-2020. we find increasing concentration on fewer and fewer datasets within task communities, significant adoption of datasets from other tasks, and concentration across the field on datasets that have been introduced by researchers situated within a small number of elite institutions. our results have implications for scientific evaluation, ai ethics, and equity\/access within the field. ","620":"chinese couplet is a special form of poetry composed of complex syntax with ancient chinese language. due to the complexity of semantic and grammatical rules, creation of a suitable couplet is a formidable challenge. this paper presents a transformer-based sequence-to-sequence couplet generation model. with the utilization of anchibert, the model is able to capture ancient chinese language understanding. moreover, we evaluate the glyph, pinyin and part-of-speech tagging on the couplet grammatical rules to further improve the model. ","621":"as the fourth largest language family in the world, the dravidian languages have become a research hotspot in natural language processing (nlp). although the dravidian languages contain a large number of languages, there are relatively few public available resources. besides, text classification task, as a basic task of natural language processing, how to combine it to multiple languages in the dravidian languages, is still a major difficulty in dravidian natural language processing. hence, to address these problems, we proposed a multilingual text classification framework for the dravidian languages. on the one hand, the framework used the labse pre-trained model as the base model. aiming at the problem of text information bias in multi-task learning, we propose to use the mlm strategy to select language-specific words, and used adversarial training to perturb them. on the other hand, in view of the problem that the model cannot well recognize and utilize the correlation among languages, we further proposed a language-specific representation module to enrich semantic information for the model. the experimental results demonstrated that the framework we proposed has a significant performance in multilingual text classification tasks with each strategy achieving certain improvements. ","622":"learning modality-fused representations and processing unaligned multimodal sequences are meaningful and challenging in multimodal emotion recognition. existing approaches use directional pairwise attention or a message hub to fuse language, visual, and audio modalities. however, those approaches introduce information redundancy when fusing features and are inefficient without considering the complementarity of modalities. in this paper, we propose an efficient neural network to learn modality-fused representations with cb-transformer (lmr-cbt) for multimodal emotion recognition from unaligned multimodal sequences. specifically, we first perform feature extraction for the three modalities respectively to obtain the local structure of the sequences. then, we design a novel transformer with cross-modal blocks (cb-transformer) that enables complementary learning of different modalities, mainly divided into local temporal learning,cross-modal feature fusion and global self-attention representations. in addition, we splice the fused features with the original features to classify the emotions of the sequences. finally, we conduct word-aligned and unaligned experiments on three challenging datasets, iemocap, cmu-mosi, and cmu-mosei. the experimental results show the superiority and efficiency of our proposed method in both settings. compared with the mainstream methods, our approach reaches the state-of-the-art with a minimum number of parameters. ","623":"in this paper, we are going to develop a natural language processing model to help us to predict stocks in the long term. the whole network includes two modules. the first module is a natural language processing model which seeks out reliable factors from input reports. while the other is a time-series forecasting model which takes the factors as input and aims to predict stocks earnings yield. to indicate the efficiency of our model to combine the sentiment analysis module and the time-series forecasting module, we name our method esan. ","624":"long document summarization is an important and hard task in the field of natural language processing. a good performance of the long document summarization reveals the model has a decent understanding of the human language. currently, most researches focus on how to modify the attention mechanism of the transformer to achieve a higher rouge score. the study of data pre-processing and post-processing are relatively few. in this paper, we use two pre-processing methods and a post-processing method and analyze the effect of these methods on various long document summarization models. ","625":"one challenge for evaluating current sequence- or dialogue-level chatbots, such as empathetic open-domain conversation models, is to determine whether the chatbot performs in an emotionally consistent way. the most recent work only evaluates on the aspects of context coherence, language fluency, response diversity, or logical self-consistency between dialogues. this work proposes training an evaluator to determine the emotional consistency of chatbots. ","626":"wikipedia is an important free source of intelligible knowledge. despite that, brazilian portuguese wikipedia still lacks descriptions for many subjects. in an effort to expand the brazilian wikipedia, we contribute plsum, a framework for generating wiki-like abstractive summaries from multiple descriptive websites. the framework has an extractive stage followed by an abstractive one. in particular, for the abstractive stage, we fine-tune and compare two recent variations of the transformer neural network, ptt5, and longformer. to fine-tune and evaluate the model, we created a dataset with thousands of examples, linking reference websites to wikipedia. our results show that it is possible to generate meaningful abstractive summaries from brazilian portuguese web content. ","627":"we propose a new framework, translation between augmented natural languages (tanl), to solve many structured prediction language tasks including joint entity and relation extraction, nested named entity recognition, relation classification, semantic role labeling, event extraction, coreference resolution, and dialogue state tracking. instead of tackling the problem by training task-specific discriminative classifiers, we frame it as a translation task between augmented natural languages, from which the task-relevant information can be easily extracted. our approach can match or outperform task-specific models on all tasks, and in particular, achieves new state-of-the-art results on joint entity and relation extraction (conll04, ade, nyt, and ace2005 datasets), relation classification (fewrel and tacred), and semantic role labeling (conll-2005 and conll-2012). we accomplish this while using the same architecture and hyperparameters for all tasks and even when training a single model to solve all tasks at the same time (multi-task learning). finally, we show that our framework can also significantly improve the performance in a low-resource regime, thanks to better use of label semantics. ","628":"generating images from natural language instructions is an intriguing yet highly challenging task. we approach text-to-image generation by combining the power of the retrained clip representation with an off-the-shelf image generator (gans), optimizing in the latent space of gan to find images that achieve maximum clip score with the given input text. compared to traditional methods that train generative models from text to image starting from scratch, the clip+gan approach is training-free, zero shot and can be easily customized with different generators.   however, optimizing clip score in the gan space casts a highly challenging optimization problem and off-the-shelf optimizers such as adam fail to yield satisfying results. in this work, we propose a fusedream pipeline, which improves the clip+gan approach with three key techniques: 1) an augclip score which robustifies the clip objective by introducing random augmentation on image. 2) a novel initialization and over-parameterization strategy for optimization which allows us to efficiently navigate the non-convex landscape in gan space. 3) a composed generation technique which, by leveraging a novel bi-level optimization formulation, can compose multiple images to extend the gan space and overcome the data-bias.   when promoted by different input text, fusedream can generate high-quality images with varying objects, backgrounds, artistic styles, even novel counterfactual concepts that do not appear in the training data of the gan we use. quantitatively, the images generated by fusedream yield top-level inception score and fid score on ms coco dataset, without additional architecture design or training. our code is publicly available at \\url{https:\/\/github.com\/gnobitab\/fusedream}. ","629":"languages are powerful solutions to coordination problems: they provide stable, shared expectations about how the words we say correspond to the beliefs and intentions in our heads. yet language use in a variable and non-stationary social environment requires linguistic representations to be flexible: old words acquire new ad hoc or partner-specific meanings on the fly. in this paper, we introduce chai (continual hierarchical adaptation through inference), a hierarchical bayesian theory of coordination and convention formation that aims to reconcile the long-standing tension between these two basic observations. we argue that the central computational problem of communication is not simply transmission, as in classical formulations, but continual learning and adaptation over multiple timescales. partner-specific common ground quickly emerges from social inferences within dyadic interactions, while community-wide social conventions are stable priors that have been abstracted away from interactions with multiple partners. we present new empirical data alongside simulations showing how our model provides a computational foundation for several phenomena that have posed a challenge for previous accounts: (1) the convergence to more efficient referring expressions across repeated interaction with the same partner, (2) the gradual transfer of partner-specific common ground to strangers, and (3) the influence of communicative context on which conventions eventually form. ","630":"natural language generation from structured data mainly focuses on surface-level descriptions, suffering from uncontrollable content selection and low fidelity. previous works leverage logical forms to facilitate logical knowledge-conditioned text generation. though achieving remarkable progress, they are data-hungry, which makes the adoption for real-world applications challenging with limited data. to this end, this paper proposes a unified framework for logical knowledge-conditioned text generation in the few-shot setting. with only a few seeds logical forms (e.g., 20\/100 shot), our approach leverages self-training and samples pseudo logical forms based on content and structure consistency. experimental results demonstrate that our approach can obtain better few-shot performance than baselines. ","631":"fusion technique is a key research topic in multimodal sentiment analysis. the recent attention-based fusion demonstrates advances over simple operation-based fusion. however, these fusion works adopt single-scale, i.e., token-level or utterance-level, unimodal representation. such single-scale fusion is suboptimal because that different modality should be aligned with different granularities. this paper proposes a fusion model named scalevlad to gather multi-scale representation from text, video, and audio with shared vectors of locally aggregated descriptors to improve unaligned multimodal sentiment analysis. these shared vectors can be regarded as shared topics to align different modalities. in addition, we propose a self-supervised shifted clustering loss to keep the fused feature differentiation among samples. the backbones are three transformer encoders corresponding to three modalities, and the aggregated features generated from the fusion module are feed to a transformer plus a full connection to finish task predictions. experiments on three popular sentiment analysis benchmarks, iemocap, mosi, and mosei, demonstrate significant gains over baselines. ","632":"existing accounts of explanation emphasise the role of prior experience in the solution of new problems. however, most of the contemporary models for multi-hop textual inference construct explanations considering each test case in isolation. this paradigm is known to suffer from semantic drift, which causes the construction of spurious explanations leading to wrong conclusions. in contrast, we investigate an abductive framework for explainable multi-hop inference that adopts the retrieve-reuse-revise paradigm largely studied in case-based reasoning. specifically, we present a novel framework that addresses and explains unseen inference problems by retrieving and adapting prior natural language explanations from similar training examples. we empirically evaluate the case-based abductive framework on downstream commonsense and scientific reasoning tasks. our experiments demonstrate that the proposed framework can be effectively integrated with sparse and dense pre-trained encoding mechanisms or downstream transformers, achieving strong performance when compared to existing explainable approaches. moreover, we study the impact of the retrieve-reuse-revise paradigm on explainability and semantic drift, showing that it boosts the quality of the constructed explanations, resulting in improved downstream inference performance. ","633":"comparison with a human is an essential requirement for a benchmark for it to be a reliable measurement of model capabilities. nevertheless, the methods for model comparison could have a fundamental flaw - the arithmetic mean of separate metrics is used for all tasks of different complexity, different size of test and training sets.   in this paper, we examine popular nlp benchmarks' overall scoring methods and rearrange the models by geometric and harmonic mean (appropriate for averaging rates) according to their reported results. we analyze several popular benchmarks including glue, superglue, xglue, and xtreme. the analysis shows that e.g. human level on superglue is still not reached, and there is still room for improvement for the current models. ","634":"code summarization aims to generate brief natural language descriptions for source code. as source code is highly structured and follows strict programming language grammars, its abstract syntax tree (ast) is often leveraged to inform the encoder about the structural information. however, asts are usually much longer than the source code. current approaches ignore the size limit and simply feed the whole linearized ast into the encoder. to address this problem, we propose ast-transformer to efficiently encode tree-structured asts. experiments show that ast-transformer outperforms the state-of-arts by a substantial margin while being able to reduce $90\\sim95\\%$ of the computational complexity in the encoding process. ","635":"modeling law search and retrieval as prediction problems has recently emerged as a predominant approach in law intelligence. focusing on the law article retrieval task, we present a deep learning framework named lamberta, which is designed for civil-law codes, and specifically trained on the italian civil code. to our knowledge, this is the first study proposing an advanced approach to law article prediction for the italian legal system based on a bert (bidirectional encoder representations from transformers) learning framework, which has recently attracted increased attention among deep learning approaches, showing outstanding effectiveness in several natural language processing and learning tasks. we define lamberta models by fine-tuning an italian pre-trained bert on the italian civil code or its portions, for law article retrieval as a classification task. one key aspect of our lamberta framework is that we conceived it to address an extreme classification scenario, which is characterized by a high number of classes, the few-shot learning problem, and the lack of test query benchmarks for italian legal prediction tasks. to solve such issues, we define different methods for the unsupervised labeling of the law articles, which can in principle be applied to any law article code system. we provide insights into the explainability and interpretability of our lamberta models, and we present an extensive experimental analysis over query sets of different type, for single-label as well as multi-label evaluation tasks. empirical evidence has shown the effectiveness of lamberta, and also its superiority against widely used deep-learning text classifiers and a few-shot learner conceived for an attribute-aware prediction task. ","636":"self-supervised learning approach like contrastive learning is attached great attention in natural language processing. it uses pairs of training data augmentations to build a classification task for an encoder with well representation ability. however, the construction of learning pairs over contrastive learning is much harder in nlp tasks. previous works generate word-level changes to form pairs, but small transforms may cause notable changes on the meaning of sentences as the discrete and sparse nature of natural language. in this paper, adversarial training is performed to generate challenging and harder learning adversarial examples over the embedding space of nlp as learning pairs. using contrastive learning improves the generalization ability of adversarial training because contrastive loss can uniform the sample distribution. and at the same time, adversarial training also enhances the robustness of contrastive learning. two novel frameworks, supervised contrastive adversarial learning (scal) and unsupervised scal (uscal), are proposed, which yields learning pairs by utilizing the adversarial training for contrastive learning. the label-based loss of supervised tasks is exploited to generate adversarial examples while unsupervised tasks bring contrastive loss. to validate the effectiveness of the proposed framework, we employ it to transformer-based models for natural language understanding, sentence semantic textual similarity and adversarial learning tasks. experimental results on glue benchmark tasks show that our fine-tuned supervised method outperforms bert$_{base}$ over 1.75\\%. we also evaluate our unsupervised method on semantic textual similarity (sts) tasks, and our method gets 77.29\\% with bert$_{base}$. the robustness of our approach conducts state-of-the-art results under multiple adversarial datasets on nli tasks. ","637":"training data memorization in nlp can both be beneficial (e.g., closed-book qa) and undesirable (personal data extraction). in any case, successful model training requires a non-trivial amount of memorization to store word spellings, various linguistic idiosyncrasies and common knowledge. however, little is known about what affects the memorization behavior of nlp models, as the field tends to focus on the equally important question of generalization. in this work, we demonstrate that the size of the subword vocabulary learned by byte-pair encoding (bpe) greatly affects both ability and tendency of standard transformer models to memorize training data, even when we control for the number of learned parameters. we find that with a large subword vocabulary size, transformer models fit random mappings more easily and are more vulnerable to membership inference attacks. similarly, given a prompt, transformer-based language models with large subword vocabularies reproduce the training data more often. we conjecture this effect is caused by reduction in the sequences' length that happens as the bpe vocabulary grows. our findings can allow a more informed choice of hyper-parameters, that is better tailored for a particular use-case. ","638":"in this paper, we investigate a novel and challenging task, namely controllable video captioning with an exemplar sentence. formally, given a video and a syntactically valid exemplar sentence, the task aims to generate one caption which not only describes the semantic contents of the video, but also follows the syntactic form of the given exemplar sentence. in order to tackle such an exemplar-based video captioning task, we propose a novel syntax modulated caption generator (smcg) incorporated in an encoder-decoder-reconstructor architecture. the proposed smcg takes video semantic representation as an input, and conditionally modulates the gates and cells of long short-term memory network with respect to the encoded syntactic information of the given exemplar sentence. therefore, smcg is able to control the states for word prediction and achieve the syntax customized caption generation. we conduct experiments by collecting auxiliary exemplar sentences for two public video captioning datasets. extensive experimental results demonstrate the effectiveness of our approach on generating syntax controllable and semantic preserved video captions. by providing different exemplar sentences, our approach is capable of producing different captions with various syntactic structures, thus indicating a promising way to strengthen the diversity of video captioning. ","639":"contrastive language-image pre-training (clip) has made a remarkable breakthrough in open-vocabulary zero-shot image recognition. many recent studies leverage the pre-trained clip models for image-level classification and manipulation. in this paper, we further explore the potentials of clip for pixel-level dense prediction, specifically in semantic segmentation. our method, denseclip, in the absence of annotations and fine-tuning, yields reasonable segmentation results on open concepts across various datasets. by adding pseudo labeling and self-training, denseclip+ surpasses sota transductive zero-shot semantic segmentation methods by large margins, e.g., mious of unseen classes on pascal voc\/pascal context\/coco stuff are improved from 35.6\/20.7\/30.3 to 86.1\/66.7\/54.7. we also test the robustness of denseclip under input corruption and evaluate its capability in discriminating fine-grained objects and novel concepts. our finding suggests that denseclip can serve as a new reliable source of supervision for dense prediction tasks to achieve annotation-free segmentation. ","640":"enhancing the diversity of sentences to describe video contents is an important problem arising in recent video captioning research. in this paper, we explore this problem from a novel perspective of customizing video captions by imitating exemplar sentence syntaxes. specifically, given a video and any syntax-valid exemplar sentence, we introduce a new task of syntax customized video captioning (scvc) aiming to generate one caption which not only semantically describes the video contents but also syntactically imitates the given exemplar sentence. to tackle the scvc task, we propose a novel video captioning model, where a hierarchical sentence syntax encoder is firstly designed to extract the syntactic structure of the exemplar sentence, then a syntax conditioned caption decoder is devised to generate the syntactically structured caption expressing video semantics. as there is no available syntax customized groundtruth video captions, we tackle such a challenge by proposing a new training strategy, which leverages the traditional pairwise video captioning data and our collected exemplar sentences to accomplish the model learning. extensive experiments, in terms of semantic, syntactic, fluency, and diversity evaluations, clearly demonstrate our model capability to generate syntax-varied and semantics-coherent video captions that well imitate different exemplar sentences with enriched diversities. ","641":"biological data and knowledge bases increasingly rely on semantic web technologies and the use of knowledge graphs for data integration, retrieval and federated queries. we propose a solution for automatically semantifying biological assays. our solution contrasts the problem of automated semantification as labeling versus clustering where the two methods are on opposite ends of the method complexity spectrum. characteristically modeling our problem, we find the clustering solution significantly outperforms a deep neural network state-of-the-art labeling approach. this novel contribution is based on two factors: 1) a learning objective closely modeled after the data outperforms an alternative approach with sophisticated semantic modeling; 2) automatically semantifying biological assays achieves a high performance f1 of nearly 83%, which to our knowledge is the first reported standardized evaluation of the task offering a strong benchmark model. ","642":"conversational analysis systems are trained using noisy human labels and often require heavy preprocessing during multi-modal feature extraction. using noisy labels in single-task learning increases the risk of over-fitting. auxiliary tasks could improve the performance of the primary task learning during the same training -- this approach sits in the intersection of transfer learning and multi-task learning (mtl). in this paper, we explore how the preprocessed data used for feature engineering can be re-used as auxiliary tasks, thereby promoting the productive use of data. our main contributions are: (1) the identification of sixteen beneficially auxiliary tasks, (2) studying the method of distributing learning capacity between the primary and auxiliary tasks, and (3) studying the relative supervision hierarchy between the primary and auxiliary tasks. extensive experiments on iemocap and semaine data validate the improvements over single-task approaches, and suggest that it may generalize across multiple primary tasks. ","643":"contrastive learning techniques have been widely used in the field of computer vision as a means of augmenting datasets. in this paper, we extend the use of these contrastive learning embeddings to sentiment analysis tasks and demonstrate that fine-tuning on these embeddings provides an improvement over fine-tuning on bert-based embeddings to achieve higher benchmarks on the task of sentiment analysis when evaluated on the dynasent dataset. we also explore how our fine-tuned models perform on cross-domain benchmark datasets. additionally, we explore upsampling techniques to achieve a more balanced class distribution to make further improvements on our benchmark tasks. ","644":"lack of labeled data is a main obstacle in relation extraction. semi-supervised relation extraction (ssre) has been proven to be a promising way for this problem through annotating unlabeled samples as additional training data. almost all prior researches along this line adopt multiple models to make the annotations more reliable by taking the intersection set of predicted results from these models. however, the difference set, which contains rich information about unlabeled data, has been long neglected by prior studies.   in this paper, we propose to learn not only from the consensus but also the disagreement among different models in ssre. to this end, we develop a simple and general multi-teacher distillation (mtd) framework, which can be easily integrated into any existing ssre methods. specifically, we first let the teachers correspond to the multiple models and select the samples in the intersection set of the last iteration in ssre methods to augment labeled data as usual. we then transfer the class distributions for samples in the difference set as soft labels to guide the student. we finally perform prediction using the trained student model. experimental results on two public datasets demonstrate that our framework significantly promotes the performance of the base ssre methods with pretty low computational cost. ","645":"knowledge-enhanced pre-trained language models (keplms) are pre-trained models with relation triples injecting from knowledge graphs to improve language understanding abilities. to guarantee effective knowledge injection, previous studies integrate models with knowledge encoders for representing knowledge retrieved from knowledge graphs. the operations for knowledge retrieval and encoding bring significant computational burdens, restricting the usage of such models in real-world applications that require high inference speed. in this paper, we propose a novel keplm named dkplm that decomposes knowledge injection process of the pre-trained language models in pre-training, fine-tuning and inference stages, which facilitates the applications of keplms in real-world scenarios. specifically, we first detect knowledge-aware long-tail entities as the target for knowledge injection, enhancing the keplms' semantic understanding abilities and avoiding injecting redundant information. the embeddings of long-tail entities are replaced by \"pseudo token representations\" formed by relevant knowledge triples. we further design the relational knowledge decoding task for pre-training to force the models to truly understand the injected knowledge by relation triple reconstruction. experiments show that our model outperforms other keplms significantly over zero-shot knowledge probing tasks and multiple knowledge-aware language understanding tasks. we further show that dkplm has a higher inference speed than other competing models due to the decomposing mechanism. ","646":"in this paper, we propose that the dot product pairwise matching attention layer, which is widely used in transformer-based models, is redundant for the model performance. attention in its original formulation has to be rather seen as a human-level tool to explore and\/or visualize relevancy scores in the sequences. instead, we present a simple and fast alternative without any approximation that, to the best of our knowledge, outperforms existing attention approximations on several tasks from the long-range arena benchmark. ","647":"knowledge graph (kg) inference is the vital technique to address the natural incompleteness of kgs. the existing kg inference approaches can be classified into rule learning-based and kg embedding-based models. however, these approaches cannot well balance accuracy, generalization, interpretability and efficiency, simultaneously. besides, these models always rely on pure triples and neglect additional information. therefore, both kg embedding (kge) and rule learning kg inference approaches face challenges due to the sparse entities and the limited semantics. we propose a novel and effective closed-loop kg inference framework enginekgi operating similarly as an engine based on these observations. enginekgi combines kge and rule learning to complement each other in a closed-loop pattern while taking advantage of semantics in paths and concepts. kge module exploits paths to enhance the semantic association between entities and introduces rules for interpretability. a novel rule pruning mechanism is proposed in the rule learning module by leveraging paths as initial candidate rules and employing kg embeddings together with concepts for extracting more high-quality rules. experimental results on four real-world datasets show that our model outperforms other baselines on link prediction tasks, demonstrating the effectiveness and superiority of our model on kg inference in a joint logic and data-driven fashion with a closed-loop mechanism. ","648":"this paper presents a novel deep learning architecture for acoustic model in the context of automatic speech recognition (asr), termed as mixnet. besides the conventional layers, such as fully connected layers in dnn-hmm and memory cells in lstm-hmm, the model uses two additional layers based on mixture of experts (moe). the first moe layer operating at the input is based on pre-defined broad phonetic classes and the second layer operating at the penultimate layer is based on automatically learned acoustic classes. in natural speech, overlap in distribution across different acoustic classes is inevitable, which leads to inter-class mis-classification. the asr accuracy is expected to improve if the conventional architecture of acoustic model is modified to make them more suitable to account for such overlaps. mixnet is developed keeping this in mind. analysis conducted by means of scatter diagram verifies that moe indeed improves the separation between classes that translates to better asr accuracy. experiments are conducted on a large vocabulary asr task which show that the proposed architecture provides 13.6% and 10.0% relative reduction in word error rates compared to the conventional models, namely, dnn and lstm respectively, trained using smbr criteria. in comparison to an existing method developed for phone-classification (by eigen et al), our proposed method yields a significant improvement. ","649":"question generation (qg) receives increasing research attention in nlp community. one motivation for qg is that qg significantly facilitates the preparation of educational reading practice and assessments. while the significant advancement of qg techniques was reported, current qg results are not ideal for educational reading practice assessment in terms of \\textit{controllability} and \\textit{question difficulty}. this paper reports our results toward the two issues. first, we report a state-of-the-art exam-like qg model by advancing the current best model from 11.96 to 20.19 (in terms of bleu 4 score). second, we propose to investigate a variant of qg setting by allowing users to provide keywords for guiding qg direction. we also present a simple but effective model toward the qg controllability task. experiments are also performed and the results demonstrate the feasibility and potentials of improving qg diversity and controllability by the proposed keyword provision qg model. ","650":"with the enrichment of literature resources, researchers are facing the growing problem of information explosion and knowledge overload. to help scholars retrieve literature and acquire knowledge successfully, clarifying the semantic structure of the content in academic literature has become the essential research question. in the research on identifying the structure function of chapters in academic articles, only a few studies used the deep learning model and explored the optimization for feature input. this limits the application, optimization potential of deep learning models for the research task. this paper took articles of the acl conference as the corpus. we employ the traditional machine learning models and deep learning models to construct the classifiers based on various feature input. experimental results show that (1) compared with the chapter content, the chapter title is more conducive to identifying the structure function of academic articles. (2) relative position is a valuable feature for building traditional models. (3) inspired by (2), this paper further introduces contextual information into the deep learning models and achieved significant results. meanwhile, our models show good migration ability in the open test containing 200 sampled non-training samples. we also annotated the acl main conference papers in recent five years based on the best practice performing models and performed a time series analysis of the overall corpus. this work explores and summarizes the practical features and models for this task through multiple comparative experiments and provides a reference for related text classification tasks. finally, we indicate the limitations and shortcomings of the current model and the direction of further optimization. ","651":"training an image captioning model in an unsupervised manner without utilizing annotated image-caption pairs is an important step towards tapping into a wider corpus of text and images. in the supervised setting, image-caption pairs are \"well-matched\", where all objects mentioned in the sentence appear in the corresponding image. these pairings are, however, not available in the unsupervised setting. to overcome this, a main school of research that has been shown to be effective in overcoming this is to construct pairs from the images and texts in the training set according to their overlap of objects. unlike in the supervised setting, these constructed pairings are however not guaranteed to have fully overlapping set of objects. our work in this paper overcomes this by harvesting objects corresponding to a given sentence from the training set, even if they don't belong to the same image. when used as input to a transformer, such mixture of objects enable larger if not full object coverage, and when supervised by the corresponding sentence, produced results that outperform current state of the art unsupervised methods by a significant margin. building upon this finding, we further show that (1) additional information on relationship between objects and attributes of objects also helps in boosting performance; and (2) our method also extends well to non-english image captioning, which usually suffers from a scarcer level of annotations. our findings are supported by strong empirical results. ","652":"grounded video description (gvd) encourages captioning models to attend to appropriate video regions (e.g., objects) dynamically and generate a description. such a setting can help explain the decisions of captioning models and prevents the model from hallucinating object words in its description. however, such design mainly focuses on object word generation and thus may ignore fine-grained information and suffer from missing visual concepts. moreover, relational words (e.g., \"jump left or right\") are usual spatio-temporal inference results, i.e., these words cannot be grounded on certain spatial regions. to tackle the above limitations, we design a novel relational graph learning framework for gvd, in which a language-refined scene graph representation is designed to explore fine-grained visual concepts. furthermore, the refined graph can be regarded as relational inductive knowledge to assist captioning models in selecting the relevant information it needs to generate correct words. we validate the effectiveness of our model through automatic metrics and human evaluation, and the results indicate that our approach can generate more fine-grained and accurate description, and it solves the problem of object hallucination to some extent. ","653":"the impact of real world events on fictional media is particularly apparent in the american cartoon series the simpsons. while there are often very direct pop culture references evident in the dialogue and visual gags of the show, subtle changes in tone or sentiment may not be so obvious. our aim was to use natural language processing to attempt to search for changes in word frequency, topic, and sentiment before and after the september 11 terrorist attacks in new york. no clear trend change was seen, there was a slight decrease in the average sentiment over time around the relevant period between 2000 and 2002, but the scripts still maintained an overall positive value, indicating that the comedic nature of the simpsons did not wane particularly significantly. the exploration of other social issues and even specific character statistics is needed to bolster the findings here. ","654":"extracting temporal relations among events from unstructured text has extensive applications, such as temporal reasoning and question answering. while it is difficult, recent development of neural-symbolic methods has shown promising results on solving similar tasks. current temporal relation extraction methods usually suffer from limited expressivity and inconsistent relation inference. for example, in timeml annotations, the concept of intersection is absent. additionally, current methods do not guarantee the consistency among the predicted annotations. in this work, we propose smarter, a neural semantic parser, to extract temporal information in text effectively. smarter parses natural language to an executable logical form representation, based on a custom typed lambda calculus. in the training phase, dynamic programming on denotations (dpd) technique is used to provide weak supervision on logical forms. in the inference phase, smarter generates a temporal relation graph by executing the logical form. as a result, our neural semantic parser produces logical forms capturing the temporal information of text precisely. the accurate logical form representations of an event given the context ensure the correctness of the extracted relations. ","655":"we explore deep clustering of text representations for unsupervised model interpretation and induction of syntax. as these representations are high-dimensional, out-of-the-box methods like kmeans do not work well. thus, our approach jointly transforms the representations into a lower-dimensional cluster-friendly space and clusters them. we consider two notions of syntax: part of speech induction (posi) and constituency labelling (colab) in this work. interestingly, we find that multilingual bert (mbert) contains surprising amount of syntactic knowledge of english; possibly even as much as english bert (ebert). our model can be used as a supervision-free probe which is arguably a less-biased way of probing. we find that unsupervised probes show benefits from higher layers as compared to supervised probes. we further note that our unsupervised probe utilizes ebert and mbert representations differently, especially for posi. we validate the efficacy of our probe by demonstrating its capabilities as an unsupervised syntax induction technique. our probe works well for both syntactic formalisms by simply adapting the input representations. we report competitive performance of our probe on 45-tag english posi, state-of-the-art performance on 12-tag posi across 10 languages, and competitive results on colab. we also perform zero-shot syntax induction on resource impoverished languages and report strong results. ","656":"data augmentation has recently seen increased interest in nlp due to more work in low-resource domains, new tasks, and the popularity of large-scale neural networks that require large amounts of training data. despite this recent upsurge, this area is still relatively underexplored, perhaps due to the challenges posed by the discrete nature of language data. in this paper, we present a comprehensive and unifying survey of data augmentation for nlp by summarizing the literature in a structured manner. we first introduce and motivate data augmentation for nlp, and then discuss major methodologically representative approaches. next, we highlight techniques that are used for popular nlp applications and tasks. we conclude by outlining current challenges and directions for future research. overall, our paper aims to clarify the landscape of existing literature in data augmentation for nlp and motivate additional work in this area. we also present a github repository with a paper list that will be continuously updated at https:\/\/github.com\/styfeng\/dataaug4nlp ","657":"for conversational ai and virtual assistants to communicate with humans in a realistic way, they must exhibit human characteristics such as expression of emotion and personality. current attempts toward constructing human-like dialogue agents have presented significant difficulties. we propose human level attributes (hlas) based on tropes as the basis of a method for learning dialogue agents that can imitate the personalities of fictional characters. tropes are characteristics of fictional personalities that are observed recurrently and determined by viewers' impressions. by combining detailed hla data with dialogue data for specific characters, we present a dataset, hla-chat, that models character profiles and gives dialogue agents the ability to learn characters' language styles through their hlas. we then introduce a three-component system, aloha (which stands for artificial learning of human attributes), that combines character space mapping, character community detection, and language style retrieval to build a character (or personality) specific language model. our preliminary experiments demonstrate that two variations of aloha, combined with our proposed dataset, can outperform baseline models at identifying the correct dialogue responses of chosen target characters, and are stable regardless of the character's identity, the genre of the show, and the context of the dialogue. ","658":"we motivate and propose a suite of simple but effective improvements for concept-to-text generation called sapphire: set augmentation and post-hoc phrase infilling and recombination. we demonstrate their effectiveness on generative commonsense reasoning, a.k.a. the commongen task, through experiments using both bart and t5 models. through extensive automatic and human evaluation, we show that sapphire noticeably improves model performance. an in-depth qualitative analysis illustrates that sapphire effectively addresses many issues of the baseline model generations, including lack of commonsense, insufficient specificity, and poor fluency. ","659":"warning: this paper contains material which may be offensive or upsetting.   while much of recent work has focused on the detection of hate speech and overtly offensive content, very little research has explored the more subtle but equally harmful language in the form of implied stereotypes. this is a challenging domain, made even more so by the fact that humans often struggle to understand and reason about stereotypes. we build on existing literature and present co-star (conceptualisation of stereotypes for analysis and reasoning), a novel framework which encodes the underlying concepts of implied stereotypes. we also introduce the co-star training data set, which contains just over 12k structured annotations of implied stereotypes and stereotype conceptualisations, and achieve state-of-the-art results after training and manual evaluation. the co-star models are, however, limited in their ability to understand more complex and subtly worded stereotypes, and our research motivates future work in developing models with more sophisticated methods for encoding common-sense knowledge. ","660":"communicating with humans is challenging for ais because it requires a shared understanding of the world, complex semantics (e.g., metaphors or analogies), and at times multi-modal gestures (e.g., pointing with a finger, or an arrow in a diagram). we investigate these challenges in the context of iconary, a collaborative game of drawing and guessing based on pictionary, that poses a novel challenge for the research community. in iconary, a guesser tries to identify a phrase that a drawer is drawing by composing icons, and the drawer iteratively revises the drawing to help the guesser in response. this back-and-forth often uses canonical scenes, visual metaphor, or icon compositions to express challenging words, making it an ideal test for mixing language and visual\/symbolic communication in ai. we propose models to play iconary and train them on over 55,000 games between human players. our models are skillful players and are able to employ world knowledge in language models to play with words unseen during training. elite human players outperform our models, particularly at the drawing task, leaving an important gap for future research to address. we release our dataset, code, and evaluation setup as a challenge to the community at http:\/\/www.github.com\/allenai\/iconary. ","661":"machine learning is shifting towards general-purpose pretrained generative models, trained in a self-supervised manner on large amounts of data, which can then be applied to solve a large number of tasks. however, due to their generic training methodology, these models often fail to meet some of the downstream requirements (e.g. hallucination in abstractive summarization or wrong format in automatic code generation). this raises an important question on how to adapt pre-trained generative models to a new task without destroying its capabilities. recent work has suggested to solve this problem by representing task-specific requirements through energy-based models (ebms) and approximating these ebms using distributional policy gradients (dpg). unfortunately, this approach is limited to unconditional distributions, represented by unconditional ebms. in this paper, we extend this approach to conditional tasks by proposing conditional dpg (cdpg). we evaluate cdpg on three different control objectives across two tasks: summarization with t5 and code generation with gpt-neo. our results show that fine-tuning using cdpg robustly moves these pretrained models closer towards meeting control objectives and -- in contrast with baseline approaches -- does not result in catastrophic forgetting. ","662":"the existing search tools for exploring the nasa astrophysics data system (ads) can be quite rich and empowering (e.g., similar and trending operators), but researchers are not yet allowed to fully leverage semantic search. for example, a query for \"results from the planck mission\" should be able to distinguish between all the various meanings of planck (person, mission, constant, institutions and more) without further clarification from the user. at ads, we are applying modern machine learning and natural language processing techniques to our dataset of recent astronomy publications to train astrobert, a deeply contextual language model based on research at google. using astrobert, we aim to enrich the ads dataset and improve its discoverability, and in particular we are developing our own named entity recognition tool. we present here our preliminary results and lessons learned. ","663":"recent research suggests that systematic generalization in natural language understanding remains a challenge for state-of-the-art neural models such as transformers and graph neural networks. to tackle this challenge, we propose edge transformer, a new model that combines inspiration from transformers and rule-based symbolic ai. the first key idea in edge transformers is to associate vector states with every edge, that is, with every pair of input nodes -- as opposed to just every node, as it is done in the transformer model. the second major innovation is a triangular attention mechanism that updates edge representations in a way that is inspired by unification from logic programming. we evaluate edge transformer on compositional generalization benchmarks in relational reasoning, semantic parsing, and dependency parsing. in all three settings, the edge transformer outperforms relation-aware, universal and classical transformer baselines. ","664":"motivated by the success of pre-trained language models such as bert in a broad range of natural language processing (nlp) tasks, recent research efforts have been made for adapting these models for different application domains. along this line, existing domain-oriented models have primarily followed the vanilla bert architecture and have a straightforward use of the domain corpus. however, domain-oriented tasks usually require accurate understanding of domain phrases, and such fine-grained phrase-level knowledge is hard to be captured by existing pre-training scheme. also, the word co-occurrences guided semantic learning of pre-training models can be largely augmented by entity-level association knowledge. but meanwhile, by doing so there is a risk of introducing noise due to the lack of groundtruth word-level alignment. to address the above issues, we provide a generalized domain-oriented approach, which leverages auxiliary domain knowledge to improve the existing pre-training framework from two aspects. first, to preserve phrase knowledge effectively, we build a domain phrase pool as auxiliary training tool, meanwhile we introduce adaptive hybrid masked model to incorporate such knowledge. it integrates two learning modes, word learning and phrase learning, and allows them to switch between each other. second, we introduce cross entity alignment to leverage entity association as weak supervision to augment the semantic learning of pre-trained models. to alleviate the potential noise in this process, we introduce an interpretable optimal transport based approach to guide alignment learning. experiments on four domain-oriented tasks demonstrate the superiority of our framework. ","665":"deep language models have achieved remarkable success in the nlp domain. the standard way to train a deep language model is to employ unsupervised learning from scratch on a large unlabeled corpus. however, such large corpora are only available for widely-adopted and high-resource languages and domains. this study presents the first deep language model, dprk-bert, for the dprk language. we achieve this by compiling the first unlabeled corpus for the dprk language and fine-tuning a preexisting the rok language model. we compare the proposed model with existing approaches and show significant improvements on two dprk datasets. we also present a cross-lingual version of this model which yields better generalization across the two korean languages. finally, we provide various nlp tools related to the dprk language that would foster future research. ","666":"dascim (data science and mining) part of lix at ecole polytechnique, established in 2013 and since then producing research results in the area of large scale data analysis via methods of machine and deep learning. the group has been specifically active in the area of nlp and text mining with interesting results at methodological and resources level. here follow our different contributions of interest to the afia community. ","667":"this work presents a detailed comparison of the performance of deep learning models such as convolutional neural networks (cnn), long short-term memory (lstm), gated recurrent units (gru), their hybrids, and a selection of shallow learning classifiers for sentiment analysis of arabic reviews. additionally, the comparison includes state-of-the-art models such as the transformer architecture and the arabert pre-trained model. the datasets used in this study are multi-dialect arabic hotel and book review datasets, which are some of the largest publicly available datasets for arabic reviews. results showed deep learning outperforming shallow learning for binary and multi-label classification, in contrast with the results of similar work reported in the literature. this discrepancy in outcome was caused by dataset size as we found it to be proportional to the performance of deep learning models. the performance of deep and shallow learning techniques was analyzed in terms of accuracy and f1 score. the best performing shallow learning technique was random forest followed by decision tree, and adaboost. the deep learning models performed similarly using a default embedding layer, while the transformer model performed best when augmented with arabert. ","668":"bnlp is an open source language processing toolkit for bengali language consisting with tokenization, word embedding, pos tagging, ner tagging facilities. bnlp provides pre-trained model with high accuracy to do model based tokenization, embedding, pos tagging, ner tagging task for bengali language. bnlp pre-trained model achieves significant results in bengali text tokenization, word embedding, pos tagging and ner tagging task. bnlp is using widely in the bengali research communities with 16k downloads, 119 stars and 31 forks. bnlp is available at https:\/\/github.com\/sagorbrur\/bnlp. ","669":"we target at the task of weakly-supervised video object grounding (wsvog), where only video-sentence annotations are available during model learning. it aims to localize objects described in the sentence to visual regions in the video, which is a fundamental capability needed in pattern analysis and machine learning. despite the recent progress, existing methods all suffer from the severe problem of spurious association, which will harm the grounding performance. in this paper, we start from the definition of wsvog and pinpoint the spurious association from two aspects: (1) the association itself is not object-relevant but extremely ambiguous due to weak supervision, and (2) the association is unavoidably confounded by the observational bias when taking the statistics-based matching strategy in existing methods. with this in mind, we design a unified causal framework to learn the deconfounded object-relevant association for more accurate and robust video object grounding. specifically, we learn the object-relevant association by causal intervention from the perspective of video data generation process. to overcome the problems of lacking fine-grained supervision in terms of intervention, we propose a novel spatial-temporal adversarial contrastive learning paradigm. to further remove the accompanying confounding effect within the object-relevant association, we pursue the true causality by conducting causal intervention via backdoor adjustment. finally, the deconfounded object-relevant association is learned and optimized under a unified causal framework in an end-to-end manner. extensive experiments on both iid and ood testing sets of three benchmarks demonstrate its accurate and robust grounding performance against state-of-the-arts. ","670":"the facebook network allows its users to record their reactions to text via a typology of emotions. this network, taken at scale, is therefore a prime data set of annotated sentiment data. this paper uses millions of such reactions, derived from a decade worth of facebook post data centred around a sri lankan context, to model an eye of the beholder approach to sentiment detection for online sinhala textual content. three different sentiment analysis models are built, taking into account a limited subset of reactions, all reactions, and another that derives a positive\/negative star rating value. the efficacy of these models in capturing the reactions of the observers are then computed and discussed. the analysis reveals that binary classification of reactions, for sinhala content, is significantly more accurate than the other approaches. furthermore, the inclusion of the like reaction hinders the capability of accurately predicting other reactions. ","671":"deep neural networks such as bert have made great progress in relation classification. although they can achieve good performance, it is still a question of concern whether these models recognize the directionality of relations, especially when they may lack interpretability. to explore the question, a novel evaluation task, called relation direction recognition (rdr), is proposed to explore whether models learn the directionality of relations. three metrics for rdr are introduced to measure the degree to which models recognize the directionality of relations. several state-of-the-art models are evaluated on rdr. experimental results on a real-world dataset indicate that there are clear gaps among them in recognizing the directionality of relations, even though these models obtain similar performance in the traditional metric (e.g. macro-f1). finally, some suggestions are discussed to enhance models to recognize the directionality of relations from the perspective of model design or training. ","672":"named entity recognition (ner) models generally perform poorly when large training datasets are unavailable for low-resource domains. recently, pre-training a large-scale language model has become a promising direction for coping with the data scarcity issue. however, the underlying discrepancies between the language modeling and ner task could limit the models' performance, and pre-training for the ner task has rarely been studied since the collected ner datasets are generally small or large but with low quality. in this paper, we construct a massive ner corpus with a relatively high quality, and we pre-train a ner-bert model based on the created dataset. experimental results show that our pre-trained model can significantly outperform bert as well as other strong baselines in low-resource scenarios across nine diverse domains. moreover, a visualization of entity representations further indicates the effectiveness of ner-bert for categorizing a variety of entities. ","673":"recently, vector-quantized image modeling has demonstrated impressive performance on generation tasks such as text-to-image generation. however, we discover that the current image quantizers do not satisfy translation equivariance in the quantized space due to aliasing, degrading performance in the downstream text-to-image generation and image-to-text generation, even in simple experimental setups. instead of focusing on anti-aliasing, we take a direct approach to encourage translation equivariance in the quantized space. in particular, we explore a desirable property of image quantizers, called 'translation equivariance in the quantized space' and propose a simple but effective way to achieve translation equivariance by regularizing orthogonality in the codebook embedding vectors. using this method, we improve accuracy by +22% in text-to-image generation and +26% in image-to-text generation, outperforming the vqgan. ","674":"in this paper, we propose an approach to quantitatively analyze impacts of different training label errors to rnn-t based asr models. the result shows deletion errors are more harmful than substitution and insertion label errors in rnn-t training data. we also examined label error impact mitigation approaches on rnn-t and found that, though all the methods mitigate the label-error-caused degradation to some extent, they could not remove the performance gap between the models trained with and without the presence of label errors. based on the analysis results, we suggest to design data pipelines for rnn-t with higher priority on reducing deletion label errors. we also find that ensuring high-quality training labels remains important, despite of the existence of the label error mitigation approaches. ","675":"the abductive natural language inference task ($\\alpha$nli) is proposed to infer the most plausible explanation between the cause and the event. in the $\\alpha$nli task, two observations are given, and the most plausible hypothesis is asked to pick out from the candidates. existing methods model the relation between each candidate hypothesis separately and penalize the inference network uniformly. in this paper, we argue that it is unnecessary to distinguish the reasoning abilities among correct hypotheses; and similarly, all wrong hypotheses contribute the same when explaining the reasons of the observations. therefore, we propose to group instead of ranking the hypotheses and design a structural loss called ``joint softmax focal loss'' in this paper. based on the observation that the hypotheses are generally semantically related, we have designed a novel interactive language model aiming at exploiting the rich interaction among competing hypotheses. we name this new model for $\\alpha$nli: interactive model with structural loss (imsl). the experimental results show that our imsl has achieved the highest performance on the roberta-large pretrained model, with acc and auc results increased by about 1\\% and 5\\% respectively. ","676":"while transfer learning has become a ubiquitous technique used across natural language processing (nlp) tasks, it is often unable to replicate the performance of pre-trained models on text of niche domains like automotive. in this paper we aim to understand the main characteristics of the distribution shift with automotive domain text (describing technical functionalities such as cruise control) and attempt to explain the potential reasons for the gap in performance. we focus on performing the named entity recognition (ner) task as it requires strong lexical, syntactic and semantic understanding by the model. our experiments with 2 different encoders, namely bert-base-uncased and scibert-base-scivocab-uncased have lead to interesting findings that showed: 1) the performance of scibert is better than bert when used for automotive domain, 2) fine-tuning the language models with automotive domain text did not make significant improvements to the ner performance, 3) the distribution shift is challenging as it is characterized by lack of repeating contexts, sparseness of entities, large number of out-of-vocabulary (oov) words and class overlap due to domain specific nuances. ","677":"temporal language grounding in videos aims to localize the temporal span relevant to the given query sentence. previous methods treat it either as a boundary regression task or a span extraction task. this paper will formulate temporal language grounding into video reading comprehension and propose a relation-aware network (ranet) to address it. this framework aims to select a video moment choice from the predefined answer set with the aid of coarse-and-fine choice-query interaction and choice-choice relation construction. a choice-query interactor is proposed to match the visual and textual information simultaneously in sentence-moment and token-moment levels, leading to a coarse-and-fine cross-modal interaction. moreover, a novel multi-choice relation constructor is introduced by leveraging graph convolution to capture the dependencies among video moment choices for the best choice selection. extensive experiments on activitynet-captions, tacos, and charades-sta demonstrate the effectiveness of our solution. codes have been available. ","678":"while attention is all you need may be proving true, we do not know why: attention-based transformer models such as bert are superior but how information flows from input tokens to output predictions are unclear. we introduce influence patterns, abstractions of sets of paths through a transformer model. patterns quantify and localize the flow of information to paths passing through a sequence of model nodes. experimentally, we find that significant portion of information flow in bert goes through skip connections instead of attention heads. we further show that consistency of patterns across instances is an indicator of bert's performance. finally, we demonstrate that patterns account for far more model performance than previous attention-based and layer-based methods. ","679":"it is difficult for humans to distinguish the true and false of rumors, but current deep learning models can surpass humans and achieve excellent accuracy on many rumor datasets. in this paper, we investigate whether deep learning models that seem to perform well actually learn to detect rumors. we evaluate models on their generalization ability to out-of-domain examples by fine-tuning bert-based models on five real-world datasets and evaluating against all test sets. the experimental results indicate that the generalization ability of the models on other unseen datasets are unsatisfactory, even common-sense rumors cannot be detected. moreover, we found through experiments that models take shortcuts and learn absurd knowledge when the rumor datasets have serious data pitfalls. this means that simple modifications to the rumor text based on specific rules will lead to inconsistent model predictions. to more realistically evaluate rumor detection models, we proposed a new evaluation method called paired test (pairt), which requires models to correctly predict a pair of test samples at the same time. furthermore, we make recommendations on how to better create rumor dataset and evaluate rumor detection model at the end of this paper. ","680":"we propose to deliberate the hypothesis alignment of a streaming rnn-t model with the previously proposed align-refine non-autoregressive decoding method and its improved versions. the method performs a few refinement steps, where each step shares a transformer decoder that attends to both text features (extracted from alignments) and audio features, and outputs complete updated alignments. the transformer decoder is trained with the ctc loss which facilitates parallel greedy decoding, and performs full-context attention to capture label dependencies. we improve align-refine by introducing cascaded encoder that captures more audio context before refinement, and alignment augmentation which enforces learning label dependency. we show that, conditioned on hypothesis alignments of a streaming rnn-t model, our method obtains significantly more accurate recognition results than the first-pass rnn-t, with only small amount of model parameters. ","681":"argument search aims at identifying arguments in natural language texts. in the past, this task has been addressed by a combination of keyword search and argument identification on the sentence- or document-level. however, existing frameworks often address only specific components of argument search and do not address the following aspects: (1) argument-query matching: identifying arguments that frame the topic slightly differently than the actual search query; (2) argument identification: identifying arguments that consist of multiple sentences; (3) argument clustering: selecting retrieved arguments by topical aspects. in this paper, we propose a framework for addressing these shortcomings. we suggest (1) to combine the keyword search with precomputed topic clusters for argument-query matching, (2) to apply a novel approach based on sentence-level sequence-labeling for argument identification, and (3) to present aggregated arguments to users based on topic-aware argument clustering. our experiments on several real-world debate data sets demonstrate that density-based clustering algorithms, such as hdbscan, are particularly suitable for argument-query matching. with our sentence-level, bilstm-based sequence-labeling approach we achieve a macro f1 score of 0.71. finally, evaluating our argument clustering method indicates that a fine-grained clustering of arguments by subtopics remains challenging but is worthwhile to be explored. ","682":"commonsense reasoning is one of the key problems in natural language processing, but the relative scarcity of labeled data holds back the progress for languages other than english. pretrained cross-lingual models are a source of powerful language-agnostic representations, yet their inherent reasoning capabilities are still actively studied. in this work, we design a simple approach to commonsense reasoning which trains a linear classifier with weights of multi-head attention as features. to evaluate this approach, we create a multilingual winograd schema corpus by processing several datasets from prior work within a standardized pipeline and measure cross-lingual generalization ability in terms of out-of-sample performance. the method performs competitively with recent supervised and unsupervised approaches for commonsense reasoning, even when applied to other languages in a zero-shot manner. also, we demonstrate that most of the performance is given by the same small subset of attention heads for all studied languages, which provides evidence of universal reasoning capabilities in multilingual encoders. ","683":"connecting vision and language plays an essential role in generative intelligence. for this reason, large research efforts have been devoted to image captioning, i.e. describing images with syntactically and semantically meaningful sentences. starting from 2015 the task has generally been addressed with pipelines composed of a visual encoder and a language model for text generation. during these years, both components have evolved considerably through the exploitation of object regions, attributes, the introduction of multi-modal connections, fully-attentive approaches, and bert-like early-fusion strategies. however, regardless of the impressive results, research in image captioning has not reached a conclusive answer yet. this work aims at providing a comprehensive overview of image captioning approaches, from visual encoding and text generation to training strategies, datasets, and evaluation metrics. in this respect, we quantitatively compare many relevant state-of-the-art approaches to identify the most impactful technical innovations in architectures and training strategies. moreover, many variants of the problem and its open challenges are discussed. the final goal of this work is to serve as a tool for understanding the existing literature and highlighting the future directions for a research area where computer vision and natural language processing can find an optimal synergy. ","684":"while neural language models often perform surprisingly well on natural language understanding (nlu) tasks, their strengths and limitations remain poorly understood. controlled synthetic tasks are thus an increasingly important resource for diagnosing model behavior. in this work we focus on story understanding, a core competency for nlu systems. however, the main synthetic resource for story understanding, the babi benchmark, lacks such a systematic mechanism for controllable task generation. we develop dyna-babi, a dynamic framework providing fine-grained control over task generation in babi. we demonstrate our ideas by constructing three new tasks requiring compositional generalization, an important evaluation setting absent from the original benchmark. we tested both special-purpose models developed for babi as well as state-of-the-art pre-trained methods, and found that while both approaches solve the original tasks (>99% accuracy), neither approach succeeded in the compositional generalization setting, indicating the limitations of the original training data. we explored ways to augment the original data, and found that though diversifying training data was far more useful than simply increasing dataset size, it was still insufficient for driving robust compositional generalization (with <70% accuracy for complex compositions). our results underscore the importance of highly controllable task generators for creating robust nlu systems through a virtuous cycle of model and data development. ","685":"commonsense knowledge (csk) about concepts and their properties is useful for ai applications. prior works like conceptnet, comet and others compiled large csk collections, but are restricted in their expressiveness to subject-predicate-object (spo) triples with simple concepts for s and strings for p and o. this paper presents a method, called ascent++, to automatically build a large-scale knowledge base (kb) of csk assertions, with refined expressiveness and both better precision and recall than prior works. ascent++ goes beyond spo triples by capturing composite concepts with subgroups and aspects, and by refining assertions with semantic facets. the latter is important to express the temporal and spatial validity of assertions and further qualifiers. ascent++ combines open information extraction with judicious cleaning and ranking by typicality and saliency scores. for high coverage, our method taps into the large-scale crawl c4 with broad web contents. the evaluation with human judgements shows the superior quality of the ascent++ kb, and an extrinsic evaluation for qa-support tasks underlines the benefits of ascent++. a web interface, data and code can be accessed at https:\/\/www.mpi-inf.mpg.de\/ascentpp. ","686":"research in the vision and language area encompasses challenging topics that seek to connect visual and textual information. when the visual information is related to videos, this takes us into video-text research, which includes several challenging tasks such as video question answering, video summarization with natural language, and video-to-text and text-to-video conversion. this paper reviews the video-to-text problem, in which the goal is to associate an input video with its textual description. this association can be mainly made by retrieving the most relevant descriptions from a corpus or generating a new one given a context video. these two ways represent essential tasks for computer vision and natural language processing communities, called text retrieval from video task and video captioning\/description task. these two tasks are substantially more complex than predicting or retrieving a single sentence from an image. the spatiotemporal information present in videos introduces diversity and complexity regarding the visual content and the structure of associated language descriptions. this review categorizes and describes the state-of-the-art techniques for the video-to-text problem. it covers the main video-to-text methods and the ways to evaluate their performance. we analyze twenty-six benchmark datasets, showing their drawbacks and strengths for the problem requirements. we also show the progress that researchers have made on each dataset, we cover the challenges in the field, and we discuss future research directions. ","687":"in this paper, we address reasoning tasks from open vocabulary knowledge bases (openkbs) using state-of-the-art neural language models (nlms) with applications in scientific literature. for this purpose, self-attention based nlms are trained using a common sense kb as a source task. the nlms are then tested on a target kb for open vocabulary reasoning tasks involving scientific knowledge related to the most prevalent chronic diseases (also known as non-communicable diseases, ncds). our results identified nlms that performed consistently and with significance in knowledge inference for both source and target tasks. furthermore, in our analysis by inspection we discussed the semantic regularities and reasoning capabilities learned by the models, while showing a first insight into the potential benefits of our approach to aid ncd research. ","688":"the covid-19 pandemic has affected societies and human health and well-being in various ways. in this study, we collected reddit data from 2019 (pre-pandemic) and 2020 (pandemic) from the subreddits communities associated with 8 universities, applied natural language processing (nlp) techniques, and trained graphical neural networks with social media data, to study how the pandemic has affected people's emotions and psychological states compared to the pre-pandemic era. specifically, we first applied a pre-trained robustly optimized bert pre-training approach (roberta) to learn embedding from the semantic information of reddit messages and trained a graph attention network (gat) for sentiment classification. the usage of gat allows us to leverage the relational information among the messages during training. we then applied subgroup-adaptive model stacking to combine the prediction probabilities from roberta and gat to yield the final classification on sentiment. with the manually labeled and model-predicted sentiment labels on the collected data, we applied a generalized linear mixed-effects model to estimate the effects of pandemic and online teaching on people's sentiment in a statistically significant manner. the results suggest the odds of negative sentiments in 2020 is $14.6\\%$ higher than the odds in 2019 ($p$-value $<0.001$), and the odds of negative sentiments are $41.6\\%$ higher with in-person teaching than with online teaching in 2020 ($p$-value $=0.037$) in the studied population. ","689":"social media posts contain potentially valuable information about medical conditions and health-related behavior. biocreative vii task 3 focuses on mining this information by recognizing mentions of medications and dietary supplements in tweets. we approach this task by fine tuning multiple bert-style language models to perform token-level classification, and combining them into ensembles to generate final predictions. our best system consists of five megatron-bert-345m models and achieves a strict f1 score of 0.764 on unseen test data. ","690":"the biocreative vii track-2 challenge consists of named entity recognition, entity-linking (or entity-normalization), and topic indexing tasks -- with entities and topics limited to chemicals for this challenge. named entity recognition is a well-established problem and we achieve our best performance with bert-based biomegatron models. we extend our bert-based approach to the entity linking task. after the second stage of pretraining biobert with a metric-learning loss strategy called self-alignment pretraining (sap), we link entities based on the cosine similarity between their sap-biobert word embeddings. despite the success of our named entity recognition experiments, we find the chemical indexing task generally more challenging.   in addition to conventional ner methods, we attempt both named entity recognition and entity linking with a novel text-to-text or \"prompt\" based method that uses generative language models such as t5 and gpt. we achieve encouraging results with this new approach. ","691":"in track-1 of the biocreative vii challenge participants are asked to identify interactions between drugs\/chemicals and proteins. in-context named entity annotations for each drug\/chemical and protein are provided and one of fourteen different interactions must be automatically predicted. for this relation extraction task, we attempt both a bert-based sentence classification approach, and a more novel text-to-text approach using a t5 model. we find that larger bert-based models perform better in general, with our biomegatron-based model achieving the highest scores across all metrics, achieving 0.74 f1 score. though our novel t5 text-to-text method did not perform as well as most of our bert-based models, it outperformed those trained on similar data, showing promising results, achieving 0.65 f1 score. we believe a text-to-text approach to relation extraction has some competitive advantages and there is a lot of room for research advancement. ","692":"cultural diversity encoded within languages of the world is at risk, as many languages have become endangered in the last decades in a context of growing globalization. to preserve this diversity, it is first necessary to understand what drives language extinction, and which mechanisms might enable coexistence. here, we study language shift mechanisms using theoretical and data-driven perspectives. a large-scale empirical analysis of multilingual societies using twitter and census data yields a wide diversity of spatial patterns of language coexistence. it ranges from a mixing of language speakers to segregation with multilinguals on the boundaries of disjoint linguistic domains. to understand how these different states can emerge and, especially, become stable, we propose a model in which language coexistence is reached when learning the other language is facilitated and when bilinguals favor the use of the endangered language. simulations carried out in a metapopulation framework highlight the importance of spatial interactions arising from people mobility to explain the stability of a mixed state or the presence of a boundary between two linguistic regions. further, we find that the history of languages is critical to understand their present state. ","693":"decision support systems based on clinical notes have the potential to improve patient care by pointing doctors towards overseen risks. predicting a patient's outcome is an essential part of such systems, for which the use of deep neural networks has shown promising results. however, the patterns learned by these networks are mostly opaque and previous work revealed flaws regarding the reproduction of unintended biases. we thus introduce an extendable testing framework that evaluates the behavior of clinical outcome models regarding changes of the input. the framework helps to understand learned patterns and their influence on model decisions. in this work, we apply it to analyse the change in behavior with regard to the patient characteristics gender, age and ethnicity. our evaluation of three current clinical nlp models demonstrates the concrete effects of these characteristics on the models' decisions. they show that model behavior varies drastically even when fine-tuned on the same data and that allegedly best-performing models have not always learned the most medically plausible patterns. ","694":"one of the key communicative competencies is the ability to maintain fluency in monologic speech and the ability to produce sophisticated language to argue a position convincingly. in this paper we aim to predict ted talk-style affective ratings in a crowdsourced dataset of argumentative speech consisting of 7 hours of speech from 110 individuals. the speech samples were elicited through task prompts relating to three debating topics. the samples received a total of 2211 ratings from 737 human raters pertaining to 14 affective categories. we present an effective approach to the classification task of predicting these categories through fine-tuning a model pre-trained on a large dataset of ted talks public speeches. we use a combination of fluency features derived from a state-of-the-art automatic speech recognition system and a large set of human-interpretable linguistic features obtained from an automatic text analysis system. classification accuracy was greater than 60% for all 14 rating categories, with a peak performance of 72% for the rating category 'informative'. in a secondary experiment, we determined the relative importance of features from different groups using sp-lime. ","695":"with growing amounts of available textual data, development of algorithms capable of automatic analysis, categorization and summarization of these data has become a necessity. in this research we present a novel algorithm for keyword identification, i.e., an extraction of one or multi-word phrases representing key aspects of a given document, called transformer-based neural tagger for keyword identification (tnt-kid). by adapting the transformer architecture for a specific task at hand and leveraging language model pretraining on a domain specific corpus, the model is capable of overcoming deficiencies of both supervised and unsupervised state-of-the-art approaches to keyword extraction by offering competitive and robust performance on a variety of different datasets while requiring only a fraction of manually labeled data required by the best performing systems. this study also offers thorough error analysis with valuable insights into the inner workings of the model and an ablation study measuring the influence of specific components of the keyword identification workflow on the overall performance. ","696":"the inception of modeling contextual information using models such as bert, elmo, and flair has significantly improved representation learning for words. it has also given sota results in almost every nlp task - machine translation, text summarization and named entity recognition, to name a few. in this work, in addition to using these dominant context-aware representations, we propose a knowledge aware representation learning (karl) network for named entity recognition (ner). we discuss the challenges of using existing methods in incorporating world knowledge for ner and show how our proposed methods could be leveraged to overcome those challenges. karl is based on a transformer encoder that utilizes large knowledge bases represented as fact triplets, converts them to a graph context, and extracts essential entity information residing inside to generate contextualized triplet representation for feature augmentation. experimental results show that the augmentation done using karl can considerably boost the performance of our ner system and achieve significantly better results than existing approaches in the literature on three publicly available ner datasets, namely conll 2003, conll++, and ontonotes v5. we also observe better generalization and application to a real-world setting from karl on unseen entities. ","697":"in this manuscript we present a detailed proof for undecidability of the equivalence of finite substitutions on regular language $b\\{0,1\\}^*c$. the proof is based on the works of leonid p. lisovik. ","698":"recent years of research in natural language processing (nlp) have witnessed dramatic growth in training large models for generating context-aware language representations. in this regard, numerous nlp systems have leveraged the power of neural network-based architectures to incorporate sense information in embeddings, resulting in contextualized word embeddings (cwes). despite this progress, the nlp community has not witnessed any significant work performing a comparative study on the contextualization power of such architectures. this paper presents a comparative study and an extensive analysis of nine widely adopted transformer models. these models are bert, ctrl, distilbert, openai-gpt, openai-gpt2, transformer-xl, xlnet, electra, and albert. we evaluate their contextualization power using two lexical sample word sense disambiguation (wsd) tasks, senseval-2 and senseval-3. we adopt a simple yet effective approach to wsd that uses a k-nearest neighbor (knn) classification on cwes. experimental results show that the proposed techniques also achieve superior results over the current state-of-the-art on both the wsd tasks ","699":"many downstream applications are using dependency trees, and are thus relying on dependency parsers producing correct, or at least consistent, output. however, dependency parsers are trained using machine learning, and are therefore susceptible to unwanted inconsistencies due to biases in the training data. this paper explores the effects of such biases in four languages - english, swedish, russian, and ukrainian - though an experiment where we study the effect of replacing numerals in sentences. we show that such seemingly insignificant changes in the input can cause large differences in the output, and suggest that data augmentation can remedy the problems. ","700":"we propose a new approach to explain bayesian networks. the approach revolves around a new definition of a probabilistic argument and the evidence it provides. we define a notion of independent arguments, and propose an algorithm to extract a list of relevant, independent arguments given a bayesian network, a target node and a set of observations. to demonstrate the relevance of the arguments, we show how we can use the extracted arguments to approximate message passing. finally, we show a simple scheme to explain the arguments in natural language. ","701":"magahi is an indo-aryan language, spoken mainly in the eastern parts of india. despite having a significant number of speakers, there has been virtually no language resource (lr) or language technology (lt) developed for the language, mainly because of its status as a non-scheduled language. the present paper describes an attempt to develop an annotated corpus of magahi. the data is mainly taken from a couple of blogs in magahi, some collection of stories in magahi and the recordings of conversation in magahi and it is annotated at the pos level using bis tagset. ","702":"through recent advancements in speech technologies and introduction of smart assistants, such as amazon alexa, apple siri and google home, increasing number of users are interacting with various applications through voice commands. e-commerce companies typically display short product titles on their webpages, either human-curated or algorithmically generated, when brevity is required. however, these titles are dissimilar from natural spoken language. for example, \"lucky charms gluten free break-fast cereal, 20.5 oz a box lucky charms gluten free\" is acceptable to display on a webpage, while a similar title cannot be used in a voice based text-to-speech application. in such conversational systems, an easy to comprehend sentence, such as \"a 20.5 ounce box of lucky charms gluten free cereal\" is preferred. compared to display devices, where images and detailed product information can be presented to users, short titles for products which convey the most important information, are necessary when interfacing with voice assistants. we propose ebert, a sequence-to-sequence approach by further pre-training the bert embeddings on an e-commerce product description corpus, and then fine-tuning the resulting model to generate short, natural, spoken language titles from input web titles. our extensive experiments on a real-world industry dataset, as well as human evaluation of model output, demonstrate that ebert summarization outperforms comparable baseline models. owing to the efficacy of the model, a version of this model has been deployed in real-world setting. ","703":"probabilistic topic models like latent dirichlet allocation (lda) have been previously extended to the bilingual setting. a fundamental modeling assumption in several of these extensions is that the input corpora are in the form of document pairs whose constituent documents share a single topic distribution. however, this assumption is strong for comparable corpora that consist of documents thematically similar to an extent only, which are, in turn, the most commonly available or easy to obtain. in this paper we relax this assumption by proposing for the paired documents to have separate, yet bound topic distributions. % a binding mechanism between the distributions of the paired documents. we suggest that the strength of the bound should depend on each pair's semantic similarity. to estimate the similarity of documents that are written in different languages we use cross-lingual word embeddings that are learned with shallow neural networks. we evaluate the proposed binding mechanism by extending two topic models: a bilingual adaptation of lda that assumes bag-of-words inputs and a model that incorporates part of the text structure in the form of boundaries of semantically coherent segments. to assess the performance of the novel topic models we conduct intrinsic and extrinsic experiments on five bilingual, comparable corpora of english documents with french, german, italian, spanish and portuguese documents. the results demonstrate the efficiency of our approach in terms of both topic coherence measured by the normalized point-wise mutual information, and generalization performance measured by perplexity and in terms of mean reciprocal rank in a cross-lingual document retrieval task for each of the language pairs. ","704":"this paper presents our contributions to the mediaeval 2021 task namely \"watermm: water quality in social multimedia\". the task aims at analyzing social media posts relevant to water quality with particular focus on the aspects like watercolor, smell, taste, and related illnesses. to this aim, a multimodal dataset containing both textual and visual information along with meta-data is provided. considering the quality and quantity of available content, we mainly focus on textual information by employing three different models individually and jointly in a late-fusion manner. these models include (i) bidirectional encoder representations from transformers (bert), (ii) robustly optimized bert pre-training approach (xlm-roberta), and a (iii) custom long short-term memory (lstm) model obtaining an overall f1-score of 0.794, 0.717, 0.663 on the official test set, respectively. in the fusion scheme, all the models are treated equally and no significant improvement is observed in the performance over the best performing individual model. ","705":"in this paper i present a classifier for automatic identification of linguistic politeness in hindi texts. i have used the manually annotated corpus of over 25,000 blog comments to train an svm. making use of the discursive and interactional approaches to politeness the paper gives an exposition of the normative, conventionalised politeness structures of hindi. it is seen that using these manually recognised structures as features in training the svm significantly improves the performance of the classifier on the test set. the trained system gives a significantly high accuracy of over 77% which is within 2% of human accuracy. ","706":"our computers today, from sophisticated servers to small smartphones, operate based on the same computing model, which requires running a sequence of discrete instructions, specified as an algorithm. this sequential computing paradigm has not yet led to a fast algorithm for an np-complete problem despite numerous attempts over the past half a century. unfortunately, even after the introduction of quantum mechanics to the world of computing, we still followed a similar sequential paradigm, which has not yet helped us obtain such an algorithm either. here a completely different model of computing is proposed to replace the sequential paradigm of algorithms with inherent parallelism of physical processes. using the proposed model, instead of writing algorithms to solve np-complete problems, we construct physical systems whose equilibrium states correspond to the desired solutions and let them evolve to search for the solutions. the main requirements of the model are identified and quantum circuits are proposed for its potential implementation. ","707":"in this paper, we explore machine translation improvement via generative adversarial network (gan) architecture. we take inspiration from relgan, a model for text generation, and nmt-gan, an adversarial machine translation model, to implement a model that learns to transform awkward, non-fluent english sentences to fluent ones, while only being trained on monolingual corpora. we utilize a parameter $\\lambda$ to control the amount of deviation from the input sentence, i.e. a trade-off between keeping the original tokens and modifying it to be more fluent. our results improved upon phrase-based machine translation in some cases. especially, gan with a transformer generator shows some promising results. we suggests some directions for future works to build upon this proof-of-concept. ","708":"english proficiency assessments have become a necessary metric for filtering and selecting prospective candidates for both academia and industry. with the rise in demand for such assessments, it has become increasingly necessary to have the automated human-interpretable results to prevent inconsistencies and ensure meaningful feedback to the second language learners. feature-based classical approaches have been more interpretable in understanding what the scoring model learns. therefore, in this work, we utilize classical machine learning models to formulate a speech scoring task as both a classification and a regression problem, followed by a thorough study to interpret and study the relation between the linguistic cues and the english proficiency level of the speaker. first, we extract linguist features under five categories (fluency, pronunciation, content, grammar and vocabulary, and acoustic) and train models to grade responses. in comparison, we find that the regression-based models perform equivalent to or better than the classification approach. second, we perform ablation studies to understand the impact of each of the feature and feature categories on the performance of proficiency grading. further, to understand individual feature contributions, we present the importance of top features on the best performing algorithm for the grading task. third, we make use of partial dependence plots and shapley values to explore feature importance and conclude that the best performing trained model learns the underlying rubrics used for grading the dataset used in this study. ","709":"multilingual models are parameter-efficient and especially effective in improving low-resource languages by leveraging crosslingual transfer. despite recent advance in massive multilingual translation with ever-growing model and data, how to effectively train multilingual models has not been well understood. in this paper, we show that a common situation in multilingual training, data imbalance among languages, poses optimization tension between high resource and low resource languages where the found multilingual solution is often sub-optimal for low resources. we show that common training method which upsamples low resources can not robustly optimize population loss with risks of either underfitting high resource languages or overfitting low resource ones. drawing on recent findings on the geometry of loss landscape and its effect on generalization, we propose a principled optimization algorithm, curvature aware task scaling (cats), which adaptively rescales gradients from different tasks with a meta objective of guiding multilingual training to low-curvature neighborhoods with uniformly low loss for all languages. we ran experiments on common benchmarks (ted, wmt and opus-100) with varying degrees of data imbalance. cats effectively improved multilingual optimization and as a result demonstrated consistent gains on low resources ($+0.8$ to $+2.2$ bleu) without hurting high resources. in addition, cats is robust to overparameterization and large batch size training, making it a promising training method for massive multilingual models that truly improve low resource languages. ","710":"with the development of internet technology, the phenomenon of information overload is becoming more and more obvious. it takes a lot of time for users to obtain the information they need. however, keyphrases that summarize document information highly are helpful for users to quickly obtain and understand documents. for academic resources, most existing studies extract keyphrases through the title and abstract of papers. we find that title information in references also contains author-assigned keyphrases. therefore, this article uses reference information and applies two typical methods of unsupervised extraction methods (tf*idf and textrank), two representative traditional supervised learning algorithms (na\\\"ive bayes and conditional random field) and a supervised deep learning model (bilstm-crf), to analyze the specific performance of reference information on keyphrase extraction. it is expected to improve the quality of keyphrase recognition from the perspective of expanding the source text. the experimental results show that reference information can increase precision, recall, and f1 of automatic keyphrase extraction to a certain extent. this indicates the usefulness of reference information on keyphrase extraction of academic papers and provides a new idea for the following research on automatic keyphrase extraction. ","711":"prior work on sentiment analysis using weak supervision primarily focuses on different reviews such as movies (imdb), restaurants (yelp), products (amazon).~one under-explored field in this regard is customer chat data for a customer-agent chat in customer support due to the lack of availability of free public data. here, we perform sentiment analysis on customer chat using weak supervision on our in-house dataset. we fine-tune the pre-trained language model (lm) roberta as a sentiment classifier using weak supervision. our contribution is as follows:1) we show that by using weak sentiment classifiers along with domain-specific lexicon-based rules as labeling functions (lf), we can train a fairly accurate customer chat sentiment classifier using weak supervision. 2) we compare the performance of our custom-trained model with off-the-shelf google cloud nlp api for sentiment analysis. we show that by injecting domain-specific knowledge using lfs, even with weak supervision, we can train a model to handle some domain-specific use cases better than off-the-shelf google cloud nlp api. 3) we also present an analysis of how customer sentiment in a chat relates to problem resolution. ","712":"personalizing dialogue agents is important for dialogue systems to generate more specific, consistent, and engaging responses. however, most current dialogue personalization approaches rely on explicit persona descriptions during inference, which severely restricts its application. in this paper, we propose a novel approach that learns to predict persona information based on the dialogue history to personalize the dialogue agent without relying on any explicit persona descriptions during inference. experimental results on the personachat dataset show that the proposed method can improve the consistency of generated responses when conditioning on the predicted profile of the dialogue agent (i.e. \"self persona\"), and improve the engagingness of the generated responses when conditioning on the predicted persona of the dialogue partner (i.e. \"their persona\"). we also find that a trained persona prediction model can be successfully transferred to other datasets and help generate more relevant responses. ","713":"transitioning between topics is a natural component of human-human dialog. although topic transition has been studied in dialogue for decades, only a handful of corpora based studies have been performed to investigate the subtleties of topic transitions. thus, this study annotates 215 conversations from the switchboard corpus and investigates how variables such as length, number of topic transitions, topic transitions share by participants and turns\/topic are related. this work presents an empirical study on topic transition in switchboard corpus followed by modelling topic transition with a precision of 83% for in-domain(id) test set and 82% on 10 out-of-domain}(ood) test set. it is envisioned that this work will help in emulating human-human like topic transition in open-domain dialog systems. ","714":"conversational bilingual speech encompasses three types of utterances: two purely monolingual types and one intra-sententially code-switched type. in this work, we propose a general framework to jointly model the likelihoods of the monolingual and code-switch sub-tasks that comprise bilingual speech recognition. by defining the monolingual sub-tasks with label-to-frame synchronization, our joint modeling framework can be conditionally factorized such that the final bilingual output, which may or may not be code-switched, is obtained given only monolingual information. we show that this conditionally factorized joint framework can be modeled by an end-to-end differentiable neural network. we demonstrate the efficacy of our proposed model on bilingual mandarin-english speech recognition across both monolingual and code-switched corpora. ","715":"structuring medical data in france remains a challenge mainly because of the lack of medical data due to privacy concerns and the lack of methods and approaches on processing the french language. one of these challenges is structuring drug-related information in french clinical documents. to our knowledge, over the last decade, there are less than five relevant papers that study french prescriptions. this paper proposes a new approach for extracting drug-related information from french clinical scanned documents while preserving patients' privacy. in addition, we deployed our method in a health data management platform where it is used to structure drug medical data and help patients organize their drug schedules. it can be implemented on any web or mobile platform. this work closes the gap between theoretical and practical work by creating an application adapted to real production problems. it is a combination of a rule-based phase and a deep learning approach. finally, numerical results show the outperformance and relevance of the proposed methodology. ","716":"the increasing popularity of the web has subsequently increased the abundance of reviews on products and services. mining these reviews for expressed sentiment is beneficial for both companies and consumers, as quality can be improved based on this information. in this paper, we consider the state-of-the-art haabsa++ algorithm for aspect-based sentiment analysis tasked with identifying the sentiment expressed towards a given aspect in review sentences. specifically, we train the neural network part of this algorithm using an adversarial network, a novel machine learning training method where a generator network tries to fool the classifier network by generating highly realistic new samples, as such increasing robustness. this method, as of yet never in its classical form applied to aspect-based sentiment analysis, is found to be able to considerably improve the out-of-sample accuracy of haabsa++: for the semeval 2015 dataset, accuracy was increased from 81.7% to 82.5%, and for the semeval 2016 task, accuracy increased from 84.4% to 87.3%. ","717":"initial fault detection and diagnostics are imperative measures to improve the efficiency, safety, and stability of vehicle operation. in recent years, numerous studies have investigated data-driven approaches to improve the vehicle diagnostics process using available vehicle data. moreover, data-driven methods are employed to enhance customer-service agent interactions. in this study, we demonstrate a machine learning pipeline to improve automated vehicle diagnostics. first, natural language processing (nlp) is used to automate the extraction of crucial information from free-text failure reports (generated during customers' calls to the service department). then, deep learning algorithms are employed to validate service requests and filter vague or misleading claims. ultimately, different classification algorithms are implemented to classify service requests so that valid service requests can be directed to the relevant service department. the proposed model- bidirectional long short term memory (bilstm) along with convolution neural network (cnn)- shows more than 18\\% accuracy improvement in validating service requests compared to technicians' capabilities. in addition, using domain-based nlp techniques at preprocessing and feature extraction stages along with cnn-bilstm based request validation enhanced the accuracy ($>25\\%$), sensitivity ($>39\\%$), specificity ($>11\\%$), and precision ($>11\\%$) of gradient tree boosting (gtb) service classification model. the receiver operating characteristic area under the curve (roc-auc) reached 0.82. ","718":"detecting customized moments and highlights from videos given natural language (nl) user queries is an important but under-studied topic. one of the challenges in pursuing this direction is the lack of annotated data. to address this issue, we present the query-based video highlights (qvhighlights) dataset. it consists of over 10,000 youtube videos, covering a wide range of topics, from everyday activities and travel in lifestyle vlog videos to social and political activities in news videos. each video in the dataset is annotated with: (1) a human-written free-form nl query, (2) relevant moments in the video w.r.t. the query, and (3) five-point scale saliency scores for all query-relevant clips. this comprehensive annotation enables us to develop and evaluate systems that detect relevant moments as well as salient highlights for diverse, flexible user queries. we also present a strong baseline for this task, moment-detr, a transformer encoder-decoder model that views moment retrieval as a direct set prediction problem, taking extracted video and query representations as inputs and predicting moment coordinates and saliency scores end-to-end. while our model does not utilize any human prior, we show that it performs competitively when compared to well-engineered architectures. with weakly supervised pretraining using asr captions, momentdetr substantially outperforms previous methods. lastly, we present several ablations and visualizations of moment-detr. data and code is publicly available at https:\/\/github.com\/jayleicn\/moment_detr ","719":"despite machine learning models' success in natural language processing (nlp) tasks, predictions from these models frequently fail on out-of-distribution (ood) samples. prior works have focused on developing state-of-the-art methods for detecting ood. the fundamental question of how ood samples differ from in-distribution samples remains unanswered. this paper explores how data dynamics in training models can be used to understand the fundamental differences between ood and in-distribution samples in extensive detail. we found that syntactic characteristics of the data samples that the model consistently predicts incorrectly in both ood and in-distribution cases directly contradict each other. in addition, we observed preliminary evidence supporting the hypothesis that models are more likely to latch on trivial syntactic heuristics (e.g., overlap of words between two sentences) when making predictions on ood samples. we hope our preliminary study accelerates the data-centric analysis on various machine learning phenomena. ","720":"changepoint analysis deals with unsupervised detection and\/or estimation of time-points in time-series data, when the distribution generating the data changes. in this article, we consider \\emph{offline} changepoint detection in the context of large scale textual data. we build a specialised temporal topic model with provisions for changepoints in the distribution of topic proportions. as full likelihood based inference in this model is computationally intractable, we develop a computationally tractable approximate inference procedure. more specifically, we use sample splitting to estimate topic polytopes first and then apply a likelihood ratio statistic together with a modified version of the wild binary segmentation algorithm of fryzlewicz et al. (2014). our methodology facilitates automated detection of structural changes in large corpora without the need of manual processing by domain experts. as changepoints under our model correspond to changes in topic structure, the estimated changepoints are often highly interpretable as marking the surge or decline in popularity of a fashionable topic. we apply our procedure on two large datasets: (i) a corpus of english literature from the period 1800-1922 (underwoodet al., 2015); (ii) abstracts from the high energy physics arxiv repository (clementet al., 2019). we obtain some historically well-known changepoints and discover some new ones. ","721":"excessive sleepiness in attention-critical contexts can lead to adverse events, such as car crashes. detecting and monitoring sleepiness can help prevent these adverse events from happening. in this paper, we use the voiceome dataset to extract speech from 1,828 participants to develop a deep transfer learning model using hidden-unit bert (hubert) speech representations to detect sleepiness from individuals. speech is an under-utilized source of data in sleep detection, but as speech collection is easy, cost-effective, and non-invasive, it provides a promising resource for sleepiness detection. two complementary techniques were conducted in order to seek converging evidence regarding the importance of individual speech tasks. our first technique, masking, evaluated task importance by combining all speech tasks, masking selected responses in the speech, and observing systematic changes in model accuracy. our second technique, separate training, compared the accuracy of multiple models, each of which used the same architecture, but was trained on a different subset of speech tasks. our evaluation shows that the best-performing model utilizes the memory recall task and categorical naming task from the boston naming test, which achieved an accuracy of 80.07% (f1-score of 0.85) and 81.13% (f1-score of 0.89), respectively. ","722":"we conduct an empirical study of neural machine translation (nmt) for truly low-resource languages, and propose a training curriculum fit for cases when both parallel training data and compute resource are lacking, reflecting the reality of most of the world's languages and the researchers working on these languages. previously, unsupervised nmt, which employs back-translation (bt) and auto-encoding (ae) tasks has been shown barren for low-resource languages. we demonstrate that leveraging comparable data and code-switching as weak supervision, combined with bt and ae objectives, result in remarkable improvements for low-resource languages even when using only modest compute resources. the training curriculum proposed in this work achieves bleu scores that improve over supervised nmt trained on the same backbone architecture by +12.2 bleu for english to gujarati and +3.7 bleu for english to kazakh, showcasing the potential of weakly-supervised nmt for the low-resource languages. when trained on supervised data, our training curriculum achieves a new state-of-the-art result on the somali dataset (bleu of 29.3 for somali to english). we also observe that adding more time and gpus to training can further improve performance, which underscores the importance of reporting compute resource usage in mt research. ","723":"the translation of natural language questions to sql queries has attracted growing attention, in particular in connection with transformers and similar language models. a large number of techniques are geared towards the english language; in this work, we thus investigated translation to sql when input questions are given in the portuguese language. to do so, we properly adapted state-of-the-art tools and resources. we changed the rat-sql+gap system by relying on a multilingual bart model (we report tests with other language models), and we produced a translated version of the spider dataset. our experiments expose interesting phenomena that arise when non-english languages are targeted; in particular, it is better to train with original and translated training datasets together, even if a single target language is desired. this multilingual bart model fine-tuned with a double-size training dataset (english and portuguese) achieved 83% of the baseline, making inferences for the portuguese test dataset. this investigation can help other researchers to produce results in machine learning in a language different from english. our multilingual ready version of rat-sql+gap and the data are available, open-sourced as mrat-sql+gap at: https:\/\/github.com\/c4ai\/gap-text2sql ","724":"spoken language understanding (slu) tasks are usually solved by first transcribing an utterance with automatic speech recognition (asr) and then feeding the output to a text-based model. recent advances in self-supervised representation learning for speech data have focused on improving the asr component. we investigate whether representation learning for speech has matured enough to replace asr in slu. we compare learned speech features from wav2vec 2.0, state-of-the-art asr transcripts, and the ground truth text as input for a novel speech-based named entity recognition task, a cardiac arrest detection task on real-world emergency calls and two existing slu benchmarks. we show that learned speech features are superior to asr transcripts on three classification tasks. for machine translation, asr transcripts are still the better choice. we highlight the intrinsic robustness of wav2vec 2.0 representations to out-of-vocabulary words as key to better performance. ","725":"with the development of deep learning (dl), natural language processing (nlp) makes it possible for us to analyze and understand a large amount of language texts. accordingly, we can achieve a semantic communication in terms of joint semantic source and channel coding over a noisy channel with the help of nlp. however, the existing method to realize this goal is to use a fixed transformer of nlp while ignoring the difference of semantic information contained in each sentence. to solve this problem, we propose a new semantic communication system based on universal transformer. compared with the traditional transformer, an adaptive circulation mechanism is introduced in the universal transformer. through the introduction of the circulation mechanism, the new semantic communication system can be more flexible to transmit sentences with different semantic information, and achieve better end-to-end performance under various channel conditions. ","726":"state-of-the-art language models (lms) represented by long-short term memory recurrent neural networks (lstm-rnns) and transformers are becoming increasingly complex and expensive for practical applications. low-bit neural network quantization provides a powerful solution to dramatically reduce their model size. current quantization methods are based on uniform precision and fail to account for the varying performance sensitivity at different parts of lms to quantization errors. to this end, novel mixed precision neural network lm quantization methods are proposed in this paper. the optimal local precision choices for lstm-rnn and transformer based neural lms are automatically learned using three techniques. the first two approaches are based on quantization sensitivity metrics in the form of either the kl-divergence measured between full precision and quantized lms, or hessian trace weighted quantization perturbation that can be approximated efficiently using matrix free techniques. the third approach is based on mixed precision neural architecture search. in order to overcome the difficulty in using gradient descent methods to directly estimate discrete quantized weights, alternating direction methods of multipliers (admm) are used to efficiently train quantized lms. experiments were conducted on state-of-the-art lf-mmi cnn-tdnn systems featuring speed perturbation, i-vector and learning hidden unit contribution (lhuc) based speaker adaptation on two tasks: switchboard telephone speech and ami meeting transcription. the proposed mixed precision quantization techniques achieved \"lossless\" quantization on both tasks, by producing model size compression ratios of up to approximately 16 times over the full precision lstm and transformer baseline lms, while incurring no statistically significant word error rate increase. ","727":"we present an empirical study on embedding the lyrics of a song into a fixed-dimensional feature for the purpose of music tagging. five methods of computing token-level and four methods of computing document-level representations are trained on an industrial-scale dataset of tens of millions of songs. we compare simple averaging of pretrained embeddings to modern recurrent and attention-based neural architectures. evaluating on a wide range of tagging tasks such as genre classification, explicit content identification and era detection, we find that averaging word embeddings outperform more complex architectures in many downstream metrics. ","728":"conversation question answering requires the ability to interpret a question correctly. current models, however, are still unsatisfactory due to the difficulty of understanding the co-references and ellipsis in daily conversation. even though generative approaches achieved remarkable progress, they are still trapped by semantic incompleteness. this paper presents an action-based approach to recover the complete expression of the question. specifically, we first locate the positions of co-reference or ellipsis in the question while assigning the corresponding action to each candidate span. we then look for matching phrases related to the candidate clues in the conversation context. finally, according to the predicted action, we decide whether to replace the co-reference or supplement the ellipsis with the matched information. we demonstrate the effectiveness of our method on both english and chinese utterance rewrite tasks, improving the state-of-the-art em (exact match) by 3.9\\% and rouge-l by 1.0\\% respectively on the restoration-200k dataset. ","729":"state-of-the-art neural language models represented by transformers are becoming increasingly complex and expensive for practical applications. low-bit deep neural network quantization techniques provides a powerful solution to dramatically reduce their model size. current low-bit quantization methods are based on uniform precision and fail to account for the varying performance sensitivity at different parts of the system to quantization errors. to this end, novel mixed precision dnn quantization methods are proposed in this paper. the optimal local precision settings are automatically learned using two techniques. the first is based on a quantization sensitivity metric in the form of hessian trace weighted quantization perturbation. the second is based on mixed precision transformer architecture search. alternating direction methods of multipliers (admm) are used to efficiently train mixed precision quantized dnn systems. experiments conducted on penn treebank (ptb) and a switchboard corpus trained lf-mmi tdnn system suggest the proposed mixed precision transformer quantization techniques achieved model size compression ratios of up to 16 times over the full precision baseline with no recognition performance degradation. when being used to compress a larger full precision transformer lm with more layers, overall word error rate (wer) reductions up to 1.7% absolute (18% relative) were obtained. ","730":"contrastive learning has emerged as a powerful representation learning method and facilitates various downstream tasks especially when supervised data is limited. how to construct efficient contrastive samples through data augmentation is key to its success. unlike vision tasks, the data augmentation method for contrastive learning has not been investigated sufficiently in language tasks. in this paper, we propose a novel approach to construct contrastive samples for language tasks using text summarization. we use these samples for supervised contrastive learning to gain better text representations which greatly benefit text classification tasks with limited annotations. to further improve the method, we mix up samples from different classes and add an extra regularization, named mixsum, in addition to the cross-entropy-loss. experiments on real-world text classification datasets (amazon-5, yelp-5, ag news, and imdb) demonstrate the effectiveness of the proposed contrastive learning framework with summarization-based data augmentation and mixsum regularization. ","731":"with 4.5 million hours of english speech from 10 different sources across 120 countries and models of up to 10 billion parameters, we explore the frontiers of scale for automatic speech recognition. we propose data selection techniques to efficiently scale training data to find the most valuable samples in massive datasets. to efficiently scale model sizes, we leverage various optimizations such as sparse transducer loss and model sharding. by training 1-10b parameter universal english asr models, we push the limits of speech recognition performance across many domains. furthermore, our models learn powerful speech representations with zero and few-shot capabilities on novel domains and styles of speech, exceeding previous results across multiple in-house and public benchmarks. for speakers with disorders due to brain damage, our best zero-shot and few-shot models achieve 22% and 60% relative improvement on the aphasiabank test set, respectively, while realizing the best performance on public social media videos. furthermore, the same universal model reaches equivalent performance with 500x less in-domain data on the spgispeech financial-domain dataset. ","732":"in this work, we propose a new and general framework to defend against backdoor attacks, inspired by the fact that attack triggers usually follow a \\textsc{specific} type of attacking pattern, and therefore, poisoned training examples have greater impacts on each other during training. we introduce the notion of the {\\it influence graph}, which consists of nodes and edges respectively representative of individual training points and associated pair-wise influences. the influence between a pair of training points represents the impact of removing one training point on the prediction of another, approximated by the influence function \\citep{koh2017understanding}. malicious training points are extracted by finding the maximum average sub-graph subject to a particular size. extensive experiments on computer vision and natural language processing tasks demonstrate the effectiveness and generality of the proposed framework. ","733":"deep learning has recently made remarkable progress in natural language processing. yet, the resulting algorithms remain far from competing with the language abilities of the human brain. predictive coding theory offers a potential explanation to this discrepancy: while deep language algorithms are optimized to predict adjacent words, the human brain would be tuned to make long-range and hierarchical predictions. to test this hypothesis, we analyze the fmri brain signals of 304 subjects each listening to 70min of short stories. after confirming that the activations of deep language algorithms linearly map onto those of the brain, we show that enhancing these models with long-range forecast representations improves their brain-mapping. the results further reveal a hierarchy of predictions in the brain, whereby the fronto-parietal cortices forecast more abstract and more distant representations than the temporal cortices. overall, this study strengthens predictive coding theory and suggests a critical role of long-range and hierarchical predictions in natural language processing. ","734":"natural language provides an accessible and expressive interface to specify long-term tasks for robotic agents. however, non-experts are likely to specify such tasks with high-level instructions, which abstract over specific robot actions through several layers of abstraction. we propose that key to bridging this gap between language and robot actions over long execution horizons are persistent representations. we propose a persistent spatial semantic representation method, and show how it enables building an agent that performs hierarchical reasoning to effectively execute long-term tasks. we evaluate our approach on the alfred benchmark and achieve state-of-the-art results, despite completely avoiding the commonly used step-by-step instructions. ","735":"the fourth industrial revolution is rapidly changing the manufacturing landscape. due to the growing research and fast evolution in this field, no clear definitions of these concepts yet exist. this work provides a clear description of technological trends and gaps. we introduce a novel method to create a map of industry 4.0 technologies, using natural language processing to extract technology terms from 14,667 research articles and applying network analysis. we identified eight clusters of industry 4.0 technologies, which served as the basis for our analysis. our results show that industrial internet of things (iiot) technologies have become the center of the industry 4.0 technology map. this is in line with the initial definitions of industry 4.0, which centered on iiot. given the recent growth in the importance of artificial intelligence (ai), we suggest accounting for ai's fundamental role in industry 4.0 and understanding the fourth industrial revolution as an ai-powered natural collaboration between humans and machines. this article introduces a novel approach for literature reviews, and the results highlight trends and research gaps to guide future work and help these actors reap the benefits of digital transformations. ","736":"spoken language understanding has been addressed as a supervised learning problem, where a set of training data is available for each domain. however, annotating data for each domain is both financially costly and non-scalable so we should fully utilize information across all domains. one existing approach solves the problem by conducting multi-domain learning, using shared parameters for joint training across domains. we propose to improve the parameterization of this method by using domain-specific and task-specific model parameters to improve knowledge learning and transfer. experiments on 5 domains show that our model is more effective for multi-domain slu and obtain the best results. in addition, we show its transferability by outperforming the prior best model by 12.4\\% when adapting to a new domain with little data. ","737":"mobile devices are transforming the way people interact with computers, and speech interfaces to applications are ever more important. automatic speech recognition systems recently published are very accurate, but often require powerful machinery (specialised graphical processing units) for inference, which makes them impractical to run on commodity devices, especially in streaming mode. impressed by the accuracy of, but dissatisfied with the inference times of the baseline kazakh asr model of (khassanov et al.,2021) when not using a gpu, we trained a new baseline acoustic model (on the same dataset as the aforementioned paper) and three language models for use with the coqui stt framework. results look promising, but further epochs of training and parameter sweeping or, alternatively, limiting the vocabulary that the asr system must support, is needed to reach a production-level accuracy. ","738":"this work combines information about the dialogue history encoded by pre-trained model with a meaning representation of the current system utterance to realize contextual language generation in task-oriented dialogues. we utilize the pre-trained multi-context convert model for context representation in a model trained from scratch; and leverage the immediate preceding user utterance for context generation in a model adapted from the pre-trained gpt-2. both experiments with the multiwoz dataset show that contextual information encoded by pre-trained model improves the performance of response generation both in automatic metrics and human evaluation. our presented contextual generator enables higher variety of generated responses that fit better to the ongoing dialogue. analysing the context size shows that longer context does not automatically lead to better performance, but the immediate preceding user utterance plays an essential role for contextual generation. in addition, we also propose a re-ranker for the gpt-based generation model. the experiments show that the response selected by the re-ranker has a significant improvement on automatic metrics. ","739":"gpt-3 shows remarkable in-context learning ability of large-scale language models (lms) trained on hundreds of billion scale data. here we address some remaining issues less reported by the gpt-3 paper, such as a non-english lm, the performances of different sized models, and the effect of recently introduced prompt optimization on in-context learning. to achieve this, we introduce hyperclova, a korean variant of 82b gpt-3 trained on a korean-centric corpus of 560b tokens. enhanced by our korean-specific tokenization, hyperclova with our training configuration shows state-of-the-art in-context zero-shot and few-shot learning performances on various downstream tasks in korean. also, we show the performance benefits of prompt-based learning and demonstrate how it can be integrated into the prompt engineering pipeline. then we discuss the possibility of materializing the no code ai paradigm by providing ai prototyping capabilities to non-experts of ml by introducing hyperclova studio, an interactive prompt engineering interface. lastly, we demonstrate the potential of our methods with three successful in-house applications. ","740":"cross-domain sentiment classification has been a hot spot these years, which aims to learn a reliable classifier using labeled data from the source domain and evaluate it on the target domain. in this vein, most approaches utilized domain adaptation that maps data from different domains into a common feature space. to further improve the model performance, several methods targeted to mine domain-specific information were proposed. however, most of them only utilized a limited part of domain-specific information. in this study, we first develop a method of extracting domain-specific words based on the topic information. then, we propose a topic driven adaptive network (tdan) for cross-domain sentiment classification. the network consists of two sub-networks: semantics attention network and domain-specific word attention network, the structures of which are based on transformers. these sub-networks take different forms of input and their outputs are fused as the feature vector. experiments validate the effectiveness of our tdan on sentiment classification across domains. ","741":"medical conversation summarization is integral in capturing information gathered during interactions between patients and physicians. summarized conversations are used to facilitate patient hand-offs between physicians, and as part of providing care in the future. summaries, however, can be time-consuming to produce and require domain expertise. modern pre-trained nlp models such as pegasus have emerged as capable alternatives to human summarization, reaching state-of-the-art performance on many summarization benchmarks. however, many downstream tasks still require at least moderately sized datasets to achieve satisfactory performance. in this work we (1) explore the effect of dataset size on transfer learning medical conversation summarization using pegasus and (2) evaluate various iterative labeling strategies in the low-data regime, following their success in the classification setting. we find that model performance saturates with increase in dataset size and that the various active-learning strategies evaluated all show equivalent performance consistent with simple dataset size increase. we also find that naive iterative pseudo-labeling is on-par or slightly worse than no pseudo-labeling. our work sheds light on the successes and challenges of translating low-data regime techniques in classification to medical conversation summarization and helps guides future work in this space. relevant code available at \\url{https:\/\/github.com\/curai\/curai-research\/tree\/main\/medical-summarization-ml4h-2021}. ","742":"in this paper, we introduce a collaborative and modern annotation tool for audio and speech: audino. the tool allows annotators to define and describe temporal segmentation in audios. these segments can be labelled and transcribed easily using a dynamically generated form. an admin can centrally control user roles and project assignment through the admin dashboard. the dashboard also enables describing labels and their values. the annotations can easily be exported in json format for further analysis. the tool allows audio data and their corresponding annotations to be uploaded and assigned to a user through a key-based api. the flexibility available in the annotation tool enables annotation for speech scoring, voice activity detection (vad), speaker diarisation, speaker identification, speech recognition, emotion recognition tasks and more. the mit open source license allows it to be used for academic and commercial projects. ","743":"technologies for enhancing well-being, healthcare vigilance and monitoring are on the rise. however, despite patient interest, such technologies suffer from low adoption. one hypothesis for this limited adoption is loss of human interaction that is central to doctor-patient encounters. in this paper we seek to address this limitation via a conversational agent that adopts one aspect of in-person doctor-patient interactions: a human avatar to facilitate medical grounded question answering. this is akin to the in-person scenario where the doctor may point to the human body or the patient may point to their own body to express their conditions. additionally, our agent has multiple interaction modes, that may give more options for the patient to use the agent, not just for medical question answering, but also to engage in conversations about general topics and current events. both the avatar, and the multiple interaction modes could help improve adherence.   we present a high level overview of the design of our agent, marie bot wellbeing. we also report implementation details of our early prototype , and present preliminary results. ","744":"in this study, we propose a novel multi-modal end-to-end neural approach for automated assessment of non-native english speakers' spontaneous speech using attention fusion. the pipeline employs bi-directional recurrent convolutional neural networks and bi-directional long short-term memory neural networks to encode acoustic and lexical cues from spectrograms and transcriptions, respectively. attention fusion is performed on these learned predictive features to learn complex interactions between different modalities before final scoring. we compare our model with strong baselines and find combined attention to both lexical and acoustic cues significantly improves the overall performance of the system. further, we present a qualitative and quantitative analysis of our model. ","745":"in problem solving, understanding the problem that one seeks to solve is an essential initial step. in this paper, we propose computational methods for facilitating problem understanding through the task of recognizing the unknown in specifications of long math problems. we focus on the topic of probability. our experimental results show that learning models yield strong results on the task, a promising first step towards human interpretable, modular approaches to understanding long math problems. ","746":"we develop a system that formally represents spatial semantics concepts within natural language descriptions of spatial arrangements. the system builds on a model of spatial semantics representation according to which words in a sentence are assigned spatial roles and the relations among these roles are represented with spatial relations. we combine our system with the shape grammar formalism that uses shape rules to generate languages (sets) of two-dimensional shapes. our proposed system consists of pairs of shape rules and verbal rules where the verbal rules describe in english the action of the associated shape rule. we present various types of natural language descriptions of shapes that are successfully parsed by our system and we discuss open questions and challenges we see at the interface of language and perception. ","747":"the ability to reason with multiple hierarchical structures is an attractive and desirable property of sequential inductive biases for natural language processing. do the state-of-the-art transformers and lstm architectures implicitly encode for these biases? to answer this, we propose orchard, a diagnostic dataset for systematically evaluating hierarchical reasoning in state-of-the-art neural sequence models. while there have been prior evaluation frameworks such as listops or logical inference, our work presents a novel and more natural setting where our models learn to reason with multiple explicit hierarchical structures instead of only one, i.e., requiring the ability to do both long-term sequence memorizing, relational reasoning while reasoning with hierarchical structure. consequently, backed by a set of rigorous experiments, we show that (1) transformer and lstm models surprisingly fail in systematic generalization, and (2) with increased references between hierarchies, transformer performs no better than random. ","748":"inducing latent tree structures from sequential data is an emerging trend in the nlp research landscape today, largely popularized by recent methods such as gumbel lstm and ordered neurons (on-lstm). this paper proposes fasttrees, a new general purpose neural module for fast sequence encoding. unlike most previous works that consider recurrence to be necessary for tree induction, our work explores the notion of parallel tree induction, i.e., imbuing our model with hierarchical inductive biases in a parallelizable, non-autoregressive fashion. to this end, our proposed fasttrees achieves competitive or superior performance to on-lstm on four well-established sequence modeling tasks, i.e., language modeling, logical inference, sentiment analysis and natural language inference. moreover, we show that the fasttrees module can be applied to enhance transformer models, achieving performance gains on three sequence transduction tasks (machine translation, subject-verb agreement and mathematical language understanding), paving the way for modular tree induction modules. overall, we outperform existing state-of-the-art models on logical inference tasks by +4% and mathematical language understanding by +8%. ","749":"language models trained on large-scale unfiltered datasets curated from the open web acquire systemic biases, prejudices, and harmful views from their training data. we present a methodology for programmatically identifying and removing harmful text from web-scale datasets. a pretrained language model is used to calculate the log-likelihood of researcher-written trigger phrases conditioned on a specific document, which is used to identify and filter documents from the dataset. we demonstrate that models trained on this filtered dataset exhibit lower propensity to generate harmful text, with a marginal decrease in performance on standard language modeling benchmarks compared to unfiltered baselines. we provide a partial explanation for this performance gap by surfacing examples of hate speech and other undesirable content from standard language modeling benchmarks. finally, we discuss the generalization of this method and how trigger phrases which reflect specific values can be used by researchers to build language models which are more closely aligned with their values. ","750":"automatic question answering is an important yet challenging task in e-commerce given the millions of questions posted by users about the product that they are interested in purchasing. hence, there is a great demand for automatic answer generation systems that provide quick responses using related information about the product. there are three sources of knowledge available for answering a user posted query, they are reviews, duplicate or similar questions, and specifications. effectively utilizing these information sources will greatly aid us in answering complex questions. however, there are two main challenges present in exploiting these sources: (i) the presence of irrelevant information and (ii) the presence of ambiguity of sentiment present in reviews and similar questions. through this work we propose a novel pipeline (msqap) that utilizes the rich information present in the aforementioned sources by separately performing relevancy and ambiguity prediction before generating a response.   experimental results show that our relevancy prediction model (bert-qa) outperforms all other variants and has an improvement of 12.36% in f1 score compared to the bert-base baseline. our generation model (t5-qa) outperforms the baselines in all content preservation metrics such as bleu, rouge and has an average improvement of 35.02% in rouge and 198.75% in bleu compared to the highest performing baseline (hssc-q). human evaluation of our pipeline shows us that our method has an overall improvement in accuracy of 30.7% over the generation model (t5-qa), resulting in our full pipeline-based approach (msqap) providing more accurate answers. to the best of our knowledge, this is the first work in the e-commerce domain that automatically generates natural language answers combining the information present in diverse sources such as specifications, similar questions, and reviews data. ","751":"fine-tuning pre-trained language models improves the quality of commercial reply suggestion systems, but at the cost of unsustainable training times. popular training time reduction approaches are resource intensive, thus we explore low-cost model compression techniques like layer dropping and layer freezing. we demonstrate the efficacy of these techniques in large-data scenarios, enabling the training time reduction for a commercial email reply suggestion system by 42%, without affecting the model relevance or user engagement. we further study the robustness of these techniques to pre-trained model and dataset size ablation, and share several insights and recommendations for commercial applications. ","752":"meaning representation (amr) is a graph-based semantic representation for sentences, composed of collections of concepts linked by semantic relations. amr-based approaches have found success in a variety of applications, but a challenge to using it in tasks that require document-level context is that it only represents individual sentences. prior work in amr-based summarization has automatically merged the individual sentence graphs into a document graph, but the method of merging and its effects on summary content selection have not been independently evaluated. in this paper, we present a novel dataset consisting of human-annotated alignments between the nodes of paired documents and summaries which may be used to evaluate (1) merge strategies; and (2) the performance of content selection methods over nodes of a merged or unmerged amr graph. we apply these two forms of evaluation to prior work as well as a new method for node merging and show that our new method has significantly better performance than prior work. ","753":"in the paper, we test two different approaches to the {unsupervised} word sense disambiguation task for polish. in both methods, we use neural language models to predict words similar to those being disambiguated and, on the basis of these words, we predict the partition of word senses in different ways. in the first method, we cluster selected similar words, while in the second, we cluster vectors representing their subsets. the evaluation was carried out on texts annotated with plwordnet senses and provided a relatively good result (f1=0.68 for all ambiguous words). the results are significantly better than those obtained for the neural model-based unsupervised method proposed in \\cite{waw:myk:17:sense} and are at the level of the supervised method presented there. the proposed method may be a way of solving word sense disambiguation problem for languages that lack sense annotated data. ","754":"online hatred is a growing concern on many social media platforms. to address this issue, different social media platforms have introduced moderation policies for such content. they also employ moderators who can check the posts violating moderation policies and take appropriate action. academicians in the abusive language research domain also perform various studies to detect such content better. although there is extensive research in abusive language detection in english, there is a lacuna in abusive language detection in low resource languages like hindi, urdu etc. in this fire 2021 shared task - \"hasoc- abusive and threatening language detection in urdu\" the organizers propose an abusive language detection dataset in urdu along with threatening language detection. in this paper, we explored several machine learning models such as xgboost, lgbm, m-bert based models for abusive and threatening content detection in urdu based on the shared task. we observed the transformer model specifically trained on abusive language dataset in arabic helps in getting the best performance. our model came first for both abusive and threatening content detection with an f1scoreof 0.88 and 0.54, respectively. ","755":"hate speech is considered to be one of the major issues currently plaguing online social media. repeated and repetitive exposure to hate speech has been shown to create physiological effects on the target users. thus, hate speech, in all its forms, should be addressed on these platforms in order to maintain good health. in this paper, we explored several transformer based machine learning models for the detection of hate speech and offensive content in english and indo-aryan languages at fire 2021. we explore several models such as mbert, xlmr-large, xlmr-base by team name \"super mario\". our models came 2nd position in code-mixed data set (macro f1: 0.7107), 2nd position in hindi two-class classification(macro f1: 0.7797), 4th in english four-class category (macro f1: 0.8006) and 12th in english two-class category (macro f1: 0.6447). ","756":"prepositions are frequently occurring polysemous words. disambiguation of prepositions is crucial in tasks like semantic role labelling, question answering, text entailment, and noun compound paraphrasing. in this paper, we propose a novel methodology for preposition sense disambiguation (psd), which does not use any linguistic tools. in a supervised setting, the machine learning model is presented with sentences wherein prepositions have been annotated with senses. these senses are ids in what is called the preposition project (tpp). we use the hidden layer representations from pre-trained bert and bert variants. the latent representations are then classified into the correct sense id using a multi layer perceptron. the dataset used for this task is from semeval-2007 task-6. our methodology gives an accuracy of 86.85% which is better than the state-of-the-art. ","757":"aspect-based sentiment analysis(absa) is a textual analysis methodology that defines the polarity of opinions on certain aspects related to specific targets. the majority of research on absa is in english, with a small amount of work available in arabic. most previous arabic research has relied on deep learning models that depend primarily on context-independent word embeddings (e.g.word2vec), where each word has a fixed representation independent of its context. this article explores the modeling capabilities of contextual embeddings from pre-trained language models, such as bert, and making use of sentence pair input on arabic aspect sentiment polarity classification task. in particular, we develop a simple but effective bert-based neural baseline to handle this task. our bert architecture with a simple linear classification layer surpassed the state-of-the-art works, according to the experimental results on three different arabic datasets. achieving an accuracy of 89.51% on the arabic hotel reviews dataset, 73% on the human annotated book reviews dataset, and 85.73% on the arabic news dataset. ","758":"this work originates from the observation that today's state-of-the-art statistical language models are impressive not only for their performance, but also - and quite crucially - because they are built entirely from correlations in unstructured text data. the latter observation prompts a fundamental question that lies at the heart of this paper: what mathematical structure exists in unstructured text data? we put forth enriched category theory as a natural answer. we show that sequences of symbols from a finite alphabet, such as those found in a corpus of text, form a category enriched over probabilities. we then address a second fundamental question: how can this information be stored and modeled in a way that preserves the categorical structure? we answer this by constructing a functor from our enriched category of text to a particular enriched category of reduced density operators. the latter leverages the loewner order on positive semidefinite operators, which can further be interpreted as a toy example of entailment. ","759":"adapting large-scale pretrained language models to downstream tasks via fine-tuning is the standard method for achieving state-of-the-art performance on nlp benchmarks. however, fine-tuning all weights of models with millions or billions of parameters is sample-inefficient, unstable in low-resource settings, and wasteful as it requires storing a separate copy of the model for each task. recent work has developed parameter-efficient fine-tuning methods, but these approaches either still require a relatively large number of parameters or underperform standard fine-tuning. in this work, we propose compacter, a method for fine-tuning large-scale language models with a better trade-off between task performance and the number of trainable parameters than prior work. compacter accomplishes this by building on top of ideas from adapters, low-rank optimization, and parameterized hypercomplex multiplication layers. specifically, compacter inserts task-specific weight matrices into a pretrained model's weights, which are computed efficiently as a sum of kronecker products between shared \"slow\" weights and \"fast\" rank-one matrices defined per compacter layer. by only training 0.047% of a pretrained model's parameters, compacter performs on par with standard fine-tuning on glue and outperforms standard fine-tuning on superglue and low-resource settings. our code is publicly available at~\\url{https:\/\/github.com\/rabeehk\/compacter}. ","760":"in the task of chinese named entity recognition based on deep learning, activation function plays an irreplaceable role, it introduces nonlinear characteristics into neural network, so that the fitted model can be applied to various tasks. however, the information density of industrial safety analysis text is relatively high, and the correlation and similarity between the information are large, which is easy to cause the problem of high deviation and high standard deviation of the model, no specific activation function has been designed in previous studies, and the traditional activation function has the problems of gradient vanishing and negative region, which also lead to the recognition accuracy of the model can not be further improved. to solve these problems, a novel activation function ais is proposed in this paper. ais is an activation function applied in industrial safety engineering, which is composed of two piecewise nonlinear functions. in the positive region, the structure combining exponential function and quadratic function is used to alleviate the problem of deviation and standard deviation, and the linear function is added to modify it, which makes the whole activation function smoother and overcomes the problem of gradient vanishing. in the negative region, the cubic function structure is used to solve the negative region problem and accelerate the convergence of the model. based on the deep learning model of bert-bilstm-crf, the performance of ais is evaluated. the results show that, compared with other activation functions, ais overcomes the problems of gradient vanishing and negative region, reduces the deviation of the model, speeds up the model fitting, and improves the extraction ability of the model for industrial entities. ","761":"persian poetry has consistently expressed its philosophy, wisdom, speech, and rationale on the basis of its couplets, making it an enigmatic language on its own to both native and non-native speakers. nevertheless, the notice able gap between persian prose and poem has left the two pieces of literature medium-less. having curated a parallel corpus of prose and their equivalent poems, we introduce a novel neural machine translation (nmt) approach to translate prose to ancient persian poetry using transformer-based language models in an extremely low-resource setting. more specifically, we trained a transformer model from scratch to obtain initial translations and pretrained different variations of bert to obtain final translations. to address the challenge of using masked language modelling under poeticness criteria, we heuristically joined the two models and generated valid poems in terms of automatic and human assessments. final results demonstrate the eligibility and creativity of our novel heuristically aided approach among literature professionals and non-professionals in generating novel persian poems. ","762":"incorporating personas information allows diverse and engaging responses in dialogue response generation. unfortunately, prior works have primarily focused on self personas and have overlooked the value of partner personas. moreover, in practical applications, the availability of ground truth partner personas is often not the case. this paper attempts to tackle these issues by offering a novel framework that leverages automatic partner personas generation to enhance the succeeding dialogue generation. we incorporate reinforcement learning with a dedicatedly designed critic network for reward judgement. experimental results from both automatic and human evaluation demonstrate a) our framework is capable of generating relevant, informative and coherent partner personas, even compared to the ground truth partner personas. b) generated partner personas enhance the succeeding response generation, thus surpassing our baselines and comparison model when partner personas are missing during the inference stage. c) our framework generates responses that are more informative and engaging than our baseline conditioned on the ground truth partner personas during inference. d) our dedicatedly designed critic network reinforces our framework effectively. finally, our framework gives better explainability and reduces the demands for external databases for partner personas. ","763":"hierarchies are the backbones of complex systems and their analysis allows for a deeper understanding of their structure and how they evolve. we consider languages to be also complex adaptive systems. hence, we analyzed the hierarchical organization of historical syntactic networks from german that were created from a corpus of texts from the 11th to 17th centuries. we tracked the emergence of syntactic structures in these networks and mapped them to specific communicative needs. we named these emerging structures communicative hierarchies. we hypothesise that the communicative needs of speakers are the organizational force of syntax. we propose that the emergence of these multiple communicative hierarchies is what shapes syntax, and that these hierarchies are the prerequisite to the zipf's law. the emergence of communicative hierarchies indicates that the objective of language evolution is not only to increase the efficiency of transferring information. language is also evolving to increase our capacity to communicate more sophisticated abstractions as we advance as a species. ","764":"in this paper, we present our work participating in the biocreative vii track 3 - automatic extraction of medication names in tweets, where we implemented a multi-task learning model that is jointly trained on text classification and sequence labelling. our best system run achieved a strict f1 of 80.4, ranking first and more than 10 points higher than the average score of all participants. our analyses show that the ensemble technique, multi-task learning, and data augmentation are all beneficial for medication detection in tweets. ","765":"do language models have beliefs about the world? dennett (1995) famously argues that even thermostats have beliefs, on the view that a belief is simply an informational state decoupled from any motivational state. in this paper, we discuss approaches to detecting when models have beliefs about the world, and we improve on methods for updating model beliefs to be more truthful, with a focus on methods based on learned optimizers or hypernetworks. our main contributions include: (1) new metrics for evaluating belief-updating methods that focus on the logical consistency of beliefs, (2) a training objective for sequential, local, and generalizing model updates (slag) that improves the performance of learned optimizers, and (3) the introduction of the belief graph, which is a new form of interface with language models that shows the interdependencies between model beliefs. our experiments suggest that models possess belief-like qualities to only a limited extent, but update methods can both fix incorrect model beliefs and greatly improve their consistency. although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work. code is available at https:\/\/github.com\/peterbhase\/slag-belief-updating ","766":"recent work has shown that distributed word representations can encode abstract information from child-directed speech. in this paper, we use diachronic distributed word representations to perform temporal modeling and analysis of lexical development in children. unlike all previous work, we use temporally sliced corpus to learn distributed word representations of child-speech and child-directed speech under a curriculum-learning setting. in our experiments, we perform a lexical categorization task to plot the semantic and syntactic knowledge acquisition trajectories in children. next, we perform linear mixed-effects modeling over the diachronic representational changes to study the role of input word frequencies in the rate of word acquisition in children. we also perform a fine-grained analysis of lexical knowledge transfer from adults to children using representational similarity analysis. finally, we perform a qualitative analysis of the diachronic representations from our model, which reveals the grounding and word associations in the mental lexicon of children. our experiments demonstrate the ease of usage and effectiveness of diachronic distributed word representations in modeling lexical development. ","767":"this paper presents a new task of predicting the coverage of a text document for relation extraction (re): does the document contain many relational tuples for a given entity? coverage predictions are useful in selecting the best documents for knowledge base construction with large input corpora. to study this problem, we present a dataset of 31,366 diverse documents for 520 entities. we analyze the correlation of document coverage with features like length, entity mention frequency, alexa rank, language complexity and information retrieval scores. each of these features has only moderate predictive power. we employ methods combining features with statistical models like tf-idf and language models like bert. the model combining features and bert, herb, achieves an f1 score of up to 46%. we demonstrate the utility of coverage predictions on two use cases: kb construction and claim refutation. ","768":"social media platforms provide a goldmine for mining public opinion on issues of wide societal interest and impact. opinion mining is a problem that can be operationalised by capturing and aggregating the stance of individual social media posts as supporting, opposing or being neutral towards the issue at hand. while most prior work in stance detection has investigated datasets that cover short periods of time, interest in investigating longitudinal datasets has recently increased. evolving dynamics in linguistic and behavioural patterns observed in new data require adapting stance detection systems to deal with the changes. in this survey paper, we investigate the intersection between computational linguistics and the temporal evolution of human communication in digital media. we perform a critical review of emerging research considering dynamics, exploring different semantic and pragmatic factors that impact linguistic data in general, and stance in particular. we further discuss current directions in capturing stance dynamics in social media. we discuss the challenges encountered when dealing with stance dynamics, identify open challenges and discuss future directions in three key dimensions: utterance, context and influence. ","769":"this paper presents an automatic method to evaluate the naturalness of natural language generation in dialogue systems. while this task was previously rendered through expensive and time-consuming human labor, we present this novel task of automatic naturalness evaluation of generated language. by fine-tuning the bert model, our proposed naturalness evaluation method shows robust results and outperforms the baselines: support vector machines, bi-directional lstms, and bleurt. in addition, the training speed and evaluation performance of naturalness model are improved by transfer learning from quality and informativeness linguistic knowledge. ","770":"named entity recognition (ner) remains challenging when entity mentions can be discontinuous. existing methods break the recognition process into several sequential steps. in training, they predict conditioned on the golden intermediate results, while at inference relying on the model output of the previous steps, which introduces exposure bias. to solve this problem, we first construct a segment graph for each sentence, in which each node denotes a segment (a continuous entity on its own, or a part of discontinuous entities), and an edge links two nodes that belong to the same entity. the nodes and edges can be generated respectively in one stage with a grid tagging scheme and learned jointly using a novel architecture named mac. then discontinuous ner can be reformulated as a non-parametric process of discovering maximal cliques in the graph and concatenating the spans in each clique. experiments on three benchmarks show that our method outperforms the state-of-the-art (sota) results, with up to 3.5 percentage points improvement on f1, and achieves 5x speedup over the sota model. ","771":"a key distinguishing feature of conversational recommender systems over traditional recommender systems is their ability to elicit user preferences using natural language. currently, the predominant approach to preference elicitation is to ask questions directly about items or item attributes. these strategies do not perform well in cases where the user does not have sufficient knowledge of the target domain to answer such questions. conversely, in a shopping setting, talking about the planned use of items does not present any difficulties, even for those that are new to a domain. in this paper, we propose a novel approach to preference elicitation by asking implicit questions based on item usage. our approach consists of two main steps. first, we identify the sentences from a large review corpus that contain information about item usage. then, we generate implicit preference elicitation questions from those sentences using a neural text-to-text model. the main contributions of this work also include a multi-stage data annotation protocol using crowdsourcing for collecting high-quality labeled training data for the neural model. we show that our approach is effective in selecting review sentences and transforming them to elicitation questions, even with limited training data. additionally, we provide an analysis of patterns where the model does not perform optimally. ","772":"prompt-based approaches are strong at few-shot learning. however, perez et al. (2021) have recently cast doubt on their performance because they had difficulty getting good results in a \"true\" few-shot setting in which prompts and hyperparameters cannot be tuned on a dev set. in view of this, we conduct an extensive study of pet, a method that combines textual instructions with example-based finetuning. we show that, if correctly configured, pet performs strongly in a true few-shot setting, i.e., without a dev set. crucial for this strong performance is pet's ability to intelligently handle multiple prompts. we then put our findings to a real-world test by running pet on raft, a benchmark of tasks taken directly from realistic nlp applications for which no labeled dev or test sets are available. pet achieves a new state of the art on raft and performs close to non-expert humans for 7 out of 11 tasks. these results demonstrate that prompt-based learners like pet excel at true few-shot learning and underpin our belief that learning from instructions will play an important role on the path towards human-like few-shot learning capabilities. ","773":"event extraction (ee) plays an important role in many industrial application scenarios, and high-quality ee methods require a large amount of manual annotation data to train supervised learning models. however, the cost of obtaining annotation data is very high, especially for annotation of domain events, which requires the participation of experts from corresponding domain. so we introduce active learning (al) technology to reduce the cost of event annotation. but the existing al methods have two main problems, which make them not well used for event extraction. firstly, the existing pool-based selection strategies have limitations in terms of computational cost and sample validity. secondly, the existing evaluation of sample importance lacks the use of local sample information. in this paper, we present a novel deep al method for ee. we propose a batch-based selection strategy and a memory-based loss prediction model (mblp) to select unlabeled samples efficiently. during the selection process, we use an internal-external sample loss ranking method to evaluate the sample importance by using local information. finally, we propose a delayed training strategy to train the mblp model. extensive experiments are performed on three domain datasets, and our method outperforms other state-of-the-art methods. ","774":"speaker diarization is a task to label audio or video recordings with classes that correspond to speaker identity, or in short, a task to identify \"who spoke when\". in the early years, speaker diarization algorithms were developed for speech recognition on multispeaker audio recordings to enable speaker adaptive processing. these algorithms also gained their own value as a standalone application over time to provide speaker-specific metainformation for downstream tasks such as audio retrieval. more recently, with the emergence of deep learning technology, which has driven revolutionary changes in research and practices across speech application domains, rapid advancements have been made for speaker diarization. in this paper, we review not only the historical development of speaker diarization technology but also the recent advancements in neural speaker diarization approaches. furthermore, we discuss how speaker diarization systems have been integrated with speech recognition applications and how the recent surge of deep learning is leading the way of jointly modeling these two components to be complementary to each other. by considering such exciting technical trends, we believe that this paper is a valuable contribution to the community to provide a survey work by consolidating the recent developments with neural methods and thus facilitating further progress toward a more efficient speaker diarization. ","775":"solving symbolic mathematics has always been of in the arena of human ingenuity that needs compositional reasoning and recurrence. however, recent studies have shown that large-scale language models such as transformers are universal and surprisingly can be trained as a sequence-to-sequence task to solve complex mathematical equations. these large transformer models need humongous amounts of training data to generalize to unseen symbolic mathematics problems. in this paper, we present a sample efficient way of solving the symbolic tasks by first pretraining the transformer model with language translation and then fine-tuning the pretrained transformer model to solve the downstream task of symbolic mathematics. we achieve comparable accuracy on the integration task with our pretrained model while using around $1.5$ orders of magnitude less number of training samples with respect to the state-of-the-art deep learning for symbolic mathematics. the test accuracy on differential equation tasks is considerably lower comparing with integration as they need higher order recursions that are not present in language translations. we pretrain our model with different pairs of language translations. our results show language bias in solving symbolic mathematics tasks. finally, we study the robustness of the fine-tuned model on symbolic math tasks against distribution shift, and our approach generalizes better in distribution shift scenarios for the function integration. ","776":"the choice of token vocabulary affects the performance of machine translation. this paper aims to figure out what is a good vocabulary and whether one can find the optimal vocabulary without trial training. to answer these questions, we first provide an alternative understanding of the role of vocabulary from the perspective of information theory. motivated by this, we formulate the quest of vocabularization -- finding the best token dictionary with a proper size -- as an optimal transport (ot) problem. we propose volt, a simple and efficient solution without trial training. empirical results show that volt outperforms widely-used vocabularies in diverse scenarios, including wmt-14 english-german and ted's 52 translation directions. for example, volt achieves almost 70% vocabulary size reduction and 0.5 bleu gain on english-german translation. also, compared to bpe-search, volt reduces the search time from 384 gpu hours to 30 gpu hours on english-german translation. codes are available at https:\/\/github.com\/jingjing-nlp\/volt . ","777":"this paper describes our submission to the constrained track of wmt21 shared news translation task. we focus on the three relatively low resource language pairs bengali to and from hindi, english to and from hausa, and xhosa to and from zulu. to overcome the limitation of relatively low parallel data we train a multilingual model using a multitask objective employing both parallel and monolingual data. in addition, we augment the data using back translation. we also train a bilingual model incorporating back translation and knowledge distillation then combine the two models using sequence-to-sequence mapping. we see around 70% relative gain in bleu point for english to and from hausa, and around 25% relative improvements for both bengali to and from hindi, and xhosa to and from zulu compared to bilingual baselines. ","778":"sociodemographic biases are a common problem for natural language processing, affecting the fairness and integrity of its applications. within sentiment analysis, these biases may undermine sentiment predictions for texts that mention personal attributes that unbiased human readers would consider neutral. such discrimination can have great consequences in the applications of sentiment analysis both in the public and private sectors. for example, incorrect inferences in applications like online abuse and opinion analysis in social media platforms can lead to unwanted ramifications, such as wrongful censoring, towards certain populations. in this paper, we address the discrimination against people with disabilities, pwd, done by sentiment analysis and toxicity classification models. we provide an examination of sentiment and toxicity analysis models to understand in detail how they discriminate pwd. we present the bias identification test in sentiments (bits), a corpus of 1,126 sentences designed to probe sentiment analysis models for biases in disability. we use this corpus to demonstrate statistically significant biases in four widely used sentiment analysis tools (textblob, vader, google cloud natural language api and distilbert) and two toxicity analysis models trained to predict toxic comments on jigsaw challenges (toxic comment classification and unintended bias in toxic comments). the results show that all exhibit strong negative biases on sentences that mention disability. we publicly release bits corpus for others to identify potential biases against disability in any sentiment analysis tools and also to update the corpus to be used as a test for other sociodemographic variables as well. ","779":"traditional approaches to building natural language (nl) interfaces typically use a semantic parser to parse the user command and convert it to a logical form, which is then translated to an executable action in an application. however, it is still challenging for a semantic parser to correctly parse natural language. for a different domain, the parser may need to be retrained or tuned, and a new translator also needs to be written to convert the logical forms to executable actions. in this work, we propose a novel and application independent approach to building nl interfaces that does not need a semantic parser or a translator. it is based on natural language to natural language matching and learning, where the representation of each action and each user command are both in natural language. to perform a user intended action, the system only needs to match the user command with the correct action representation, and then execute the corresponding action. the system also interactively learns new (paraphrased) commands for actions to expand the action representations over time. our experimental results show the effectiveness of the proposed approach. ","780":"in this work, we extensively redesign the newly introduced method of token mixing using fourier transforms (fnet) to replace the computationally expensive self-attention mechanism in a full transformer implementation on a long document summarization task (> 512 tokens). as a baseline, we also carried out long document summarization using established methods such as longformer and big bird transformer models that are capable of processing over 8000 tokens and are currently the state of the art methods for these type of problems. the original fnet paper implemented this in an encoder only architecture while abstractive summarization requires both an encoder and a decoder. since such a pretrained transformer model does not currently exist in the public domain, we decided to implement a full transformer based on this fourier token mixing approach in an encoder\/decoder architecture which we trained starting with glove embeddings for the individual words in the corpus. we investigated a number of different extensions to the original fnet architecture and evaluated them on their rouge f1-score performance on a summarization task. all modifications showed better performance on the summarization task than when using the original fnet encoder in a transformer architecture. ","781":"with the advent of transformer, which was used in translation models in 2017, attention-based architectures began to attract attention. furthermore, after the emergence of bert, which strengthened the nlu-specific encoder part, which is a part of the transformer, and the gpt architecture, which strengthened the nlg-specific decoder part, various methodologies, data, and models for learning the pretrained language model began to appear. furthermore, in the past three years, various pretrained language models specialized for korean have appeared. in this paper, we intend to numerically and qualitatively compare and analyze various korean plms released to the public. ","782":"pretrained contextualized text representation models learn an effective representation of a natural language to make it machine understandable. after the breakthrough of the attention mechanism, a new generation of pretrained models have been proposed achieving good performances since the introduction of the transformer. bidirectional encoder representations from transformers (bert) has become the state-of-the-art model for language understanding. despite their success, most of the available models have been trained on indo-european languages however similar research for under-represented languages and dialects remains sparse.   in this paper, we investigate the feasibility of training monolingual transformer-based language models for under represented languages, with a specific focus on the tunisian dialect. we evaluate our language model on sentiment analysis task, dialect identification task and reading comprehension question-answering task. we show that the use of noisy web crawled data instead of structured data (wikipedia, articles, etc.) is more convenient for such non-standardized language. moreover, results indicate that a relatively small web crawled dataset leads to performances that are as good as those obtained using larger datasets. finally, our best performing tunbert model reaches or improves the state-of-the-art in all three downstream tasks. we release the tunbert pretrained model and the datasets used for fine-tuning. ","783":"riots and protests, if gone out of control, can cause havoc in a country. we have seen examples of this, such as the blm movement, climate strikes, caa movement, and many more, which caused disruption to a large extent. our motive behind creating this dataset was to use it to develop machine learning systems that can give its users insight into the trending events going on and alert them about the events that could lead to disruption in the nation. if any event starts going out of control, it can be handled and mitigated by monitoring it before the matter escalates. this dataset collects tweets of past or ongoing events known to have caused disruption and labels these tweets as 1. we also collect tweets that are considered non-eventful and label them as 0 so that they can also be used to train a classification system. the dataset contains 94855 records of unique events and 168706 records of unique non-events, thus giving the total dataset 263561 records. we extract multiple features from the tweets, such as the user's follower count and the user's location, to understand the impact and reach of the tweets. this dataset might be useful in various event related machine learning problems such as event classification, event recognition, and so on. ","784":"recently many studies have been conducted on the topic of relation extraction. the drugprot track at biocreative vii provides a manually-annotated corpus for the purpose of the development and evaluation of relation extraction systems, in which interactions between chemicals and genes are studied. we describe the ensemble system that we used for our submission, which combines predictions of fine-tuned biobert, scibert and const-biobert models by majority voting. we specifically tested the contribution of syntactic information to relation extraction with bert. we observed that adding constituentbased syntactic information to bert improved precision, but decreased recall, since relations rarely seen in the train set were less likely to be predicted by bert models in which the syntactic information is infused. our code is available online [https:\/\/github.com\/maple177\/drugprot-relation-extraction]. ","785":"we investigate a method to extract relations from texts based on global alignment and syntactic information. combined with svm, this method is shown to have a performance comparable or even better than lstm on two re tasks. ","786":"recent neural-based relation extraction approaches, though achieving promising improvement on benchmark datasets, have reported their vulnerability towards adversarial attacks. thus far, efforts mostly focused on generating adversarial samples or defending adversarial attacks, but little is known about the difference between normal and adversarial samples. in this work, we take the first step to leverage the salience-based method to analyze those adversarial samples. we observe that salience tokens have a direct correlation with adversarial perturbations. we further find the adversarial perturbations are either those tokens not existing in the training set or superficial cues associated with relation labels. to some extent, our approach unveils the characters against adversarial samples. we release an open-source testbed, \"diagnoseadv\" in https:\/\/github.com\/zjunlp\/diagnoseadv. ","787":"in this work, we explore the constructive side of online reviews: advice, tips, requests, and suggestions that users provide about goods, venues, services, and other items of interest. to reduce training costs and annotation efforts needed to build a classifier for a specific label set, we present and evaluate several entailment-based zero-shot approaches to suggestion classification in a label-fully-unseen fashion. in particular, we introduce the strategy of assigning target class labels to sentences in english language with user intentions, which significantly improves prediction quality. the proposed strategies are evaluated with a comprehensive experimental study that validated our results both quantitatively and qualitatively. ","788":"bidirectional encoder representations from transformers (bert) has shown marvelous improvements across various nlp tasks, and its consecutive variants have been proposed to further improve the performance of the pre-trained language models. in this paper, we aim to first introduce the whole word masking (wwm) strategy for chinese bert, along with a series of chinese pre-trained language models. then we also propose a simple but effective model called macbert, which improves upon roberta in several ways. especially, we propose a new masking strategy called mlm as correction (mac). to demonstrate the effectiveness of these models, we create a series of chinese pre-trained language models as our baselines, including bert, roberta, electra, rbt, etc. we carried out extensive experiments on ten chinese nlp tasks to evaluate the created chinese pre-trained language models as well as the proposed macbert. experimental results show that macbert could achieve state-of-the-art performances on many nlp tasks, and we also ablate details with several findings that may help future research. we open-source our pre-trained language models for further facilitating our research community. resources are available: https:\/\/github.com\/ymcui\/chinese-bert-wwm ","789":"motivated by recent evidence pointing out the fragility of high-performing span prediction models, we direct our attention to multiple choice reading comprehension. in particular, this work introduces a novel method for improving answer selection on long documents through weighted global normalization of predictions over portions of the documents. we show that applying our method to a span prediction model adapted for answer selection helps model performance on long summaries from narrativeqa, a challenging reading comprehension dataset with an answer selection task, and we strongly improve on the task baseline performance by +36.2 mean reciprocal rank. ","790":"retrieve-based dialogue response selection aims to find a proper response from a candidate set given a multi-turn context. pre-trained language models (plms) based methods have yielded significant improvements on this task. the sequence representation plays a key role in the learning of matching degree between the dialogue context and the response. however, we observe that different context-response pairs sharing the same context always have a greater similarity in the sequence representations calculated by plms, which makes it hard to distinguish positive responses from negative ones. motivated by this, we propose a novel \\textbf{f}ine-\\textbf{g}rained \\textbf{c}ontrastive (fgc) learning method for the response selection task based on plms. this fgc learning strategy helps plms to generate more distinguishable matching representations of each dialogue at fine grains, and further make better predictions on choosing positive responses. empirical studies on two benchmark datasets demonstrate that the proposed fgc learning method can generally and significantly improve the model performance of existing plm-based matching models. ","791":"in conversational machine reading, systems need to interpret natural language rules, answer high-level questions such as \"may i qualify for va health care benefits?\", and ask follow-up clarification questions whose answer is necessary to answer the original question. however, existing works assume the rule text is provided for each user question, which neglects the essential retrieval step in real scenarios. in this work, we propose and investigate an open-retrieval setting of conversational machine reading. in the open-retrieval setting, the relevant rule texts are unknown so that a system needs to retrieve question-relevant evidence from a collection of rule texts, and answer users' high-level questions according to multiple retrieved rule texts in a conversational manner. we propose mudern, a multi-passage discourse-aware entailment reasoning network which extracts conditions in the rule texts through discourse segmentation, conducts multi-passage entailment reasoning to answer user questions directly, or asks clarification follow-up questions to inquiry more information. on our created or-sharc dataset, mudern achieves the state-of-the-art performance, outperforming existing single-passage conversational machine reading models as well as a new multi-passage conversational machine reading baseline by a large margin. in addition, we conduct in-depth analyses to provide new insights into this new setting and our model. ","792":"cross-model retrieval has emerged as one of the most important upgrades for text-only search engines (se). recently, with powerful representation for pairwise text-image inputs via early interaction, the accuracy of vision-language (vl) transformers has outperformed existing methods for text-image retrieval. however, when the same paradigm is used for inference, the efficiency of the vl transformers is still too low to be applied in a real cross-modal se. inspired by the mechanism of human learning and using cross-modal knowledge, this paper presents a novel vision-language decomposed transformer (vldeformer), which greatly increases the efficiency of vl transformers while maintaining their outstanding accuracy. by the proposed method, the cross-model retrieval is separated into two stages: the vl transformer learning stage, and the vl decomposition stage. the latter stage plays the role of single modal indexing, which is to some extent like the term indexing of a text se. the model learns cross-modal knowledge from early-interaction pre-training and is then decomposed into an individual encoder. the decomposition requires only small target datasets for supervision and achieves both $1000+$ times acceleration and less than $0.6$\\% average recall drop. vldeformer also outperforms state-of-the-art visual-semantic embedding methods on coco and flickr30k. ","793":"the neural machine translation model assumes that syntax knowledge can be learned from the bilingual corpus via an attention network automatically. however, the attention network trained in weak supervision actually cannot capture the deep structure of the sentence. naturally, we expect to introduce external syntax knowledge to guide the learning of the attention network. thus, we propose a novel, parameter-free, dependency-scaled self-attention network, which integrates explicit syntactic dependencies into the attention network to dispel the dispersion of attention distribution. finally, two knowledge sparse techniques are proposed to prevent the model from overfitting noisy syntactic dependencies. experiments and extensive analyses on the iwslt14 german-to-english and wmt16 german-to-english translation tasks validate the effectiveness of our approach. ","794":"we intend to generate low-dimensional explicit distributional semantic vectors. in explicit semantic vectors, each dimension corresponds to a word, so word vectors are interpretable. in this research, we propose a new approach to obtain low-dimensional explicit semantic vectors. first, the proposed approach considers the three criteria word similarity, number of zero, and word frequency as features for the words in a corpus. then, we extract some rules for obtaining the initial basis words using a decision tree that is drawn based on the three features. second, we propose a binary weighting method based on the binary particle swarm optimization algorithm that obtains n_b = 1000 context words. we also use a word selection method that provides n_s = 1000 context words. third, we extract the golden words of the corpus based on the binary weighting method. then, we add the extracted golden words to the context words that are selected by the word selection method as the golden context words. we use the ukwac corpus for constructing the word vectors. we use men, rg-65, and simlex-999 test sets to evaluate the word vectors. we report the results compared to a baseline that uses 5k most frequent words in the corpus as context words. the baseline method uses a fixed window to count the co-occurrences. we obtain the word vectors using the 1000 selected context words together with the golden context words. our approach compared to the baseline method increases the spearman correlation coefficient for the men, rg-65, and simlex-999 test sets by 4.66%, 14.73%, and 1.08%, respectively. ","795":"identifying outlier documents, whose content is different from the majority of the documents in a corpus, has played an important role to manage a large text collection. however, due to the absence of explicit information about the inlier (or target) distribution, existing unsupervised outlier detectors are likely to make unreliable results depending on the density or diversity of the outliers in the corpus. to address this challenge, we introduce a new task referred to as out-of-category detection, which aims to distinguish the documents according to their semantic relevance to the inlier (or target) categories by using the category names as weak supervision. in practice, this task can be widely applicable in that it can flexibly designate the scope of target categories according to users' interests while requiring only the target-category names as minimum guidance. in this paper, we present an out-of-category detection framework, which effectively measures how confidently each document belongs to one of the target categories based on its category-specific relevance score. our framework adopts a two-step approach; (i) it first generates the pseudo-category label of all unlabeled documents by exploiting the word-document similarity encoded in a text embedding space, then (ii) it trains a neural classifier by using the pseudo-labels in order to compute the confidence from its target-category prediction. the experiments on real-world datasets demonstrate that our framework achieves the best detection performance among all baseline methods in various scenarios specifying different target categories. ","796":"keeping the performance of language technologies optimal as time passes is of great practical interest. here we survey prior work concerned with the effect of time on system performance, establishing more nuanced terminology for discussing the topic and proper experimental design to support solid conclusions about the observed phenomena. we present a set of experiments with systems powered by large neural pretrained representations for english to demonstrate that {\\em temporal model deterioration} is not as big a concern, with some models in fact improving when tested on data drawn from a later time period. it is however the case that {\\em temporal domain adaptation} is beneficial, with better performance for a given time period possible when the system is trained on temporally more recent data. our experiments reveal that the distinctions between temporal model deterioration and temporal domain adaptation becomes salient for systems built upon pretrained representations. finally we examine the efficacy of two approaches for temporal domain adaptation without human annotations on new data, with self-labeling proving to be superior to continual pre-training. notably, for named entity recognition, self-labeling leads to better temporal adaptation than human annotation. ","797":"large transformer models yield impressive results on many tasks, but are expensive to train, or even fine-tune, and so slow at decoding that their use and study becomes out of reach. we address this problem by leveraging sparsity. we study sparse variants for all layers in the transformer and propose scaling transformers, a family of next generation transformer models that use sparse layers to scale efficiently and perform unbatched decoding much faster than the standard transformer as we scale up the model size. surprisingly, the sparse layers are enough to obtain the same perplexity as the standard transformer with the same number of parameters. we also integrate with prior sparsity approaches to attention and enable fast inference on long sequences even with limited memory. this results in performance competitive to the state-of-the-art on long text summarization. ","798":"cloud native application cnapp (as a distributed system) is a collection of independent components (micro-services) interacting via communication protocols. this gives rise to present an abstract architecture of cnapp as dynamically re-configurable acyclic directed multi graph where vertices are microservices, and edges are the protocols. generic mechanisms for such reconfigurations evidently correspond to higher-level functions (functionals). this implies also internal abstract architecture of microservice as a collection of event-triggered serverless functions (including functions implementing the protocols) that are dynamically composed into event-dependent data-flow graphs. again, generic mechanisms for such compositions correspond to calculus of functionals and relations. ","799":"objective: clinical notes contain information not present elsewhere, including drug response and symptoms, all of which are highly important when predicting key outcomes in acute care patients. we propose the automatic annotation of phenotypes from clinical notes as a method to capture essential information, which is complementary to typically used vital signs and laboratory test results, to predict outcomes in the intensive care unit (icu).   methods: we develop a novel phenotype annotation model to annotate phenotypic features of patients which are then used as input features of predictive models to predict icu patient outcomes. we demonstrate and validate our approach conducting experiments on three icu prediction tasks including in-hospital mortality, physiological decompensation and length of stay for over 24,000 patients by using mimic-iii dataset.   results: the predictive models incorporating phenotypic information achieve 0.845 (auc-roc) to predict in-hospital mortality, 0.839 (auc-roc) for physiological decompensation and 0.430 (kappa) for length of stay, all of which consistently outperform the baseline models leveraging only vital signs and laboratory test results. moreover, we conduct a thorough interpretability study, showing that phenotypes provide valuable insights at the patient and cohort levels.   conclusion: the proposed approach demonstrates phenotypic information complements traditionally used vital signs and laboratory test results, improving significantly forecast of outcomes in the icu. ","800":"purpose: validate the applicability of natural language processing (nlp) techniques to reveal, and quantify, qualities of the experience of chronic pain, by means of the novel reddit reports of chronic pain (rrcp) dataset, aimed at being a standard for future research on this underdeveloped area. methods: define and validate the rrcp dataset for a set of pathologies related to chronic pain. for each pathology, identify the main qualities emergent of the consequent experience of chronic pain. compare the identified qualities for each pathology and validate with clinical research. results: the rrcp dataset comprises 136,573 reddit submissions from 12 subreddits related to chronic pain. macro analysis reveals that pathologies affecting the same or similar body parts result in semantically similar descriptions of pain. detailed analysis reveals that there are qualities to experiencing chronic pain from a given pathology that are nothing like experiencing it from another pathology, and that some are common to every experience of chronic pain. these allow us to compare subjective experiences of chronic pain (e.g., for the rrcp population, experiencing arthritis is very similar to experiencing ankylosing spondylitis in its various qualities or concerns, whilst experiencing fibromyalgia encompasses the same qualities and others not emergent of the other two pathologies). conclusion: our unsupervised semantic analysis of descriptions of chronic pain reflects clinical knowledge on how different pathologies manifest in terms of the chronic pain experience. our results validate the use of nlp techniques to automatically extract and quantify clinically relevant information from descriptions of chronic pain experiences. ","801":"sports game summarization aims at generating sports news from live commentaries. however, existing datasets are all constructed through automated collection and cleaning processes, resulting in a lot of noise. besides, current works neglect the knowledge gap between live commentaries and sports news, which limits the performance of sports game summarization. in this paper, we introduce k-sportssum, a new dataset with two characteristics: (1) k-sportssum collects a large amount of data from massive games. it has 7,854 commentary-news pairs. to improve the quality, k-sportssum employs a manual cleaning process; (2) different from existing datasets, to narrow the knowledge gap, k-sportssum further provides a large-scale knowledge corpus that contains the information of 523 sports teams and 14,724 sports players. additionally, we also introduce a knowledge-enhanced summarizer that utilizes both live commentaries and the knowledge to generate sports news. extensive experiments on k-sportssum and sportssum datasets show that our model achieves new state-of-the-art performances. qualitative analysis and human study further verify that our model generates more informative sports news. ","802":"automatic monitoring of adverse drug events (ades) or reactions (adrs) is currently receiving significant attention from the biomedical community. in recent years, user-generated data on social media has become a valuable resource for this task. neural models have achieved impressive performance on automatic text classification for adr detection. yet, training and evaluation of these methods are carried out on user-generated texts about a targeted drug. in this paper, we assess the robustness of state-of-the-art neural architectures across different drug groups. we investigate several strategies to use pseudo-labeled data in addition to a manually annotated train set. out-of-dataset experiments diagnose the bottleneck of supervised models in terms of breakdown performance, while additional pseudo-labeled data improves overall results regardless of the text selection strategy. ","803":"twitter is perhaps the social media more amenable for research. it requires only a few steps to obtain information, and there are plenty of libraries that can help in this regard. nonetheless, knowing whether a particular event is expressed on twitter is a challenging task that requires a considerable collection of tweets. this proposal aims to facilitate, to a researcher interested, the process of mining events on twitter by opening a collection of processed information taken from twitter since december 2015. the events could be related to natural disasters, health issues, and people's mobility, among other studies that can be pursued with the library proposed. different applications are presented in this contribution to illustrate the library's capabilities: an exploratory analysis of the topics discovered in tweets, a study on similarity among dialects of the spanish language, and a mobility report on different countries. in summary, the python library presented is applied to different domains and retrieves a plethora of information in terms of frequencies by day of words and bi-grams of words for arabic, english, spanish, and russian languages. as well as mobility information related to the number of travels among locations for more than 200 countries or territories. ","804":"this paper reports on the state-of-the-art in application of multidimensional scaling (mds) techniques to create semantic maps in linguistic research. mds refers to a statistical technique that represents objects (lexical items, linguistic contexts, languages, etc.) as points in a space so that close similarity between the objects corresponds to close distances between the corresponding points in the representation. we focus on the use of mds in combination with parallel corpus data as used in research on cross-linguistic variation.   we first introduce the mathematical foundations of mds and then give an exhaustive overview of past research that employs mds techniques in combination with parallel corpus data. we propose a set of terminology to succinctly describe the key parameters of a particular mds application. we then show that this computational methodology is theory-neutral, i.e. it can be employed to answer research questions in a variety of linguistic theoretical frameworks. finally, we show how this leads to two lines of future developments for mds research in linguistics. ","805":"despite the huge and continuous advances in computational linguistics, the lack of annotated data for named entity recognition (ner) is still a challenging issue, especially in low-resource languages and when domain knowledge is required for high-quality annotations. recent findings in nlp show the effectiveness of cloze-style questions in enabling language models to leverage the knowledge they acquired during the pre-training phase. in our work, we propose a simple and intuitive adaptation of pattern-exploiting training (pet), a recent approach which combines the cloze-questions mechanism and fine-tuning for few-shot learning: the key idea is to rephrase the ner task with patterns. our approach achieves considerably better performance than standard fine-tuning and comparable or improved results with respect to other few-shot baselines without relying on manually annotated data or distant supervision on three benchmark datasets: ncbi-disease, bc2gm and a private italian biomedical corpus. ","806":"since traditional social media platforms continue to ban actors spreading hate speech or other forms of abusive languages (a process known as deplatforming), these actors migrate to alternative platforms that do not moderate users content. one popular platform relevant for the german hater community is telegram for which limited research efforts have been made so far. this study aims to develop a broad framework comprising (i) an abusive language classification model for german telegram messages and (ii) a classification model for the hatefulness of telegram channels. for the first part, we use existing abusive language datasets containing posts from other platforms to develop our classification models. for the channel classification model, we develop a method that combines channel-specific content information collected from a topic model with a social graph to predict the hatefulness of channels. furthermore, we complement these two approaches for hate speech detection with insightful results on the evolution of the hater community on telegram in germany. we also propose methods for conducting scalable network analyses for social media platforms to the hate speech research community. as an additional output of this study, we provide an annotated abusive language dataset containing 1,149 annotated telegram messages. ","807":"contrastive learning has been studied for improving the performance of learning sentence embeddings. the current state-of-the-art method is the simcse, which takes dropout as the data augmentation method and feeds a pre-trained transformer encoder the same input sentence twice. the corresponding outputs, two sentence embeddings derived from the same sentence with different dropout masks, can be used to build a positive pair. a network being applied with a dropout mask can be regarded as a sub-network of itsef, whose expected scale is determined by the dropout rate. in this paper, we push sub-networks with different expected scales learn similar embedding for the same sentence. simcse failed to do so because they fixed the dropout rate to a tuned hyperparameter. we achieve this by sampling dropout rate from a distribution eatch forward process. as this method may make optimization harder, we also propose a simple sentence-wise mask strategy to sample more sub-networks. we evaluated the proposed s-simcse on several popular semantic text similarity datasets. experimental results show that s-simcse outperforms the state-of-the-art simcse more than $1\\%$ on bert$_{base}$ ","808":"innovations in neural architectures have fostered significant breakthroughs in language modeling and computer vision. unfortunately, novel architectures often result in challenging hyper-parameter choices and training instability if the network parameters are not properly initialized. a number of architecture-specific initialization schemes have been proposed, but these schemes are not always portable to new architectures. this paper presents gradinit, an automated and architecture agnostic method for initializing neural networks. gradinit is based on a simple heuristic; the norm of each network layer is adjusted so that a single step of sgd or adam with prescribed hyperparameters results in the smallest possible loss value. this adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. gradinit accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. it also improves the stability of the original transformer architecture for machine translation, enabling training it without learning rate warmup using either adam or sgd under a wide range of learning rates and momentum coefficients. code is available at https:\/\/github.com\/zhuchen03\/gradinit. ","809":"the determination of the reading sequence of text is fundamental to document understanding. this problem is easily solved in pages where the text is organized into a sequence of lines and vertical alignment runs the height of the page (producing multiple columns which can be read from left to right). we present a situation -- the directory page parsing problem -- where information is presented on the page in an irregular, visually-organized, two-dimensional format. directory pages are fairly common in financial prospectuses and carry information about organizations, their addresses and relationships that is key to business tasks in client onboarding. interestingly, directory pages sometimes have hierarchical structure, motivating the need to generalize the reading sequence to a reading tree. we present solutions to the problem of identifying directory pages and constructing the reading tree, using (learnt) classifiers for text segments and a bottom-up (right to left, bottom-to-top) traversal of segments. the solution is a key part of a production service supporting automatic extraction of organization, address and relationship information from client onboarding documents. ","810":"glove learns word embeddings by leveraging statistical information from word co-occurrence matrices. however, word pairs in the matrices are extracted from a predefined local context window, which might lead to limited word pairs and potentially semantic irrelevant word pairs. in this paper, we propose semglove, which distills semantic co-occurrences from bert into static glove word embeddings. particularly, we propose two models to extract co-occurrence statistics based on either the masked language model or the multi-head attention weights of bert. our methods can extract word pairs without limiting by the local window assumption and can define the co-occurrence weights by directly considering the semantic distance between word pairs. experiments on several word similarity datasets and four external tasks show that semglove can outperform glove. ","811":"data building for automatic post-editing (ape) requires extensive and expert-level human effort, as it contains an elaborate process that involves identifying errors in sentences and providing suitable revisions. hence, we develop a self-supervised data generation tool, deployable as a web application, that minimizes human supervision and constructs personalized ape data from a parallel corpus for several language pairs with english as the target language. data-centric ape research can be conducted using this tool, involving many language pairs that have not been studied thus far owing to the lack of suitable data. ","812":"text variational autoencoders (vaes) are notorious for posterior collapse, a phenomenon where the model's decoder learns to ignore signals from the encoder. because posterior collapse is known to be exacerbated by expressive decoders, transformers have seen limited adoption as components of text vaes. existing studies that incorporate transformers into text vaes (li et al., 2020; fang et al., 2021) mitigate posterior collapse using massive pretraining, a technique unavailable to most of the research community without extensive computing resources. we present a simple two-phase training scheme to convert a sequence-to-sequence transformer into a vae with just finetuning. the resulting language model is competitive with massively pretrained transformer-based vaes in some internal metrics while falling short on others. to facilitate training we comprehensively explore the impact of common posterior collapse alleviation techniques in the literature. we release our code for reproducability. ","813":"many studies were recently done for investigating the properties of contextual language models but surprisingly, only a few of them consider the properties of these models in terms of semantic similarity. in this article, we first focus on these properties for english by exploiting the distributional principle of substitution as a probing mechanism in the controlled context of semcor and wordnet paradigmatic relations. then, we propose to adapt the same method to a more open setting for characterizing the differences between static and contextual language models. ","814":"self-supervised learning algorithms, including bert and simclr, have enabled significant strides in fields like natural language processing, computer vision, and speech processing. however, these algorithms are domain-specific, meaning that new self-supervised learning algorithms must be developed for each new setting, including myriad healthcare, scientific, and multimodal domains. to catalyze progress toward domain-agnostic methods, we introduce dabs: a domain-agnostic benchmark for self-supervised learning. to perform well on dabs, an algorithm is evaluated on seven diverse domains: natural images, multichannel sensor data, english text, speech recordings, multilingual text, chest x-rays, and images with text descriptions. each domain contains an unlabeled dataset for pretraining; the model is then is scored based on its downstream performance on a set of labeled tasks in the domain. we also present e-mix and shed: two baseline domain-agnostic algorithms; their relatively modest performance demonstrates that significant progress is needed before self-supervised learning is an out-of-the-box solution for arbitrary domains. code for benchmark datasets and baseline algorithms is available at https:\/\/github.com\/alextamkin\/dabs. ","815":"one proposed mechanism of language change concerns the role played by second-language (l2) learners in situations of language contact. if sufficiently many l2 speakers are present in a speech community in relation to the number of first-language (l1) speakers, then those features which present a difficulty in l2 acquisition may be prone to disappearing from the language. this paper proposes a mathematical model of such contact situations based on reinforcement learning and nonlinear dynamics. the equilibria of a deterministic reduction of a full stochastic model, describing a mixed population of l1 and l2 speakers, are fully characterized. whether or not the language changes in response to the introduction of l2 learners turns out to depend on three factors: the overall proportion of l2 learners in the population, the relative advantages of the linguistic variants in question, and the strength of the difficulty speakers face in acquiring the language as an l2. these factors are related by a mathematical formula describing a phase transition from retention of the l2-difficult feature to its loss from both speaker populations. this supplies predictions that can be tested against empirical data. here, the model is evaluated with the help of two case studies, morphological levelling in afrikaans and the erosion of null subjects in afro-peruvian spanish; the model is found to be broadly in agreement with the historical development in both cases. ","816":"gpu compilers are complex software programs with many optimizations specific to target hardware. these optimizations are often controlled by heuristics hand-designed by compiler experts using time- and resource-intensive processes. in this paper, we developed a gpu compiler autotuning framework that uses off-policy deep reinforcement learning to generate heuristics that improve the frame rates of graphics applications. furthermore, we demonstrate the resilience of these learned heuristics to frequent compiler updates by analyzing their stability across a year of code check-ins without retraining. we show that our machine learning-based compiler autotuning framework matches or surpasses the frame rates for 98% of graphics benchmarks with an average uplift of 1.6% up to 15.8%. ","817":"one of the fundamental functionalities for accepting a socially assistive robot is its communication capabilities with other agents in the environment. in the context of the robin project, situational dialogue through voice interaction with a robot was investigated. this paper presents different speech recognition experiments with deep neural networks focusing on producing fast (under 100ms latency from the network itself), while still reliable models. even though one of the key desired characteristics is low latency, the final deep neural network model achieves state of the art results for recognizing romanian language, obtaining a 9.91% word error rate (wer), when combined with a language model, thus improving over the previous results while offering at the same time an improved runtime performance. additionally, we explore two modules for correcting the asr output (hyphen and capitalization restoration and unknown words correction), targeting the robin project's goals (dialogue in closed micro-worlds). we design a modular architecture based on apis allowing an integration engine (either in the robot or external) to chain together the available modules as needed. finally, we test the proposed design by integrating it in the relate platform and making the asr service available to web users by either uploading a file or recording new speech. ","818":"language models can generate harmful and biased outputs and exhibit undesirable behavior according to a given cultural context. we propose a process for adapting language models to society (palms) with values-targeted datasets, an iterative process to significantly change model behavior by crafting and fine-tuning on a dataset that reflects a predetermined set of target values. we evaluate our process using three metrics: quantitative metrics with human evaluations that score output adherence to a target value, toxicity scoring on outputs; and qualitative metrics analyzing the most common word associated with a given social category. through each iteration, we add additional training dataset examples based on observed shortcomings from evaluations. palms performs significantly better on all metrics compared to baseline and control models for a broad range of gpt-3 language model sizes without compromising capability integrity. we find that the effectiveness of palms increases with model size. we show that significantly adjusting language model behavior is feasible with a small, hand-curated dataset. ","819":"we show that it is possible to craft transformations that, applied to compositional grammars, result in grammars that neural networks can learn easily, but humans do not. this could explain the disconnect between current metrics of compositionality, that are arguably human-centric, and the ability of neural networks to generalize to unseen examples. we propose to use the transformations as a benchmark, icy, which could be used to measure aspects of the compositional inductive bias of networks, and to search for networks with similar compositional inductive biases to humans. as an example of this approach, we propose a hierarchical model, hu-rnn, which shows an inductive bias towards position-independent, word-like groups of tokens. ","820":"fake news and misinformation are a matter of concern for people around the globe. users of the internet and social media sites encounter content with false information much frequently. fake news detection is one of the most analyzed and prominent areas of research. these detection techniques apply popular machine learning and deep learning algorithms. previous work in this domain covers fake news detection vastly among text circulating online. platforms that have extensively been observed and analyzed include news websites and twitter. facebook, reddit, whatsapp, youtube, and other social applications are gradually gaining attention in this emerging field. researchers are analyzing online data based on multiple modalities composed of text, image, video, speech, and other contributing factors. the combination of various modalities has resulted in efficient fake news detection. at present, there is an abundance of surveys consolidating textual fake news detection algorithms. this review primarily deals with multi-modal fake news detection techniques that include images, videos, and their combinations with text. we provide a comprehensive literature survey of eighty articles presenting state-of-the-art detection techniques, thereby identifying research gaps and building a pathway for researchers to further advance this domain. ","821":"transformer-based language models such as bert have outperformed previous models on a large number of english benchmarks, but their evaluation is often limited to english or a small number of well-resourced languages. in this work, we evaluate monolingual, multilingual, and randomly initialized language models from the bert family on a variety of uralic languages including estonian, finnish, hungarian, erzya, moksha, karelian, livvi, komi permyak, komi zyrian, northern s\\'ami, and skolt s\\'ami. when monolingual models are available (currently only et, fi, hu), these perform better on their native language, but in general they transfer worse than multilingual models or models of genetically unrelated languages that share the same character set. remarkably, straightforward transfer of high-resource models, even without special efforts toward hyperparameter optimization, yields what appear to be state of the art pos and ner tools for the minority uralic languages where there is sufficient data for finetuning. ","822":"in a typical customer service chat scenario, customers contact a support center to ask for help or raise complaints, and human agents try to solve the issues. in most cases, at the end of the conversation, agents are asked to write a short summary emphasizing the problem and the proposed solution, usually for the benefit of other agents that may have to deal with the same customer or issue. the goal of the present article is advancing the automation of this task. we introduce the first large scale, high quality, customer care dialog summarization dataset with close to 6500 human annotated summaries. the data is based on real-world customer support dialogs and includes both extractive and abstractive summaries. we also introduce a new unsupervised, extractive summarization method specific to dialogs. ","823":"scholarly knowledge graphs (kgs) provide a rich source of structured information representing knowledge encoded in scientific publications. with the sheer volume of published scientific literature comprising a plethora of inhomogeneous entities and relations to describe scientific concepts, these kgs are inherently incomplete. we present exbert, a method for leveraging pre-trained transformer language models to perform scholarly knowledge graph completion. we model triples of a knowledge graph as text and perform triple classification (i.e., belongs to kg or not). the evaluation shows that exbert outperforms other baselines on three scholarly kg completion datasets in the tasks of triple classification, link prediction, and relation prediction. furthermore, we present two scholarly datasets as resources for the research community, collected from public kgs and online resources. ","824":"mixture-of-experts based acoustic models with dynamic routing mechanisms have proved promising results for speech recognition. the design principle of router architecture is important for the large model capacity and high computational efficiency. our previous work speechmoe only uses local grapheme embedding to help routers to make route decisions. to further improve speech recognition performance against varying domains and accents, we propose a new router architecture which integrates additional global domain and accent embedding into router input to promote adaptability. experimental results show that the proposed speechmoe2 can achieve lower character error rate (cer) with comparable parameters than speechmoe on both multi-domain and multi-accent task. primarily, the proposed method provides up to 1.6% - 4.8% relative cer improvement for the multidomain task and 1.9% - 17.7% relative cer improvement for the multi-accent task respectively. besides, increasing the number of experts also achieves consistent performance improvement and keeps the computational cost constant. ","825":"developing named entity recognition (ner) systems for indian languages has been a long-standing challenge, mainly owing to the requirement of a large amount of annotated clean training instances. this paper proposes an end-to-end framework for ner for indian languages in a low-resource setting by exploiting parallel corpora of english and indian languages and an english ner dataset. the proposed framework includes an annotation projection method that combines word alignment score and ner tag prediction confidence score on source language (english) data to generate weakly labeled data in a target indian language. we employ a variant of the teacher-student model and optimize it jointly on the pseudo labels of the teacher model and predictions on the generated weakly labeled data. we also present manually annotated test sets for three indian languages: hindi, bengali, and gujarati. we evaluate the performance of the proposed framework on the test sets of the three indian languages. empirical results show a minimum 10% performance improvement compared to the zero-shot transfer learning model on all languages. this indicates that weakly labeled data generated using the proposed annotation projection method in target indian languages can complement well-annotated source language data to enhance performance. our code is publicly available at https:\/\/github.com\/aksh555\/cl-neril ","826":"in recent years participatory budgeting (pb) in scotland has grown from a handful of community-led processes to a movement supported by local and national government. this is epitomized by an agreement between the scottish government and the convention of scottish local authorities (cosla) that at least 1% of local authority budgets will be subject to pb. this ongoing research paper explores the challenges that emerge from this 'scaling up' or 'mainstreaming' across the 32 local authorities that make up scotland. the main objective is to evaluate local authority use of the digital platform consul, which applies natural language processing (nlp) to address these challenges. this project adopts a qualitative longitudinal design with interviews, observations of pb processes, and analysis of the digital platform data. thematic analysis is employed to capture the major issues and themes which emerge. longitudinal analysis then explores how these evolve over time. the potential for 32 live study sites provides a unique opportunity to explore discrete political and social contexts which materialize and allow for a deeper dive into the challenges and issues that may exist, something a wider cross-sectional study would miss. initial results show that issues and challenges which come from scaling up may be tackled using nlp technology which, in a previous controlled use case-based evaluation, has shown to improve the effectiveness of citizen participation. ","827":"automatic summarization of legal texts is an important and still a challenging task since legal documents are often long and complicated with unusual structures and styles. recent advances of deep models trained end-to-end with differentiable losses can well-summarize natural text, yet when applied to legal domain, they show limited results. in this paper, we propose to use reinforcement learning to train current deep summarization models to improve their performance on the legal domain. to this end, we adopt proximal policy optimization methods and introduce novel reward functions that encourage the generation of candidate summaries satisfying both lexical and semantic criteria. we apply our method to training different summarization backbones and observe a consistent and significant performance gain across 3 public legal datasets. ","828":"as major progress is made in open-ended text generation, measuring how close machine-generated text is to human language remains a critical open problem. we introduce mauve, a comparison measure for open-ended text generation, which directly compares the learnt distribution from a text generation model to the distribution of human-written text using divergence frontiers. mauve scales up to modern text generation models by computing information divergences in a quantized embedding space. through an extensive empirical study on three open-ended generation tasks, we find that mauve identifies known properties of generated text, scales naturally with model size, and correlates with human judgments, with fewer restrictions than existing distributional evaluation metrics. ","829":"recently, large-scale transformer-based models have been proven to be effective over a variety of tasks across many domains. nevertheless, putting them into production is very expensive, requiring comprehensive optimization techniques to reduce inference costs. this paper introduces a series of transformer inference optimization techniques that are both in algorithm level and hardware level. these techniques include a pre-padding decoding mechanism that improves token parallelism for text generation, and highly optimized kernels designed for very long input length and large hidden size. on this basis, we propose a transformer inference acceleration library -- easy and efficient transformer (eet), which has a significant performance improvement over existing libraries. compared to faster transformer v4.0's implementation for gpt-2 layer on a100, eet achieves a 1.5-4.5x state-of-art speedup varying with different context lengths. eet is available at https:\/\/github.com\/netease-fuxi\/eet. a demo video is available at https:\/\/youtu.be\/22upcngcerg. ","830":"to assess the effectiveness of any medical intervention, researchers must conduct a time-intensive and highly manual literature review. nlp systems can help to automate or assist in parts of this expensive process. in support of this goal, we release ms^2 (multi-document summarization of medical studies), a dataset of over 470k documents and 20k summaries derived from the scientific literature. this dataset facilitates the development of systems that can assess and aggregate contradictory evidence across multiple studies, and is the first large-scale, publicly available multi-document summarization dataset in the biomedical domain. we experiment with a summarization system based on bart, with promising early results. we formulate our summarization inputs and targets in both free text and structured forms and modify a recently proposed metric to assess the quality of our system's generated summaries. data and models are available at https:\/\/github.com\/allenai\/ms2 ","831":"most popular goal-oriented dialogue agents are capable of understanding the conversational context. however, with the surge of virtual assistants with screen, the next generation of agents are required to also understand screen context in order to provide a proper interactive experience, and better understand users' goals. in this paper, we propose a novel multimodal conversational framework, where the dialogue agent's next action and their arguments are derived jointly conditioned both on the conversational and the visual context. specifically, we propose a new model, that can reason over the visual context within a conversation and populate api arguments with visual entities given the user query. our model can recognize visual features such as color and shape as well as the metadata based features such as price or star rating associated with a visual entity. in order to train our model, due to a lack of suitable multimodal conversational datasets, we also propose a novel multimodal dialog simulator to generate synthetic data and also collect realistic user data from mturk to improve model robustness. the proposed model achieves a reasonable 85% model accuracy, without high inference latency. we also demonstrate the proposed approach in a prototypical furniture shopping experience for a multimodal virtual assistant. ","832":"the advent of noisy intermediate-scale quantum (nisq) computers raises a crucial challenge to design quantum neural networks for fully quantum learning tasks. to bridge the gap, this work proposes an end-to-end learning framework named qtn-vqc, by introducing a trainable quantum tensor network (qtn) for quantum embedding on a variational quantum circuit (vqc). the architecture of qtn is composed of a parametric tensor-train network for feature extraction and a tensor product encoding for quantum embedding. we highlight the qtn for quantum embedding in terms of two perspectives: (1) we theoretically characterize qtn by analyzing its representation power of input features; (2) qtn enables an end-to-end parametric model pipeline, namely qtn-vqc, from the generation of quantum embedding to the output measurement. our experiments on the mnist dataset demonstrate the advantages of qtn for quantum embedding over other quantum embedding approaches. ","833":"we present a method for cross-lingual training an asr system using absolutely no transcribed training data from the target language, and with no phonetic knowledge of the language in question. our approach uses a novel application of a decipherment algorithm, which operates given only unpaired speech and text data from the target language. we apply this decipherment to phone sequences generated by a universal phone recogniser trained on out-of-language speech corpora, which we follow with flat-start semi-supervised training to obtain an acoustic model for the new language. to the best of our knowledge, this is the first practical approach to zero-resource cross-lingual asr which does not rely on any hand-crafted phonetic information. we carry out experiments on read speech from the globalphone corpus, and show that it is possible to learn a decipherment model on just 20 minutes of data from the target language. when used to generate pseudo-labels for semi-supervised training, we obtain wers that range from 25% to just 5% absolute worse than the equivalent fully supervised models trained on the same data. ","834":"open book question answering is a subset of question answering tasks where the system aims to find answers in a given set of documents (open-book) and common knowledge about a topic. this article proposes a solution for answering natural language questions from a corpus of amazon web services (aws) technical documents with no domain-specific labeled data (zero-shot). these questions can have yes-no-none answers, short answers, long answers, or any combination of the above. this solution comprises a two-step architecture in which a retriever finds the right document and an extractor finds the answers in the retrieved document. we are introducing a new test dataset for open-book qa based on real customer questions on aws technical documentation. after experimenting with several information retrieval systems and extractor models based on extractive language models, the solution attempts to find the yes-no-none answers and text answers in the same pass. the model is trained on the the stanford question answering dataset - squad (rajpurkaret al., 2016) and natural questions (kwiatkowski et al., 2019) datasets. we were able to achieve 49% f1 and 39% exact match score (em) end-to-end with no domain-specific training. ","835":"the visual sentiment analysis task is being offered for the first time at mediaeval. the main purpose of the task is to predict the emotional response to images of natural disasters shared on social media. disaster-related images are generally complex and often evoke an emotional response, making them an ideal use case of visual sentiment analysis. we believe being able to perform meaningful analysis of natural disaster-related data could be of great societal importance, and a joint effort in this regard can open several interesting directions for future research. the task is composed of three sub-tasks, each aiming to explore a different aspect of the challenge. in this paper, we provide a detailed overview of the task, the general motivation of the task, and an overview of the dataset and the metrics to be used for the evaluation of the proposed solutions. ","836":"large datasets of paired images and text have become increasingly popular for learning generic representations for vision and vision-and-language tasks. such datasets have been built by querying search engines or collecting html alt-text -- since web data is noisy, they require complex filtering pipelines to maintain quality. we explore alternate data sources to collect high quality data with minimal filtering. we introduce redcaps -- a large-scale dataset of 12m image-text pairs collected from reddit. images and captions from reddit depict and describe a wide variety of objects and scenes. we collect data from a manually curated set of subreddits, which give coarse image labels and allow us to steer the dataset composition without labeling individual instances. we show that captioning models trained on redcaps produce rich and varied captions preferred by humans, and learn visual representations that transfer to many downstream tasks. ","837":"we present namesakes, a dataset of ambiguously named entities obtained from english-language wikipedia and news articles. it consists of 58862 mentions of 4148 unique entities and their namesakes: 1000 mentions from news, 28843 from wikipedia articles about the entity, and 29019 wikipedia backlink mentions. namesakes should be helpful in establishing challenging benchmarks for the task of named entity linking (nel). ","838":"the generation of personalized dialogue is vital to natural and human-like conversation. typically, personalized dialogue generation models involve conditioning the generated response on the dialogue history and a representation of the persona\/personality of the interlocutor. as it is impractical to obtain the persona\/personality representations for every interlocutor, recent works have explored the possibility of generating personalized dialogue by finetuning the model with dialogue examples corresponding to a given persona instead. however, in real-world implementations, a sufficient number of corresponding dialogue examples are also rarely available. hence, in this paper, we propose a dual latent variable generator (dlvgen) capable of generating personalized dialogue in the absence of any persona\/personality information or any corresponding dialogue examples. unlike prior work, dlvgen models the latent distribution over potential responses as well as the latent distribution over the agent's potential persona. during inference, latent variables are sampled from both distributions and fed into the decoder. empirical results show that dlvgen is capable of generating diverse responses which accurately incorporate the agent's persona. ","839":"we develop a vector space semantics for lambek calculus with soft subexponentials, apply the calculus to construct compositional vector interpretations for parasitic gap noun phrases and discourse units with anaphora and ellipsis, and experiment with the constructions in a distributional sentence similarity task. as opposed to previous work, which used lambek calculus with a relevant modality the calculus used in this paper uses a bounded version of the modality and is decidable. the vector space semantics of this new modality allows us to meaningfully define contraction as projection and provide a linear theory behind what we could previously only achieve via nonlinear maps. ","840":"many language pairs are low resource, meaning the amount and\/or quality of available parallel data is not sufficient to train a neural machine translation (nmt) model which can reach an acceptable standard of accuracy. many works have explored using the readily available monolingual data in either or both of the languages to improve the standard of translation models in low, and even high, resource languages. one of the most successful of such works is the back-translation that utilizes the translations of the target language monolingual data to increase the amount of the training data. the quality of the backward model which is trained on the available parallel data has been shown to determine the performance of the back-translation approach. despite this, only the forward model is improved on the monolingual target data in standard back-translation. a previous study proposed an iterative back-translation approach for improving both models over several iterations. but unlike in the traditional back-translation, it relied on both the target and source monolingual data. this work, therefore, proposes a novel approach that enables both the backward and forward models to benefit from the monolingual target data through a hybrid of self-learning and back-translation respectively. experimental results have shown the superiority of the proposed approach over the traditional back-translation method on english-german low resource neural machine translation. we also proposed an iterative self-learning approach that outperforms the iterative back-translation while also relying only on the monolingual target data and require the training of less models. ","841":"this paper introduces a new romanian speech corpus from the robin project, called robin technical acquisition speech corpus (robintasc). its main purpose was to improve the behaviour of a conversational agent, allowing human-machine interaction in the context of purchasing technical equipment. the paper contains a detailed description of the acquisition process, corpus statistics as well as an evaluation of the corpus influence on a low-latency asr system as well as a dialogue component. ","842":"measuring, evaluating and reducing gender bias has come to the forefront with newer and improved language embeddings being released every few months. but could this bias vary from domain to domain? we see a lot of work to study these biases in various embedding models but limited work has been done to debias indic languages. we aim to measure and study this bias in hindi language, which is a higher-order language (gendered) with reference to english, a lower-order language. to achieve this, we study the variations across domains to quantify if domain embeddings allow us some insight into gender bias for this pair of hindi-english model. we will generate embeddings in four different corpora and compare results by implementing different metrics like with pre-trained state of the art indic-english translation model, which has performed better at many nlp tasks than existing models. ","843":"over the past few years, various word-level textual attack approaches have been proposed to reveal the vulnerability of deep neural networks used in natural language processing. typically, these approaches involve an important optimization step to determine which substitute to be used for each word in the original input. however, current research on this step is still rather limited, from the perspectives of both problem-understanding and problem-solving. in this paper, we address these issues by uncovering the theoretical properties of the problem and proposing an efficient local search algorithm (ls) to solve it. we establish the first provable approximation guarantee on solving the problem in general cases.extensive experiments involving 5 nlp tasks, 8 datasets and 26 nlp models show that ls can largely reduce the number of queries usually by an order of magnitude to achieve high attack success rates. further experiments show that the adversarial examples crafted by ls usually have higher quality, exhibit better transferability, and can bring more robustness improvement to victim models by adversarial training. ","844":"over the years, topic models have provided an efficient way of extracting insights from text. however, while many models have been proposed, none are able to model topic temporality and hierarchy jointly. modelling time provide more precise topics by separating lexically close but temporally distinct topics while modelling hierarchy provides a more detailed view of the content of a document corpus. in this study, we therefore propose a novel method, htmot, to perform hierarchical topic modelling over time. we train htmot using a new implementation of gibbs sampling, which is more efficient. specifically, we show that only applying time modelling to deep sub-topics provides a way to extract specific stories or events while high level topics extract larger themes in the corpus. our results show that our training procedure is fast and can extract accurate high-level topics and temporally precise sub-topics. we measured our model's performance using the word intrusion task and outlined some limitations of this evaluation method, especially for hierarchical models. as a case study, we focused on the various developments in the space industry in 2020. ","845":"hierarchical text classification (htc) to a taxonomy is essential for various real applications butchallenging since htc models often need to process a large volume of data that are severelyimbalanced and have hierarchy dependencies. existing local and global approaches use deep learningto improve htc by reducing the time complexity and incorporating the hierarchy dependencies.however, it is difficult to satisfy both conditions in a single htc model. this paper proposes ahierarchy decoder (hidec) that uses recursive hierarchy decoding based on an encoder-decoderarchitecture. the key idea of the hidec involves decoding a context matrix into a sub-hierarchysequence using recursive hierarchy decoding, while staying aware of hierarchical dependenciesand level information. the hidec is a unified model that incorporates the benefits of existingapproaches, thereby alleviating the aforementioned difficulties without any trade-off. in addition, itcan be applied to both single- and multi-label classification with a minor modification. the superiorityof the proposed model was verified on two benchmark datasets (wos-46985 and rcv1) with anexplanation of the reasons for its success ","846":"controlling the generative model to adapt a new domain with limited samples is a difficult challenge and it is receiving increasing attention. recently, few-shot learning has shown promising process in domain adaptation. however, the texts generated by few-shot learning are typically devoid of linguistic diversity. to address this shortcoming, we frame the adaptation of text generation systems as a reinforcement learning problem and provide a new approach to make text generation models easily adaptable to target domain with the minimal amount of in-domain data. experimental results on five target domains in two few-shot configurations demonstrate that our method significantly outperforms domain adaptation when very few in-domain samples are available. ","847":"by illuminating latent structures in a corpus of text, topic models are an essential tool for categorizing, summarizing, and exploring large collections of documents. probabilistic topic models, such as latent dirichlet allocation (lda), describe how words in documents are generated via a set of latent distributions called topics. recently, the embedded topic model (etm) has extended lda to utilize the semantic information in word embeddings to derive semantically richer topics. as lda and its extensions are unsupervised models, they aren't defined to make efficient use of a user's prior knowledge of the domain. to this end, we propose the keyword assisted embedded topic model (keyetm), which equips etm with the ability to incorporate user knowledge in the form of informative topic-level priors over the vocabulary. using both quantitative metrics and human responses on a topic intrusion task, we demonstrate that keyetm produces better topics than other guided, generative models in the literature. ","848":"automatic speech recognition (asr) of multi-channel multi-speaker overlapped speech remains one of the most challenging tasks to the speech community. in this paper, we look into this challenge by utilizing the location information of target speakers in the 3d space for the first time. to explore the strength of proposed the 3d spatial feature, two paradigms are investigated. 1) a pipelined system with a multi-channel speech separation module followed by the state-of-the-art single-channel asr module; 2) a \"all-in-one\" model where the 3d spatial feature is directly used as an input to asr system without explicit separation modules. both of them are fully differentiable and can be back-propagated end-to-end. we test them on simulated overlapped speech and real recordings. experimental results show that 1) the proposed all-in-one model achieved a comparable error rate to the pipelined system while reducing the inference time by half; 2) the proposed 3d spatial feature significantly outperformed (31\\% cerr) all previous works of using the 1d directional information in both paradigms. ","849":"diet management is key to managing chronic diseases such as diabetes. automated food recommender systems may be able to assist by providing meal recommendations that conform to a user's nutrition goals and food preferences. current recommendation systems suffer from a lack of accuracy that is in part due to a lack of knowledge of food preferences, namely foods users like to and are able to eat frequently. in this work, we propose a method for learning food preferences from food logs, a comprehensive but noisy source of information about users' dietary habits. we also introduce accompanying metrics. the method generates and compares word embeddings to identify the parent food category of each food entry and then calculates the most popular. our proposed approach identifies 82% of a user's ten most frequently eaten foods. our method is publicly available on (https:\/\/github.com\/aametwally\/learningfoodpreferences) ","850":"aspect-based sentiment analysis (absa), exploring sentiment polarity of aspect-given sentence, is a fine-grained task in the field of nature language processing. previously researches typically tend to predict polarity based on the meaning of aspect and opinions. however, those approaches mainly focus on considering relations implicitly at the word level, ignore the historical impact of other positional words when the aspect appears in a certain position. therefore, we propose a position-based contributive embeddings (posce) to highlight the historical reference to special position aspect. contribution of each positional words to the polarity is similar to the process of fairly distributing gains to several actors working in coalition (game theory). therefore, we quote from the method of shapley value and finally gain posce to enhance the aspect-based representation for absa task. furthermore, the posce can also be used for improving performances on multimodal absa task. extensive experiments on both text and text-audio level using semeval dataset show that the mainstream models advance performance in accuracy and f1 (increase 2.82% and 4.21% on average respectively) by applying our posce. ","851":"due to high annotation costs making the best use of existing human-created training data is an important research direction. we, therefore, carry out a systematic evaluation of transferability of bert-based neural ranking models across five english datasets. previous studies focused primarily on zero-shot and few-shot transfer from a large dataset to a dataset with a small number of queries. in contrast, each of our collections has a substantial number of queries, which enables a full-shot evaluation mode and improves reliability of our results. furthermore, since source datasets licences often prohibit commercial use, we compare transfer learning to training on pseudo-labels generated by a bm25 scorer. we find that training on pseudo-labels -- possibly with subsequent fine-tuning using a modest number of annotated queries -- can produce a competitive or better model compared to transfer learning. yet, it is necessary to improve the stability and\/or effectiveness of the few-shot training, which, sometimes, can degrade performance of a pretrained model. ","852":"supporting the current trend in the ai community, we propose the ai journey 2021 challenge called fusion brain which is targeted to make the universal architecture process different modalities (namely, images, texts, and code) and to solve multiple tasks for vision and language. the fusion brain challenge https:\/\/github.com\/sberbank-ai\/fusion_brain_aij2021 combines the following specific tasks: code2code translation, handwritten text recognition, zero-shot object detection, and visual question answering. we have created datasets for each task to test the participants' submissions on it. moreover, we have opened a new handwritten dataset in both russian and english, which consists of 94,130 pairs of images and texts. the russian part of the dataset is the largest russian handwritten dataset in the world. we also propose the baseline solution and corresponding task-specific solutions as well as overall metrics. ","853":"knowledge enriched language representation learning has shown promising performance across various knowledge-intensive nlp tasks. however, existing knowledge based language models are all trained with monolingual knowledge graph data, which limits their application to more languages. in this work, we present a novel framework to pretrain knowledge based multilingual language models (kmlms). we first generate a large amount of code-switched synthetic sentences and reasoning-based multilingual training data using the wikidata knowledge graphs. then based on the intra- and inter-sentence structures of the generated data, we design pretraining tasks to facilitate knowledge learning, which allows the language models to not only memorize the factual knowledge but also learn useful logical patterns. our pretrained kmlms demonstrate significant performance improvements on a wide range of knowledge-intensive cross-lingual nlp tasks, including named entity recognition, factual knowledge retrieval, relation classification, and a new task designed by us, namely, logic reasoning. our code and pretrained language models will be made publicly available. ","854":"this paper presents a novel knowledge distillation method for dialogue sequence labeling. dialogue sequence labeling is a supervised learning task that estimates labels for each utterance in the target dialogue document, and is useful for many applications such as dialogue act estimation. accurate labeling is often realized by a hierarchically-structured large model consisting of utterance-level and dialogue-level networks that capture the contexts within an utterance and between utterances, respectively. however, due to its large model size, such a model cannot be deployed on resource-constrained devices. to overcome this difficulty, we focus on knowledge distillation which trains a small model by distilling the knowledge of a large and high performance teacher model. our key idea is to distill the knowledge while keeping the complex contexts captured by the teacher model. to this end, the proposed method, hierarchical knowledge distillation, trains the small model by distilling not only the probability distribution of the label classification, but also the knowledge of utterance-level and dialogue-level contexts trained in the teacher model by training the model to mimic the teacher model's output in each level. experiments on dialogue act estimation and call scene segmentation demonstrate the effectiveness of the proposed method. ","855":"why do children learn some words before others? understanding individual variability across children and also variability across words, may be informative of the learning processes that underlie language learning. we investigated item-based variability in vocabulary development using lexical properties of distributional statistics derived from a large corpus of child-directed speech. unlike previous analyses, we predicted word trajectories cross-sectionally, shedding light on trends in vocabulary development that may not have been evident at a single time point. we also show that whether one looks at a single age group or across ages as a whole, the best distributional predictor of whether a child knows a word is the number of other known words with which that word tends to co-occur. keywords: age of acquisition; vocabulary development; lexical diversity; child-directed speech; ","856":"topic evolution modeling has received significant attentions in recent decades. although various topic evolution models have been proposed, most studies focus on the single document corpus. however in practice, we can easily access data from multiple sources and also observe relationships between them. then it is of great interest to recognize the relationship between multiple text corpora and further utilize this relationship to improve topic modeling. in this work, we focus on a special type of relationship between two text corpora, which we define as the \"lead-lag relationship\". this relationship characterizes the phenomenon that one text corpus would influence the topics to be discussed in the other text corpus in the future. to discover the lead-lag relationship, we propose a jointly dynamic topic model and also develop an embedding extension to address the modeling problem of large-scale text corpus. with the recognized lead-lag relationship, the similarities of the two text corpora can be figured out and the quality of topic learning in both corpora can be improved. we numerically investigate the performance of the jointly dynamic topic modeling approach using synthetic data. finally, we apply the proposed model on two text corpora consisting of statistical papers and the graduation theses. results show the proposed model can well recognize the lead-lag relationship between the two corpora, and the specific and shared topic patterns in the two corpora are also discovered. ","857":"in the past decade, the social networks platforms and micro-blogging sites such as facebook, twitter, instagram, and weibo have become an integral part of our day-to-day activities and is widely used all over the world by billions of users to share their views and circulate information in the form of messages, pictures, and videos. these are even used by government agencies to spread important information through their verified facebook accounts and official twitter handles, as they can reach a huge population within a limited time window. however, many deceptive activities like propaganda and rumor can mislead users on a daily basis. in these covid times, fake news and rumors are very prevalent and are shared in a huge number which has created chaos in this tough time. and hence, the need for fake news detection in the present scenario is inevitable. in this paper, we survey the recent literature about different approaches to detect fake news over the internet. in particular, we firstly discuss fake news and the various terms related to it that have been considered in the literature. secondly, we highlight the various publicly available datasets and various online tools that are available and can debunk fake news in real-time. thirdly, we describe fake news detection methods based on two broader areas i.e., its content and the social context. finally, we provide a comparison of various techniques that are used to debunk fake news. ","858":"aspect-based sentiment classification aims to predict the sentiment polarity of a specific aspect in a sentence. however, most existing methods attempt to construct dependency relations into a homogeneous dependency graph with the sparsity and ambiguity, which cannot cover the comprehensive contextualized features of short texts or consider any additional node types or semantic relation information. to solve those issues, we present a sentiment analysis model named isomer, which performs a dual-channel attention on heterogeneous dependency graphs incorporating external knowledge, to effectively integrate other additional information. specifically, a transfer-enhanced dual-channel heterogeneous dependency attention network is devised in isomer to model short texts using heterogeneous dependency graphs. these heterogeneous dependency graphs not only consider different types of information but also incorporate external knowledge. experiments studies show that our model outperforms recent models on benchmark datasets. furthermore, the results suggest that our method captures the importance of various information features to focus on informative contextual words. ","859":"the persian language is an inflectional subject-object-verb language. this fact makes persian a more uncertain language. however, using techniques such as zero-width non-joiner (zwnj) recognition, punctuation restoration, and persian ezafe construction will lead us to a more understandable and precise language. in most of the works in persian, these techniques are addressed individually. despite that, we believe that for text refinement in persian, all of these tasks are necessary. in this work, we proposed a virapart framework that uses embedded parsbert in its core for text clarifications. first, used the bert variant for persian following by a classifier layer for classification procedures. next, we combined models outputs to output cleartext. in the end, the proposed model for zwnj recognition, punctuation restoration, and persian ezafe construction performs the averaged f1 macro scores of 96.90%, 92.13%, and 98.50%, respectively. experimental results show that our proposed approach is very effective in text refinement for the persian language. ","860":"numerous visio-linguistic (v+l) representation learning methods have been developed, yet existing datasets do not evaluate the extent to which they represent visual and linguistic concepts in a unified space. inspired by the crosslingual transfer and psycholinguistics literature, we propose a novel evaluation setting for v+l models: zero-shot cross-modal transfer. existing v+l benchmarks also often report global accuracy scores on the entire dataset, rendering it difficult to pinpoint the specific reasoning tasks that models fail and succeed at. to address this issue and enable the evaluation of cross-modal transfer, we present travlr, a synthetic dataset comprising four v+l reasoning tasks. each example encodes the scene bimodally such that either modality can be dropped during training\/testing with no loss of relevant information. travlr's training and testing distributions are also constrained along task-relevant dimensions, enabling the evaluation of out-of-distribution generalisation. we evaluate four state-of-the-art v+l models and find that although they perform well on the test set from the same modality, all models fail to transfer cross-modally and have limited success accommodating the addition or deletion of one modality. in alignment with prior work, we also find these models to require large amounts of data to learn simple spatial relationships. we release travlr as an open challenge for the research community. ","861":"automatically learned vector representations of words, also known as \"word embeddings\", are becoming a basic building block for more and more natural language processing algorithms. there are different ways and tools for constructing word embeddings. most of the approaches rely on raw texts, the construction items being the word occurrences and\/or letter n-grams. more elaborated research is using additional linguistic features extracted after text preprocessing. morphology is clearly served by vector representations constructed from raw texts and letter n-grams. syntax and semantics studies may profit more from the vector representations constructed with additional features such as lemma, part-of-speech, syntactic or semantic dependants associated with each word. one of the key objectives of the reterom project is the development of advanced technologies for romanian natural language processing, including morphological, syntactic and semantic analysis of text. as such, we plan to develop an open-access large library of ready-to-use word embeddings sets, each set being characterized by different parameters: used features (wordforms, letter n-grams, lemmas, poses etc.), vector lengths, window\/context size and frequency thresholds. to this end, the previously created sets of word embeddings (based on word occurrences) on the corola corpus (p\\u{a}i\\c{s} and tufi\\c{s}, 2018) are and will be further augmented with new representations learned from the same corpus by using specific features such as lemmas and parts of speech. furthermore, in order to better understand and explore the vectors, graphical representations will be available by customized interfaces. ","862":"ensuring proper punctuation and letter casing is a key pre-processing step towards applying complex natural language processing algorithms. this is especially significant for textual sources where punctuation and casing are missing, such as the raw output of automatic speech recognition systems. additionally, short text messages and micro-blogging platforms offer unreliable and often wrong punctuation and casing. this survey offers an overview of both historical and state-of-the-art techniques for restoring punctuation and correcting word casing. furthermore, current challenges and research directions are highlighted. ","863":"a knowledge graph is an essential and trending technology with great applications in entity recognition, search, or question answering. there are a plethora of methods in natural language processing for performing the task of named entity recognition; however, there are very few methods that could provide triples for a domain-specific text. in this paper, an effort has been made towards developing a system that could convert the text from a given textbook into triples that can be used to visualize as a knowledge graph and use for further applications. the initial assessment and evaluation gave promising results with an f1 score of 82%. ","864":"this work introduces a new method to consider subjectivity and general context dependency in text analysis and uses as example the detection of emotions conveyed in text. the proposed method takes into account subjectivity using a computational version of the framework theory by marvin minsky (1974) leveraging on the word2vec approach to text vectorization by mikolov et al. (2013), used to generate distributed representation of words based on the context where they appear. our approach is based on three components: 1. a framework\/'room' representing the point of view; 2. a benchmark representing the criteria for the analysis - in this case the emotion classification, from a study of human emotions by robert plutchik (1980); and 3. the document to be analyzed. by using similarity measure between words, we are able to extract the relative relevance of the elements in the benchmark - intensities of emotions in our case study - for the document to be analyzed. our method provides a measure that take into account the point of view of the entity reading the document. this method could be applied to all the cases where evaluating subjectivity is relevant to understand the relative value or meaning of a text. subjectivity can be not limited to human reactions, but it could be used to provide a text with an interpretation related to a given domain (\"room\"). to evaluate our method, we used a test case in the political domain. ","865":"as an effective strategy, data augmentation (da) alleviates data scarcity scenarios where deep learning techniques may fail. it is widely applied in computer vision then introduced to natural language processing and achieves improvements in many tasks. one of the main focuses of the da methods is to improve the diversity of training data, thereby helping the model to better generalize to unseen testing data. in this survey, we frame da methods into three categories based on the diversity of augmented data, including paraphrasing, noising, and sampling. our paper sets out to analyze da methods in detail according to the above categories. further, we also introduce their applications in nlp tasks as well as the challenges. ","866":"practical needs of developing task-oriented dialogue assistants require the ability to understand many languages. novel benchmarks for multilingual natural language understanding (nlu) include monolingual sentences in several languages, annotated with intents and slots. in such setup models for cross-lingual transfer show remarkable performance in joint intent recognition and slot filling. however, existing benchmarks lack of code-switched utterances, which are difficult to gather and label due to complexity in the grammatical structure. the evaluation of nlu models seems biased and limited, since code-switching is being left out of scope.   our work adopts recognized methods to generate plausible and naturally-sounding code-switched utterances and uses them to create a synthetic code-switched test set. based on experiments, we report that the state-of-the-art nlu models are unable to handle code-switching. at worst, the performance, evaluated by semantic accuracy, drops as low as 15\\% from 80\\% across languages. further we show, that pre-training on synthetic code-mixed data helps to maintain performance on the proposed test set at a comparable level with monolingual data. finally, we analyze different language pairs and show that the closer the languages are, the better the nlu model handles their alternation. this is in line with the common understanding of how multilingual models conduct transferring between languages ","867":"this paper is a technical report on our system submitted to the chemical identification task of the biocreative vii track 2 challenge. the main feature of this challenge is that the data consists of full-text articles, while current datasets usually consist of only titles and abstracts. to effectively address the problem, we aim to improve tagging consistency and entity coverage using various methods such as majority voting within the same articles for named entity recognition (ner) and a hybrid approach that combines a dictionary and a neural model for normalization. in the experiments on the nlm-chem dataset, we show that our methods improve models' performance, particularly in terms of recall. finally, in the official evaluation of the challenge, our system was ranked 1st in ner by significantly outperforming the baseline model and more than 80 submissions from 16 teams. ","868":"the system log generated in a computer system refers to large-scale data that are collected simultaneously and used as the basic data for determining simple errors and detecting external adversarial intrusion or the abnormal behaviors of insiders. the aim of system log anomaly detection is to promptly identify anomalies while minimizing human intervention, which is a critical problem in the industry. previous studies performed anomaly detection through algorithms after converting various forms of log data into a standardized template using a parser. these methods involved generating a template for refining the log key. particularly, a template corresponding to a specific event should be defined in advance for all the log data using which the information within the log key may get lost.in this study, we propose lanobert, a parser free system log anomaly detection method that uses the bert model, exhibiting excellent natural language processing performance. the proposed method, lanobert, learns the model through masked language modeling, which is a bert-based pre-training method, and proceeds with unsupervised learning-based anomaly detection using the masked language modeling loss function per log key word during the inference process. lanobert achieved better performance compared to previous methodology in an experiment conducted using benchmark log datasets, hdfs, and bgl, and also compared to certain supervised learning-based models. ","869":"in this paper, we describe the submission of the joint samsung research philippines-konvergen ai team for the wmt'21 large scale multilingual translation task - small track 2. we submit a standard seq2seq transformer model to the shared task without any training or architecture tricks, relying mainly on the strength of our data preprocessing techniques to boost performance. our final submission model scored 22.92 average bleu on the flores-101 devtest set, and scored 22.97 average bleu on the contest's hidden test set, ranking us sixth overall. despite using only a standard transformer, our model ranked first in indonesian to javanese, showing that data preprocessing matters equally, if not more, than cutting edge model architectures and training techniques. ","870":"this study examines the use of natural language processing (nlp) models to evaluate whether language patterns used by item writers in a medical licensure exam might contain evidence of biased or stereotypical language. this type of bias in item language choices can be particularly impactful for items in a medical licensure assessment, as it could pose a threat to content validity and defensibility of test score validity evidence. to the best of our knowledge, this is the first attempt using machine learning (ml) and nlp to explore language bias on a large item bank. using a prediction algorithm trained on clusters of similar item stems, we demonstrate that our approach can be used to review large item banks for potential biased language or stereotypical patient characteristics in clinical science vignettes. the findings may guide the development of methods to address stereotypical language patterns found in test items and enable an efficient updating of those items, if needed, to reflect contemporary norms, thereby improving the evidence to support the validity of the test scores. ","871":"the distribution gap between training datasets and data encountered in production is well acknowledged. training datasets are often constructed over a fixed period of time and by carefully curating the data to be labeled. thus, training datasets may not contain all possible variations of data that could be encountered in real-world production environments. tasked with building an entity resolution system - a model that identifies and consolidates data points that represent the same person - our first model exhibited a clear training-production performance gap. in this case study, we discuss our human-in-the-loop enabled, data-centric solution to closing the training-production performance divergence. we conclude with takeaways that apply to data-centric learning at large. ","872":"dataless text classification, i.e., a new paradigm of weakly supervised learning, refers to the task of learning with unlabeled documents and a few predefined representative words of categories, known as seed words. the recent generative dataless methods construct document-specific category priors by using seed word occurrences only, however, such category priors often contain very limited and even noisy supervised signals. to remedy this problem, in this paper we propose a novel formulation of category prior. first, for each document, we consider its label membership degree by not only counting seed word occurrences, but also using a novel prototype scheme, which captures pseudo-nearest neighboring categories. second, for each label, we consider its frequency prior knowledge of the corpus, which is also a discriminative knowledge for classification. by incorporating the proposed category prior into the previous generative dataless method, we suggest a novel generative dataless method, namely weakly supervised prototype topic model (wsptm). the experimental results on real-world datasets demonstrate that wsptm outperforms the existing baseline methods. ","873":"in this paper, we discuss the development of a multilingual dataset annotated with a hierarchical, fine-grained tagset marking different types of aggression and the \"context\" in which they occur. the context, here, is defined by the conversational thread in which a specific comment occurs and also the \"type\" of discursive role that the comment is performing with respect to the previous comment. the initial dataset, being discussed here (and made available as part of the comma@icon shared task), consists of a total 15,000 annotated comments in four languages - meitei, bangla, hindi, and indian english - collected from various social media platforms such as youtube, facebook, twitter and telegram. as is usual on social media websites, a large number of these comments are multilingual, mostly code-mixed with english. the paper gives a detailed description of the tagset being used for annotation and also the process of developing a multi-label, fine-grained tagset that can be used for marking comments with aggression and bias of various kinds including gender bias, religious intolerance (called communal bias in the tagset), class\/caste bias and ethnic\/racial bias. we also define and discuss the tags that have been used for marking different the discursive role being performed through the comments, such as attack, defend, etc. we also present a statistical analysis of the dataset as well as results of our baseline experiments with developing an automatic aggression identification system using the dataset developed. ","874":"the link prediction is the task of predicting missing relations between entities of the knowledge graph. recent work in link prediction has attempted to provide a model for increasing link prediction accuracy by using more layers in neural network architecture. in this paper, we propose a novel method of refining the knowledge graph so that link prediction operation can be performed more accurately using relatively fast translational models. translational link prediction models, such as transe, transh, transd, have less complexity than deep learning approaches. our method uses the hierarchy of relationships and entities in the knowledge graph to add the entity information as auxiliary nodes to the graph and connect them to the nodes which contain this information in their hierarchy. our experiments show that our method can significantly increase the performance of translational link prediction methods in h@10, mr, mrr. ","875":"we study the fact checking problem, which aims to identify the veracity of a given claim. specifically, we focus on the task of fact extraction and verification (fever) and its accompanied dataset. the task consists of the subtasks of retrieving the relevant documents (and sentences) from wikipedia and validating whether the information in the documents supports or refutes a given claim. this task is essential and can be the building block of applications such as fake news detection and medical claim verification. in this paper, we aim at a better understanding of the challenges of the task by presenting the literature in a structured and comprehensive way. we describe the proposed methods by analyzing the technical perspectives of the different approaches and discussing the performance results on the fever dataset, which is the most well-studied and formally structured dataset on the fact extraction and verification task. we also conduct the largest experimental study to date on identifying beneficial loss functions for the sentence retrieval component. our analysis indicates that sampling negative sentences is important for improving the performance and decreasing the computational complexity. finally, we describe open issues and future challenges, and we motivate future research in the task. ","876":"user posts whose perceived toxicity depends on the conversational context are rare in current toxicity detection datasets. hence, toxicity detectors trained on existing datasets will also tend to disregard context, making the detection of context-sensitive toxicity harder when it does occur. we construct and publicly release a dataset of 10,000 posts with two kinds of toxicity labels: (i) annotators considered each post with the previous one as context; and (ii) annotators had no additional context. based on this, we introduce a new task, context sensitivity estimation, which aims to identify posts whose perceived toxicity changes if the context (previous post) is also considered. we then evaluate machine learning systems on this task, showing that classifiers of practical quality can be developed, and we show that data augmentation with knowledge distillation can improve the performance further. such systems could be used to enhance toxicity detection datasets with more context-dependent posts, or to suggest when moderators should consider the parent posts, which often may be unnecessary and may otherwise introduce significant additional cost. ","877":"we introduce a new language representation model in finance called financial embedding analysis of sentiment (fineas). in financial markets, news and investor sentiment are significant drivers of security prices. thus, leveraging the capabilities of modern nlp approaches for financial sentiment analysis is a crucial component in identifying patterns and trends that are useful for market participants and regulators. in recent years, methods that use transfer learning from large transformer-based language models like bert, have achieved state-of-the-art results in text classification tasks, including sentiment analysis using labelled datasets. researchers have quickly adopted these approaches to financial texts, but best practices in this domain are not well-established. in this work, we propose a new model for financial sentiment analysis based on supervised fine-tuned sentence embeddings from a standard bert model. we demonstrate our approach achieves significant improvements in comparison to vanilla bert, lstm, and finbert, a financial domain specific bert. ","878":"this paper presents a method for controlling the prosody at the phoneme level in an autoregressive attention-based text-to-speech system. instead of learning latent prosodic features with a variational framework as is commonly done, we directly extract phoneme-level f0 and duration features from the speech data in the training set. each prosodic feature is discretized using unsupervised clustering in order to produce a sequence of prosodic labels for each utterance. this sequence is used in parallel to the phoneme sequence in order to condition the decoder with the utilization of a prosodic encoder and a corresponding attention module. experimental results show that the proposed method retains the high quality of generated speech, while allowing phoneme-level control of f0 and duration. by replacing the f0 cluster centroids with musical notes, the model can also provide control over the note and octave within the range of the speaker. ","879":"we consider tensor grammars, which are an example of \\commutative\" grammars, based on the classical (rather than intuitionistic) linear logic. they can be seen as a surface representation of abstract categorial grammars acg in the sense that derivations of acg translate to derivations of tensor grammars and this translation is isomorphic on the level of string languages. the basic ingredient are tensor terms, which can be seen as encoding and generalizing proof-nets. using tensor terms makes the syntax extremely simple and a direct geometric meaning becomes transparent. then we address the problem of encoding noncommutative operations in our setting. this turns out possible after enriching the system with new unary operators. the resulting system allows representing both acg and lambek grammars as conservative fragments, while the formalism remains, as it seems to us, rather simple and intuitive. ","880":"this paper presents an expressive speech synthesis architecture for modeling and controlling the speaking style at a word level. it attempts to learn word-level stylistic and prosodic representations of the speech data, with the aid of two encoders. the first one models style by finding a combination of style tokens for each word given the acoustic features, and the second outputs a word-level sequence conditioned only on the phonetic information in order to disentangle it from the style information. the two encoder outputs are aligned and concatenated with the phoneme encoder outputs and then decoded with a non-attentive tacotron model. an extra prior encoder is used to predict the style tokens autoregressively, in order for the model to be able to run without a reference utterance. we find that the resulting model gives both word-level and global control over the style, as well as prosody transfer capabilities. ","881":"this paper presents a method for phoneme-level prosody control of f0 and duration on a multispeaker text-to-speech setup, which is based on prosodic clustering. an autoregressive attention-based model is used, incorporating multispeaker architecture modules in parallel to a prosody encoder. several improvements over the basic single-speaker method are proposed that increase the prosodic control range and coverage. more specifically we employ data augmentation, f0 normalization, balanced clustering for duration, and speaker-independent prosodic clustering. these modifications enable fine-grained phoneme-level prosody control for all speakers contained in the training set, while maintaining the speaker identity. the model is also fine-tuned to unseen speakers with limited amounts of data and it is shown to maintain its prosody control capabilities, verifying that the speaker-independent prosodic clustering is effective. experimental results verify that the model maintains high output speech quality and that the proposed method allows efficient prosody control within each speaker's range despite the variability that a multispeaker setting introduces. ","882":"lattices form a compact representation of multiple hypotheses generated from an automatic speech recognition system and have been shown to improve performance of downstream tasks like spoken language understanding and speech translation, compared to using one-best hypothesis. in this work, we look into the effectiveness of lattice cues for rescoring n-best lists in second-pass. we encode lattices with a recurrent network and train an attention encoder-decoder model for n-best rescoring. the rescoring model with attention to lattices achieves 4-5% relative word error rate reduction over first-pass and 6-8% with attention to both lattices and acoustic features. we show that rescoring models with attention to lattices outperform models with attention to n-best hypotheses. we also study different ways to incorporate lattice weights in the lattice encoder and demonstrate their importance for n-best rescoring. ","883":"newspaper reports provide a rich source of information on the unfolding of public debate on specific policy fields that can serve as basis for inquiry in political science. such debates are often triggered by critical events, which attract public attention and incite the reactions of political actors: crisis sparks the debate. however, due to the challenges of reliable annotation and modeling, few large-scale datasets with high-quality annotation are available. this paper introduces debatenet2.0, which traces the political discourse on the european refugee crisis in the german quality newspaper taz during the year 2015. the core units of our annotation are political claims (requests for specific actions to be taken within the policy field) and the actors who make them (politicians, parties, etc.). the contribution of this paper is twofold. first, we document and release debatenet2.0 along with its companion r package, mardyr, guiding the reader through the practical and conceptual issues related to the annotation of policy debates in newspapers. second, we outline and apply a discourse network analysis (dna) to debatenet2.0, comparing two crucial moments of the policy debate on the 'refugee crisis': the migration flux through the mediterranean in april\/may and the one along the balkan route in september\/october. besides the released resources and the case-study, our contribution is also methodological: we talk the reader through the steps from a newspaper article to a discourse network, demonstrating that there is not just one discourse network for the german migration debate, but multiple ones, depending on the topic of interest (political actors, policy fields, time spans). ","884":"the pre-trained language models have achieved great successes in various natural language understanding (nlu) tasks due to its capacity to capture the deep contextualized information in text by pre-training on large-scale corpora. in this technical report, we present our practice of pre-training language models named nezha (neural contextualized representation for chinese language understanding) on chinese corpora and finetuning for the chinese nlu tasks. the current version of nezha is based on bert with a collection of proven improvements, which include functional relative positional encoding as an effective positional encoding scheme, whole word masking strategy, mixed precision training and the lamb optimizer in training the models. the experimental results show that nezha achieves the state-of-the-art performances when finetuned on several representative chinese tasks, including named entity recognition (people's daily ner), sentence matching (lcqmc), chinese sentiment classification (chnsenti) and natural language inference (xnli). ","885":"the main approaches to sentiment analysis are rule-based methods and ma-chine learning, in particular, deep neural network models with the trans-former architecture, including bert. the performance of neural network models in the tasks of sentiment analysis is superior to the performance of rule-based methods. the reasons for this situation remain unclear due to the poor interpretability of deep neural network models. one of the main keys to understanding the fundamental differences between the two approaches is the analysis of how sentiment lexicon is taken into account in neural network models. to this end, we study the attention weights matrices of the russian-language rubert model. we fine-tune rubert on sentiment text corpora and compare the distributions of attention weights for sentiment and neutral lexicons. it turns out that, on average, 3\/4 of the heads of various model var-iants statistically pay more attention to the sentiment lexicon compared to the neutral one. ","886":"the performance of sentiment analysis methods has greatly increased in recent years. this is due to the use of various models based on the transformer architecture, in particular bert. however, deep neural network models are difficult to train and poorly interpretable. an alternative approach is rule-based methods using sentiment lexicons. they are fast, require no training, and are well interpreted. but recently, due to the widespread use of deep learning, lexicon-based methods have receded into the background. the purpose of the article is to study the performance of the so-cal and sentistrength lexicon-based methods, adapted for the russian language. we have tested these methods, as well as the rubert neural network model, on 16 text corpora and have analyzed their results. rubert outperforms both lexicon-based methods on average, but so-cal surpasses rubert for four corpora out of 16. ","887":"in this paper, we propose an approach to improve image captioning solution for images with novel objects that do not have caption labels in the training dataset. we refer to our approach as partially-supervised novel object captioning (ps-noc). ps-noc is agnostic to model architecture, and primarily focuses on the training approach that uses existing fully paired image-caption data and the images with only the novel object detection labels (partially paired data). we create synthetic paired captioning data for novel objects by leveraging context from existing image-caption pairs. we then create pseudo-label captions for partially paired images with novel objects, and use this additional data to fine-tune the captioning model. we also propose a variant of scst within ps-noc, called scst-f1, that directly optimizes the f1-score of novel objects. using a popular captioning model (up-down) as baseline, ps-noc sets new state-of-the-art results on held-out ms coco out-of-domain test split, i.e., 85.9 f1-score and 103.8 cider. this is an improvement of 85.9 and 34.1 points respectively compared to baseline model that does not use partially paired data during training. we also perform detailed ablation studies to demonstrate the effectiveness of our approach. ","888":"the visual question answering (vqa) task utilizes both visual image and language analysis to answer a textual question with respect to an image. it has been a popular research topic with an increasing number of real-world applications in the last decade. this paper describes our recent research of alicemind-mmu (alibaba's collection of encoder-decoders from machine intelligence lab of damo academy - multimedia understanding) that obtains similar or even slightly better results than human being does on vqa. this is achieved by systematically improving the vqa pipeline including: (1) pre-training with comprehensive visual and textual feature representation; (2) effective cross-modal interaction with learning to attend; and (3) a novel knowledge mining framework with specialized expert modules for the complex vqa task. treating different types of visual questions with corresponding expertise needed plays an important role in boosting the performance of our vqa architecture up to the human level. an extensive set of experiments and analysis are conducted to demonstrate the effectiveness of the new research work. ","889":"radiology reports are unstructured and contain the imaging findings and corresponding diagnoses transcribed by radiologists which include clinical facts and negated and\/or uncertain statements. extracting pathologic findings and diagnoses from radiology reports is important for quality control, population health, and monitoring of disease progress. existing works, primarily rely either on rule-based systems or transformer-based pre-trained model fine-tuning, but could not take the factual and uncertain information into consideration, and therefore generate false-positive outputs. in this work, we introduce three sedulous augmentation techniques which retain factual and critical information while generating augmentations for contrastive learning. we introduce radbert-cl, which fuses these information into bluebert via a self-supervised contrastive loss. our experiments on mimic-cxr show superior performance of radbert-cl on fine-tuning for multi-class, multi-label report classification. we illustrate that when few labeled data are available, radbert-cl outperforms conventional sota transformers (bert\/bluebert) by significantly larger margins (6-11%). we also show that the representations learned by radbert-cl can capture critical medical information in the latent space. ","890":"understanding the influence of a training instance on a neural network model leads to improving interpretability. however, it is difficult and inefficient to evaluate the influence, which shows how a model's prediction would be changed if a training instance were not used. in this paper, we propose an efficient method for estimating the influence. our method is inspired by dropout, which zero-masks a sub-network and prevents the sub-network from learning each training instance. by switching between dropout masks, we can use sub-networks that learned or did not learn each training instance and estimate its influence. through experiments with bert and vggnet on classification datasets, we demonstrate that the proposed method can capture training influences, enhance the interpretability of error predictions, and cleanse the training dataset for improving generalization. ","891":"automated question quality rating (aqqr) aims to evaluate question quality through computational means, thereby addressing emerging challenges in online learnersourced question repositories. existing methods for aqqr rely solely on explicitly-defined criteria such as readability and word count, while not fully utilising the power of state-of-the-art deep-learning techniques. we propose deepqr, a novel neural-network model for aqqr that is trained using multiple-choice-question (mcq) datasets collected from peerwise, a widely-used learnersourcing platform. along with designing deepqr, we investigate models based on explicitly-defined features, or semantic features, or both. we also introduce a self-attention mechanism to capture semantic correlations between mcq components, and a contrastive-learning approach to acquire question representations using quality ratings. extensive experiments on datasets collected from eight university-level courses illustrate that deepqr has superior performance over six comparative models. ","892":"in this paper, we propose a three-stage training methodology to improve the speech recognition accuracy of low-resource languages. we explore and propose an effective combination of techniques such as transfer learning, encoder freezing, data augmentation using text-to-speech (tts), and semi-supervised learning (ssl). to improve the accuracy of a low-resource italian asr, we leverage a well-trained english model, unlabeled text corpus, and unlabeled audio corpus using transfer learning, tts augmentation, and ssl respectively. in the first stage, we use transfer learning from a well-trained english model. this primarily helps in learning the acoustic information from a resource-rich language. this stage achieves around 24% relative word error rate (wer) reduction over the baseline. in stage two, we utilize unlabeled text data via tts data-augmentation to incorporate language information into the model. we also explore freezing the acoustic encoder at this stage. tts data augmentation helps us further reduce the wer by ~ 21% relatively. finally, in stage three we reduce the wer by another 4% relative by using ssl from unlabeled audio data. overall, our two-pass speech recognition system with a monotonic chunkwise attention (mocha) in the first pass and a full-attention in the second pass achieves a wer reduction of ~ 42% relative to the baseline. ","893":"we present samanantar, the largest publicly available parallel corpora collection for indic languages. the collection contains a total of 49.7 million sentence pairs between english and 11 indic languages (from two language families). specifically, we compile 12.4 million sentence pairs from existing, publicly-available parallel corpora, and additionally mine 37.4 million sentence pairs from the web, resulting in a 4x increase. we mine the parallel sentences from the web by combining many corpora, tools, and methods: (a) web-crawled monolingual corpora, (b) document ocr for extracting sentences from scanned documents, (c) multilingual representation models for aligning sentences, and (d) approximate nearest neighbor search for searching in a large collection of sentences. human evaluation of samples from the newly mined corpora validate the high quality of the parallel sentences across 11 languages. further, we extract 83.4 million sentence pairs between all 55 indic language pairs from the english-centric parallel corpus using english as the pivot language. we trained multilingual nmt models spanning all these languages on samanantar, which outperform existing models and baselines on publicly available benchmarks, such as flores, establishing the utility of samanantar. our data and models are available publicly at https:\/\/indicnlp.ai4bharat.org\/samanantar\/ and we hope they will help advance research in nmt and multilingual nlp for indic languages. ","894":"the design or simulation analysis of special equipment products must follow the national standards, and hence it may be necessary to repeatedly consult the contents of the standards in the design process. however, it is difficult for the traditional question answering system based on keyword retrieval to give accurate answers to technical questions. therefore, we use natural language processing techniques to design a question answering system for the decision-making process in pressure vessel design. to solve the problem of insufficient training data for the technology question answering system, we propose a method to generate questions according to a declarative sentence from several different dimensions so that multiple question-answer pairs can be obtained from a declarative sentence. in addition, we designed an interactive attention model based on a bidirectional long short-term memory (bilstm) network to improve the performance of the similarity comparison of two question sentences. finally, the performance of the question answering system was tested on public and technical domain datasets. ","895":"deep learning models named transformers achieved state-of-the-art results in a vast majority of nlp tasks at the cost of increased computational complexity and high memory consumption. using the transformer model in real-time inference becomes a major challenge when implemented in production, because it requires expensive computational resources. the more executions of a transformer are needed the lower the overall throughput is, and switching to the smaller encoders leads to the decrease of accuracy. our paper is devoted to the problem of how to choose the right architecture for the ranking step of the information retrieval pipeline, so that the number of required calls of transformer encoder is minimal with the maximum achievable quality of ranking. we investigated several late-interaction models such as colbert and poly-encoder architectures along with their modifications. also, we took care of the memory footprint of the search index and tried to apply the learning-to-hash method to binarize the output vectors from the transformer encoders. the results of the evaluation are provided using trec 2019-2021 and ms marco dev datasets. ","896":"we propose a zero-shot learning relation classification (zslrc) framework that improves on state-of-the-art by its ability to recognize novel relations that were not present in training data. the zero-shot learning approach mimics the way humans learn and recognize new concepts with no prior knowledge. to achieve this, zslrc uses advanced prototypical networks that are modified to utilize weighted side (auxiliary) information. zslrc's side information is built from keywords, hypernyms of name entities, and labels and their synonyms. zslrc also includes an automatic hypernym extraction framework that acquires hypernyms of various name entities directly from the web. zslrc improves on state-of-the-art few-shot learning relation classification methods that rely on labeled training data and is therefore applicable more widely even in real-world scenarios where some relations have no corresponding labeled examples for training. we present results using extensive experiments on two public datasets (nyt and fewrel) and show that zslrc significantly outperforms state-of-the-art methods on supervised learning, few-shot learning, and zero-shot learning tasks. our experimental results also demonstrate the effectiveness and robustness of our proposed model. ","897":"in this paper, we propose to build a stylish image captioning model through a multi-style multi modality mechanism (2m). we demonstrate that with 2m, we can build an effective stylish captioner and that multi-references produced by the model can also support explaining the model through identifying erroneous input features on faulty examples. we show how this 2m mechanism can be used to build stylish captioning models and show how these models can be utilized to provide explanations of likely errors in the models. ","898":"to tackle the conundrum of detecting offensive comments\/posts which are considerably informal, unstructured, miswritten and code-mixed, we introduce two inventive methods in this research paper. offensive comments\/posts on the social media platforms, can affect an individual, a group or underage alike. in order to classify comments\/posts in two popular dravidian languages, tamil and malayalam, as a part of the hasoc - dravidiancodemix fire 2021 shared task, we employ two transformer-based prototypes which successfully stood in the top 8 for all the tasks. the codes for our approach can be viewed and utilized. ","899":"we present the results of the dravidian-codemix shared task held at fire 2021, a track on sentiment analysis for dravidian languages in code-mixed text. we describe the task, its organization, and the submitted systems. this shared task is the continuation of last year's dravidian-codemix shared task held at fire 2020. this year's tasks included code-mixing at the intra-token and inter-token levels. additionally, apart from tamil and malayalam, kannada was also introduced. we received 22 systems for tamil-english, 15 systems for malayalam-english, and 15 for kannada-english. the top system for tamil-english, malayalam-english and kannada-english scored weighted average f1-score of 0.711, 0.804, and 0.630, respectively. in summary, the quality and quantity of the submission show that there is great interest in dravidian languages in code-mixed setting and state of the art in this domain still needs more improvement. ","900":"we observe a recent behaviour on social media, in which users intentionally remove consonantal dots from arabic letters, in order to bypass content-classification algorithms. content classification is typically done by fine-tuning pre-trained language models, which have been recently employed by many natural-language-processing applications. in this work we study the effect of applying pre-trained arabic language models on \"undotted\" arabic texts. we suggest several ways of supporting undotted texts with pre-trained models, without additional training, and measure their performance on two arabic natural-language-processing downstream tasks. the results are encouraging; in one of the tasks our method shows nearly perfect performance. ","901":"transformer-based models are widely used in natural language processing (nlp). central to the transformer model is the self-attention mechanism, which captures the interactions of token pairs in the input sequences and depends quadratically on the sequence length. training such models on longer sequences is expensive. in this paper, we show that a bernoulli sampling attention mechanism based on locality sensitive hashing (lsh), decreases the quadratic complexity of such models to linear. we bypass the quadratic cost by considering self-attention as a sum of individual tokens associated with bernoulli random variables that can, in principle, be sampled at once by a single hash (although in practice, this number may be a small constant). this leads to an efficient sampling scheme to estimate self-attention which relies on specific modifications of lsh (to enable deployment on gpu architectures). we evaluate our algorithm on the glue benchmark with standard 512 sequence length where we see favorable performance relative to a standard pretrained transformer. on the long range arena (lra) benchmark, for evaluating performance on long sequences, our method achieves results consistent with softmax self-attention but with sizable speed-ups and memory savings and often outperforms other efficient self-attention methods. our code is available at https:\/\/github.com\/mlpen\/yoso ","902":"multi-hop qa with annotated supporting facts, which is the task of reading comprehension (rc) considering the interpretability of the answer, has been extensively studied. in this study, we define an interpretable reading comprehension (irc) model as a pipeline model with the capability of predicting unanswerable queries. the irc model justifies the answer prediction by establishing consistency between the predicted supporting facts and the actual rationale for interpretability. the irc model detects unanswerable questions, instead of outputting the answer forcibly based on the insufficient information, to ensure the reliability of the answer. we also propose an end-to-end training method for the pipeline rc model. to evaluate the interpretability and the reliability, we conducted the experiments considering unanswerability in a multi-hop question for a given passage. we show that our end-to-end trainable pipeline model outperformed a non-interpretable model on our modified hotpotqa dataset. experimental results also show that the irc model achieves comparable results to the previous non-interpretable models in spite of the trade-off between prediction performance and interpretability. ","903":"this pilot study focuses on a tool called l2l that allows second language (l2) learners to visualise and analyse their zoom interactions with native speakers. l2l uses the zoom transcript to automatically generate conversation metrics and its playback feature with timestamps allows students to replay any chosen portion of the conversation for post-session reflection and self-review. this exploratory study investigates a seven-week teletandem project, where undergraduate students from an irish university learning french (b2) interacted with their peers from a french university learning english (b2+) via zoom. the data collected from a survey (n=43) and semi-structured interviews (n=35) show that the quantitative conversation metrics and qualitative review of the synchronous content helped raise students' confidence levels while engaging with native speakers. furthermore, it allowed them to set tangible goals to improve their participation, and be more aware of what, why and how they are learning. ","904":"how do neural language models keep track of number agreement between subject and verb? we show that `diagnostic classifiers', trained to predict number from the internal states of a language model, provide a detailed understanding of how, when, and where this information is represented. moreover, they give us insight into when and where number information is corrupted in cases where the language model ends up making agreement errors. to demonstrate the causal role played by the representations we find, we then use agreement information to influence the course of the lstm during the processing of difficult sentences. results from such an intervention reveal a large increase in the language model's accuracy. together, these results show that diagnostic classifiers give us an unrivalled detailed look into the representation of linguistic information in neural models, and demonstrate that this knowledge can be used to improve their performance. ","905":"many unanswerable adversarial questions fool the question-answer (qa) system with some plausible answers. building a robust, frequently asked questions (faq) chatbot needs a large amount of diverse adversarial examples. recent question generation methods are ineffective at generating many high-quality and diverse adversarial question-answer pairs from unstructured text. we propose the diversity controllable semantically valid adversarial attacker (dcsa), a high-quality, diverse, controllable method to generate standard and adversarial samples with a semantic graph. the fluent and semantically generated qa pairs fool our passage retrieval model successfully. after that, we conduct a study on the robustness and generalization of the qa model with generated qa pairs among different domains. we find that the generated data set improves the generalizability of the qa model to the new target domain and the robustness of the qa model to detect unanswerable adversarial questions. ","906":"automatic speech recognition (asr) is a complex and challenging task. in recent years, there have been significant advances in the area. in particular, for the brazilian portuguese (bp) language, there were about 376 hours public available for asr task until the second half of 2020. with the release of new datasets in early 2021, this number increased to 574 hours. the existing resources, however, are composed of audios containing only read and prepared speech. there is a lack of datasets including spontaneous speech, which are essential in different asr applications. this paper presents coraa (corpus of annotated audios) v1. with 290.77 hours, a publicly available dataset for asr in bp containing validated pairs (audio-transcription). coraa also contains european portuguese audios (4.69 hours). we also present a public asr model based on wav2vec 2.0 xlsr-53 and fine-tuned over coraa. our model achieved a word error rate of 24.18% on coraa test set and 20.08% on common voice test set. when measuring the character error rate, we obtained 11.02% and 6.34% for coraa and common voice, respectively. coraa corpora were assembled to both improve asr models in bp with phenomena from spontaneous speech and motivate young researchers to start their studies on asr for portuguese. all the corpora are publicly available at https:\/\/github.com\/nilc-nlp\/coraa under the cc by-nc-nd 4.0 license. ","907":"limited computational budgets often prevent transformers from being used in production and from having their high accuracy utilized. tinybert addresses the computational efficiency by self-distilling bert into a smaller transformer representation having fewer layers and smaller internal embedding. however, tinybert's performance drops when we reduce the number of layers by 50%, and drops even more abruptly when we reduce the number of layers by 75% for advanced nlp tasks such as span question answering. additionally, a separate model must be trained for each inference scenario with its distinct computational budget. in this work we present dynamic-tinybert, a tinybert model that utilizes sequence-length reduction and hyperparameter optimization for enhanced inference efficiency per any computational budget. dynamic-tinybert is trained only once, performing on-par with bert and achieving an accuracy-speedup trade-off superior to any other efficient approaches (up to 3.3x with <1% loss-drop). upon publication, the code to reproduce our work will be open-sourced. ","908":"aspect-based sentiment analysis (absa) task consists of three typical subtasks: aspect term extraction, opinion term extraction, and sentiment polarity classification. these three subtasks are usually performed jointly to save resources and reduce the error propagation in the pipeline. however, most of the existing joint models only focus on the benefits of encoder sharing between subtasks but ignore the difference. therefore, we propose a joint absa model, which not only enjoys the benefits of encoder sharing but also focuses on the difference to improve the effectiveness of the model. in detail, we introduce a dual-encoder design, in which a pair encoder especially focuses on candidate aspect-opinion pair classification, and the original encoder keeps attention on sequence labeling. empirical results show that our proposed model shows robustness and significantly outperforms the previous state-of-the-art on four benchmark datasets. ","909":"data-hungry deep neural networks have established themselves as the standard for many nlp tasks including the traditional sequence tagging ones. despite their state-of-the-art performance on high-resource languages, they still fall behind of their statistical counter-parts in low-resource scenarios. one methodology to counter attack this problem is text augmentation, i.e., generating new synthetic training data points from existing data. although nlp has recently witnessed a load of textual augmentation techniques, the field still lacks a systematic performance analysis on a diverse set of languages and sequence tagging tasks. to fill this gap, we investigate three categories of text augmentation methodologies which perform changes on the syntax (e.g., cropping sub-sentences), token (e.g., random word insertion) and character (e.g., character swapping) levels. we systematically compare them on part-of-speech tagging, dependency parsing and semantic role labeling for a diverse set of language families using various models including the architectures that rely on pretrained multilingual contextualized language models such as mbert. augmentation most significantly improves dependency parsing, followed by part-of-speech tagging and semantic role labeling. we find the experimented techniques to be effective on morphologically rich languages in general rather than analytic languages such as vietnamese. our results suggest that the augmentation techniques can further improve over strong baselines based on mbert. we identify the character-level methods as the most consistent performers, while synonym replacement and syntactic augmenters provide inconsistent improvements. finally, we discuss that the results most heavily depend on the task, language pair, and the model type. ","910":"despite their success, modern language models are fragile. even small changes in their training pipeline can lead to unexpected results. we study this phenomenon by examining the robustness of albert (arxiv:1909.11942) in combination with stochastic weight averaging (swa) (arxiv:1803.05407) -- a cheap way of ensembling -- on a sentiment analysis task (sst-2). in particular, we analyze swa's stability via checklist criteria (arxiv:2005.04118), examining the agreement on errors made by models differing only in their random seed. we hypothesize that swa is more stable because it ensembles model snapshots taken along the gradient descent trajectory. we quantify stability by comparing the models' mistakes with fleiss' kappa (fleiss, 1971) and overlap ratio scores. we find that swa reduces error rates in general; yet the models still suffer from their own distinct biases (according to checklist). ","911":"rampant use of offensive language on social media led to recent efforts on automatic identification of such language. though offensive language has general characteristics, attacks on specific entities may exhibit distinct phenomena such as malicious alterations in the spelling of names. in this paper, we present a method for identifying entity specific offensive language. we employ two key insights, namely that replies on twitter often imply opposition and some accounts are persistent in their offensiveness towards specific targets. using our methodology, we are able to collect thousands of targeted offensive tweets. we show the efficacy of the approach on arabic tweets with 13% and 79% relative f1-measure improvement in entity specific offensive language detection when using deep-learning based and support vector machine based classifiers respectively. further, expanding the training set with automatically identified offensive tweets directed at multiple entities can improve f1-measure by 48%. ","912":"this study addresses a series of methodological questions that arise when modeling inflectional morphology with linear discriminative learning. taking the semi-productive german noun system as example, we illustrate how decisions made about the representation of form and meaning influence model performance. we clarify that for modeling frequency effects in learning, it is essential to make use of incremental learning rather than the endstate of learning. we also discuss how the model can be set up to approximate the learning of inflected words in context. in addition, we illustrate how in this approach the wug task can be modeled in considerable detail. in general, the model provides an excellent memory for known words, but appropriately shows more limited performance for unseen data, in line with the semi-productivity of german noun inflection and generalization performance of native german speakers. ","913":"large-scale language models such as gpt-3 are excellent few-shot learners, allowing them to be controlled via natural text prompts. recent studies report that prompt-based direct classification eliminates the need for fine-tuning but lacks data and inference scalability. this paper proposes a novel data augmentation technique that leverages large-scale language models to generate realistic text samples from a mixture of real samples. we also propose utilizing soft-labels predicted by the language models, effectively distilling knowledge from the large-scale language models and creating textual perturbations simultaneously. we perform data augmentation experiments on diverse classification tasks and show that our method hugely outperforms existing text augmentation methods. ablation studies and a qualitative analysis provide more insights into our approach. ","914":"this paper presents the results and analyses stemming from the first voiceprivacy 2020 challenge which focuses on developing anonymization solutions for speech technology. we provide a systematic overview of the challenge design with an analysis of submitted systems and evaluation results. in particular, we describe the voice anonymization task and datasets used for system development and evaluation. also, we present different attack models and the associated objective and subjective evaluation metrics. we introduce two anonymization baselines and provide a summary description of the anonymization systems developed by the challenge participants. we report objective and subjective evaluation results for baseline and submitted systems. in addition, we present experimental results for alternative privacy metrics and attack models developed as a part of the post-evaluation analysis. finally, we summarize our insights and observations that will influence the design of the next voiceprivacy challenge edition and some directions for future voice anonymization research. ","915":"constructing a large-scale labeled dataset in the real world, especially for high-level tasks (eg, visual question answering), can be expensive and time-consuming. in addition, with the ever-growing amounts of data and architecture complexity, active learning has become an important aspect of computer vision research. in this work, we address active learning in the multi-modal setting of visual question answering (vqa). in light of the multi-modal inputs, image and question, we propose a novel method for effective sample acquisition through the use of ad hoc single-modal branches for each input to leverage its information. our mutual information based sample acquisition strategy single-modal entropic measure (smem) in addition to our self-distillation technique enables the sample acquisitor to exploit all present modalities and find the most informative samples. our novel idea is simple to implement, cost-efficient, and readily adaptable to other multi-modal tasks. we confirm our findings on various vqa datasets through state-of-the-art performance by comparing to existing active learning baselines. ","916":"in the summarization domain, a key requirement for summaries is to be factually consistent with the input document. previous work has found that natural language inference (nli) models do not perform competitively when applied to inconsistency detection. in this work, we revisit the use of nli for inconsistency detection, finding that past work suffered from a mismatch in input granularity between nli datasets (sentence-level), and inconsistency detection (document level). we provide a highly effective and light-weight method called summacconv that enables nli models to be successfully used for this task by segmenting documents into sentence units and aggregating scores between pairs of sentences. on our newly introduced benchmark called summac (summary consistency) consisting of six large inconsistency detection datasets, summacconv obtains state-of-the-art results with a balanced accuracy of 74.4%, a 5% point improvement compared to prior work. we make the models and datasets available: https:\/\/github.com\/tingofurro\/summac ","917":"current language models can generate high-quality text. are they simply copying text they have seen before, or have they learned generalizable linguistic abstractions? to tease apart these possibilities, we introduce raven, a suite of analyses for assessing the novelty of generated text, focusing on sequential structure (n-grams) and syntactic structure. we apply these analyses to four neural language models (an lstm, a transformer, transformer-xl, and gpt-2). for local structure - e.g., individual dependencies - model-generated text is substantially less novel than our baseline of human-generated text from each model's test set. for larger-scale structure - e.g., overall sentence structure - model-generated text is as novel or even more novel than the human-generated baseline, but models still sometimes copy substantially, in some cases duplicating passages over 1,000 words long from the training set. we also perform extensive manual analysis showing that gpt-2's novel text is usually well-formed morphologically and syntactically but has reasonably frequent semantic issues (e.g., being self-contradictory). ","918":"twitch chats pose a unique problem in natural language understanding due to a large presence of neologisms, specifically emotes. there are a total of 8.06 million emotes, over 400k of which were used in the week studied. there is virtually no information on the meaning or sentiment of emotes, and with a constant influx of new emotes and drift in their frequencies, it becomes impossible to maintain an updated manually-labeled dataset. our paper makes a two fold contribution. first we establish a new baseline for sentiment analysis on twitch data, outperforming the previous supervised benchmark by 7.9% points. secondly, we introduce a simple but powerful unsupervised framework based on word embeddings and k-nn to enrich existing models with out-of-vocabulary knowledge. this framework allows us to auto-generate a pseudo-dictionary of emotes and we show that we can nearly match the supervised benchmark above even when injecting such emote knowledge into sentiment classifiers trained on extraneous datasets such as movie reviews or twitter. ","919":"state of the art language models return a natural language text continuation from any piece of input text. this ability to generate coherent text extensions implies significant sophistication, including a knowledge of grammar and semantics. in this paper, we propose a mathematical framework for passing from probability distributions on extensions of given texts, such as the ones learned by today's large language models, to an enriched category containing semantic information. roughly speaking, we model probability distributions on texts as a category enriched over the unit interval. objects of this category are expressions in language, and hom objects are conditional probabilities that one expression is an extension of another. this category is syntactical -- it describes what goes with what. then, via the yoneda embedding, we pass to the enriched category of unit interval-valued copresheaves on this syntactical category. this category of enriched copresheaves is semantic -- it is where we find meaning, logical operations such as entailment, and the building blocks for more elaborate semantic concepts. ","920":"state-of-the-art language models can match human performance on many tasks, but they still struggle to robustly perform multi-step mathematical reasoning. to diagnose the failures of current models and support research, we introduce gsm8k, a dataset of 8.5k high quality linguistically diverse grade school math word problems. we find that even the largest transformer models fail to achieve high test performance, despite the conceptual simplicity of this problem distribution. to increase performance, we propose training verifiers to judge the correctness of model completions. at test time, we generate many candidate solutions and select the one ranked highest by the verifier. we demonstrate that verification significantly improves performance on gsm8k, and we provide strong empirical evidence that verification scales more effectively with increased data than a finetuning baseline. ","921":"we present medcod, a medically-accurate, emotive, diverse, and controllable dialog system with a unique approach to the natural language generator module. medcod has been developed and evaluated specifically for the history taking task. it integrates the advantage of a traditional modular approach to incorporate (medical) domain knowledge with modern deep learning techniques to generate flexible, human-like natural language expressions. two key aspects of medcod's natural language output are described in detail. first, the generated sentences are emotive and empathetic, similar to how a doctor would communicate to the patient. second, the generated sentence structures and phrasings are varied and diverse while maintaining medical consistency with the desired medical concept (provided by the dialogue manager module of medcod). experimental results demonstrate the effectiveness of our approach in creating a human-like medical dialogue system. relevant code is available at https:\/\/github.com\/curai\/curai-research\/tree\/main\/medcod ","922":"sequence models are a critical component of modern nlp systems, but their predictions are difficult to explain. we consider model explanations though rationales, subsets of context that can explain individual model predictions. we find sequential rationales by solving a combinatorial optimization: the best rationale is the smallest subset of input tokens that would predict the same output as the full sequence. enumerating all subsets is intractable, so we propose an efficient greedy algorithm to approximate this objective. the algorithm, which is called greedy rationalization, applies to any model. for this approach to be effective, the model should form compatible conditional distributions when making predictions on incomplete subsets of the context. this condition can be enforced with a short fine-tuning step. we study greedy rationalization on language modeling and machine translation. compared to existing baselines, greedy rationalization is best at optimizing the combinatorial objective and provides the most faithful rationales. on a new dataset of annotated sequential rationales, greedy rationales are most similar to human rationales. ","923":"most existing approaches for knowledge base question answering (kbqa) focus on a specific underlying knowledge base either because of inherent assumptions in the approach, or because evaluating it on a different knowledge base requires non-trivial changes. however, many popular knowledge bases share similarities in their underlying schemas that can be leveraged to facilitate generalization across knowledge bases. to achieve this generalization, we introduce a kbqa framework based on a 2-stage architecture that explicitly separates semantic parsing from the knowledge base interaction, facilitating transfer learning across datasets and knowledge graphs. we show that pretraining on datasets with a different underlying knowledge base can nevertheless provide significant performance gains and reduce sample complexity. our approach achieves comparable or state-of-the-art performance for lc-quad (dbpedia), webqsp (freebase), simplequestions (wikidata) and metaqa (wikimovies-kg). ","924":"we present the winning entry to the multilingual lexical normalization (multilexnorm) shared task at w-nut 2021 (van der goot et al., 2021a), which evaluates lexical-normalization systems on 12 social media datasets in 11 languages. we base our solution on a pre-trained byte-level language model, byt5 (xue et al., 2021a), which we further pre-train on synthetic data and then fine-tune on authentic normalization data. our system achieves the best performance by a wide margin in intrinsic evaluation, and also the best performance in extrinsic evaluation through dependency parsing. the source code is released at https:\/\/github.com\/ufal\/multilexnorm2021 and the fine-tuned models at https:\/\/huggingface.co\/ufal. ","925":"we propose a character-based nonautoregressive gec approach, with automatically generated character transformations. recently, per-word classification of correction edits has proven an efficient, parallelizable alternative to current encoder-decoder gec systems. we show that word replacement edits may be suboptimal and lead to explosion of rules for spelling, diacritization and errors in morphologically rich languages, and propose a method for generating character transformations from gec corpus. finally, we train character transformation models for czech, german and russian, reaching solid results and dramatic speedup compared to autoregressive systems. the source code is released at https:\/\/github.com\/ufal\/wnut2021_character_transformations_gec. ","926":"schemata are structured representations of complex tasks that can aid artificial intelligence by allowing models to break down complex tasks into intermediate steps. we propose a novel system that induces schemata from web videos and generalizes them to capture unseen tasks with the goal of improving video retrieval performance. our system proceeds in three major phases: (1) given a task with related videos, we construct an initial schema for a task using a joint video-text model to match video segments with text representing steps from wikihow; (2) we generalize schemata to unseen tasks by leveraging language models to edit the text within existing schemata. through generalization, we can allow our schemata to cover a more extensive range of tasks with a small amount of learning data; (3) we conduct zero-shot instructional video retrieval with the unseen task names as the queries. our schema-guided approach outperforms existing methods for video retrieval, and we demonstrate that the schemata induced by our system are better than those generated by other models. ","927":"sensitivity of deep-neural models to input noise is known to be a challenging problem. in nlp, model performance often deteriorates with naturally occurring noise, such as spelling errors. to mitigate this issue, models may leverage artificially noised data. however, the amount and type of generated noise has so far been determined arbitrarily. we therefore propose to model the errors statistically from grammatical-error-correction corpora. we present a thorough evaluation of several state-of-the-art nlp systems' robustness in multiple languages, with tasks including morpho-syntactic analysis, named entity recognition, neural machine translation, a subset of the glue benchmark and reading comprehension. we also compare two approaches to address the performance drop: a) training the nlp models with noised data generated by our framework; and b) reducing the input noise with external system for natural language correction. the code is released at https:\/\/github.com\/ufal\/kazitext. ","928":"anticipating the outbreak of a food crisis is crucial to efficiently allocate emergency relief and reduce human suffering. however, existing food insecurity early warning systems rely on risk measures that are often delayed, outdated, or incomplete. here, we leverage recent advances in deep learning to extract high-frequency precursors to food crises from the text of a large corpus of news articles about fragile states published between 1980 and 2020. our text features are causally grounded, interpretable, validated by existing data, and allow us to predict 32% more food crises than existing models up to three months ahead of time at the district level across 15 fragile states. these results could have profound implications on how humanitarian aid gets allocated and open new avenues for machine learning to improve decision making in data-scarce environments. ","929":"data-centric ai has recently proven to be more effective and high-performance, while traditional model-centric ai delivers fewer and fewer benefits. it emphasizes improving the quality of datasets to achieve better model performance. this field has significant potential because of its great practicability and getting more and more attention. however, we have not seen significant research progress in this field, especially in nlp. we propose dataclue, which is the first data-centric benchmark applied in nlp field. we also provide three simple but effective baselines to foster research in this field (improve macro-f1 up to 5.7% point). in addition, we conduct comprehensive experiments with human annotators and show the hardness of dataclue. we also try an advanced method: the forgetting informed bootstrapping label correction method. all the resources related to dataclue, including datasets, toolkit, leaderboard, and baselines, is available online at https:\/\/github.com\/cluebenchmark\/dataclue ","930":"fact-checking has become increasingly important due to the speed with which both information and misinformation can spread in the modern media ecosystem. therefore, researchers have been exploring how fact-checking can be automated, using techniques based on natural language processing, machine learning, knowledge representation, and databases to automatically predict the veracity of claims. in this paper, we survey automated fact-checking stemming from natural language processing, and discuss its connections to related tasks and disciplines. in this process, we present an overview of existing datasets and models, aiming to unify the various definitions given and identify common concepts. finally, we highlight challenges for future research. ","931":"judging the readability of text has many important applications, for instance when performing text simplification or when sourcing reading material for language learners. in this paper, we present a 518 participant study which investigates how scrolling behaviour relates to the readability of a text. we make our dataset publicly available and show that (1) there are statistically significant differences in the way readers interact with text depending on the text level, (2) such measures can be used to predict the readability of text, and (3) the background of a reader impacts their reading interactions and the factors contributing to text difficulty. ","932":"recent years have seen a growing adoption of transformer models such as bert in natural language processing and even in computer vision. however, due to their size, there has been limited adoption of such models within resource-constrained computing environments. this paper proposes novel pruning algorithm to compress transformer models by eliminating redundant attention heads. we apply the a* search algorithm to obtain a pruned model with strict accuracy guarantees. our results indicate that the method could eliminate as much as 40% of the attention heads in the bert transformer model with no loss in accuracy. ","933":"in this paper, a text-to-rapping\/singing system is introduced, which can be adapted to any speaker's voice. it utilizes a tacotron-based multispeaker acoustic model trained on read-only speech data and which provides prosody control at the phoneme level. dataset augmentation and additional prosody manipulation based on traditional dsp algorithms are also investigated. the neural tts model is fine-tuned to an unseen speaker's limited recordings, allowing rapping\/singing synthesis with the target's speaker voice. the detailed pipeline of the system is described, which includes the extraction of the target pitch and duration values from an a capella song and their conversion into target speaker's valid range of notes before synthesis. an additional stage of prosodic manipulation of the output via wsola is also investigated for better matching the target duration values. the synthesized utterances can be mixed with an instrumental accompaniment track to produce a complete song. the proposed system is evaluated via subjective listening tests as well as in comparison to an available alternate system which also aims to produce synthetic singing voice from read-only training data. results show that the proposed approach can produce high quality rapping\/singing voice with increased naturalness. ","934":"the idea of using phonological features instead of phonemes as input to sequence-to-sequence tts has been recently proposed for zero-shot multilingual speech synthesis. this approach is useful for code-switching, as it facilitates the seamless uttering of foreign text embedded in a stream of native text. in our work, we train a language-agnostic multispeaker model conditioned on a set of phonologically derived features common across different languages, with the goal of achieving cross-lingual speaker adaptation. we first experiment with the effect of language phonological similarity on cross-lingual tts of several source-target language combinations. subsequently, we fine-tune the model with very limited data of a new speaker's voice in either a seen or an unseen language, and achieve synthetic speech of equal quality, while preserving the target speaker's identity. with as few as 32 and 8 utterances of target speaker data, we obtain high speaker similarity scores and naturalness comparable to the corresponding literature. in the extreme case of only 2 available adaptation utterances, we find that our model behaves as a few-shot learner, as the performance is similar in both the seen and unseen adaptation language scenarios. ","935":"data augmentation techniques are widely used for enhancing the performance of machine learning models by tackling class imbalance issues and data sparsity. state-of-the-art generative language models have been shown to provide significant gains across different nlp tasks. however, their applicability to data augmentation for text classification tasks in few-shot settings have not been fully explored, especially for specialised domains. in this paper, we leverage gpt-2 (radford a et al, 2019) for generating artificial training instances in order to improve classification performance. our aim is to analyse the impact the selection process of seed training examples have over the quality of gpt-generated samples and consequently the classifier performance. we perform experiments with several seed selection strategies that, among others, exploit class hierarchical structures and domain expert selection. our results show that fine-tuning gpt-2 in a handful of label instances leads to consistent classification improvements and outperform competitive baselines. finally, we show that guiding this process through domain expert selection can lead to further improvements, which opens up interesting research avenues for combining generative models and active learning. ","936":"this paper presents an end-to-end text-to-speech system with low latency on a cpu, suitable for real-time applications. the system is composed of an autoregressive attention-based sequence-to-sequence acoustic model and the lpcnet vocoder for waveform generation. an acoustic model architecture that adopts modules from both the tacotron 1 and 2 models is proposed, while stability is ensured by using a recently proposed purely location-based attention mechanism, suitable for arbitrary sentence length generation. during inference, the decoder is unrolled and acoustic feature generation is performed in a streaming manner, allowing for a nearly constant latency which is independent from the sentence length. experimental results show that the acoustic model can produce feature sequences with minimal latency about 31 times faster than real-time on a computer cpu and 6.5 times on a mobile cpu, enabling it to meet the conditions required for real-time applications on both devices. the full end-to-end system can generate almost natural quality speech, which is verified by listening tests. ","937":"natural language understanding's relation extraction makes innovative and encouraging novel business concepts possible and facilitates new digitilized decision-making processes. current approaches allow the extraction of relations with a fixed number of entities as attributes. extracting relations with an arbitrary amount of attributes requires complex systems and costly relation-trigger annotations to assist these systems. we introduce multi-attribute relation extraction (mare) as an assumption-less problem formulation with two approaches, facilitating an explicit mapping from business use cases to the data annotations. avoiding elaborated annotation constraints simplifies the application of relation extraction approaches. the evaluation compares our models to current state-of-the-art event extraction and binary relation extraction methods. our approaches show improvement compared to these on the extraction of general multi-attribute relations. ","938":"aspect sentiment triplet extraction (aste) aims to recognize targets, their sentiment polarities and opinions explaining the sentiment from a sentence. aste could be naturally divided into 3 atom subtasks, namely target detection, opinion detection and sentiment classification. we argue that the proper subtask combination, compositional feature extraction for target-opinion pairs, and interaction between subtasks would be the key to success. prior work, however, may fail on `one-to-many' or `many-to-one' situations or derive non-existent sentiment triplets due to defective subtask formulation, sub-optimal feature representation or the lack of subtask interaction. in this paper, we divide aste into target-opinion joint detection and sentiment classification subtasks, which is in line with human cognition, and correspondingly utilize sequence encoder and table encoder to handle them. table encoder extracts sentiment at token-pair level, so that the compositional feature between targets and opinions can be easily captured. to establish explicit interaction between subtasks, we utilize the table representation to guide the sequence encoding, and inject the sequence features back into the table encoder. experiments show that our model outperforms state-of-the-art methods on six popular aste datasets. ","939":"we establish a rubric-based human evaluation protocol for image captioning models. our scoring rubrics and their definitions are carefully developed based on machine- and human-generated captions on the mscoco dataset. each caption is evaluated along two main dimensions in a tradeoff (precision and recall) as well as other aspects that measure the text quality (fluency, conciseness, and inclusive language). our evaluations demonstrate several critical problems of the current evaluation practice. human-generated captions show substantially higher quality than machine-generated ones, especially in coverage of salient information (i.e., recall), while all automatic metrics say the opposite. our rubric-based results reveal that clipscore, a recent metric that uses image features, better correlates with human judgments than conventional text-only metrics because it is more sensitive to recall. we hope that this work will promote a more transparent evaluation protocol for image captioning and its automatic metrics. ","940":"automated scoring (as), the natural language processing task of scoring essays and speeches in an educational testing setting, is growing in popularity and being deployed across contexts from government examinations to companies providing language proficiency services. however, existing systems either forgo human raters entirely, thus harming the reliability of the test, or score every response by both human and machine thereby increasing costs. we target the spectrum of possible solutions in between, making use of both humans and machines to provide a higher quality test while keeping costs reasonable to democratize access to as. in this work, we propose a combination of the existing paradigms, sampling responses to be scored by humans intelligently. we propose reward sampling and observe significant gains in accuracy (19.80% increase on average) and quadratic weighted kappa (qwk) (25.60% on average) with a relatively small human budget (30% samples) using our proposed sampling. the accuracy increase observed using standard random and importance sampling baselines are 8.6% and 12.2% respectively. furthermore, we demonstrate the system's model agnostic nature by measuring its performance on a variety of models currently deployed in an as setting as well as pseudo models. finally, we propose an algorithm to estimate the accuracy\/qwk with statistical guarantees (our code is available at https:\/\/git.io\/j1ioy). ","941":"enormous hope in the efficacy of vaccines became recently a successful reality in the fight against the covid-19 pandemic. however, vaccine hesitancy, fueled by exposure to social media misinformation about covid-19 vaccines became a major hurdle. therefore, it is essential to automatically detect where misinformation about covid-19 vaccines on social media is spread and what kind of misinformation is discussed, such that inoculation interventions can be delivered at the right time and in the right place, in addition to interventions designed to address vaccine hesitancy. this paper is addressing the first step in tackling hesitancy against covid-19 vaccines, namely the automatic detection of known misinformation about the vaccines on twitter, the social media platform that has the highest volume of conversations about covid-19 and its vaccines. we present covaxlies, a new dataset of tweets judged relevant to several misinformation targets about covid-19 vaccines on which a novel method of detecting misinformation was developed. our method organizes covaxlies in a misinformation knowledge graph as it casts misinformation detection as a graph link prediction problem. the misinformation detection method detailed in this paper takes advantage of the link scoring functions provided by several knowledge embedding methods. the experimental results demonstrate the superiority of this method when compared with classification-based methods, widely used currently. ","942":"we explore the use of large pretrained language models as few-shot semantic parsers. the goal in semantic parsing is to generate a structured meaning representation given a natural language input. however, language models are trained to generate natural language. to bridge the gap, we use language models to paraphrase inputs into a controlled sublanguage resembling english that can be automatically mapped to a target meaning representation. our results demonstrate that with only a small amount of data and very little code to convert into english-like representations, our blueprint for rapidly bootstrapping semantic parsers leads to surprisingly effective performance on multiple community tasks, greatly exceeding baseline methods also trained on the same limited data. ","943":"recent advances in text autoencoders have significantly improved the quality of the latent space, which enables models to generate grammatical and consistent text from aggregated latent vectors. as a successful application of this property, unsupervised opinion summarization models generate a summary by decoding the aggregated latent vectors of inputs. more specifically, they perform the aggregation via simple average. however, little is known about how the vector aggregation step affects the generation quality. in this study, we revisit the commonly used simple average approach by examining the latent space and generated summaries. we found that text autoencoders tend to generate overly generic summaries from simply averaged latent vectors due to an unexpected $l_2$-norm shrinkage in the aggregated latent vectors, which we refer to as summary vector degeneration. to overcome this issue, we develop a framework coop, which searches input combinations for the latent vector aggregation using input-output word overlap. experimental results show that coop successfully alleviates the summary vector degeneration issue and establishes new state-of-the-art performance on two opinion summarization benchmarks. code is available at \\url{https:\/\/github.com\/megagonlabs\/coop}. ","944":"labelled \"ground truth\" datasets are routinely used to evaluate and audit ai algorithms applied in high-stakes settings. however, there do not exist widely accepted benchmarks for the quality of labels in these datasets. we provide empirical evidence that quality of labels can significantly distort the results of algorithmic audits in real-world settings. using data annotators typically hired by ai firms in india, we show that fidelity of the ground truth data can lead to spurious differences in performance of asrs between urban and rural populations. after a rigorous, albeit expensive, label cleaning process, these disparities between groups disappear. our findings highlight how trade-offs between label quality and data annotation costs can complicate algorithmic audits in practice. they also emphasize the need for development of consensus-driven, widely accepted benchmarks for label quality. ","945":"this paper is a comparison study in the context of topic detection on covid-19 data. there are various approaches for topic detection, among which the clustering approach is selected in this paper. clustering requires distance and calculating distance needs embedding. the aim of this research is to simultaneously study the three factors of embedding methods, distance metrics and clustering methods and their interaction. a dataset including one-month tweets collected with covid-19-related hashtags is used for this study. five methods, from earlier to new methods, are selected among the embedding methods: word2vec, fasttext, glove, bert and t5. five clustering methods are investigated in this paper that are: k-means, dbscan, optics, spectral and jarvis-patrick. euclidian distance and cosine distance as the most important distance metrics in this field are also examined. first, more than 7,500 tests are performed to tune the parameters. then, all the different combinations of embedding methods with distance metrics and clustering methods are investigated by silhouette metric. the number of these combinations is 50 cases. first, the results of these 50 tests are examined. then, the rank of each method is taken into account in all the tests of that method. finally, the major variables of the research (embedding methods, distance metrics and clustering methods) are studied separately. averaging is performed over the control variables to neutralize their effect. the experimental results show that t5 strongly outperforms other embedding methods in terms of silhouette metric. in terms of distance metrics, cosine distance is weakly better. dbscan is also superior to other methods in terms of clustering methods. ","946":"this paper provides an overview of nvidia nemo's neural machine translation systems for the constrained data track of the wmt21 news and biomedical shared translation tasks. our news task submissions for english-german (en-de) and english-russian (en-ru) are built on top of a baseline transformer-based sequence-to-sequence model. specifically, we use a combination of 1) checkpoint averaging 2) model scaling 3) data augmentation with backtranslation and knowledge distillation from right-to-left factorized models 4) finetuning on test sets from previous years 5) model ensembling 6) shallow fusion decoding with transformer language models and 7) noisy channel re-ranking. additionally, our biomedical task submission for english-russian uses a biomedically biased vocabulary and is trained from scratch on news task data, medically relevant text curated from the news task dataset, and biomedical data provided by the shared task. our news system achieves a sacrebleu score of 39.5 on the wmt'20 en-de test set outperforming the best submission from last year's task of 38.8. our biomedical task ru-en and en-ru systems reach bleu scores of 43.8 and 40.3 respectively on the wmt'20 biomedical task test set, outperforming the previous year's best submissions. ","947":"sequence-to-sequence learning with neural networks has become the de facto standard for sequence prediction tasks. this approach typically models the local distribution over the next word with a powerful neural network that can condition on arbitrary context. while flexible and performant, these models often require large datasets for training and can fail spectacularly on benchmarks designed to test for compositional generalization. this work explores an alternative, hierarchical approach to sequence-to-sequence learning with quasi-synchronous grammars, where each node in the target tree is transduced by a node in the source tree. both the source and target trees are treated as latent and induced during training. we develop a neural parameterization of the grammar which enables parameter sharing over the combinatorial space of derivation rules without the need for manual feature engineering. we apply this latent neural grammar to various domains -- a diagnostic language navigation task designed to test for compositional generalization (scan), style transfer, and small-scale machine translation -- and find that it performs respectably compared to standard baselines. ","948":"document ai, or document intelligence, is a relatively new research topic that refers to the techniques for automatically reading, understanding, and analyzing business documents. it is an important research direction for natural language processing and computer vision. in recent years, the popularity of deep learning technology has greatly advanced the development of document ai, such as document layout analysis, visual information extraction, document visual question answering, document image classification, etc. this paper briefly reviews some of the representative models, tasks, and benchmark datasets. furthermore, we also introduce early-stage heuristic rule-based document analysis, statistical machine learning algorithms, and deep learning approaches especially pre-training methods. finally, we look into future directions for document ai research. ","949":"many educational technologies use artificial intelligence (ai) that presents generated or produced language to the learner. we contend that all language, including all ai communication, encodes information about the identity of the human or humans who contributed to crafting the language. with ai communication, however, the user may index identity information that does not match the source. this can lead to representational harms if language associated with one cultural group is presented as \"standard\" or \"neutral\", if the language advantages one group over another, or if the language reinforces negative stereotypes. in this work, we discuss a case study using a visual question generation (vqg) task involving gathering crowdsourced data from targeted demographic groups. generated questions will be presented to human evaluators to understand how they index the identity behind the language, whether and how they perceive any representational harms, and how they would ideally address any such harms caused by ai communication. we reflect on the educational applications of this work as well as the implications for equality, diversity, and inclusion (edi). ","950":"transformer-based language models trained on large text corpora have enjoyed immense popularity in the natural language processing community and are commonly used as a starting point for downstream tasks. while these models are undeniably useful, it is a challenge to quantify their performance beyond traditional accuracy metrics. in this paper, we compare bert-based language models through snapshots of acquired knowledge at sequential stages of the training process. structured relationships from training corpora may be uncovered through querying a masked language model with probing tasks. we present a methodology to unveil a knowledge acquisition timeline by generating knowledge graph extracts from cloze \"fill-in-the-blank\" statements at various stages of roberta's early training. we extend this analysis to a comparison of pretrained variations of bert models (distilbert, bert-base, roberta). this work proposes a quantitative framework to compare language models through knowledge graph extraction (ged, graph2vec) and showcases a part-of-speech analysis (posor) to identify the linguistic strengths of each model variant. using these metrics, machine learning practitioners can compare models, diagnose their models' behavioral strengths and weaknesses, and identify new targeted datasets to improve model performance. ","951":"it may be difficult for some individuals to open up and share their thoughts and feelings in front of a mental health expert. for those who are more at ease with a virtual agent, conversational agents can serve as an intermediate step in the right direction. the conversational agent must therefore be empathetic and able to conduct free-flowing conversations. to this effect, we present an approach for creating a generative empathetic open-domain chatbot that can be used for mental health applications. we leverage large scale pre-training and empathetic conversational data to make the responses more empathetic in nature and a multi-turn dialogue arrangement to maintain context. our models achieve state-of-the-art results on the empathetic dialogues test set. ","952":"while wikipedia has been utilized for fact-checking and claim verification to debunk misinformation and disinformation, it is essential to either improve article quality and rule out noisy articles. self-contradiction is one of the low-quality article types in wikipedia. in this work, we propose a task of detecting self-contradiction articles in wikipedia. based on the \"self-contradictory\" template, we create a novel dataset for the self-contradiction detection task. conventional contradiction detection focuses on comparing pairs of sentences or claims, but self-contradiction detection needs to further reason the semantics of an article and simultaneously learn the contradiction-aware comparison from all pairs of sentences. therefore, we present the first model, pairwise contradiction neural network (pcnn), to not only effectively identify self-contradiction articles, but also highlight the most contradiction pairs of contradiction sentences. the main idea of pcnn is two-fold. first, to mitigate the effect of data scarcity on self-contradiction articles, we pre-train the module of pairwise contradiction learning using snli and mnli benchmarks. second, we select top-k sentence pairs with the highest contradiction probability values and model their correlation to determine whether the corresponding article belongs to self-contradiction. experiments conducted on the proposed wikicontradiction dataset exhibit that pcnn can generate promising performance and comprehensively highlight the sentence pairs the contradiction locates. ","953":"deep transformer neural network models have improved the predictive accuracy of intelligent text processing systems in the biomedical domain. they have obtained state-of-the-art performance scores on a wide variety of biomedical and clinical natural language processing (nlp) benchmarks. however, the robustness and reliability of these models has been less explored so far. neural nlp models can be easily fooled by adversarial samples, i.e. minor changes to input that preserve the meaning and understandability of the text but force the nlp system to make erroneous decisions. this raises serious concerns about the security and trust-worthiness of biomedical nlp systems, especially when they are intended to be deployed in real-world use cases. we investigated the robustness of several transformer neural language models, i.e. biobert, scibert, biomed-roberta, and bio-clinicalbert, on a wide range of biomedical and clinical text processing tasks. we implemented various adversarial attack methods to test the nlp systems in different attack scenarios. experimental results showed that the biomedical nlp models are sensitive to adversarial samples; their performance dropped in average by 21 and 18.9 absolute percent on character-level and word-level adversarial noise, respectively. conducting extensive adversarial training experiments, we fine-tuned the nlp models on a mixture of clean samples and adversarial inputs. results showed that adversarial training is an effective defense mechanism against adversarial noise; the models robustness improved in average by 11.3 absolute percent. in addition, the models performance on clean data increased in average by 2.4 absolute present, demonstrating that adversarial training can boost generalization abilities of biomedical nlp systems. ","954":"when a new computer security vulnerability is publicly disclosed, only a textual description of it is available. cybersecurity experts later provide an analysis of the severity of the vulnerability using the common vulnerability scoring system (cvss). specifically, the different characteristics of the vulnerability are summarized into a vector (consisting of a set of metrics), from which a severity score is computed. however, because of the high number of vulnerabilities disclosed everyday this process requires lot of manpower, and several days may pass before a vulnerability is analyzed. we propose to leverage recent advances in the field of natural language processing (nlp) to determine the cvss vector and the associated severity score of a vulnerability from its textual description in an explainable manner. to this purpose, we trained multiple bert classifiers, one for each metric composing the cvss vector. experimental results show that our trained classifiers are able to determine the value of the metrics of the cvss vector with high accuracy. the severity score computed from the predicted cvss vector is also very close to the real severity score attributed by a human expert. for explainability purpose, gradient-based input saliency method was used to determine the most relevant input words for a given prediction made by our classifiers. often, the top relevant words include terms in agreement with the rationales of a human cybersecurity expert, making the explanation comprehensible for end-users. ","955":"novel concepts are essential for design innovation and can be generated with the aid of data stimuli and computers. however, current generative design algorithms focus on diagrammatic or spatial concepts that are either too abstract to understand or too detailed for early phase design exploration. this paper explores the uses of generative pre-trained transformers (gpt) for natural language design concept generation. our experiments involve the use of gpt-2 and gpt-3 for different creative reasonings in design tasks. both show reasonably good performance for verbal design concept generation. ","956":"dynamic models of paradigm change can elucidate how the simplest of processes may lead to unexpected outcomes, and thereby can reveal new potential explanations for observed linguistic phenomena. ackerman & malouf (2015) present a model in which inflectional systems reduce in disorder through the action of an attraction-only dynamic, in which lexemes only ever grow more similar to one another over time. here we emphasise that: (1) attraction-only models cannot evolve the structured diversity which characterises true inflectional systems, because they inevitably remove all variation; and (2) models with both attraction and repulsion enable the emergence of systems that are strikingly reminiscent of morphomic structure such as inflection classes. thus, just one small ingredient -- change based on dissimilarity -- separates models that tend inexorably to uniformity, and which therefore are implausible for inflectional morphology, from those which evolve stable, morphome-like structure. these models have the potential to alter how we attempt to account for morphological complexity. ","957":"the progress in natural language processing (nlp) research over the last years, offers novel business opportunities for companies, as automated user interaction or improved data analysis. building sophisticated nlp applications requires dealing with modern machine learning (ml) technologies, which impedes enterprises from establishing successful nlp projects. our experience in applied nlp research projects shows that the continuous integration of research prototypes in production-like environments with quality assurance builds trust in the software and shows convenience and usefulness regarding the business goal. we introduce stamp 4 nlp as an iterative and incremental process model for developing nlp applications. with stamp 4 nlp, we merge software engineering principles with best practices from data science. instantiating our process model allows efficiently creating prototypes by utilizing templates, conventions, and implementations, enabling developers and data scientists to focus on the business goals. due to our iterative-incremental approach, businesses can deploy an enhanced version of the prototype to their software environment after every iteration, maximizing potential business value and trust early and avoiding the cost of successful yet never deployed experiments. ","958":"the introduction of covid-19 lockdown measures and an outlook on return to normality are demanding societal changes. among the most pressing questions is how individuals adjust to the pandemic. this paper examines the emotional responses to the pandemic in a repeated-measures design. data (n=1698) were collected in april 2020 (during strict lockdown measures) and in april 2021 (when vaccination programmes gained traction). we asked participants to report their emotions and express these in text data. statistical tests revealed an average trend towards better adjustment to the pandemic. however, clustering analyses suggested a more complex heterogeneous pattern with a well-coping and a resigning subgroup of participants. linguistic computational analyses uncovered that topics and n-gram frequencies shifted towards attention to the vaccination programme and away from general worrying. implications for public mental health efforts in identifying people at heightened risk are discussed. the dataset is made publicly available. ","959":"despite great success on many machine learning tasks, deep neural networks are still vulnerable to adversarial samples. while gradient-based adversarial attack methods are well-explored in the field of computer vision, it is impractical to directly apply them in natural language processing due to the discrete nature of text. to bridge this gap, we propose a general framework to adapt existing gradient-based methods to craft textual adversarial samples. in this framework, gradient-based continuous perturbations are added to the embedding layer and are amplified in the forward propagation process. then the final perturbed latent representations are decoded with a mask language model head to obtain potential adversarial samples. in this paper, we instantiate our framework with \\textbf{t}extual \\textbf{p}rojected \\textbf{g}radient \\textbf{d}escent (\\textbf{tpgd}). we conduct comprehensive experiments to evaluate our framework by performing transfer black-box attacks on bert, roberta and albert on three benchmark datasets. experimental results demonstrate our method achieves an overall better performance and produces more fluent and grammatical adversarial samples compared to strong baseline methods. all the code and data will be made public. ","960":"due to the recent advances of natural language processing, several works have applied the pre-trained masked language model (mlm) of bert to the post-correction of speech recognition. however, existing pre-trained models only consider the semantic correction while the phonetic features of words is neglected. the semantic-only post-correction will consequently decrease the performance since homophonic errors are fairly common in chinese asr. in this paper, we proposed a novel approach to collectively exploit the contextualized representation and the phonetic information between the error and its replacing candidates to alleviate the error rate of chinese asr. our experiment results on real world speech recognition datasets showed that our proposed method has evidently lower cer than the baseline model, which utilized a pre-trained bert mlm as the corrector. ","961":"neural text generation models are likely to suffer from the low-diversity problem. various decoding strategies and training-based methods have been proposed to promote diversity only by exploiting contextual features, but rarely do they consider incorporating syntactic structure clues. in this work, we propose using linguistic annotation, i.e., part-of-speech (pos), to guide the text generation. in detail, we introduce pos guided softmax to explicitly model two posterior probabilities: (i) next-pos, and (ii) next-token from the vocabulary of the target pos. a pos guided sampling strategy is further proposed to address the low-diversity problem by enriching the diversity of pos. extensive experiments and human evaluations demonstrate that, compared with existing state-of-the-art methods, our pos guided softmax and sampling (posg) can generate more diverse text while maintaining comparable quality. ","962":"this paper describes netmarble's submission to wmt21 automatic post-editing (ape) shared task for the english-german language pair. first, we propose a curriculum training strategy in training stages. facebook fair's wmt19 news translation model was chosen to engage the large and powerful pre-trained neural networks. then, we post-train the translation model with different levels of data at each training stages. as the training stages go on, we make the system learn to solve multiple tasks by adding extra information at different training stages gradually. we also show a way to utilize the additional data in large volume for ape tasks. for further improvement, we apply multi-task learning strategy with the dynamic weight average during the fine-tuning stage. to fine-tune the ape corpus with limited data, we add some related subtasks to learn a unified representation. finally, for better performance, we leverage external translations as augmented machine translation (mt) during the post-training and fine-tuning. as experimental results show, our ape system significantly improves the translations of provided mt results by -2.848 and +3.74 on the development dataset in terms of ter and bleu, respectively. it also demonstrates its effectiveness on the test dataset with higher quality than the development dataset. ","963":"we solve university level probability and statistics questions by program synthesis using openai's codex, a transformer trained on text and fine-tuned on code. we transform course problems from mit's 18.05 introduction to probability and statistics and harvard's stat110 probability into programming tasks. we then execute the generated code to get a solution. since these course questions are grounded in probability, we often aim to have codex generate probabilistic programs that simulate a large number of probabilistic dependencies to compute its solution. our approach requires prompt engineering to transform the question from its original form to an explicit, tractable form that results in a correct program and solution. to estimate the amount of work needed to translate an original question into its tractable form, we measure the similarity between original and transformed questions. our work is the first to introduce a new dataset of university-level probability and statistics problems and solve these problems in a scalable fashion using the program synthesis capabilities of large language models. ","964":"automatic meeting summarization is becoming increasingly popular these days. the ability to automatically summarize meetings and to extract key information could greatly increase the efficiency of our work and life. in this paper, we experiment with different approaches to improve the performance of query-based meeting summarization. we started with hmnet\\cite{hmnet}, a hierarchical network that employs both a word-level transformer and a turn-level transformer, as the baseline. we explore the effectiveness of pre-training the model with a large news-summarization dataset. we investigate adding the embeddings of queries as a part of the input vectors for query-based summarization. furthermore, we experiment with extending the locate-then-summarize approach of qmsum\\cite{qmsum} with an intermediate clustering step. lastly, we compare the performance of our baseline models with bart, a state-of-the-art language model that is effective for summarization. we achieved improved performance by adding query embeddings to the input of the model, by using bart as an alternative language model, and by using clustering methods to extract key information at utterance level before feeding the text into summarization models. ","965":"speech summarization, which generates a text summary from speech, can be achieved by combining automatic speech recognition (asr) and text summarization (ts). with this cascade approach, we can exploit state-of-the-art models and large training datasets for both subtasks, i.e., transformer for asr and bidirectional encoder representations from transformers (bert) for ts. however, asr errors directly affect the quality of the output summary in the cascade approach. we propose a cascade speech summarization model that is robust to asr errors and that exploits multiple hypotheses generated by asr to attenuate the effect of asr errors on the summary. we investigate several schemes to combine asr hypotheses. first, we propose using the sum of sub-word embedding vectors weighted by their posterior values provided by an asr system as an input to a bert-based ts system. then, we introduce a more general scheme that uses an attention-based fusion module added to a pre-trained bert module to align and combine several asr hypotheses. finally, we perform speech summarization experiments on the how2 dataset and a newly assembled ted-based dataset that we will release with this paper. these experiments show that retraining the bert-based ts system with these schemes can improve summarization performance and that the attention-based fusion module is particularly effective. ","966":"end-to-end models are becoming popular approaches for mispronunciation detection and diagnosis (mdd). a streaming mdd framework which is demanded by many practical applications still remains a challenge. this paper proposes a streaming end-to-end mdd framework called cca-mdd. cca-mdd supports online processing and is able to run strictly in real-time. the encoder of cca-mdd consists of a conv-transformer network based streaming acoustic encoder and an improved cross-attention named coupled cross-attention (cca). the coupled cross-attention integrates encoded acoustic features with pre-encoded linguistic features. an ensemble of decoders trained from multi-task learning is applied for final mdd decision. experiments on publicly available corpora demonstrate that cca-mdd achieves comparable performance to published offline end-to-end mdd models. ","967":"more capable language models increasingly saturate existing task benchmarks, in some cases outperforming humans. this has left little headroom with which to measure further progress. adversarial dataset creation has been proposed as a strategy to construct more challenging datasets, and two common approaches are: (1) filtering out easy examples and (2) model-in-the-loop data collection. in this work, we study the impact of applying each approach to create more challenging evaluation datasets. we adapt the aflite algorithm to filter evaluation data, and run experiments against 18 different adversary models. we find that aflite indeed selects more challenging examples, lowering the performance of evaluated models more as stronger adversary models are used. however, the resulting ranking of models can also be unstable and highly sensitive to the choice of adversary model used. moreover, aflite oversamples examples with low annotator agreement, meaning that model comparisons hinge on the most contentiously labeled examples. smaller-scale experiments on the adversarially collected datasets anli and adversarialqa show similar findings, broadly lowering performance with stronger adversaries while disproportionately affecting the adversary model. ","968":"we solve mit's linear algebra 18.06 course and columbia university's computational linear algebra coms3251 courses with perfect accuracy by interactive program synthesis. this surprisingly strong result is achieved by turning the course questions into programming tasks and then running the programs to produce the correct answers. we use openai codex with zero-shot learning, without providing any examples in the prompts, to synthesize code from questions. we quantify the difference between the original question text and the transformed question text that yields a correct answer. since all coms3251 questions are not available online the model is not overfitting. we go beyond just generating code for questions with numerical answers by interactively generating code that also results visually pleasing plots as output. finally, we automatically generate new questions given a few sample questions which may be used as new course content. this work is a significant step forward in solving quantitative math problems and opens the door for solving many university level stem courses by machine. ","969":"self-supervised training has shown promising gains in pretraining models and facilitating the downstream finetuning for speech recognition, like multilingual asr. most existing methods adopt a 2-stage scheme where the self-supervised loss is optimized in the first pretraining stage, and the standard supervised finetuning resumes in the second stage. in this paper, we propose an end-to-end (e2e) joint unsupervised and supervised training (just) method to combine the supervised rnn-t loss and the self-supervised contrastive and masked language modeling (mlm) losses. we validate its performance on the public dataset multilingual librispeech (mls), which includes 8 languages and is extremely imbalanced. on mls, we explore (1) just trained from scratch, and (2) just finetuned from a pretrained checkpoint. experiments show that just can consistently outperform other existing state-of-the-art methods, and beat the monolingual baseline by a significant margin, demonstrating just's capability of handling low-resource languages in multilingual asr. our average wer of all languages outperforms average monolingual baseline by 33.3%, and the state-of-the-art 2-stage xlsr by 32%. on low-resource languages like polish, our wer is less than half of the monolingual baseline and even beats the supervised transfer learning method which uses external supervision. ","970":"gpt-2 has been frequently adapted in story generation models as it provides powerful generative capability. however, it still fails to generate consistent stories and lacks diversity. current story generation models leverage additional information such as plots or commonsense into gpt-2 to guide the generation process. these approaches focus on improving generation quality of stories while our work look at both quality and diversity. we explore combining bert and gpt-2 to build a variational autoencoder (vae), and extend it by adding additional objectives to learn global features such as story topic and discourse relations. our evaluations show our enhanced vae can provide better quality and diversity trade off, generate less repetitive story content and learn a more informative latent variable. ","971":"nlp systems use language models such as masked language models (mlms) that are pre-trained on large quantities of text such as wikipedia create representations of language. bert is a powerful and flexible general-purpose mlm system developed using unlabeled text. pre-training on large quantities of text also has the potential to transparently embed the cultural and social biases found in the source text into the mlm system. this study aims to compare biases in general purpose and medical mlms with the stereoset bias assessment tool. the general purpose mlms showed significant bias overall, with bert scoring 57 and roberta scoring 61. the category of gender bias is where the best performances were found, with 63 for bert and 73 for roberta. performances for profession, race, and religion were similar to the overall bias scores for the general-purpose mlms.medical mlms showed more bias in all categories than the general-purpose mlms except for scibert, which showed a race bias score of 55, which was superior to the race bias score of 53 for bert. more gender (medical 54-58 vs. general 63-73) and religious (46-54 vs. 58) biases were found with medical mlms. this evaluation of four medical mlms for stereotyped assessments about race, gender, religion, and profession showed inferior performance to general-purpose mlms. these medically focused mlms differ considerably in training source data, which is likely the root cause of the differences in ratings for stereotyped biases from the stereoset tool. ","972":"this paper presents collie: a simple, yet effective model for continual learning of how language is grounded in vision. given a pre-trained multimodal embedding model, where language and images are projected in the same semantic space (in this case clip by openai), collie learns a transformation function that adjusts the language embeddings when needed to accommodate new language use. unlike traditional few-shot learning, the model does not just learn new classes and labels, but can also generalize to similar language use. we verify the model's performance on two different tasks of continual learning and show that it can efficiently learn and generalize from only a few examples, with little interference with the model's original zero-shot performance. ","973":"motivated by the seemingly high accuracy levels of machine learning models in moldavian versus romanian dialect identification and the increasing research interest on this topic, we provide a follow-up on the moldavian versus romanian cross-dialect topic identification (mrc) shared task of the vardial 2019 evaluation campaign. the shared task included two sub-task types: one that consisted in discriminating between the moldavian and romanian dialects and one that consisted in classifying documents by topic across the two dialects of romanian. participants achieved impressive scores, e.g. the top model for moldavian versus romanian dialect identification obtained a macro f1 score of 0.895. we conduct a subjective evaluation by human annotators, showing that humans attain much lower accuracy rates compared to machine learning (ml) models. hence, it remains unclear why the methods proposed by participants attain such high accuracy rates. our goal is to understand (i) why the proposed methods work so well (by visualizing the discriminative features) and (ii) to what extent these methods can keep their high accuracy levels, e.g. when we shorten the text samples to single sentences or when we use tweets at inference time. a secondary goal of our work is to propose an improved ml model using ensemble learning. our experiments show that ml models can accurately identify the dialects, even at the sentence level and across different domains (news articles versus tweets). we also analyze the most discriminative features of the best performing models, providing some explanations behind the decisions taken by these models. interestingly, we learn new dialectal patterns previously unknown to us or to our human annotators. furthermore, we conduct experiments showing that the machine learning performance on the mrc shared task can be improved through an ensemble based on stacking. ","974":"in traditional visual question generation (vqg), most images have multiple concepts (e.g. objects and categories) for which a question could be generated, but models are trained to mimic an arbitrary choice of concept as given in their training data. this makes training difficult and also poses issues for evaluation -- multiple valid questions exist for most images but only one or a few are captured by the human references. we present guiding visual question generation - a variant of vqg which conditions the question generator on categorical information based on expectations on the type of question and the objects it should explore. we propose two variants: (i) an explicitly guided model that enables an actor (human or automated) to select which objects and categories to generate a question for; and (ii) an implicitly guided model that learns which objects and categories to condition on, based on discrete latent variables. the proposed models are evaluated on an answer-category augmented vqa dataset and our quantitative results show a substantial improvement over the current state of the art (over 9 bleu-4 increase). human evaluation validates that guidance helps the generation of questions that are grammatically coherent and relevant to the given image and objects. ","975":"in this work, we propose a method for incorporating question-answering (qa) signals into a summarization model. our method identifies salient noun phrases (nps) in the input document by automatically generating wh-questions that are answered by the nps and automatically determining whether those questions are answered in the gold summaries. this qa-based signal is incorporated into a two-stage summarization model which first marks salient nps in the input document using a classification model, then conditionally generates a summary. our experiments demonstrate that the models trained using qa-based supervision generate higher-quality summaries than baseline methods of identifying salient spans on benchmark summarization datasets. further, we show that the content of the generated summaries can be controlled based on which nps are marked in the input document. finally, we propose a method of augmenting the training data so the gold summaries are more consistent with the marked input spans used during training and show how this results in models which learn to better exclude unmarked document content. ","976":"sentiment analysis of social media posts and comments for various marketing and emotional purposes is gaining recognition. with the increasing presence of code-mixed content in various native languages, there is a need for ardent research to produce promising results. this research paper bestows a tiny contribution to this research in the form of sentiment analysis of code-mixed social media comments in the popular dravidian languages kannada, tamil and malayalam. it describes the work for the shared task conducted by dravidian-codemix at fire 2021 by employing pre-trained models like ulmfit and multilingual bert fine-tuned on the code-mixed dataset, transliteration (trai) of the same, english translations (traa) of the trai data and the combination of all the three. the results are recorded in this research paper where the best models stood 4th, 5th and 10th ranks in the tamil, kannada and malayalam tasks respectively. ","977":"the vast network of oil and gas transmission pipelines requires periodic monitoring for maintenance and hazard inspection to avoid equipment failure and potential accidents. the severe covid-19 pandemic situation forced the companies to shrink the size of their teams. one risk which is faced on-site is represented by the uncontrolled release of flammable oil and gas. among many inspection methods, the unmanned aerial vehicle system contains flexibility and stability. unmanned aerial vehicles can transfer data in real-time, while they are doing their monitoring tasks. the current article focuses on unmanned aerial vehicles equipped with optical sensing and artificial intelligence, especially image recognition with deep learning techniques for pipeline surveillance. unmanned aerial vehicles can be used for regular patrolling duties to identify and capture images and videos of the area of interest. places that are hard to reach will be accessed faster, cheaper and with less risk. the current paper is based on the idea of capturing video and images of drone-based inspections, which can discover several potential hazardous problems before they become dangerous. damage can emerge as a weakening of the cladding on the external pipe insulation. there can also be the case when the thickness of piping through external corrosion can occur. the paper describes a survey completed by experts from the oil and gas industry done for finding the functional and non-functional requirements of the proposed system. ","978":"over the last years, word and sentence embeddings have established as text preprocessing for all kinds of nlp tasks and improved the performances significantly. unfortunately, it has also been shown that these embeddings inherit various kinds of biases from the training data and thereby pass on biases present in society to nlp solutions. many papers attempted to quantify bias in word or sentence embeddings to evaluate debiasing methods or compare different embedding models, usually with cosine-based metrics. however, lately some works have raised doubts about these metrics showing that even though such metrics report low biases, other tests still show biases. in fact, there is a great variety of bias metrics or tests proposed in the literature without any consensus on the optimal solutions. yet we lack works that evaluate bias metrics on a theoretical level or elaborate the advantages and disadvantages of different bias metrics. in this work, we will explore different cosine based bias metrics. we formalize a bias definition based on the ideas from previous works and derive conditions for bias metrics. furthermore, we thoroughly investigate the existing cosine-based metrics and their limitations to show why these metrics can fail to report biases in some cases. finally, we propose a new metric, same, to address the shortcomings of existing metrics and mathematically prove that same behaves appropriately. ","979":"the role of social media in fashion industry has been blooming as the years have continued on. in this work, we investigate sentiment analysis for fashion related posts in social media platforms. there are two main challenges of this task. on the first place, information of different modalities must be jointly considered to make the final predictions. on the second place, some unique fashion related attributes should be taken into account. while most existing works focus on traditional multimodal sentiment analysis, they always fail to exploit the fashion related attributes in this task. we propose a novel framework that jointly leverages the image vision, post text, as well as fashion attribute modality to determine the sentiment category. one characteristic of our model is that it extracts fashion attributes and integrates them with the image vision information for effective representation. furthermore, it exploits the mutual relationship between the fashion attributes and the post texts via a mutual attention mechanism. since there is no existing dataset suitable for this task, we prepare a large-scale sentiment analysis dataset of over 12k fashion related social media posts. extensive experiments are conducted to demonstrate the effectiveness of our model. ","980":"developing speech technologies is a challenge for low-resource languages for which both annotated and raw speech data is sparse. maltese is one such language. recent years have seen an increased interest in the computational processing of maltese, including speech technologies, but resources for the latter remain sparse. in this paper, we consider data augmentation techniques for improving speech recognition for such languages, focusing on maltese as a test case. we consider three different types of data augmentation: unsupervised training, multilingual training and the use of synthesized speech as training data. the goal is to determine which of these techniques, or combination of them, is the most effective to improve speech recognition for languages where the starting point is a small corpus of approximately 7 hours of transcribed speech. our results show that combining the three data augmentation techniques studied here lead us to an absolute wer improvement of 15% without the use of a language model. ","981":"automatic post-editing (ape) is an important remedy for reducing errors of raw translated texts that are produced by machine translation (mt) systems or software-aided translation. in this paper, we present a systematic approach to tackle the ape task for vietnamese. specifically, we construct the first large-scale dataset of 5m vietnamese translated and corrected sentence pairs. we then apply strong neural mt models to handle the ape task, using our constructed dataset. experimental results from both automatic and human evaluations show the effectiveness of the neural mt models in handling the vietnamese ape task. ","982":"human evaluation has always been expensive while researchers struggle to trust the automatic metrics. to address this, we propose to customise traditional metrics by taking advantages of the pre-trained language models (plms) and the limited available human labelled scores. we first re-introduce the hlepor metric factors, followed by the python version we developed (ported) which achieved the automatic tuning of the weighting parameters in hlepor metric. then we present the customised hlepor (cushlepor) which uses optuna hyper-parameter optimisation framework to fine-tune hlepor weighting parameters towards better agreement to pre-trained language models (using labse) regarding the exact mt language pairs that cushlepor is deployed to. we also optimise cushlepor towards professional human evaluation data based on mqm and psqm framework on english-german and chinese-english language pairs. the experimental investigations show cushlepor boosts hlepor performances towards better agreements to plms like labse with much lower cost, and better agreements to human evaluations including mqm and psqm scores, and yields much better performances than bleu (data available at \\url{https:\/\/github.com\/poethan\/cushlepor}). official results show that our submissions win three language pairs including \\textbf{english-german} and \\textbf{chinese-english} on \\textit{news} domain via cushlepor(lm) and \\textbf{english-russian} on \\textit{ted} domain via hlepor. ","983":"from both human translators (ht) and machine translation (mt) researchers' point of view, translation quality evaluation (tqe) is an essential task. translation service providers (tsps) have to deliver large volumes of translations which meet customer specifications with harsh constraints of required quality level in tight time-frames and costs. mt researchers strive to make their models better, which also requires reliable quality evaluation. while automatic machine translation evaluation (mte) metrics and quality estimation (qe) tools are widely available and easy to access, existing automated tools are not good enough, and human assessment from professional translators (hap) are often chosen as the golden standard \\cite{han-etal-2021-tqa}. human evaluations, however, are often accused of having low reliability and agreement. is this caused by subjectivity or statistics is at play? how to avoid the entire text to be checked and be more efficient with tqe from cost and efficiency perspectives, and what is the optimal sample size of the translated text, so as to reliably estimate the translation quality of the entire material? this work carries out such motivated research to correctly estimate the confidence intervals \\cite{brown_etal2001interval} depending on the sample size of the translated text, e.g. the amount of words or sentences, that needs to be processed on tqe workflow step for confident and reliable evaluation of overall translation quality. the methodology we applied for this work is from bernoulli statistical distribution modelling (bsdm) and monte carlo sampling analysis (mcsa). ","984":"massive open online courses (moocs) have become a popular choice for e-learning thanks to their great flexibility. however, due to large numbers of learners and their diverse backgrounds, it is taxing to offer real-time support. learners may post their feelings of confusion and struggle in the respective mooc forums, but with the large volume of posts and high workloads for mooc instructors, it is unlikely that the instructors can identify all learners requiring intervention. this problem has been studied as a natural language processing (nlp) problem recently, and is known to be challenging, due to the imbalance of the data and the complex nature of the task. in this paper, we explore for the first time bayesian deep learning on learner-based text posts with two methods: monte carlo dropout and variational inference, as a new solution to assessing the need of instructor interventions for a learner's post. we compare models based on our proposed methods with probabilistic modelling to its baseline non-bayesian models under similar circumstances, for different cases of applying prediction. the results suggest that bayesian deep learning offers a critical uncertainty measure that is not supplied by traditional neural networks. this adds more explainability, trust and robustness to ai, which is crucial in education-based applications. additionally, it can achieve similar or better performance compared to non-probabilistic neural networks, as well as grant lower variance. ","985":"although many context-aware neural machine translation models have been proposed to incorporate contexts in translation, most of those models are trained end-to-end on parallel documents aligned in sentence-level. because only a few domains (and language pairs) have such document-level parallel data, we cannot perform accurate context-aware translation in most domains. we therefore present a simple method to turn a sentence-level translation model into a context-aware model by incorporating a document-level language model into the decoder. our context-aware decoder is built upon only a sentence-level parallel corpora and monolingual corpora; thus no document-level parallel data is needed. in a theoretical viewpoint, the core part of this work is the novel representation of contextual information using point-wise mutual information between context and the current sentence. we show the effectiveness of our approach in three language pairs, english to french, english to russian, and japanese to english, by evaluation in \\textsc{bleu} and contrastive tests for context-aware translation. ","986":"medical report generation, which aims to automatically generate a long and coherent report of a given medical image, has been receiving growing research interests. existing approaches mainly adopt a supervised manner and heavily rely on coupled image-report pairs. however, in the medical domain, building a large-scale image-report paired dataset is both time-consuming and expensive. to relax the dependency on paired data, we propose an unsupervised model knowledge graph auto-encoder (kgae) which accepts independent sets of images and reports in training. kgae consists of a pre-constructed knowledge graph, a knowledge-driven encoder and a knowledge-driven decoder. the knowledge graph works as the shared latent space to bridge the visual and textual domains; the knowledge-driven encoder projects medical images and reports to the corresponding coordinates in this latent space and the knowledge-driven decoder generates a medical report given a coordinate in this space. since the knowledge-driven encoder and decoder can be trained with independent sets of images and reports, kgae is unsupervised. the experiments show that the unsupervised kgae generates desirable medical reports without using any image-report training pairs. moreover, kgae can also work in both semi-supervised and supervised settings, and accept paired images and reports in training. by further fine-tuning with image-report pairs, kgae consistently outperforms the current state-of-the-art models on two datasets. ","987":"the development of neural networks for clinical artificial intelligence (ai) is reliant on interpretability, transparency, and performance. the need to delve into the black-box neural network and derive interpretable explanations of model output is paramount. a task of high clinical importance is predicting the likelihood of a patient being readmitted to hospital in the near future to enable efficient triage. with the increasing adoption of electronic health records (ehrs), there is great interest in applications of natural language processing (nlp) to clinical free-text contained within ehrs. in this work, we apply infocal, the current state-of-the-art model that produces extractive rationales for its predictions, to the task of predicting hospital readmission using hospital discharge notes. we compare extractive rationales produced by infocal to competitive transformer-based models pretrained on clinical text data and for which the attention mechanism can be used for interpretation. we find each presented model with selected interpretability or feature importance methods yield varying results, with clinical language domain expertise and pretraining critical to performance and subsequent interpretability. ","988":"crowdsourcing is regarded as one prospective solution for effective supervised learning, aiming to build large-scale annotated training data by crowd workers. previous studies focus on reducing the influences from the noises of the crowdsourced annotations for supervised models. we take a different point in this work, regarding all crowdsourced annotations as gold-standard with respect to the individual annotators. in this way, we find that crowdsourcing could be highly similar to domain adaptation, and then the recent advances of cross-domain methods can be almost directly applied to crowdsourcing. here we take named entity recognition (ner) as a study case, suggesting an annotator-aware representation learning model that inspired by the domain adaptation methods which attempt to capture effective domain-aware features. we investigate both unsupervised and supervised crowdsourcing learning, assuming that no or only small-scale expert annotations are available. experimental results on a benchmark crowdsourced ner dataset show that our method is highly effective, leading to a new state-of-the-art performance. in addition, under the supervised setting, we can achieve impressive performance gains with only a very small scale of expert annotations. ","989":"lyric generation is a popular sub-field of natural language generation that has seen growth in recent years. pop lyrics are of unique interest due to the genre's unique style and content, in addition to the high level of collaboration that goes on behind the scenes in the professional pop songwriting process. in this paper, we present a collaborative line-level lyric generation system that utilizes transfer-learning via the t5 transformer model, which, till date, has not been used to generate pop lyrics. by working and communicating directly with professional songwriters, we develop a model that is able to learn lyrical and stylistic tasks like rhyming, matching line beat requirements, and ending lines with specific target words. our approach compares favorably to existing methods for multiple datasets and yields positive results from our online studies and interviews with industry songwriters. ","990":"softmax is the de facto standard in modern neural networks for language processing when it comes to normalizing logits. however, by producing a dense probability distribution each token in the vocabulary has a nonzero chance of being selected at each generation step, leading to a variety of reported problems in text generation. $\\alpha$-entmax of peters et al. (2019, arxiv:1905.05702) solves this problem, but is considerably slower than softmax.   in this paper, we propose an alternative to $\\alpha$-entmax, which keeps its virtuous characteristics, but is as fast as optimized softmax and achieves on par or better performance in machine translation task. ","991":"rumors are rampant in the era of social media. conversation structures provide valuable clues to differentiate between real and fake claims. however, existing rumor detection methods are either limited to the strict relation of user responses or oversimplify the conversation structure. in this study, to substantially reinforces the interaction of user opinions while alleviating the negative impact imposed by irrelevant posts, we first represent the conversation thread as an undirected interaction graph. we then present a claim-guided hierarchical graph attention network for rumor classification, which enhances the representation learning for responsive posts considering the entire social contexts and attends over the posts that can semantically infer the target claim. extensive experiments on three twitter datasets demonstrate that our rumor detection method achieves much better performance than state-of-the-art methods and exhibits a superior capacity for detecting rumors at early stages. ","992":"recent advancements in end-to-end speech synthesis have made it possible to generate highly natural speech. however, training these models typically requires a large amount of high-fidelity speech data, and for unseen texts, the prosody of synthesized speech is relatively unnatural. to address these issues, we propose to combine a fine-tuned bert-based front-end with a pre-trained fastspeech2-based acoustic model to improve prosody modeling. the pre-trained bert is fine-tuned on the polyphone disambiguation task, the joint chinese word segmentation (cws) and part-of-speech (pos) tagging task, and the prosody structure prediction (psp) task in a multi-task learning framework. fastspeech 2 is pre-trained on large-scale external data that are noisy but easier to obtain. experimental results show that both the fine-tuned bert model and the pre-trained fastspeech 2 can improve prosody, especially for those structurally complex sentences. ","993":"contrastive vision-language pre-training, known as clip, has provided a new paradigm for learning visual representations by using large-scale contrastive image-text pairs. it shows impressive performance on zero-shot knowledge transfer to downstream tasks. to further enhance clip's few-shot capability, clip-adapter proposed to fine-tune a lightweight residual feature adapter and significantly improves the performance for few-shot classification. however, such a process still needs extra training and computational resources. in this paper, we propose \\textbf{t}raining-free cl\\textbf{ip}-\\textbf{adapter} (\\textbf{tip-adapter}), which not only inherits clip's training-free advantage but also performs comparably or even better than clip-adapter. tip-adapter does not require any back propagation for training the adapter, but creates the weights by a key-value cache model constructed from the few-shot training set. in this non-parametric manner, tip-adapter acquires well-performed adapter weights without any training, which is both efficient and effective. moreover, the performance of tip-adapter can be further boosted by fine-tuning such properly initialized adapter for only a few epochs with super-fast convergence speed. we conduct extensive experiments of few-shot classification on imagenet and other 10 datasets to demonstrate the superiority of proposed tip-adapter. the code will be released at \\url{https:\/\/github.com\/gaopengcuhk\/tip-adapter}. ","994":"english research articles (ras) are an essential genre in academia, so the attempts to employ nlp to assist the development of academic writing ability have received considerable attention in the last two decades. however, there has been no study employing feature engineering techniques to investigate the linguistic features of ras of different academic impacts (i.e., the papers of high\/moderate citation times published in the journals of high\/moderate impact factors). this study attempts to extract micro-level linguistic features in high- and moderate-impact journal ras, using feature engineering methods. we extracted 25 highly relevant features from the corpus of english journal articles through feature selection methods. all papers in the corpus deal with covid-19 medical empirical studies. the selected features were then validated of the classification performance in terms of consistency and accuracy through supervised machine learning methods. results showed that 24 linguistic features such as the overlapping of content words between adjacent sentences, the use of third-person pronouns, auxiliary verbs, tense, emotional words provide consistent and accurate predictions for journal articles with different academic impacts. lastly, the random forest model is shown to be the best model to fit the relationship between these 24 features and journal articles with high and moderate impacts. these findings can be used to inform academic writing courses and lay the foundation for developing automatic evaluation systems for l2 graduate students. ","995":"non-parametric neural language models (nlms) learn predictive distributions of text utilizing an external datastore, which allows them to learn through explicitly memorizing the training datapoints. while effective, these models often require retrieval from a large datastore at test time, significantly increasing the inference overhead and thus limiting the deployment of non-parametric nlms in practical applications. in this paper, we take the recently proposed $k$-nearest neighbors language model (khandelwal et al., 2020) as an example, exploring methods to improve its efficiency along various dimensions. experiments on the standard wikitext-103 benchmark and domain-adaptation datasets show that our methods are able to achieve up to a 6x speed-up in inference speed while retaining comparable performance. the empirical analysis we present may provide guidelines for future research seeking to develop or deploy more efficient non-parametric nlms. ","996":"speech pause is an effective biomarker in dementia detection. recent deep learning models have exploited speech pauses to achieve highly accurate dementia detection, but have not exploited the interpretability of speech pauses, i.e., what and how positions and lengths of speech pauses affect the result of dementia detection. in this paper, we will study the positions and lengths of dementia-sensitive pauses using adversarial learning approaches. specifically, we first utilize an adversarial attack approach by adding the perturbation to the speech pauses of the testing samples, aiming to reduce the confidence levels of the detection model. then, we apply an adversarial training approach to evaluate the impact of the perturbation in training samples on the detection model. we examine the interpretability from the perspectives of model accuracy, pause context, and pause length. we found that some pauses are more sensitive to dementia than other pauses from the model's perspective, e.g., speech pauses near to the verb \"is\". increasing lengths of sensitive pauses or adding sensitive pauses leads the model inference to alzheimer's disease, while decreasing the lengths of sensitive pauses or deleting sensitive pauses leads to non-ad. ","997":"background: when neural network emotion and sentiment classifiers are used in public health informatics studies, biases present in the classifiers could produce inadvertently misleading results.   objective: this study assesses the impact of bias on covid-19 topics, and demonstrates an automatic algorithm for reducing bias when applied to covid-19 social media texts. this could help public health informatics studies produce more timely results during crises, with a reduced risk of misleading results.   methods: emotion and sentiment classifiers were applied to covid-19 data before and after debiasing the classifiers using unsupervised contrastive clustering. contrastive clustering approximates the degree to which tokens exhibit a causal versus correlational relationship with emotion or sentiment, by contrasting the tokens' relative salience to topics versus emotions or sentiments.   results: contrastive clustering distinguishes correlation from causation for tokens with an f1 score of 0.753. masking bias prone tokens from the classifier input decreases the classifier's overall f1 score by 0.02 (anger) and 0.033 (negative sentiment), but improves the f1 score for sentences annotated as bias prone by 0.155 (anger) and 0.103 (negative sentiment). averaging across topics, debiasing reduces anger estimates by 14.4% and negative sentiment estimates by 8.0%.   conclusions: contrastive clustering reduces algorithmic bias in emotion and sentiment classification for social media text pertaining to the covid-19 pandemic. public health informatics studies should account for bias, due to its prevalence across a range of topics. further research is needed to improve bias reduction techniques and to explore the adverse impact of bias on public health informatics analyses. ","998":"dialogue state tracking models play an important role in a task-oriented dialogue system. however, most of them model the slot types conditionally independently given the input. we discover that it may cause the model to be confused by slot types that share the same data type. to mitigate this issue, we propose trippy-mrf and trippy-lstm that models the slots jointly. our results show that they are able to alleviate the confusion mentioned above, and they push the state-of-the-art on dataset multiwoz 2.1 from 58.7 to 61.3. our implementation is available at https:\/\/github.com\/ctinray\/trippy-joint. ","999":"when an nlp model is trained on text data from one time period and tested or deployed on data from another, the resulting temporal misalignment can degrade end-task performance. in this work, we establish a suite of eight diverse tasks across different domains (social media, science papers, news, and reviews) and periods of time (spanning five years or more) to quantify the effects of temporal misalignment. our study is focused on the ubiquitous setting where a pretrained model is optionally adapted through continued domain-specific pretraining, followed by task-specific finetuning. we establish a suite of tasks across multiple domains to study temporal misalignment in modern nlp systems. we find stronger effects of temporal misalignment on task performance than have been previously reported. we also find that, while temporal adaptation through continued pretraining can help, these gains are small compared to task-specific finetuning on data from the target time period. our findings motivate continued research to improve temporal robustness of nlp models. ","1000":"it has been shown that machine translation models usually generate poor translations for named entities that are infrequent in the training corpus. earlier named entity translation methods mainly focus on phonetic transliteration, which ignores the sentence context for translation and is limited in domain and language coverage. to address this limitation, we propose deep, a denoising entity pre-training method that leverages large amounts of monolingual data and a knowledge base to improve named entity translation accuracy within sentences. besides, we investigate a multi-task learning strategy that finetunes a pre-trained neural machine translation model on both entity-augmented monolingual data and parallel data to further improve entity translation. experimental results on three language pairs demonstrate that \\method results in significant improvements over strong denoising auto-encoding baselines, with a gain of up to 1.3 bleu and up to 9.2 entity accuracy points for english-russian translation. ","1001":"the feasibility of making profitable trades on a single asset on stock exchanges based on patterns identification has long attracted researchers. reinforcement learning (rl) and natural language processing have gained notoriety in these single-asset trading tasks, but only a few works have explored their combination. moreover, some issues are still not addressed, such as extracting market sentiment momentum through the explicit capture of sentiment features that reflect the market condition over time and assessing the consistency and stability of rl results in different situations. filling this gap, we propose the sentiment-aware rl (sentarl) intelligent trading system that improves profit stability by leveraging market mood through an adaptive amount of past sentiment features drawn from textual news. we evaluated sentarl across twenty assets, two transaction costs, and five different periods and initializations to show its consistent effectiveness against baselines. subsequently, this thorough assessment allowed us to identify the boundary between news coverage and market sentiment regarding the correlation of price-time series above which sentarl's effectiveness is outstanding. ","1002":"feature attribution a.k.a. input salience methods which assign an importance score to a feature are abundant but may produce surprisingly different results for the same model on the same input. while differences are expected if disparate definitions of importance are assumed, most methods claim to provide faithful attributions and point at the features most relevant for a model's prediction. existing work on faithfulness evaluation is not conclusive and does not provide a clear answer as to how different methods are to be compared. focusing on text classification and the model debugging scenario, our main contribution is a protocol for faithfulness evaluation that makes use of partially synthetic data to obtain ground truth for feature importance ranking. following the protocol, we do an in-depth analysis of four standard salience method classes on a range of datasets and shortcuts for bert and lstm models and demonstrate that some of the most popular method configurations provide poor results even for simplest shortcuts. we recommend following the protocol for each new task and model combination to find the best method for identifying shortcuts. ","1003":"automatic scoring engines have been used for scoring approximately fifteen million test-takers in just the last three years. this number is increasing further due to covid-19 and the associated automation of education and testing. despite such wide usage, the ai-based testing literature of these \"intelligent\" models is highly lacking. most of the papers proposing new models rely only on quadratic weighted kappa (qwk) based agreement with human raters for showing model efficacy. however, this effectively ignores the highly multi-feature nature of essay scoring. essay scoring depends on features like coherence, grammar, relevance, sufficiency and, vocabulary. to date, there has been no study testing automated essay scoring: aes systems holistically on all these features. with this motivation, we propose a model agnostic adversarial evaluation scheme and associated metrics for aes systems to test their natural language understanding capabilities and overall robustness. we evaluate the current state-of-the-art aes models using the proposed scheme and report the results on five recent models. these models range from feature-engineering-based approaches to the latest deep learning algorithms. we find that aes models are highly overstable. even heavy modifications(as much as 25%) with content unrelated to the topic of the questions do not decrease the score produced by the models. on the other hand, irrelevant content, on average, increases the scores, thus showing that the model evaluation strategy and rubrics should be reconsidered. we also ask 200 human raters to score both an original and adversarial response to seeing if humans can detect differences between the two and whether they agree with the scores assigned by auto scores. ","1004":"this work presents a framework to classify and evaluate distinct research abstract texts which are focused on the description of processes and their applications. in this context, this paper proposes natural language processing algorithms to classify, segment and evaluate the results of scientific work. initially, the proposed framework categorize the abstract texts into according to the problems intended to be solved by employing a text classification approach. then, the abstract text is segmented into problem description, methodology and results. finally, the methodology of the abstract is ranked based on the sentiment analysis of its results. the proposed framework allows us to quickly rank the best methods to solve specific problems. to validate the proposed framework, oil production anomaly abstracts were experimented and achieved promising results. ","1005":"inherently, the legal domain contains a vast amount of data in text format. therefore it requires the application of natural language processing (nlp) to cater to the analytically demanding needs of the domain. the advancement of nlp is spreading through various domains, such as the legal domain, in forms of practical applications and academic research. identifying critical sentences, facts and arguments in a legal case is a tedious task for legal professionals. in this research we explore the usage of sentence embeddings for multi-class classification to identify critical sentences in a legal case, in the perspective of the main parties present in the case. in addition, a task-specific loss function is defined in order to improve the accuracy restricted by the straightforward use of categorical cross entropy loss. ","1006":"research on crude oil price forecasting has attracted tremendous attention from scholars and policymakers due to its significant effect on the global economy. besides supply and demand, crude oil prices are largely influenced by various factors, such as economic development, financial markets, conflicts, wars, and political events. most previous research treats crude oil price forecasting as a time series or econometric variable prediction problem. although recently there have been researches considering the effects of real-time news events, most of these works mainly use raw news headlines or topic models to extract text features without profoundly exploring the event information. in this study, a novel crude oil price forecasting framework, agesl, is proposed to deal with this problem. in our approach, an open domain event extraction algorithm is utilized to extract underlying related events, and a text sentiment analysis algorithm is used to extract sentiment from massive news. then a deep neural network integrating the news event features, sentimental features, and historical price features is built to predict future crude oil prices. empirical experiments are performed on west texas intermediate (wti) crude oil price data, and the results show that our approach obtains superior performance compared with several benchmark methods. ","1007":"literary texts are usually rich in meanings and their interpretation complicates corpus studies and automatic processing. there have been several attempts to create collections of literary texts with annotation of literary elements like the author's speech, characters, events, scenes etc. however, they resulted in small collections and standalone rules for annotation. the present article describes an experiment on lexical annotation of text worlds in a literary work and quantitative methods of their comparison. the experiment shows that for a well-agreed tag assignment annotation rules should be set much more strictly. however, if borders between text worlds and other elements are the result of a subjective interpretation, they should be modeled as fuzzy entities. ","1008":"an intelligent machine that can answer human questions based on electronic health records (ehr-qa) has a great practical value, such as supporting clinical decisions, managing hospital administration, and medical chatbots. previous table-based qa studies focusing on translating natural questions into table queries (nlq2sql), however, suffer from the unique nature of ehr data due to complex and specialized medical terminology, hence increased decoding difficulty. in this paper, we design uniqa, a unified encoder-decoder architecture for ehr-qa where natural language questions are converted to queries such as sql or sparql. we also propose input masking (im), a simple and effective method to cope with complex medical terms and various typos and better learn the sql\/sparql syntax. combining the unified architecture with an effective auxiliary training objective, uniqa demonstrated a significant performance improvement against the previous state-of-the-art model for mimicsql* (14.2% gain), the most complex nlq2sql dataset in the ehr domain, and its typo-ridden versions (approximately 28.8% gain). in addition, we confirmed consistent results for the graph-based ehr-qa dataset, mimicsparql*. ","1009":"vision-and-language navigation (vln) is a task where an agent navigates in an embodied indoor environment under human instructions. previous works ignore the distribution of sample difficulty and we argue that this potentially degrade their agent performance. to tackle this issue, we propose a novel curriculum-based training paradigm for vln tasks that can balance human prior knowledge and agent learning progress about training samples. we develop the principle of curriculum design and re-arrange the benchmark room-to-room (r2r) dataset to make it suitable for curriculum training. experiments show that our method is model-agnostic and can significantly improve the performance, the generalizability, and the training efficiency of current state-of-the-art navigation agents without increasing model complexity. ","1010":"the task of few-shot style transfer for voice cloning in text-to-speech (tts) synthesis aims at transferring speaking styles of an arbitrary source speaker to a target speaker's voice using very limited amount of neutral data. this is a very challenging task since the learning algorithm needs to deal with few-shot voice cloning and speaker-prosody disentanglement at the same time. accelerating the adaptation process for a new target speaker is of importance in real-world applications, but even more challenging. in this paper, we approach to the hard fast few-shot style transfer for voice cloning task using meta learning. we investigate the model-agnostic meta-learning (maml) algorithm and meta-transfer a pre-trained multi-speaker and multi-prosody base tts model to be highly sensitive for adaptation with few samples. domain adversarial training mechanism and orthogonal constraint are adopted to disentangle speaker and prosody representations for effective cross-speaker style transfer. experimental results show that the proposed approach is able to conduct fast voice cloning using only 5 samples (around 12 second speech data) from a target speaker, with only 100 adaptation steps. audio samples are available online. ","1011":"keyphrase extraction is the task of finding several interesting phrases in a text document, which provide a list of the main topics within the document. most existing graph-based models use co-occurrence links as cohesion indicators to model the relationship of syntactic elements. however, a word may have different forms of expression within the document, and may have several synonyms as well. simply using co-occurrence information cannot capture this information. in this paper, we enhance the graph-based ranking model by leveraging word embeddings as background knowledge to add semantic information to the inter-word graph. our approach is evaluated on established benchmark datasets and empirical results show that the word embedding neighborhood information improves the model performance. ","1012":"this report provides an engagement analysis of counternarratives against online toxicity. between february 2020 and july 2021, we observed over 15 million toxic messages on social media identified by our fine-grained, multilingual detection ai. over 1,000 dashboard users responded to toxic messages with combinations of visual memes, text, or ai-generated text, or they reported content. this leads to new, real-life insights on self-regulatory approaches for the mitigation of online hate. ","1013":"in natural language processing, most models try to learn semantic representations merely from texts. the learned representations encode the distributional semantics but fail to connect to any knowledge about the physical world. in contrast, humans learn language by grounding concepts in perception and action and the brain encodes grounded semantics for cognition. inspired by this notion and recent work in vision-language learning, we design a two-stream model for grounding language learning in vision. the model includes a vgg-based visual stream and a bert-based language stream. the two streams merge into a joint representational space. through cross-modal contrastive learning, the model first learns to align visual and language representations with the ms coco dataset. the model further learns to retrieve visual objects with language queries through a cross-modal attention module and to infer the visual relations between the retrieved objects through a bilinear operator with the visual genome dataset. after training, the language stream of this model is a stand-alone language model capable of embedding concepts in a visually grounded semantic space. this semantic space manifests principal dimensions explainable with human intuition and neurobiological knowledge. word embeddings in this semantic space are predictive of human-defined norms of semantic features and are segregated into perceptually distinctive clusters. furthermore, the visually grounded language model also enables compositional language understanding based on visual knowledge and multimodal image search with queries based on images, texts, or their combinations. ","1014":"the ubiquity of the contemporary language understanding tasks gives relevance to the development of generalized, yet highly efficient models that utilize all knowledge, provided by the data source. in this work, we present socialbert - the first model that uses knowledge about the author's position in the network during text analysis. we investigate possible models for learning social network information and successfully inject it into the baseline bert model. the evaluation shows that embedding this information maintains a good generalization, with an increase in the quality of the probabilistic model for the given author up to 7.5%. the proposed model has been trained on the majority of groups for the chosen social network, and still able to work with previously unknown groups. the obtained model, as well as the code of our experiments, is available for download and use in applied tasks. ","1015":"twitter is among the most prevalent social media platform being used by millions of people all over the world. it is used to express ideas and opinions about political, social, business, sports, health, religion, and various other categories. the study reported here aims to detect the tweet category from its text. it becomes quite challenging when text consists of 140 characters only, with full of noise. the tweet is categorized under 12 specified categories using text mining or natural language processing (nlp), and machine learning (ml) techniques. it is observed that a huge number of trending topics are provided by twitter but it is really challenging to find out that what these trending topics are all about. therefore, it is extremely crucial to automatically categorize the tweets into general categories for plenty of information extraction tasks. a large dataset is constructed by combining two different nature of datasets having varying levels of category identification complexities. it is annotated by experts under proper guidelines for increased quality and high agreement values. it makes the proposed model quite robust. various types of ml algorithms were used to train and evaluate the proposed model. these models have explored over three datasets separately. it is explored that the nature of the dataset is highly non-linear therefore complex or non-linear models perform better. the best ensemble model named, gradient boosting achieved an auc score of 85\\%. that is much better than the other related studies conducted. ","1016":"paraphrasing is a useful natural language processing task that can contribute to more diverse generated or translated texts. natural language inference (nli) and paraphrasing share some similarities and can benefit from a joint approach. we propose a novel methodology for the extraction of paraphrasing datasets from nli datasets and cleaning existing paraphrasing datasets. our approach is based on bidirectional entailment; namely, if two sentences can be mutually entailed, they are paraphrases. we evaluate our approach using several large pretrained transformer language models in the monolingual and cross-lingual setting. the results show high quality of extracted paraphrasing datasets and surprisingly high noise levels in two existing paraphrasing datasets. ","1017":"in recent times, we have seen an increased use of text chat for communication on social networks and smartphones. this particularly involves the use of hindi-english code-mixed text which contains words which are not recognized in english vocabulary. we have worked on detecting emotions in these mixed data and classify the sentences in human emotions which are angry, fear, happy or sad. we have used state of the art natural language processing models and compared their performance on the dataset comprising sentences in this mixed data. the dataset was collected and annotated from sources and then used to train the models. ","1018":"biomedical entity normalization unifies the language across biomedical experiments and studies, and further enables us to obtain a holistic view of life sciences. current approaches mainly study the normalization of more standardized entities such as diseases and drugs, while disregarding the more ambiguous but crucial entities such as pathways, functions and cell types, hindering their real-world applications. to achieve biomedical entity normalization on these under-explored entities, we first introduce an expert-curated dataset obo-syn encompassing 70 different types of entities and 2 million curated entity-synonym pairs. to utilize the unique graph structure in this dataset, we propose graphprompt, a prompt-based learning approach that creates prompt templates according to the graphs. graphprompt obtained 41.0% and 29.9% improvement on zero-shot and few-shot settings respectively, indicating the effectiveness of these graph-based prompt templates. we envision that our method graphprompt and obo-syn dataset can be broadly applied to graph-based nlp tasks, and serve as the basis for analyzing diverse and accumulating biomedical data. ","1019":"document categorization, which aims to assign a topic label to each document, plays a fundamental role in a wide variety of applications. despite the success of existing studies in conventional supervised document classification, they are less concerned with two real problems: (1) the presence of metadata: in many domains, text is accompanied by various additional information such as authors and tags. such metadata serve as compelling topic indicators and should be leveraged into the categorization framework; (2) label scarcity: labeled training samples are expensive to obtain in some cases, where categorization needs to be performed using only a small set of annotated data. in recognition of these two challenges, we propose metacat, a minimally supervised framework to categorize text with metadata. specifically, we develop a generative process describing the relationships between words, documents, labels, and metadata. guided by the generative model, we embed text and metadata into the same semantic space to encode heterogeneous signals. then, based on the same generative process, we synthesize training samples to address the bottleneck of label scarcity. we conduct a thorough evaluation on a wide range of datasets. experimental results prove the effectiveness of metacat over many competitive baselines. ","1020":"dementia is a neurodegenerative disorder that causes cognitive decline and affects more than 50 million people worldwide. dementia is under-diagnosed by healthcare professionals - only one in four people who suffer from dementia are diagnosed. even when a diagnosis is made, it may not be entered as a structured international classification of diseases (icd) diagnosis code in a patient's charts. information relevant to cognitive impairment (ci) is often found within electronic health records (ehr), but manual review of clinician notes by experts is both time consuming and often prone to errors. automated mining of these notes presents an opportunity to label patients with cognitive impairment in ehr data. we developed natural language processing (nlp) tools to identify patients with cognitive impairment and demonstrate that linguistic context enhances performance for the cognitive impairment classification task. we fine-tuned our attention based deep learning model, which can learn from complex language structures, and substantially improved accuracy (0.93) relative to a baseline nlp model (0.84). further, we show that deep learning nlp can successfully identify dementia patients without dementia-related icd codes or medications. ","1021":"the ability to capture complex linguistic structures and long-term dependencies among words in the passage is essential for discourse-level relation extraction (dre) tasks. graph neural networks (gnns), one of the methods to encode dependency graphs, have been shown effective in prior works for dre. however, relatively little attention has been paid to receptive fields of gnns, which can be crucial for cases with extremely long text that requires discourse understanding. in this work, we leverage the idea of graph pooling and propose to use pooling-unpooling framework on dre tasks. the pooling branch reduces the graph size and enables the gnns to obtain larger receptive fields within fewer layers; the unpooling branch restores the pooled graph to its original resolution so that representations for entity mention can be extracted. we propose clause matching (cm), a novel linguistically inspired graph pooling method for nlp tasks. experiments on two dre datasets demonstrate that our models significantly improve over baselines when modeling long-term dependencies is required, which shows the effectiveness of the pooling-unpooling framework and our cm pooling method. ","1022":"in low resource settings, deep neural models have often shown lower performance due to overfitting. the primary method to solve the overfitting problem is to generalize model parameters. to this end, many researchers have depended on large external resources with various manipulation techniques. in this study, we discuss how to exploit all available samples in low resource settings, without external datasets and model manipulation. this study focuses on natural language processing task. we propose a simple algorithm to find out good initialization parameters that improve robustness to a small sample set. we apply early stopping techniques that enable the use of all samples for training. finally, the proposed learning strategy is to train all samples with the good initialization parameters and stop the model with the early stopping techniques. extensive experiments are conducted on seven public sentence classification datasets, and the results demonstrate that the proposed learning strategy achieves better performance than several state-of-the-art works across the seven datasets. ","1023":"tasks are a fundamental unit of work in the daily lives of people, who are increasingly using digital means to keep track of, organize, triage and act on them. these digital tools -- such as task management applications -- provide a unique opportunity to study and understand tasks and their connection to the real world, and through intelligent assistance, help people be more productive. by logging signals such as text, timestamp information, and social connectivity graphs, an increasingly rich and detailed picture of how tasks are created and organized, what makes them important, and who acts on them, can be progressively developed. yet the context around actual task completion remains fuzzy, due to the basic disconnect between actions taken in the real world and telemetry recorded in the digital world. thus, in this paper we compile and release a novel, real-life, large-scale dataset called ms-latte that captures two core aspects of the context surrounding task completion: location and time. we describe our annotation framework and conduct a number of analyses on the data that were collected, demonstrating that it captures intuitive contextual properties for common tasks. finally, we test the dataset on the two problems of predicting spatial and temporal task co-occurrence, concluding that predictors for co-location and co-time are both learnable, with a bert fine-tuned model outperforming several other baselines. the ms-latte dataset provides an opportunity to tackle many new modeling challenges in contextual task understanding and we hope that its release will spur future research in task intelligence more broadly. ","1024":"computational protein design, i.e. inferring novel and diverse protein sequences consistent with a given structure, remains a major unsolved challenge. recently, deep generative models that learn from sequences alone or from sequences and structures jointly have shown impressive performance on this task. however, those models appear limited in terms of modeling structural constraints, capturing enough sequence diversity, or both. here we consider three recently proposed deep generative frameworks for protein design: (ar) the sequence-based autoregressive generative model, (gvp) the precise structure-based graph neural network, and fold2seq that leverages a fuzzy and scale-free representation of a three-dimensional fold, while enforcing structure-to-sequence (and vice versa) consistency. we benchmark these models on the task of computational design of antibody sequences, which demand designing sequences with high diversity for functional implication. the fold2seq framework outperforms the two other baselines in terms of diversity of the designed sequences, while maintaining the typical fold. ","1025":"mined bitexts can contain imperfect translations that yield unreliable training signals for neural machine translation (nmt). while filtering such pairs out is known to improve final model quality, we argue that it is suboptimal in low-resource conditions where even mined data can be limited. in our work, we propose instead, to refine the mined bitexts via automatic editing: given a sentence in a language xf, and a possibly imperfect translation of it xe, our model generates a revised version xf' or xe' that yields a more equivalent translation pair (i.e., <xf, xe'> or <xf', xe>). we use a simple editing strategy by (1) mining potentially imperfect translations for each sentence in a given bitext, (2) learning a model to reconstruct the original translations and translate, in a multi-task fashion. experiments demonstrate that our approach successfully improves the quality of ccmatrix mined bitext for 5 low-resource language-pairs and 10 translation directions by up to ~ 8 bleu points, in most cases improving upon a competitive back-translation baseline. ","1026":"people convey their intention and attitude through linguistic styles of the text that they write. in this study, we investigate lexicon usages across styles throughout two lenses: human perception and machine word importance, since words differ in the strength of the stylistic cues that they provide. to collect labels of human perception, we curate a new dataset, hummingbird, on top of benchmarking style datasets. we have crowd workers highlight the representative words in the text that makes them think the text has the following styles: politeness, sentiment, offensiveness, and five emotion types. we then compare these human word labels with word importance derived from a popular fine-tuned style classifier like bert. our results show that the bert often finds content words not relevant to the target style as important words used in style prediction, but humans do not perceive the same way even though for some styles (e.g., positive sentiment and joy) human- and machine-identified words share significant overlap for some styles. ","1027":"the biocreative vii track 3 challenge focused on the identification of medication names in twitter user timelines. for our submission to this challenge, we expanded the available training data by using several data augmentation techniques. the augmented data was then used to fine-tune an ensemble of language models that had been pre-trained on general-domain twitter content. the proposed approach outperformed the prior state-of-the-art algorithm kusuri and ranked high in the competition for our selected objective function, overlapping f1 score. ","1028":"the onset of the covid-19 pandemic has brought the mental health of people under risk. social counselling has gained remarkable significance in this environment. unlike general goal-oriented dialogues, a conversation between a patient and a therapist is considerably implicit, though the objective of the conversation is quite apparent. in such a case, understanding the intent of the patient is imperative in providing effective counselling in therapy sessions, and the same applies to a dialogue system as well. in this work, we take forward a small but an important step in the development of an automated dialogue system for mental-health counselling. we develop a novel dataset, named hope, to provide a platform for the dialogue-act classification in counselling conversations. we identify the requirement of such conversation and propose twelve domain-specific dialogue-act (dac) labels. we collect 12.9k utterances from publicly-available counselling session videos on youtube, extract their transcripts, clean, and annotate them with dac labels. further, we propose sparta, a transformer-based architecture with a novel speaker- and time-aware contextual learning for the dialogue-act classification. our evaluation shows convincing performance over several baselines, achieving state-of-the-art on hope. we also supplement our experiments with extensive empirical and qualitative analyses of sparta. ","1029":"while sentence anomalies have been applied periodically for testing in nlp, we have yet to establish a picture of the precise status of anomaly information in representations from nlp models. in this paper we aim to fill two primary gaps, focusing on the domain of syntactic anomalies. first, we explore fine-grained differences in anomaly encoding by designing probing tasks that vary the hierarchical level at which anomalies occur in a sentence. second, we test not only models' ability to detect a given anomaly, but also the generality of the detected anomaly signal, by examining transfer between distinct anomaly types. results suggest that all models encode some information supporting anomaly detection, but detection performance varies between anomalies, and only representations from more recent transformer models show signs of generalized knowledge of anomalies. follow-up analyses support the notion that these models pick up on a legitimate, general notion of sentence oddity, while coarser-grained word position information is likely also a contributor to the observed anomaly detection. ","1030":"speech recognition is a technique that converts human speech signals into text or words or in any form that can be easily understood by computers or other machines. there have been a few studies on bangla digit recognition systems, the majority of which used small datasets with few variations in genders, ages, dialects, and other variables. audio recordings of bangladeshi people of various genders, ages, and dialects were used to create a large speech dataset of spoken '0-9' bangla digits in this study. here, 400 noisy and noise-free samples per digit have been recorded for creating the dataset. mel frequency cepstrum coefficients (mfccs) have been utilized for extracting meaningful features from the raw speech data. then, to detect bangla numeral digits, convolutional neural networks (cnns) were utilized. the suggested technique recognizes '0-9' bangla spoken digits with 97.1% accuracy throughout the whole dataset. the efficiency of the model was also assessed using 10-fold crossvalidation, which yielded a 96.7% accuracy. ","1031":"nlp applications for code-mixed (cm) or mix-lingual text have gained a significant momentum recently, the main reason being the prevalence of language mixing in social media communications in multi-lingual societies like india, mexico, europe, parts of usa etc. word embeddings are basic build-ing blocks of any nlp system today, yet, word embedding for cm languages is an unexplored territory. the major bottleneck for cm word embeddings is switching points, where the language switches. these locations lack in contextually and statistical systems fail to model this phenomena due to high variance in the seen examples. in this paper we present our initial observations on applying switching point based positional encoding techniques for cm language, specifically hinglish (hindi - english). results are only marginally better than sota, but it is evident that positional encoding could bean effective way to train position sensitive language models for cm text. ","1032":"across many data domains, co-occurrence statistics about the joint appearance of objects are powerfully informative. by transforming unsupervised learning problems into decompositions of co-occurrence statistics, spectral algorithms provide transparent and efficient algorithms for posterior inference such as latent topic analysis and community detection. as object vocabularies grow, however, it becomes rapidly more expensive to store and run inference algorithms on co-occurrence statistics. rectifying co-occurrence, the key process to uphold model assumptions, becomes increasingly more vital in the presence of rare terms, but current techniques cannot scale to large vocabularies. we propose novel methods that simultaneously compress and rectify co-occurrence statistics, scaling gracefully with the size of vocabulary and the dimension of latent space. we also present new algorithms learning latent variables from the compressed statistics, and verify that our methods perform comparably to previous approaches on both textual and non-textual data. ","1033":"in order to improve the accuracy performance of chinese text classification models with low hardware requirements, an improved concatenation-based model is designed in this paper, which is a concatenation of 5 different sub-models, including textcnn, lstm, and bi-lstm. compared with the existing ensemble learning method, for a text classification mission, this model's accuracy is 2% higher. meanwhile, the hardware requirements of this model are much lower than the bert-based model. ","1034":"symptom checkers have emerged as an important tool for collecting symptoms and diagnosing patients, minimizing the involvement of clinical personnel. we developed a machine-learning-backed system, smarttriage, which goes beyond conventional symptom checking through a tight bi-directional integration with the electronic medical record (emr). conditioned on emr-derived patient history, our system identifies the patient's chief complaint from a free-text entry and then asks a series of discrete questions to obtain relevant symptomatology. the patient-specific data are used to predict detailed icd-10-cm codes as well as medication, laboratory, and imaging orders. patient responses and clinical decision support (cds) predictions are then inserted back into the emr. to train the machine learning components of smarttriage, we employed novel data sets of over 25 million primary care encounters and 1 million patient free-text reason-for-visit entries. these data sets were used to construct: (1) a long short-term memory (lstm) based patient history representation, (2) a fine-tuned transformer model for chief complaint extraction, (3) a random forest model for question sequencing, and (4) a feed-forward network for cds predictions. in total, our system supports 337 patient chief complaints, which together make up $>90\\%$ of all primary care encounters at kaiser permanente. ","1035":"real-time location inference of social media users is the fundamental of some spatial applications such as localized search and event detection. while tweet text is the most commonly used feature in location estimation, most of the prior works suffer from either the noise or the sparsity of textual features. in this paper, we aim to tackle these two problems. we use topic modeling as a building block to characterize the geographic topic variation and lexical variation so that \"one-hot\" encoding vectors will no longer be directly used. we also incorporate other features which can be extracted through the twitter streaming api to overcome the noise problem. experimental results show that our rate algorithm outperforms several benchmark methods, both in the precision of region classification and the mean distance error of latitude and longitude regression. ","1036":"communication is compositional if complex signals can be represented as a combination of simpler subparts. in this paper, we theoretically show that inductive biases on both the training framework and the data are needed to develop a compositional communication. moreover, we prove that compositionality spontaneously arises in the signaling games, where agents communicate over a noisy channel. we experimentally confirm that a range of noise levels, which depends on the model and the data, indeed promotes compositionality. finally, we provide a comprehensive study of this dependence and report results in terms of recently studied compositionality metrics: topographical similarity, conflict count, and context independence. ","1037":"multi-label text classification refers to the problem of assigning each given document its most relevant labels from the label set. commonly, the metadata of the given documents and the hierarchy of the labels are available in real-world applications. however, most existing studies focus on only modeling the text information, with a few attempts to utilize either metadata or hierarchy signals, but not both of them. in this paper, we bridge the gap by formalizing the problem of metadata-aware text classification in a large label hierarchy (e.g., with tens of thousands of labels). to address this problem, we present the match solution -- an end-to-end framework that leverages both metadata and hierarchy information. to incorporate metadata, we pre-train the embeddings of text and metadata in the same space and also leverage the fully-connected attentions to capture the interrelations between them. to leverage the label hierarchy, we propose different ways to regularize the parameters and output probability of each child label by its parents. extensive experiments on two massive text datasets with large-scale label hierarchies demonstrate the effectiveness of match over state-of-the-art deep learning baselines. ","1038":"we study the problem of generating data poisoning attacks against knowledge graph embedding (kge) models for the task of link prediction in knowledge graphs. to poison kge models, we propose to exploit their inductive abilities which are captured through the relationship patterns like symmetry, inversion and composition in the knowledge graph. specifically, to degrade the model's prediction confidence on target facts, we propose to improve the model's prediction confidence on a set of decoy facts. thus, we craft adversarial additions that can improve the model's prediction confidence on decoy facts through different inference patterns. our experiments demonstrate that the proposed poisoning attacks outperform state-of-art baselines on four kge models for two publicly available datasets. we also find that the symmetry pattern based attacks generalize across all model-dataset combinations which indicates the sensitivity of kge models to this pattern. ","1039":"the massive spread of hate speech, hateful content targeted at specific subpopulations, is a problem of critical social importance. automated methods for hate speech detection typically employ state-of-the-art deep learning (dl)-based text classifiers-very large pre-trained neural language models of over 100 million parameters, adapting these models to the task of hate speech detection using relevant labeled datasets. unfortunately, there are only numerous labeled datasets of limited size that are available for this purpose. we make several contributions with high potential for advancing this state of affairs. we present hypernetworks for hate speech detection, a special class of dl networks whose weights are regulated by a small-scale auxiliary network. these architectures operate at character-level, as opposed to word-level, and are several magnitudes of order smaller compared to the popular dl classifiers. we further show that training hate detection classifiers using large amounts of automatically generated examples in a procedure named as it data augmentation is beneficial in general, yet this practice especially boosts the performance of the proposed hypernetworks. in fact, we achieve performance that is comparable or better than state-of-the-art language models, which are pre-trained and orders of magnitude larger, using this approach, as evaluated using five public hate speech datasets. ","1040":"identification of fine-grained location mentions in crisis tweets is central in transforming situational awareness information extracted from social media into actionable information. most prior works have focused on identifying generic locations, without considering their specific types. to facilitate progress on the fine-grained location identification task, we assemble two tweet crisis datasets and manually annotate them with specific location types. the first dataset contains tweets from a mixed set of crisis events, while the second dataset contains tweets from the global covid-19 pandemic. we investigate the performance of state-of-the-art deep learning models for sequence tagging on these datasets, in both in-domain and cross-domain settings. ","1041":"current authentication and trusted systems depend on classical and biometric methods to recognize or authorize users. such methods include audio speech recognitions, eye, and finger signatures. recent tools utilize deep learning and transformers to achieve better results. in this paper, we develop a deep learning constructed model for arabic speakers identification by using wav2vec2.0 and hubert audio representation learning tools. the end-to-end wav2vec2.0 paradigm acquires contextualized speech representations learnings by randomly masking a set of feature vectors, and then applies a transformer neural network. we employ an mlp classifier that is able to differentiate between invariant labeled classes. we show several experimental results that safeguard the high accuracy of the proposed model. the experiments ensure that an arbitrary wave signal for a certain speaker can be identified with 98% and 97.1% accuracies in the cases of wav2vec2.0 and hubert, respectively. ","1042":"to mitigate the problem of having to traverse over the full vocabulary in the softmax normalization of a neural language model, sampling-based training criteria are proposed and investigated in the context of large vocabulary word-based neural language models. these training criteria typically enjoy the benefit of faster training and testing, at a cost of slightly degraded performance in terms of perplexity and almost no visible drop in word error rate. while noise contrastive estimation is one of the most popular choices, recently we show that other sampling-based criteria can also perform well, as long as an extra correction step is done, where the intended class posterior probability is recovered from the raw model outputs. in this work, we propose self-normalized importance sampling. compared to our previous work, the criteria considered in this work are self-normalized and there is no need to further conduct a correction step. compared to noise contrastive estimation, our method is directly comparable in terms of complexity in application. through self-normalized language model training as well as lattice rescoring experiments, we show that our proposed self-normalized importance sampling is competitive in both research-oriented and production-oriented automatic speech recognition tasks. ","1043":"african languages still lag in the advances of natural language processing techniques, one reason being the lack of representative data, having a technique that can transfer information between languages can help mitigate against the lack of data problem. this paper trains setswana and sepedi monolingual word vectors and uses vecmap to create cross-lingual embeddings for setswana-sepedi in order to do a cross-lingual transfer.   word embeddings are word vectors that represent words as continuous floating numbers where semantically similar words are mapped to nearby points in n-dimensional space. the idea of word embeddings is based on the distribution hypothesis that states, semantically similar words are distributed in similar contexts (harris, 1954).   cross-lingual embeddings leverages monolingual embeddings by learning a shared vector space for two separately trained monolingual vectors such that words with similar meaning are represented by similar vectors. in this paper, we investigate cross-lingual embeddings for setswana-sepedi monolingual word vector. we use the unsupervised cross lingual embeddings in vecmap to train the setswana-sepedi cross-language word embeddings. we evaluate the quality of the setswana-sepedi cross-lingual word representation using a semantic evaluation task. for the semantic similarity task, we translated the wordsim and simlex tasks into setswana and sepedi. we release this dataset as part of this work for other researchers. we evaluate the intrinsic quality of the embeddings to determine if there is improvement in the semantic representation of the word embeddings. ","1044":"identifying the relations between chemicals and proteins is an important text mining task. biocreative vii track 1 drugprot task aims to promote the development and evaluation of systems that can automatically detect relations between chemical compounds\/drugs and genes\/proteins in pubmed abstracts. in this paper, we describe our submission, which is an ensemble system, including multiple bert-based language models. we combine the outputs of individual models using majority voting and multilayer perceptron. our system obtained 0.7708 in precision and 0.7770 in recall, for an f1 score of 0.7739, demonstrating the effectiveness of using ensembles of bert-based language models for automatically detecting relations between chemicals and proteins. our code is available at https:\/\/github.com\/bionlplab\/drugprot_bcvii. ","1045":"although rare diseases are characterized by low prevalence, approximately 300 million people are affected by a rare disease. the early and accurate diagnosis of these conditions is a major challenge for general practitioners, who do not have enough knowledge to identify them. in addition to this, rare diseases usually show a wide variety of manifestations, which might make the diagnosis even more difficult. a delayed diagnosis can negatively affect the patient's life. therefore, there is an urgent need to increase the scientific and medical knowledge about rare diseases. natural language processing (nlp) and deep learning can help to extract relevant information about rare diseases to facilitate their diagnosis and treatments. the paper explores the use of several deep learning techniques such as bidirectional long short term memory (bilstm) networks or deep contextualized word representations based on bidirectional encoder representations from transformers (bert) to recognize rare diseases and their clinical manifestations (signs and symptoms) in the raredis corpus. this corpus contains more than 5,000 rare diseases and almost 6,000 clinical manifestations. biobert, a domain-specific language representation based on bert and trained on biomedical corpora, obtains the best results. in particular, this model obtains an f1-score of 85.2% for rare diseases, outperforming all the other models. ","1046":"virtual adversarial training (vat) has been effective in learning robust models under supervised and semi-supervised settings for both computer vision and nlp tasks. however, the efficacy of vat for multilingual and multilabel text classification has not been explored before. in this work, we explore vat for multilabel emotion recognition with a focus on leveraging unlabelled data from different languages to improve the model performance. we perform extensive semi-supervised experiments on semeval2018 multilabel and multilingual emotion recognition dataset and show performance gains of 6.2% (arabic), 3.8% (spanish) and 1.8% (english) over supervised learning with same amount of labelled data (10% of training data). we also improve the existing state-of-the-art by 7%, 4.5% and 1% (jaccard index) for spanish, arabic and english respectively and perform probing experiments for understanding the impact of different layers of the contextual models. ","1047":"bringing together considerations from three research trends (honest signals of collaboration, socio-semantic networks and homophily theory), we hypothesise that word use similarity and having similar social network positions are linked with the level of employees' digital interaction. to verify our hypothesis, we analyse the communication of close to 1600 employees, interacting on the intranet communication forum of a large company. we study their social dynamics and the 'honest signals' that, in past research, proved to be conducive to employees' engagement and collaboration. we find that word use similarity is the main driver of interaction, much more than other language characteristics or similarity in network position. our results suggest carefully choosing the language according to the target audience and have practical implications for both company managers and online community administrators. understanding how to better use language could, for example, support the development of knowledge sharing practices or internal communication campaigns. ","1048":"nowadays, knowledge graphs (kgs) have been playing a pivotal role in ai-related applications. despite the large sizes, existing kgs are far from complete and comprehensive. in order to continuously enrich kgs, automatic knowledge construction and update mechanisms are usually utilized, which inevitably bring in plenty of noise. however, most existing knowledge graph embedding (kge) methods assume that all the triple facts in kgs are correct, and project both entities and relations into a low-dimensional space without considering noise and knowledge conflicts. this will lead to low-quality and unreliable representations of kgs. to this end, in this paper, we propose a general multi-task reinforcement learning framework, which can greatly alleviate the noisy data problem. in our framework, we exploit reinforcement learning for choosing high-quality knowledge triples while filtering out the noisy ones. also, in order to take full advantage of the correlations among semantically similar relations, the triple selection processes of similar relations are trained in a collective way with multi-task learning. moreover, we extend popular kge models transe, distmult, conve and rotate with the proposed framework. finally, the experimental validation shows that our approach is able to enhance existing kge models and can provide more robust representations of kgs in noisy scenarios. ","1049":"complex knowledge base question answering is a popular area of research in the past decade. recent public datasets have led to encouraging results in this field, but are mostly limited to english and only involve a small number of question types and relations, hindering research in more realistic settings and in languages other than english. in addition, few state-of-the-art kbqa models are trained on wikidata, one of the most popular real-world knowledge bases. we propose clc-quad, the first large scale complex chinese semantic parsing dataset over wikidata to address these challenges. together with the dataset, we present a text-to-sparql baseline model, which can effectively answer multi-type complex questions, such as factual questions, dual intent questions, boolean questions, and counting questions, with wikidata as the background knowledge. we finally analyze the performance of sota kbqa models on this dataset and identify the challenges facing chinese kbqa. ","1050":"in this paper, we conduct a sentence level sentiment analysis on the product reviews from amazon and thorough analysis on the model interpretability. for the sentiment analysis task, we use the bilstm model with attention mechanism. for the study of interpretability, we consider the attention weights distribution of single sentence and the attention weights of main aspect terms. the model has an accuracy of up to 0.96. and we find that the aspect terms have the same or even more attention weights than the sentimental words in sentences. ","1051":"in this paper, we improve on existing language resources for the low-resource filipino language in two ways. first, we outline the construction of the tlunified dataset, a large-scale pretraining corpus that serves as an improvement over smaller existing pretraining datasets for the language in terms of scale and topic variety. second, we pretrain new transformer language models following the roberta pretraining technique to supplant existing models trained with small corpora. our new roberta models show significant improvements over existing filipino models in three benchmark datasets with an average gain of 4.47% test accuracy across the three classification tasks of varying difficulty. ","1052":"keyphrase extraction is a fundamental task in natural language processing, which usually contains two main parts: candidate keyphrase extraction and keyphrase importance estimation. from the view of human understanding documents, we typically measure the importance of phrase according to its syntactic accuracy, information saliency, and concept consistency simultaneously. however, most existing keyphrase extraction approaches only focus on the part of them, which leads to biased results. in this paper, we propose a new approach to estimate the importance of keyphrase from multiple perspectives (called as \\textit{kiemp}) and further improve the performance of keyphrase extraction. specifically, \\textit{kiemp} estimates the importance of phrase with three modules: a chunking module to measure its syntactic accuracy, a ranking module to check its information saliency, and a matching module to judge the concept (i.e., topic) consistency between phrase and the whole document. these three modules are seamlessly jointed together via an end-to-end multi-task learning model, which is helpful for three parts to enhance each other and balance the effects of three perspectives. experimental results on six benchmark datasets show that \\textit{kiemp} outperforms the existing state-of-the-art keyphrase extraction approaches in most cases. ","1053":"multi-task learning is useful in nlp because it is often practically desirable to have a single model that works across a range of tasks. in the medical domain, sequential training on tasks may sometimes be the only way to train models, either because access to the original (potentially sensitive) data is no longer available, or simply owing to the computational costs inherent to joint retraining. a major issue inherent to sequential learning, however, is catastrophic forgetting, i.e., a substantial drop in accuracy on prior tasks when a model is updated for a new task. elastic weight consolidation is a recently proposed method to address this issue, but scaling this approach to the modern large models used in practice requires making strong independence assumptions about model parameters, limiting its effectiveness. in this work, we apply kronecker factorization--a recent approach that relaxes independence assumptions--to prevent catastrophic forgetting in convolutional and transformer-based neural networks at scale. we show the effectiveness of this technique on the important and illustrative task of medical entity linking across three datasets, demonstrating the capability of the technique to be used to make efficient updates to existing methods as new medical data becomes available. on average, the proposed method reduces catastrophic forgetting by 51% when using a bert-based model, compared to a 27% reduction using standard elastic weight consolidation, while maintaining spatial complexity proportional to the number of model parameters. ","1054":"image captioning models generally lack the capability to take into account user interest, and usually default to global descriptions that try to balance readability, informativeness, and information overload. on the other hand, vqa models generally lack the ability to provide long descriptive answers, while expecting the textual question to be quite precise. we present a method to control the concepts that an image caption should focus on, using an additional input called the guiding text that refers to either groundable or ungroundable concepts in the image. our model consists of a transformer-based multimodal encoder that uses the guiding text together with global and object-level image features to derive early-fusion representations used to generate the guided caption. while models trained on visual genome data have an in-domain advantage of fitting well when guided with automatic object labels, we find that guided captioning models trained on conceptual captions generalize better on out-of-domain images and guiding texts. our human-evaluation results indicate that attempting in-the-wild guided image captioning requires access to large, unrestricted-domain training datasets, and that increased style diversity (even without increasing the number of unique tokens) is a key factor for improved performance. ","1055":"two key assumptions shape the usual view of ranked retrieval: (1) that the searcher can choose words for their query that might appear in the documents that they wish to see, and (2) that ranking retrieved documents will suffice because the searcher will be able to recognize those which they wished to find. when the documents to be searched are in a language not known by the searcher, neither assumption is true. in such cases, cross-language information retrieval (clir) is needed. this chapter reviews the state of the art for cross-language information retrieval and outlines some open research questions. ","1056":"we present a novel corpus of 445 human- and computer-generated documents, comprising about 27,000 clauses, annotated for semantic clause types and coherence relations that allow for nuanced comparison of artificial and natural discourse modes. the corpus covers both formal and informal discourse, and contains documents generated using fine-tuned gpt-2 (zellers et al., 2019) and gpt-3(brown et al., 2020). we showcase the usefulness of this corpus for detailed discourse analysis of text generation by providing preliminary evidence that less numerous, shorter and more often incoherent clause relations are associated with lower perceived quality of computer-generated narratives and arguments. ","1057":"the objective of automated question answering (qa) systems is to provide answers to user queries in a time efficient manner. the answers are usually found in either databases (or knowledge bases) or a collection of documents commonly referred to as the corpus. in the past few decades there has been a proliferation of acquisition of knowledge and consequently there has been an exponential growth in new scientific articles in the field of biomedicine. therefore, it has become difficult to keep track of all the information in the domain, even for domain experts. with the improvements in commercial search engines, users can type in their queries and get a small set of documents most relevant for answering their query, as well as relevant snippets from the documents in some cases. however, it may be still tedious and time consuming to manually look for the required information or answers. this has necessitated the development of efficient qa systems which aim to find exact and precise answers to user provided natural language questions in the domain of biomedicine. in this paper, we introduce the basic methodologies used for developing general domain qa systems, followed by a thorough investigation of different aspects of biomedical qa systems, including benchmark datasets and several proposed approaches, both using structured databases and collection of texts. we also explore the limitations of current systems and explore potential avenues for further advancement. ","1058":"the spread of covid-19 has sparked racism and hate on social media targeted towards asian communities. however, little is known about how racial hate spreads during a pandemic and the role of counterspeech in mitigating this spread. in this work, we study the evolution and spread of anti-asian hate speech through the lens of twitter. we create covid-hate, the largest dataset of anti-asian hate and counterspeech spanning 14 months, containing over 206 million tweets, and a social network with over 127 million nodes. by creating a novel hand-labeled dataset of 3,355 tweets, we train a text classifier to identify hate and counterspeech tweets that achieves an average macro-f1 score of 0.832. using this dataset, we conduct longitudinal analysis of tweets and users. analysis of the social network reveals that hateful and counterspeech users interact and engage extensively with one another, instead of living in isolated polarized communities. we find that nodes were highly likely to become hateful after being exposed to hateful content. notably, counterspeech messages may discourage users from turning hateful, potentially suggesting a solution to curb hate on web and social media platforms. data and code is at http:\/\/claws.cc.gatech.edu\/covid. ","1059":"although multiple covid-19 vaccines have been available for several months now, vaccine hesitancy continues to be at high levels in the united states. in part, the issue has also become politicized, especially since the presidential election in november. understanding vaccine hesitancy during this period in the context of social media, including twitter, can provide valuable guidance both to computational social scientists and policy makers. rather than studying a single twitter corpus, this paper takes a novel view of the problem by comparatively studying two twitter datasets collected between two different time periods (one before the election, and the other, a few months after) using the same, carefully controlled data collection and filtering methodology. our results show that there was a significant shift in discussion from politics to covid-19 vaccines from fall of 2020 to spring of 2021. by using clustering and machine learning-based methods in conjunction with sampling and qualitative analysis, we uncover several fine-grained reasons for vaccine hesitancy, some of which have become more (or less) important over time. our results also underscore the intense polarization and politicization of this issue over the last year. ","1060":"this paper describes our submission on the covid-19 literature annotation task at biocreative vii. we proposed an approach that exploits the knowledge of the globally non-optimal weights, usually rejected, to build a rich representation of each label. our proposed approach consists of two stages: (1) a bagging of various initializations of the training data that features weakly trained weights, (2) a stacking of heterogeneous vocabulary models based on bert and roberta embeddings. the aggregation of these weak insights performs better than a classical globally efficient model. the purpose is the distillation of the richness of knowledge to a simpler and lighter model. our system obtains an instance-based f1 of 92.96 and a label-based micro-f1 of 91.35. ","1061":"meta learning with auxiliary languages has demonstrated promising improvements for cross-lingual natural language processing. however, previous studies sample the meta-training and meta-testing data from the same language, which limits the ability of the model for cross-lingual transfer. in this paper, we propose xla-maml, which performs direct cross-lingual adaption in the meta-learning stage. we conduct zero-shot and few-shot experiments on natural language inference and question answering. the experimental results demonstrate the effectiveness of our method across different languages, tasks, and pretrained models. we also give analysis on various cross-lingual specific settings for meta-learning including sampling strategy and parallelism. ","1062":"automatically solving math word problems is a critical task in the field of natural language processing. recent models have reached their performance bottleneck and require more high-quality data for training. we propose a novel data augmentation method that reverses the mathematical logic of math word problems to produce new high-quality math problems and introduce new knowledge points that can benefit learning the mathematical reasoning logic. we apply the augmented data on two sota math word problem solving models and compare our results with a strong data augmentation baseline. experimental results show the effectiveness of our approach. we release our code and data at https:\/\/github.com\/yiyunya\/roda. ","1063":"transformer-based language models are applied to a wide range of applications in natural language processing. however, they are inefficient and difficult to deploy. in recent years, many compression algorithms have been proposed to increase the implementation efficiency of large transformer-based models on target hardware. in this work we present a new method for training sparse pre-trained transformer language models by integrating weight pruning and model distillation. these sparse pre-trained models can be used to transfer learning for a wide range of tasks while maintaining their sparsity pattern. we demonstrate our method with three known architectures to create sparse pre-trained bert-base, bert-large and distilbert. we show how the compressed sparse pre-trained models we trained transfer their knowledge to five different downstream natural language tasks with minimal accuracy loss. moreover, we show how to further compress the sparse models' weights to 8bit precision using quantization-aware training. for example, with our sparse pre-trained bert-large fine-tuned on squadv1.1 and quantized to 8bit we achieve a compression ratio of $40$x for the encoder with less than $1\\%$ accuracy loss. to the best of our knowledge, our results show the best compression-to-accuracy ratio for bert-base, bert-large, and distilbert. ","1064":"one challenge with open-domain dialogue systems is the need to produce truthful, high-quality responses on any topic. we aim to improve the quality and coverage of athena, an alexa prize dialogue system. we experiment with few-shot prompt-based learning, comparing gpt-neo to jurassic-1, for the movies, music, tv, sports, and video game domains, both within and cross-domain, with different prompt set sizes (2, 3, 10), formats, and meaning representations consisting of either sets of wikidata kg triples, or dialogue acts. our evaluation uses bleurt and human metrics, and shows that with 10-shot prompting, athena-jurassic's performance is significantly better for coherence and semantic accuracy. experiments with 2-shot cross-domain prompts results in a huge performance drop for athena-gpt-neo, whose semantic accuracy falls to 0.41, and whose untrue hallucination rate increases to 12%. experiments with dialogue acts for video games show that with 10-shot prompting, both models learn to control dialogue acts, but athena-jurassic has significantly higher coherence, and only 4% untrue hallucinations. our results suggest that athena-jurassic produces high enough quality outputs to be useful in live systems with real users. to our knowledge, these are the first results demonstrating that few-shot semantic prompt-based learning can create nlgs that generalize to new domains, and produce high-quality, semantically-controlled, conversational responses directly from meaning representations. ","1065":"question answering(qa) is one of the most challenging yet widely investigated problems in natural language processing (nlp). question-answering (qa) systems try to produce answers for given questions. these answers can be generated from unstructured or structured text. hence, qa is considered an important research area that can be used in evaluating text understanding systems. a large volume of qa studies was devoted to the english language, investigating the most advanced techniques and achieving state-of-the-art results. however, research efforts in the arabic question-answering progress at a considerably slower pace due to the scarcity of research efforts in arabic qa and the lack of large benchmark datasets. recently many pre-trained language models provided high performance in many arabic nlp problems. in this work, we evaluate the state-of-the-art pre-trained transformers models for arabic qa using four reading comprehension datasets which are arabic-squad, arcd, aqad, and tydiqa-goldp datasets. we fine-tuned and compared the performance of the arabertv2-base model, arabertv0.2-large model, and araelectra model. in the last, we provide an analysis to understand and interpret the low-performance results obtained by some models. ","1066":"idiomatic expressions can be problematic for natural language processing applications as their meaning cannot be inferred from their constituting words. a lack of successful methodological approaches and sufficiently large datasets prevents the development of machine learning approaches for detecting idioms, especially for expressions that do not occur in the training set. we present an approach, called mice, that uses contextual embeddings for that purpose. we present a new dataset of multi-word expressions with literal and idiomatic meanings and use it to train a classifier based on two state-of-the-art contextual word embeddings: elmo and bert. we show that deep neural networks using both embeddings perform much better than existing approaches, and are capable of detecting idiomatic word use, even for expressions that were not present in the training set. we demonstrate cross-lingual transfer of developed models and analyze the size of the required dataset. ","1067":"modern video-text retrieval frameworks basically consist of three parts: video encoder, text encoder and the similarity head. with the success on both visual and textual representation learning, transformer based encoders and fusion methods have also been adopted in the field of video-text retrieval. in this report, we present clip2tv, aiming at exploring where the critical elements lie in transformer based methods. to achieve this, we first revisit some recent works on multi-modal learning, then introduce some techniques into video-text retrieval, finally evaluate them through extensive experiments in different configurations. notably, clip2tv achieves 52.9@r1 on msr-vtt dataset, outperforming the previous sota result by 4.1%. ","1068":"digital sources are more prevalent than ever but effectively using them can be challenging. one core challenge is that digitized sources are often distributed, thus forcing researchers to spend time collecting, interpreting, and aligning different sources. a knowledge graph can accelerate research by providing a single connected source of truth that humans and machines can query. during two design-test cycles, we convert four data sets from the historical maritime domain into a knowledge graph. the focus during these cycles is on creating a sustainable and usable approach that can be adopted in other linked data conversion efforts. furthermore, our knowledge graph is available for maritime historians and other interested users to investigate the daily business of the dutch east india company through a unified portal. ","1069":"humans are naturally endowed with the ability to write in a particular style. they can, for instance, rephrase a formal letter in an informal way, convey a literal message with the use of figures of speech, edit a novel mimicking the style of some well-known authors. automating this form of creativity constitutes the goal of style transfer. as a natural language generation task, style transfer aims at re-writing existing texts, and specifically, it creates paraphrases that exhibit some desired stylistic attributes. from a practical perspective, it envisions beneficial applications, like chat-bots that modulate their communicative style to appear empathetic, or systems that automatically simplify technical articles for a non-expert audience.   style transfer has been dedicated several style-aware paraphrasing methods. a handful of surveys give a methodological overview of the field, but they do not support researchers to focus on specific styles. with this paper, we aim at providing a comprehensive discussion of the styles that have received attention in the transfer task. we organize them into a hierarchy, highlighting the challenges for the definition of each of them, and pointing out gaps in the current research landscape. the hierarchy comprises two main groups. one encompasses styles that people modulate arbitrarily, along the lines of registers and genres. the other group corresponds to unintentionally expressed styles, due to an author's personal characteristics. hence, our review shows how the groups relate to one another, and where specific styles, including some that have never been explored, belong in the hierarchy. moreover, we summarize the methods employed for different stylistic families, hinting researchers towards those that would be the most fitting for future research. ","1070":"data is published on the web over time in great volumes, but majority of the data is unstructured, making it hard to understand and difficult to interpret. information extraction (ie) methods obtain structured information from unstructured data. one of the challenging ie tasks is event extraction (ee) which seeks to derive information about specific incidents and their actors from the text. ee is useful in many domains such as building a knowledge base, information retrieval and summarization. in the past decades, some event ontologies like ace, cameo and icews were developed to define event forms, actors and dimensions of events observed in the text. these event ontologies still have some shortcomings such as covering only a few topics like political events, having inflexible structure in defining argument roles and insufficient gold-standard data. to address these concerns, we propose an event ontology, namely cofee, that incorporates both expert domain knowledge and a data-driven approach for identifying events from text. cofee consists of two hierarchy levels (event types and event sub-types) that include new categories relating to environmental issues, cyberspace and criminal activity which need to be monitored instantly. also, dynamic roles according to each event sub-type are defined to capture various dimensions of events. in a follow-up experiment, the proposed ontology is evaluated on wikipedia events, and it is shown to be general and comprehensive. moreover, in order to facilitate the preparation of gold-standard data for event extraction, a language-independent online tool is presented based on cofee. a gold-standard dataset annotated by 10 human experts is also prepared consisting 24k news articles in persian language. finally, we present a supervised method based on deep learning techniques to automatically extract relevant events and corresponding actors. ","1071":"learning multimodal representations involves integrating information from multiple heterogeneous sources of data. it is a challenging yet crucial area with numerous real-world applications in multimedia, affective computing, robotics, finance, human-computer interaction, and healthcare. unfortunately, multimodal research has seen limited resources to study (1) generalization across domains and modalities, (2) complexity during training and inference, and (3) robustness to noisy and missing modalities. in order to accelerate progress towards understudied modalities and tasks while ensuring real-world robustness, we release multibench, a systematic and unified large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas. multibench provides an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation. to enable holistic evaluation, multibench offers a comprehensive methodology to assess (1) generalization, (2) time and space complexity, and (3) modality robustness. multibench introduces impactful challenges for future research, including scalability to large-scale multimodal datasets and robustness to realistic imperfections. to accompany this benchmark, we also provide a standardized implementation of 20 core approaches in multimodal learning. simply applying methods proposed in different research areas can improve the state-of-the-art performance on 9\/15 datasets. therefore, multibench presents a milestone in unifying disjoint efforts in multimodal research and paves the way towards a better understanding of the capabilities and limitations of multimodal models, all the while ensuring ease of use, accessibility, and reproducibility. multibench, our standardized code, and leaderboards are publicly available, will be regularly updated, and welcomes inputs from the community. ","1072":"the primary purpose of dialogue state tracking (dst), a critical component of an end-to-end conversational system, is to build a model that responds well to real-world situations. although we often change our minds from time to time during ordinary conversations, current benchmark datasets do not adequately reflect such occurrences and instead consist of over-simplified conversations, in which no one changes their mind during a conversation. as the main question inspiring the present study, ``are current benchmark datasets sufficiently diverse to handle casual conversations in which one changes their mind after a certain topic is over?'' we found that the answer is \"no\" because simply injecting template-based turnback utterances significantly degrades the dst model performance. the test joint goal accuracy on the multiwoz decreased by over 5\\%p when the simplest form of turnback utterance was injected. moreover, the performance degeneration worsens when facing more complicated turnback situations. however, we also observed that the performance rebounds when a turnback is appropriately included in the training dataset, implying that the problem is not with the dst models but rather with the construction of the benchmark dataset. ","1073":"in recent years, larger and deeper models are springing up and continuously pushing state-of-the-art (sota) results across various fields like natural language processing (nlp) and computer vision (cv). however, despite promising results, it needs to be noted that the computations required by sota models have been increased at an exponential rate. massive computations not only have a surprisingly large carbon footprint but also have negative effects on research inclusiveness and deployment on real-world applications.   green deep learning is an increasingly hot research field that appeals to researchers to pay attention to energy usage and carbon emission during model training and inference. the target is to yield novel results with lightweight and efficient technologies. many technologies can be used to achieve this goal, like model compression and knowledge distillation. this paper focuses on presenting a systematic review of the development of green deep learning technologies. we classify these approaches into four categories: (1) compact networks, (2) energy-efficient training strategies, (3) energy-efficient inference approaches, and (4) efficient data usage. for each category, we discuss the progress that has been achieved and the unresolved challenges. ","1074":"building a benchmark dataset for hate speech detection presents various challenges. firstly, because hate speech is relatively rare, random sampling of tweets to annotate is very inefficient in finding hate speech. to address this, prior datasets often include only tweets matching known \"hate words\". however, restricting data to a pre-defined vocabulary may exclude portions of the real-world phenomenon we seek to model. a second challenge is that definitions of hate speech tend to be highly varying and subjective. annotators having diverse prior notions of hate speech may not only disagree with one another but also struggle to conform to specified labeling guidelines. our key insight is that the rarity and subjectivity of hate speech are akin to that of relevance in information retrieval (ir). this connection suggests that well-established methodologies for creating ir test collections can be usefully applied to create better benchmark datasets for hate speech. to intelligently and efficiently select which tweets to annotate, we apply standard ir techniques of {\\em pooling} and {\\em active learning}. to improve both consistency and value of annotations, we apply {\\em task decomposition} and {\\em annotator rationale} techniques. we share a new benchmark dataset for hate speech detection on twitter that provides broader coverage of hate than prior datasets. we also show a dramatic drop in accuracy of existing detection models when tested on these broader forms of hate. annotator rationales we collect not only justify labeling decisions but also enable future work opportunities for dual-supervision and\/or explanation generation in modeling. further details of our approach can be found in the supplementary materials. ","1075":"this study analyzes walt whitman's stylistic changes in his phenomenal work leaves of grass from a computational perspective and relates findings to standard literary criticism on whitman. the corpus consists of all 7 editions of leaves of grass, ranging from the earliest 1855 edition to the 1891-92 \"deathbed\" edition. starting from counting word frequencies, the simplest stylometry technique, we find consistent shifts in word choice. macro-etymological analysis reveals whitman's increasing preference for words of specific origins, which is correlated to the increasing lexical complexity in leaves of grass. principal component analysis, an unsupervised learning algorithm, reduces the dimensionality of tf-idf vectors to 2 dimensions, providing a straightforward view of stylistic changes. finally, sentiment analysis shows the evolution of whitman's emotional state throughout his writing career. ","1076":"similarity is a comparative-subjective measure that varies with the domain within which it is considered. in several nlp applications such as document classification, pattern recognition, chatbot question-answering, sentiment analysis, etc., identifying an accurate similarity score for sentence pairs has become a crucial area of research. in the existing models that assess similarity, the limitation of effectively computing this similarity based on contextual comparisons, the localization due to the centering theory, and the lack of non-semantic textual comparisons have proven to be drawbacks. hence, this paper presents a multi-layered semantic similarity network model built upon multiple similarity measures that render an overall sentence similarity score based on the principles of network science, neighboring weighted relational edges, and a proposed extended node similarity computation formula. the proposed multi-layered network model was evaluated and tested against established state-of-the-art models and is shown to have demonstrated better performance scores in assessing sentence similarity. ","1077":"document-level relation extraction aims to identify relations between entities in a whole document. prior efforts to capture long-range dependencies have relied heavily on implicitly powerful representations learned through (graph) neural networks, which makes the model less transparent. to tackle this challenge, in this paper, we propose logire, a novel probabilistic model for document-level relation extraction by learning logic rules. logire treats logic rules as latent variables and consists of two modules: a rule generator and a relation extractor. the rule generator is to generate logic rules potentially contributing to final predictions, and the relation extractor outputs final predictions based on the generated logic rules. those two modules can be efficiently optimized with the expectation-maximization (em) algorithm. by introducing logic rules into neural networks, logire can explicitly capture long-range dependencies as well as enjoy better interpretation. empirical results show that logire significantly outperforms several strong baselines in terms of relation performance (1.8 f1 score) and logical consistency (over 3.3 logic score). our code is available at https:\/\/github.com\/rudongyu\/logire. ","1078":"recent work has demonstrated that pre-training in-domain language models can boost performance when adapting to a new domain. however, the costs associated with pre-training raise an important question: given a fixed budget, what steps should an nlp practitioner take to maximize performance? in this paper, we study domain adaptation under budget constraints, and approach it as a customer choice problem between data annotation and pre-training. specifically, we measure the annotation cost of three procedural text datasets and the pre-training cost of three in-domain language models. then we evaluate the utility of different combinations of pre-training and data annotation under varying budget constraints to assess which combination strategy works best. we find that, for small budgets, spending all funds on annotation leads to the best performance; once the budget becomes large enough, a combination of data annotation and in-domain pre-training works more optimally. we therefore suggest that task-specific data annotation should be part of an economical strategy when adapting an nlp model to a new domain. ","1079":"mikolov et al. (2013a) observed that continuous bag-of-words (cbow) word embeddings tend to underperform skip-gram (sg) embeddings, and this finding has been reported in subsequent works. we find that these observations are driven not by fundamental differences in their training objectives, but more likely on faulty negative sampling cbow implementations in popular libraries such as the official implementation, word2vec.c, and gensim. we show that after correcting a bug in the cbow gradient update, one can learn cbow word embeddings that are fully competitive with sg on various intrinsic and extrinsic tasks, while being many times faster to train. ","1080":"crowdsourcing requesters on amazon mechanical turk (amt) have raised questions about the reliability of the workers. the amt workforce is very diverse and it is not possible to make blanket assumptions about them as a group. some requesters now reject work en mass when they do not get the results they expect. this has the effect of giving each worker (good or bad) a lower human intelligence task (hit) approval score, which is unfair to the good workers. it also has the effect of giving the requester a bad reputation on the workers' forums. some of the issues causing the mass rejections stem from the requesters not taking the time to create a well-formed task with complete instructions and\/or not paying a fair wage. to explore this assumption, this paper describes a study that looks at the crowdsourcing hits on amt that were available over a given span of time and records information about those hits. this study also records information from a crowdsourcing forum on the worker perspective on both those hits and on their corresponding requesters. results reveal issues in worker payment and presentation issues such as missing instructions or hits that are not doable. ","1081":"large language models can produce fluent dialogue but often hallucinate factual inaccuracies. while retrieval-augmented models help alleviate this issue, they still face a difficult challenge of both reasoning to provide correct knowledge and generating conversation simultaneously. in this work, we propose a modular model, knowledge to response (k2r), for incorporating knowledge into conversational agents, which breaks down this problem into two easier steps. k2r first generates a knowledge sequence, given a dialogue context, as an intermediate step. after this \"reasoning step\", the model then attends to its own generated knowledge sequence, as well as the dialogue context, to produce a final response. in detailed experiments, we find that such a model hallucinates less in knowledge-grounded dialogue tasks, and has advantages in terms of interpretability and modularity. in particular, it can be used to fuse qa and dialogue systems together to enable dialogue agents to give knowledgeable answers, or qa models to give conversational responses in a zero-shot setting. ","1082":"this paper tackles the under-explored problem of dom tree element representation learning. we advance the field of machine learning-based web automation and hope to spur further research regarding this crucial area with two contributions. first, we adapt several popular graph-based neural network models and apply them to embed elements in website dom trees. second, we present a large-scale and realistic dataset of webpages. by providing this open-access resource, we lower the entry barrier to this area of research. the dataset contains $51,701$ manually labeled product pages from $8,175$ real e-commerce websites. the pages can be rendered entirely in a web browser and are suitable for computer vision applications. this makes it substantially richer and more diverse than other datasets proposed for element representation learning, classification and prediction on the web. finally, using our proposed dataset, we show that the embeddings produced by a graph convolutional neural network outperform representations produced by other state-of-the-art methods in a web element prediction task. ","1083":"temporal and causal relations play an important role in determining the dependencies between events. classifying the temporal and causal relations between events has many applications, such as generating event timelines, event summarization, textual entailment and question answering. temporal and causal relations are closely related and influence each other. so we propose a joint model that incorporates both temporal and causal features to perform causal relation classification. we use the syntactic structure of the text for identifying temporal and causal relations between two events from the text. we extract parts-of-speech tag sequence, dependency tag sequence and word sequence from the text. we propose an lstm based model for temporal and causal relation classification that captures the interrelations between the three encoded features. evaluation of our model on four popular datasets yields promising results for temporal and causal relation classification. ","1084":"analogical proportions are statements of the form \"a is to b as c is to d\". they constitute an inference tool that provides a logical framework to address learning, transfer, and explainability concerns and that finds useful applications in artificial intelligence and natural language processing. in this paper, we address two problems, namely, analogy detection and resolution in morphology. multiple symbolic approaches tackle the problem of analogies in morphology and achieve competitive performance. we show that it is possible to use a data-driven strategy to outperform those models. we propose an approach using deep learning to detect and solve morphological analogies. it encodes structural properties of analogical proportions and relies on a specifically designed embedding model capturing morphological characteristics of words. we demonstrate our model's competitive performance on analogy detection and resolution over multiple languages. we provide an empirical study to analyze the impact of balancing training data and evaluate the robustness of our approach to input perturbation. ","1085":"both politics and pandemics have recently provided ample motivation for the development of machine learning-enabled disinformation (a.k.a. fake news) detection algorithms. existing literature has focused primarily on the fully-automated case, but the resulting techniques cannot reliably detect disinformation on the varied topics, sources, and time scales required for military applications. by leveraging an already-available analyst as a human-in-the-loop, however, the canonical machine learning techniques of sentiment analysis, aspect-based sentiment analysis, and stance detection become plausible methods to use for a partially-automated disinformation detection system. this paper aims to determine which of these techniques is best suited for this purpose and how each technique might best be used towards this end. training datasets of the same size and nearly identical neural architectures (a bert transformer as a word embedder with a single feed-forward layer thereafter) are used for each approach, which are then tested on sentiment- and stance-specific datasets to establish a baseline of how well each method can be used to do the other tasks. four different datasets relating to covid-19 disinformation are used to test the ability of each technique to detect disinformation on a topic that did not appear in the training data set. quantitative and qualitative results from these tests are then used to provide insight into how best to employ these techniques in practice. ","1086":"this article shows that the boundaries between the editing and online publishingprofessions are losing their strength. in this context it would only make sense that the wayhypertexts are documented be renewed, especially facing of the web's evolution. we arethinking in particular of the trickier scholar hypertexts documentation process - specifically inscientific or cultural contexts. the purpose of this article is to demonstrate that, consideringthe numerous branches of the web, the hypertext enhance of a document of quality can onlybe done through a proper dialogue between authors, editors, and broadcasters. it would satisfythe readership as they could reach the appropriate information. it will also be shown that eachactor in this auctorial-editorial process would be a gainer. indeed, a qualitative formalizationwork would be coupled with a strong broadcasting scope. finally, we will point out that thiswork of mediating must be led by an actor of information-communication, to make the textunderstandable to both humans and machines. this meditative act is designated here under theterm of serial documentarisation. ","1087":"large-scale pre-trained language models have demonstrated strong capabilities of generating realistic text. however, it remains challenging to control the generation results. previous approaches such as prompting are far from sufficient, which limits the usage of language models. to tackle this challenge, we propose an innovative method, inverse prompting, to better control text generation. the core idea of inverse prompting is to use generated text to inversely predict the prompt during beam search, which enhances the relevance between the prompt and the generated text and provides better controllability. empirically, we pre-train a large-scale chinese language model to perform a systematic study using human evaluation on the tasks of open-domain poem generation and open-domain long-form question answering. our results show that our proposed method substantially outperforms the baselines and that our generation quality is close to human performance on some of the tasks.   narrators can try our poem generation demo at https:\/\/pretrain.aminer.cn\/apps\/poetry.html, while our qa demo can be found at https:\/\/pretrain.aminer.cn\/app\/qa. for researchers, the code is provided in https:\/\/github.com\/thudm\/inverseprompting. ","1088":"neural network models often generalize poorly to mismatched domains or distributions. in nlp, this issue arises in particular when models are expected to generalize compositionally, that is, to novel combinations of familiar words and constructions. we investigate learning representations that facilitate transfer learning from one compositional task to another: the representation and the task-specific layers of the models are strategically trained differently on a pre-finetuning task such that they generalize well on mismatched splits that require compositionality. we apply this method to semantic parsing, using three very different datasets, cogs, geoquery and scan, used alternately as the pre-finetuning and target task. our method significantly improves compositional generalization over baselines on the test set of the target task, which is held out during fine-tuning. ablation studies characterize the utility of the major steps in the proposed algorithm and support our hypothesis. ","1089":"in recent years, the problem of rumours on online social media (osm) has attracted lots of attention. researchers have started investigating from two main directions. first is the descriptive analysis of rumours and secondly, proposing techniques to detect (or classify) rumours. in the descriptive line of works, where researchers have tried to analyse rumours using nlp approaches, there isnt much emphasis on psycho-linguistics analyses of social media text. these kinds of analyses on rumour case studies are vital for drawing meaningful conclusions to mitigate misinformation. for our analysis, we explored the pheme9 rumour dataset (consisting of 9 events), including source tweets (both rumour and non-rumour categories) and response tweets. we compared the rumour and nonrumour source tweets and then their corresponding reply (response) tweets to understand how they differ linguistically for every incident. furthermore, we also evaluated if these features can be used for classifying rumour vs. non-rumour tweets through machine learning models. to this end, we employed various classical and ensemble-based approaches. to filter out the highly discriminative psycholinguistic features, we explored the shap ai explainability tool. to summarise, this research contributes by performing an in-depth psycholinguistic analysis of rumours related to various kinds of events. ","1090":"transformer architectures have brought about fundamental changes to computational linguistic field, which had been dominated by recurrent neural networks for many years. its success also implies drastic changes in cross-modal tasks with language and vision, and many researchers have already tackled the issue. in this paper, we review some of the most critical milestones in the field, as well as overall trends on how transformer architecture has been incorporated into visuolinguistic cross-modal tasks. furthermore, we discuss its current limitations and speculate upon some of the prospects that we find imminent. ","1091":"an ai chatbot provides an impressive response after learning from the trained dataset. in this decade, most of the research work demonstrates that deep neural models superior to any other model. rnn model regularly used for determining the sequence-related problem like a question and it answers. this approach acquainted with everyone as seq2seq learning. in a seq2seq model mechanism, it has encoder and decoder. the encoder embedded any input sequence, and the decoder embedded output sequence. for reinforcing the seq2seq model performance, attention mechanism added into the encoder and decoder. after that, the transformer model has introduced itself as a high-performance model with multiple attention mechanism for solving the sequence-related dilemma. this model reduces training time compared with rnn based model and also achieved state-of-the-art performance for sequence transduction. in this research, we applied the transformer model for bengali general knowledge chatbot based on the bengali general knowledge question answer (qa) dataset. it scores 85.0 bleu on the applied qa data. to check the comparison of the transformer model performance, we trained the seq2seq model with attention on our dataset that scores 23.5 bleu. ","1092":"social media platforms may provide potential space for discourses that contain hate speech, and even worse, can act as a propagation mechanism for hate crimes. the fbi's uniform crime reporting (ucr) program collects hate crime data and releases statistic report yearly. these statistics provide information in determining national hate crime trends. the statistics can also provide valuable holistic and strategic insight for law enforcement agencies or justify lawmakers for specific legislation. however, the reports are mostly released next year and lag behind many immediate needs. recent research mainly focuses on hate speech detection in social media text or empirical studies on the impact of a confirmed crime. this paper proposes a framework that first utilizes text mining techniques to extract hate crime events from new york times news, then uses the results to facilitate predicting american national-level and state-level hate crime trends. experimental results show that our method can significantly enhance the prediction performance compared with time series or regression methods without event-related factors. our framework broadens the methods of national-level and state-level hate crime trends prediction. ","1093":"unsupervised dialogue structure learning is an important and meaningful task in natural language processing. the extracted dialogue structure and process can help analyze human dialogue, and play a vital role in the design and evaluation of dialogue systems. the traditional dialogue system requires experts to manually design the dialogue structure, which is very costly. but through unsupervised dialogue structure learning, dialogue structure can be automatically obtained, reducing the cost of developers constructing dialogue process. the learned dialogue structure can be used to promote the dialogue generation of the downstream task system, and improve the logic and consistency of the dialogue robot's reply.in this paper, we propose a bert-based unsupervised dialogue structure learning algorithm dsbert (dialogue structure bert). different from the previous sota models vrnn and svrnn, we combine bert and autoencoder, which can effectively combine context information. in order to better prevent the model from falling into the local optimal solution and make the dialogue state distribution more uniform and reasonable, we also propose three balanced loss functions that can be used for dialogue structure learning. experimental results show that dsbert can generate a dialogue structure closer to the real structure, can distinguish sentences with different semantics and map them to different hidden states. ","1094":"without positional information, attention-based transformer neural networks are permutation-invariant. absolute or relative positional embeddings are the most popular ways to feed transformer models with positional information. absolute positional embeddings are simple to implement, but suffer from generalization issues when evaluating on sequences longer than seen at training time. relative positions are more robust to input length change, but are more complex to implement and yield inferior model throughput due to extra computational and memory costs. in this paper, we propose an augmentation-based approach (cape) for absolute positional embeddings, which keeps the advantages of both absolute (simplicity and speed) and relative positional embeddings (better generalization). in addition, our empirical evaluation on state-of-the-art models in machine translation, image and speech recognition demonstrates that cape leads to better generalization performance as well as increased stability with respect to training hyper-parameters. ","1095":"spelling error correction is one of topics which have a long history in natural language processing. although previous studies have achieved remarkable results, challenges still exist. in the vietnamese language, a state-of-the-art method for the task infers a syllable's context from its adjacent syllables. the method's accuracy can be unsatisfactory, however, because the model may lose the context if two (or more) spelling mistakes stand near each other. in this paper, we propose a novel method to correct vietnamese spelling errors. we tackle the problems of mistyped errors and misspelled errors by using a deep learning model. the embedding layer, in particular, is powered by the byte pair encoding technique. the sequence to sequence model based on the transformer architecture makes our approach different from the previous works on the same problem. in the experiment, we train the model with a large synthetic dataset, which is randomly introduced spelling errors. we test the performance of the proposed method using a realistic dataset. this dataset contains 11,202 human-made misspellings in 9,341 different vietnamese sentences. the experimental results show that our method achieves encouraging performance with 86.8% errors detected and 81.5% errors corrected, which improves the state-of-the-art approach 5.6% and 2.2%, respectively. ","1096":"a large number of deep neural network based techniques have been developed to address the challenging problem of face presentation attack detection (pad). whereas such techniques' focus has been on improving pad performance in terms of classification accuracy and robustness against unseen attacks and environmental conditions, there exists little attention on the explainability of pad predictions. in this paper, we tackle the problem of explaining pad predictions through natural language. our approach passes feature representations of a deep layer of the pad model to a language model to generate text describing the reasoning behind the pad prediction. due to the limited amount of annotated data in our study, we apply a light-weight lstm network as our natural language generation model. we investigate how the quality of the generated explanations is affected by different loss functions, including the commonly used word-wise cross entropy loss, a sentence discriminative loss, and a sentence semantic loss. we perform our experiments using face images from a dataset consisting of 1,105 bona-fide and 924 presentation attack samples. our quantitative and qualitative results show the effectiveness of our model for generating proper pad explanations through text as well as the power of the sentence-wise losses. to the best of our knowledge, this is the first introduction of a joint biometrics-nlp task. our dataset can be obtained through our github page. ","1097":"many intellectual endeavors require mathematical problem solving, but this skill remains beyond the capabilities of computers. to measure this ability in machine learning models, we introduce math, a new dataset of 12,500 challenging competition mathematics problems. each problem in math has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations. to facilitate future research and increase accuracy on math, we also contribute a large auxiliary pretraining dataset which helps teach models the fundamentals of mathematics. even though we are able to increase accuracy on math, our results show that accuracy remains relatively low, even with enormous transformer models. moreover, we find that simply increasing budgets and model parameter counts will be impractical for achieving strong mathematical reasoning if scaling trends continue. while scaling transformers is automatically solving most other text-based tasks, scaling is not currently solving math. to have more traction on mathematical problem solving we will likely need new algorithmic advancements from the broader research community. ","1098":"many specialized domains remain untouched by deep learning, as large labeled datasets require expensive expert annotators. we address this bottleneck within the legal domain by introducing the contract understanding atticus dataset (cuad), a new dataset for legal contract review. cuad was created with dozens of legal experts from the atticus project and consists of over 13,000 annotations. the task is to highlight salient portions of a contract that are important for a human to review. we find that transformer models have nascent performance, but that this performance is strongly influenced by model design and training dataset size. despite these promising results, there is still substantial room for improvement. as one of the only large, specialized nlp benchmarks annotated by experts, cuad can serve as a challenging research benchmark for the broader nlp community. ","1099":"while programming is one of the most broadly applicable skills in modern society, modern machine learning models still cannot code solutions to basic problems. despite its importance, there has been surprisingly little work on evaluating code generation, and it can be difficult to accurately assess code generation performance rigorously. to meet this challenge, we introduce apps, a benchmark for code generation. unlike prior work in more restricted settings, our benchmark measures the ability of models to take an arbitrary natural language specification and generate satisfactory python code. similar to how companies assess candidate software developers, we then evaluate models by checking their generated code on test cases. our benchmark includes 10,000 problems, which range from having simple one-line solutions to being substantial algorithmic challenges. we fine-tune large language models on both github and our training set, and we find that the prevalence of syntax errors is decreasing exponentially as models improve. recent models such as gpt-neo can pass approximately 20% of the test cases of introductory problems, so we find that machine learning models are now beginning to learn how to code. as the social significance of automatic code generation increases over the coming years, our benchmark can provide an important measure for tracking advancements. ","1100":"in this paper, we explore self-supervised audio-visual models that learn from instructional videos. prior work has shown that these models can relate spoken words and sounds to visual content after training on a large-scale dataset of videos, but they were only trained and evaluated on videos in english. to learn multilingual audio-visual representations, we propose a cascaded approach that leverages a model trained on english videos and applies it to audio-visual data in other languages, such as japanese videos. with our cascaded approach, we show an improvement in retrieval performance of nearly 10x compared to training on the japanese videos solely. we also apply the model trained on english videos to japanese and hindi spoken captions of images, achieving state-of-the-art performance. ","1101":"visual question answering (vqa) has been gaining a lot of traction in the machine learning community in the recent years due to the challenges posed in understanding information coming from multiple modalities (i.e., images, language). in vqa, a series of questions are posed based on a set of images and the task at hand is to arrive at the answer. to achieve this, we take a symbolic reasoning based approach using the framework of formal logic. the image and the questions are converted into symbolic representations on which explicit reasoning is performed. we propose a formal logic framework where (i) images are converted to logical background facts with the help of scene graphs, (ii) the questions are translated to first-order predicate logic clauses using a transformer based deep learning model, and (iii) perform satisfiability checks, by using the background knowledge and the grounding of predicate clauses, to obtain the answer. our proposed method is highly interpretable and each step in the pipeline can be easily analyzed by a human. we validate our approach on the clevr and the gqa dataset. we achieve near perfect accuracy of 99.6% on the clevr dataset comparable to the state of art models, showcasing that formal logic is a viable tool to tackle visual question answering. our model is also data efficient, achieving 99.1% accuracy on clevr dataset when trained on just 10% of the training data. ","1102":"few-shot nlp research is highly active, yet conducted in disjoint research threads with evaluation suites that lack challenging-yet-realistic testing setups and fail to employ careful experimental design. consequently, the community does not know which techniques perform best or even if they outperform simple baselines. in response, we formulate the flex principles, a set of requirements and best practices for unified, rigorous, valid, and cost-sensitive few-shot nlp evaluation. these principles include sample size design, a novel approach to benchmark design that optimizes statistical accuracy and precision while keeping evaluation costs manageable. following the principles, we release the flex benchmark, which includes four few-shot transfer settings, zero-shot evaluation, and a public leaderboard that covers diverse nlp tasks. in addition, we present unifew, a prompt-based model for few-shot learning that unifies pretraining and finetuning prompt formats, eschewing complex machinery of recent prompt-based approaches in adapting downstream task formats to language model pretraining objectives. we demonstrate that despite simplicity, unifew achieves results competitive with both popular meta-learning and prompt-based approaches. ","1103":"we present mr. tydi, a multi-lingual benchmark dataset for mono-lingual retrieval in eleven typologically diverse languages, designed to evaluate ranking with learned dense representations. the goal of this resource is to spur research in dense retrieval techniques in non-english languages, motivated by recent observations that existing techniques for representation learning perform poorly when applied to out-of-distribution data. as a starting point, we provide zero-shot baselines for this new dataset based on a multi-lingual adaptation of dpr that we call \"mdpr\". experiments show that although the effectiveness of mdpr is much lower than bm25, dense representations nevertheless appear to provide valuable relevance signals, improving bm25 results in sparse-dense hybrids. in addition to analyses of our results, we also discuss future challenges and present a research agenda in multi-lingual dense retrieval. mr. tydi can be downloaded at https:\/\/github.com\/castorini\/mr.tydi. ","1104":"we present the first openly available corpus for detecting depression in thai. our corpus is compiled by expert verified cases of depression in several online blogs. we experiment with two different lstm based models and two different bert based models. we achieve a 77.53\\% accuracy with a thai bert model in detecting depression. this establishes a good baseline for future researcher on the same corpus. furthermore, we identify a need for thai embeddings that have been trained on a more varied corpus than wikipedia. our corpus, code and trained models have been released openly on zenodo. ","1105":"the popularity of social media has created problems such as hate speech and sexism. the identification and classification of sexism in social media are very relevant tasks, as they would allow building a healthier social environment. nevertheless, these tasks are considerably challenging. this work proposes a system to use multilingual and monolingual bert and data points translation and ensemble strategies for sexism identification and classification in english and spanish. it was conducted in the context of the sexism identification in social networks shared 2021 (exist 2021) task, proposed by the iberian languages evaluation forum (iberlef). the proposed system and its main components are described, and an in-depth hyperparameters analysis is conducted. the main results observed were: (i) the system obtained better results than the baseline model (multilingual bert); (ii) ensemble models obtained better results than monolingual models; and (iii) an ensemble model considering all individual models and the best standardized values obtained the best accuracies and f1-scores for both tasks. this work obtained first place in both tasks at exist, with the highest accuracies (0.780 for task 1 and 0.658 for task 2) and f1-scores (f1-binary of 0.780 for task 1 and f1-macro of 0.579 for task 2). ","1106":"this paper describes our participation in the detection of toxicity in comments in spanish (detoxis) shared task 2021 at the 3rd workshop on iberian languages evaluation forum. the shared task is divided into two related classification tasks: (i) task 1: toxicity detection and; (ii) task 2: toxicity level detection. they focus on the xenophobic problem exacerbated by the spread of toxic comments posted in different online news articles related to immigration. one of the necessary efforts towards mitigating this problem is to detect toxicity in the comments. our main objective was to implement an accurate model to detect xenophobia in comments about web news articles within the detoxis shared task 2021, based on the competition's official metrics: the f1-score for task 1 and the closeness evaluation metric (cem) for task 2. to solve the tasks, we worked with two types of machine learning models: (i) statistical models and (ii) deep bidirectional transformers for language understanding (bert) models. we obtained our best results in both tasks using beto, an bert model trained on a big spanish corpus. we obtained the 3rd place in task 1 official ranking with the f1-score of 0.5996, and we achieved the 6th place in task 2 official ranking with the cem of 0.7142. our results suggest: (i) bert models obtain better results than statistical models for toxicity detection in text comments; (ii) monolingual bert models have an advantage over multilingual bert models in toxicity detection in text comments in their pre-trained language. ","1107":"simultaneous speech translation (simulst) is the task in which output generation has to be performed on partial, incremental speech input. in recent years, simulst has become popular due to the spread of cross-lingual application scenarios, like international live conferences and streaming lectures, in which on-the-fly speech translation can facilitate users' access to audio-visual content. in this paper, we analyze the characteristics of the simulst systems developed so far, discussing their strengths and weaknesses. we then concentrate on the evaluation framework required to properly assess systems' effectiveness. to this end, we raise the need for a broader performance analysis, also including the user experience standpoint. simulst systems, indeed, should be evaluated not only in terms of quality\/latency measures, but also via task-oriented metrics accounting, for instance, for the visualization strategy adopted. in light of this, we highlight which are the goals achieved by the community and what is still missing. ","1108":"we determine the structure of the quotient of the free group on 26 generators by english language anagrams. this group admits a surprisingly simple presentation as a quotient of the free group by 301 of the possible 325 commutators of pairs of generators; all of the 24 missing commutators involve at least one of the letters j, q, x, z. we describe the algorithm which can be used to determine this group given any dictionary, and provide examples from the sowpods scrabble dictionary witnessing the 301 commutators found. ","1109":"ontology-based approach to the natural language understanding (nlu) processing allows to improve questions answering quality in dialogue systems. we describe our nlu engine architecture and evaluate its implementation. the engine transforms user input into the sparql select, ask or insert query to the knowledge graph provided by the ontology-based data virtualization platform. the transformation is based on the lexical level of the knowledge graph built according to the ontolex ontology. the described approach can be applied for graph data population tasks and to the question answering systems implementation, including chat bots. we describe the dialogue engine for a chat bot which can keep the conversation context and ask clarifying questions, simulating some aspects of the human logical thinking. our approach uses graph-based algorithms to avoid gathering datasets, required in the neural nets-based approaches, and provide better explainability of our models. using question answering engine in conjunction with data virtualization layer over the corporate data sources allows extracting facts from the structured data to be used in conversation. ","1110":"structured text understanding on visually rich documents (vrds) is a crucial part of document intelligence. due to the complexity of content and layout in vrds, structured text understanding has been a challenging task. most existing studies decoupled this problem into two sub-tasks: entity labeling and entity linking, which require an entire understanding of the context of documents at both token and segment levels. however, little work has been concerned with the solutions that efficiently extract the structured data from different levels. this paper proposes a unified framework named structext, which is flexible and effective for handling both sub-tasks. specifically, based on the transformer, we introduce a segment-token aligned encoder to deal with the entity labeling and entity linking tasks at different levels of granularity. moreover, we design a novel pre-training strategy with three self-supervised tasks to learn a richer representation. structext uses the existing masked visual language modeling task and the new sentence length prediction and paired boxes direction tasks to incorporate the multi-modal information across text, image, and layout. we evaluate our method for structured text understanding at segment-level and token-level and show it outperforms the state-of-the-art counterparts with significantly superior performance on the funsd, sroie, and ephoie datasets. ","1111":"multilingual nmt has become an attractive solution for mt deployment in production. but to match bilingual quality, it comes at the cost of larger and slower models. in this work, we consider several ways to make multilingual nmt faster at inference without degrading its quality. we experiment with several \"light decoder\" architectures in two 20-language multi-parallel settings: small-scale on ted talks and large-scale on paracrawl. our experiments demonstrate that combining a shallow decoder with vocabulary filtering leads to more than twice faster inference with no loss in translation quality. we validate our findings with bleu and chrf (on 380 language pairs), robustness evaluation and human evaluation. ","1112":"web search is an essential way for humans to obtain information, but it's still a great challenge for machines to understand the contents of web pages. in this paper, we introduce the task of structural reading comprehension (src) on web. given a web page and a question about it, the task is to find the answer from the web page. this task requires a system not only to understand the semantics of texts but also the structure of the web page. moreover, we proposed websrc, a novel web-based structural reading comprehension dataset. websrc consists of 400k question-answer pairs, which are collected from 6.4k web pages. along with the qa pairs, corresponding html source code, screenshots, and metadata are also provided in our dataset. each question in websrc requires a certain structural understanding of a web page to answer, and the answer is either a text span on the web page or yes\/no. we evaluate various baselines on our dataset to show the difficulty of our task. we also investigate the usefulness of structural information and visual features. our dataset and baselines have been publicly available at https:\/\/x-lance.github.io\/websrc\/. ","1113":"the temporal sentence grounding in video (tsgv) task is to locate a temporal moment from an untrimmed video, to match a language query, i.e., a sentence. without considering bias in moment annotations (e.g., start and end positions in a video), many models tend to capture statistical regularities of the moment annotations, and do not well learn cross-modal reasoning between video and language query. in this paper, we propose two debiasing strategies, data debiasing and model debiasing, to \"force\" a tsgv model to capture cross-modal interactions. data debiasing performs data oversampling through video truncation to balance moment temporal distribution in train set. model debiasing leverages video-only and query-only models to capture the distribution bias, and forces the model to learn cross-modal interactions. using vslnet as the base model, we evaluate impact of the two strategies on two datasets that contain out-of-distribution test instances. results show that both strategies are effective in improving model generalization capability. equipped with both debiasing strategies, vslnet achieves best results on both datasets. ","1114":"while many nlp pipelines assume raw, clean texts, many texts we encounter in the wild, including a vast majority of legal documents, are not so clean, with many of them being visually structured documents (vsds) such as pdfs. conventional preprocessing tools for vsds mainly focused on word segmentation and coarse layout analysis, whereas fine-grained logical structure analysis (such as identifying paragraph boundaries and their hierarchies) of vsds is underexplored. to that end, we proposed to formulate the task as prediction of \"transition labels\" between text fragments that maps the fragments to a tree, and developed a feature-based machine learning system that fuses visual, textual and semantic cues.our system is easily customizable to different types of vsds and it significantly outperformed baselines in identifying different structures in vsds. for example, our system obtained a paragraph boundary detection f1 score of 0.953 which is significantly better than a popular pdf-to-text tool with an f1 score of 0.739. ","1115":"we present an open-access natural language processing toolkit for japanese medical information extraction. we first propose a novel relation annotation schema for investigating the medical and temporal relations between medical entities in japanese medical reports. we experiment with the practical annotation scenarios by separately annotating two different types of reports. we design a pipeline system with three components for recognizing medical entities, classifying entity modalities, and extracting relations. the empirical results show accurate analyzing performance and suggest the satisfactory annotation quality, the effective annotation strategy for targeting report types, and the superiority of the latest contextual embedding models. ","1116":"word embeddings learn implicit biases from linguistic regularities captured by word co-occurrence statistics. by extending methods that quantify human-like biases in word embeddings, we introducevalnorm, a novel intrinsic evaluation task and method to quantify the valence dimension of affect in human-rated word sets from social psychology. we apply valnorm on static word embeddings from seven languages (chinese, english, german, polish, portuguese, spanish, and turkish) and from historical english text spanning 200 years. valnorm achieves consistently high accuracy in quantifying the valence of non-discriminatory, non-social group word sets. specifically, valnorm achieves a pearson correlation of r=0.88 for human judgment scores of valence for 399 words collected to establish pleasantness norms in english. in contrast, we measure gender stereotypes using the same set of word embeddings and find that social biases vary across languages. our results indicate that valence associations of non-discriminatory, non-social group words represent widely-shared associations, in seven languages and over 200 years. ","1117":"it is often challenging to solve a complex problem from scratch, but much easier if we can access other similar problems with their solutions -- a paradigm known as case-based reasoning (cbr). we propose a neuro-symbolic cbr approach (cbr-kbqa) for question answering over large knowledge bases. cbr-kbqa consists of a nonparametric memory that stores cases (question and logical forms) and a parametric model that can generate a logical form for a new question by retrieving cases that are relevant to it. on several kbqa datasets that contain complex questions, cbr-kbqa achieves competitive performance. for example, on the complexwebquestions dataset, cbr-kbqa outperforms the current state of the art by 11\\% on accuracy. furthermore, we show that cbr-kbqa is capable of using new cases \\emph{without} any further training: by incorporating a few human-labeled examples in the case memory, cbr-kbqa is able to successfully generate logical forms containing unseen kb entities as well as relations. ","1118":"large datasets in nlp suffer from noisy labels, due to erroneous automatic and human annotation procedures. we study the problem of text classification with label noise, and aim to capture this noise through an auxiliary noise model over the classifier. we first assign a probability score to each training sample of having a noisy label, through a beta mixture model fitted on the losses at an early epoch of training. then, we use this score to selectively guide the learning of the noise model and classifier. our empirical evaluation on two text classification tasks shows that our approach can improve over the baseline accuracy, and prevent over-fitting to the noise. ","1119":"this work explores the task of synthesizing speech in nonexistent human-sounding voices. we call this task \"speaker generation\", and present tacospawn, a system that performs competitively at this task. tacospawn is a recurrent attention-based text-to-speech model that learns a distribution over a speaker embedding space, which enables sampling of novel and diverse speakers. our method is easy to implement, and does not require transfer learning from speaker id systems. we present objective and subjective metrics for evaluating performance on this task, and demonstrate that our proposed objective metrics correlate with human perception of speaker similarity. audio samples are available on our demo page. ","1120":"the widespread of powerful personal devices capable of collecting voice of their users has opened the opportunity to build speaker adapted speech recognition system (asr) or to participate to collaborative learning of asr. in both cases, personalized acoustic models (am), i.e. fine-tuned am with specific speaker data, can be built. a question that naturally arises is whether the dissemination of personalized acoustic models can leak personal information. in this paper, we show that it is possible to retrieve the gender of the speaker, but also his identity, by just exploiting the weight matrix changes of a neural acoustic model locally adapted to this speaker. incidentally we observe phenomena that may be useful towards explainability of deep neural networks in the context of speech processing. gender can be identified almost surely using only the first layers and speaker verification performs well when using middle-up layers. our experimental study on the ted-lium 3 dataset with hmm\/tdnn models shows an accuracy of 95% for gender detection, and an equal error rate of 9.07% for a speaker verification task by only exploiting the weights from personalized models that could be exchanged instead of user data. ","1121":"ethics is one of the longest standing intellectual endeavors of humanity. in recent years, the fields of ai and nlp have attempted to wrangle with how learning systems that interact with humans should be constrained to behave ethically. one proposal in this vein is the construction of morality models that can take in arbitrary text and output a moral judgment about the situation described. in this work, we focus on a single case study of the recently proposed delphi model and offer a critique of the project's proposed method of automating morality judgments. through an audit of delphi, we examine broader issues that would be applicable to any similar attempt. we conclude with a discussion of how machine ethics could usefully proceed, by focusing on current and near-future uses of technology, in a way that centers around transparency, democratic values, and allows for straightforward accountability. ","1122":"we describe a novel attribution method which is grounded in sensitivity analysis and uses sobol indices. beyond modeling the individual contributions of image regions, sobol indices provide an efficient way to capture higher-order interactions between image regions and their contributions to a neural network's prediction through the lens of variance. we describe an approach that makes the computation of these indices efficient for high-dimensional problems by using perturbation masks coupled with efficient estimators to handle the high dimensionality of images. importantly, we show that the proposed method leads to favorable scores on standard benchmarks for vision (and language models) while drastically reducing the computing time compared to other black-box methods -- even surpassing the accuracy of state-of-the-art white-box methods which require access to internal representations. our code is freely available: https:\/\/github.com\/fel-thomas\/sobol-attribution-method ","1123":"pretrained language models have become the standard approach for many nlp tasks due to strong performance, but they are very expensive to train. we propose a simple and efficient learning framework, tlm, that does not rely on large-scale pretraining. given some labeled task data and a large general corpus, tlm uses task data as queries to retrieve a tiny subset of the general corpus and jointly optimizes the task objective and the language modeling objective from scratch. on eight classification datasets in four domains, tlm achieves results better than or similar to pretrained language models (e.g., roberta-large) while reducing the training flops by two orders of magnitude. with high accuracy and efficiency, we hope tlm will contribute to democratizing nlp and expediting its development. ","1124":"query by example is a well-known information retrieval task in which a document is chosen by the user as the search query and the goal is to retrieve relevant documents from a large collection. however, a document often covers multiple aspects of a topic. to address this scenario we introduce the task of faceted query by example in which users can also specify a finer grained aspect in addition to the input query document. we focus on the application of this task in scientific literature search. we envision models which are able to retrieve scientific papers analogous to a query scientific paper along specifically chosen rhetorical structure elements as one solution to this problem. in this work, the rhetorical structure elements, which we refer to as facets, indicate objectives, methods, or results of a scientific paper. we introduce and describe an expert annotated test collection to evaluate models trained to perform this task. our test collection consists of a diverse set of 50 query documents in english, drawn from computational linguistics and machine learning venues. we carefully follow the annotation guideline used by trec for depth-k pooling (k = 100 or 250) and the resulting data collection consists of graded relevance scores with high annotation agreement. state of the art models evaluated on our dataset show a significant gap to be closed in further work. our dataset may be accessed here: https:\/\/github.com\/iesl\/csfcube ","1125":"i train models for the task of neural machine translation for english-hungarian and hungarian-english, using the hunglish2 corpus. the main contribution of this work is evaluating different data augmentation methods during the training of nmt models. i propose 5 different augmentation methods that are structure-aware, meaning that instead of randomly selecting words for blanking or replacement, the dependency tree of sentences is used as a basis for augmentation. i start my thesis with a detailed literature review on neural networks, sequential modeling, neural machine translation, dependency parsing and data augmentation. after a detailed exploratory data analysis and preprocessing of the hunglish2 corpus, i perform experiments with the proposed data augmentation techniques. the best model for hungarian-english achieves a bleu score of 33.9, while the best model for english-hungarian achieves a bleu score of 28.6. ","1126":"we release 70 small and discriminative test sets for machine translation (mt) evaluation called variance-aware test sets (vat), covering 35 translation directions from wmt16 to wmt20 competitions. vat is automatically created by a novel variance-aware filtering method that filters the indiscriminative test instances of the current mt test sets without any human labor. experimental results show that vat outperforms the original wmt test sets in terms of the correlation with human judgement across mainstream language pairs and test sets. further analysis on the properties of vat reveals the challenging linguistic features (e.g., translation of low-frequency words and proper nouns) for competitive mt systems, providing guidance for constructing future mt test sets. the test sets and the code for preparing variance-aware mt test sets are freely available at https:\/\/github.com\/nlp2ct\/variance-aware-mt-test-sets . ","1127":"in a classification task, dealing with text snippets and metadata usually requires dealing with multimodal approaches. when those metadata are textual, it is tempting to use them intrinsically with a pre-trained transformer, in order to leverage the semantic information encoded inside the model. this paper describes how to improve a humanitarian classification task by adding the crisis event type to each tweet to be classified. based on additional experiments of the model weights and behavior, it identifies how the proposed neural network approach is partially over-fitting the particularities of the crisis benchmark, to better highlight how the model is still undoubtedly learning to use and take advantage of the metadata's textual semantics. ","1128":"information extraction (ie) from documents is an intensive area of research with a large set of industrial applications. current state-of-the-art methods focus on scanned documents with approaches combining computer vision, natural language processing and layout representation. we propose to challenge the usage of computer vision in the case where both token style and visual representation are available (i.e native pdf documents). our experiments on three real-world complex datasets demonstrate that using token style attributes based embedding instead of a raw visual embedding in layoutlm model is beneficial. depending on the dataset, such an embedding yields an improvement of 0.18% to 2.29% in the weighted f1-score with a decrease of 30.7% in the final number of trainable parameters of the model, leading to an improvement in both efficiency and effectiveness. ","1129":"personalizing a speech synthesis system is a highly desired application, where the system can generate speech with the user's voice with rare enrolled recordings. there are two main approaches to build such a system in recent works: speaker adaptation and speaker encoding. on the one hand, speaker adaptation methods fine-tune a trained multi-speaker text-to-speech (tts) model with few enrolled samples. however, they require at least thousands of fine-tuning steps for high-quality adaptation, making it hard to apply on devices. on the other hand, speaker encoding methods encode enrollment utterances into a speaker embedding. the trained tts model can synthesize the user's speech conditioned on the corresponding speaker embedding. nevertheless, the speaker encoder suffers from the generalization gap between the seen and unseen speakers.   in this paper, we propose applying a meta-learning algorithm to the speaker adaptation method. more specifically, we use model agnostic meta-learning (maml) as the training algorithm of a multi-speaker tts model, which aims to find a great meta-initialization to adapt the model to any few-shot speaker adaptation tasks quickly. therefore, we can also adapt the meta-trained tts model to unseen speakers efficiently. our experiments compare the proposed method (meta-tts) with two baselines: a speaker adaptation method baseline and a speaker encoding method baseline. the evaluation results show that meta-tts can synthesize high speaker-similarity speech from few enrollment samples with fewer adaptation steps than the speaker adaptation baseline and outperforms the speaker encoding baseline under the same training scheme. when the speaker encoder of the baseline is pre-trained with extra 8371 speakers of data, meta-tts can still outperform the baseline on libritts dataset and achieve comparable results on vctk dataset. ","1130":"previous research for adapting a general neural machine translation (nmt) model into a specific domain usually neglects the diversity in translation within the same domain, which is a core problem for domain adaptation in real-world scenarios. one representative of such challenging scenarios is to deploy a translation system for a conference with a specific topic, e.g., global warming or coronavirus, where there are usually extremely less resources due to the limited schedule. to motivate wider investigation in such a scenario, we present a real-world fine-grained domain adaptation task in machine translation (fgrada). the fgrada dataset consists of chinese-english translation task for four sub-domains of information technology: autonomous vehicles, ai education, real-time networks, and smart phone. each sub-domain is equipped with a development set and test set for evaluation purposes. to be closer to reality, fgrada does not employ any in-domain bilingual training data but provides bilingual dictionaries and wiki knowledge base, which can be easier obtained within a short time. we benchmark the fine-grained domain adaptation task and present in-depth analyses showing that there are still challenging problems to further improve the performance with heterogeneous resources. ","1131":"we introduce a new type of programming challenge called programming puzzles, as an objective and comprehensive evaluation of program synthesis, and release an open-source dataset of python programming puzzles (p3). each puzzle is defined by a short python program $f$, and the goal is to find an input which makes $f$ return true. the puzzles are objective in that each one is specified entirely by the source code of its verifier $f$, so evaluating $f$ is all that is needed to test a candidate solution. they do not require an answer key or input\/output examples, nor do they depend on natural language understanding. the dataset is comprehensive in that it spans problems of a range of difficulties and domains, ranging from trivial string manipulation problems, to classic programming puzzles (e.g., tower of hanoi), to interview\/competitive-programming problems (e.g., dynamic programming), to longstanding open problems in algorithms and mathematics (e.g., factoring). we develop baseline enumerative program synthesis, gpt-3 and codex solvers that are capable of solving puzzles -- even without access to any reference solutions -- by learning from their own past solutions. codex performs best, solving up to 18% of 397 test problems with a single try and 80% of the problems with 1,000 tries per problem. in a small user study, we find a positive correlation between puzzle-solving performance and coding experience, and between the puzzle difficulty for humans and ai solvers. therefore, further improvements on p3 could have a significant impact on many program synthesis areas. ","1132":"research in emotion analysis is scattered across different label formats (e.g., polarity types, basic emotion categories, and affective dimensions), linguistic levels (word vs. sentence vs. discourse), and, of course, (few well-resourced but much more under-resourced) natural languages and text genres (e.g., product reviews, tweets, news). the resulting heterogeneity makes data and software developed under these conflicting constraints hard to compare and challenging to integrate. to resolve this unsatisfactory state of affairs we here propose a training scheme that learns a shared latent representation of emotion independent from different label formats, natural languages, and even disparate model architectures. experiments on a wide range of datasets indicate that this approach yields the desired interoperability without penalizing prediction quality. code and data are archived under doi 10.5281\/zenodo.5466068. ","1133":"nowadays social media platforms such as twitter provide a great opportunity to understand public opinion of climate change compared to traditional survey methods. in this paper, we constructed a massive climate change twitter dataset and conducted comprehensive analysis using machine learning. by conducting topic modeling and natural language processing, we show the relationship between the number of tweets about climate change and major climate events; the common topics people discuss climate change; and the trend of sentiment. our dataset was published on kaggle (\\url{https:\/\/www.kaggle.com\/leonshangguan\/climate-change-tweets-ids-until-aug-2021}) and can be used in further research. ","1134":"how can we distinguish commercial from editorial content in news, or more specifically, differentiate between advertorials and regular news articles? an advertorial is a commercial message written and formatted as an article, making it harder for readers to recognize these as advertising, despite the use of disclaimers. in our research we aim to differentiate the two using a machine learning model, and a lexicon derived from it. this was accomplished by scraping 1.000 articles and 1.000 advertorials from four different dutch news sources and classifying these based on textual features. with this setup our most successful machine learning model had an accuracy of just over $90\\%$. to generate additional insights into differences between news and advertorial language, we also analyzed model coefficients and explored the corpus through co-occurrence networks and t-sne graphs. ","1135":"out-of-distribution (ood) detection is an important problem in natural language processing (nlp). in this work, we propose a simple yet effective framework $k$folden, which mimics the behaviors of ood detection during training without the use of any external data. for a task with $k$ training labels, $k$folden induces $k$ sub-models, each of which is trained on a subset with $k-1$ categories with the left category masked unknown to the sub-model. exposing an unknown label to the sub-model during training, the model is encouraged to learn to equally attribute the probability to the seen $k-1$ labels for the unknown label, enabling this framework to simultaneously resolve in- and out-distribution examples in a natural way via ood simulations. taking text classification as an archetype, we develop benchmarks for ood detection using existing text classification datasets. by conducting comprehensive comparisons and analyses on the developed benchmarks, we demonstrate the superiority of $k$folden against current methods in terms of improving ood detection performances while maintaining improved in-domain classification accuracy. the code and datasets can be found at: \\url{https:\/\/github.com\/shannonai\/kfolden-ood-detection}. ","1136":"given a patent document, identifying distinct semantic annotations is an interesting research aspect. text annotation helps the patent practitioners such as examiners and patent attorneys to quickly identify the key arguments of any invention, successively providing a timely marking of a patent text. in the process of manual patent analysis, to attain better readability, recognising the semantic information by marking paragraphs is in practice. this semantic annotation process is laborious and time-consuming. to alleviate such a problem, we proposed a novel dataset to train machine learning algorithms to automate the highlighting process. the contributions of this work are: i) we developed a multi-class, novel dataset of size 150k samples by traversing uspto patents over a decade, ii) articulated statistics and distributions of data using imperative exploratory data analysis, iii) baseline machine learning models are developed to utilize the dataset to address patent paragraph highlighting task, iv) dataset and codes relating to this task are open-sourced through a dedicated git web page: https:\/\/github.com\/renuk9390\/patent_sentiment_analysis and v) future path to extend this work using deep learning and domain specific pre-trained language models to develop a tool to highlight is provided. this work assist patent practitioners in highlighting semantic information automatically and aid to create a sustainable and efficient patent analysis using the aptitude of machine learning. ","1137":"named entity recognition (ner) aims to identify mentions of named entities in an unstructured text and classify them into the predefined named entity classes. even though deep learning-based pre-trained language models achieve good predictive performances, many domain-specific nertasks still require a sufficient amount of labeled data. active learning (al), a general framework for the label acquisition problem, has been used for the ner tasks to minimize the annotation cost without sacrificing model performance. however, heavily imbalanced class distribution of tokens introduces challenges in designing effective al querying methods for ner. we propose al sentence query evaluation functions which pay more attention to possible positive tokens, and evaluate these proposed functions with both sentence-based and token-based cost evaluation strategies. we also propose a better data-driven normalization approach to penalize too long or too short sentences. our experiments on three datasets from different domains reveal that the proposed approaches reduce the number of annotated tokens while achieving better or comparable prediction performance with conventional methods. ","1138":"with the recent developments in the field of natural language processing, there has been a rise in the use of different architectures for neural machine translation. transformer architectures are used to achieve state-of-the-art accuracy, but they are very computationally expensive to train. everyone cannot have such setups consisting of high-end gpus and other resources. we train our models on low computational resources and investigate the results. as expected, transformers outperformed other architectures, but there were some surprising results. transformers consisting of more encoders and decoders took more time to train but had fewer bleu scores. lstm performed well in the experiment and took comparatively less time to train than transformers, making it suitable to use in situations having time constraints. ","1139":"finnish is a language with multiple dialects that not only differ from each other in terms of accent (pronunciation) but also in terms of morphological forms and lexical choice. we present the first approach to automatically detect the dialect of a speaker based on a dialect transcript and transcript with audio recording in a dataset consisting of 23 different dialects. our results show that the best accuracy is received by combining both of the modalities, as text only reaches to an overall accuracy of 57\\%, where as text and audio reach to 85\\%. our code, models and data have been released openly on github and zenodo. ","1140":"idioms are special fixed phrases usually derived from stories. they are commonly used in casual conversations and literary writings. their meanings are usually highly non-compositional. the idiom cloze task is a challenge problem in natural language processing (nlp) research problem. previous approaches to this task are built on sequence-to-sequence (seq2seq) models and achieved reasonably well performance on existing datasets. however, they fall short in understanding the highly non-compositional meaning of idiomatic expressions. they also do not consider both the local and global context at the same time. in this paper, we proposed a bert-based embedding seq2seq model that encodes idiomatic expressions and considers them in both global and local context. our model uses xlnet as the encoder and roberta for choosing the most probable idiom for a given context. experiments on the epie static corpus dataset show that our model performs better than existing state-of-the-arts. ","1141":"identifying and understanding underlying sentiment or emotions in text is a key component of multiple natural language processing applications. while simple polarity sentiment analysis is a well-studied subject, fewer advances have been made in identifying more complex, finer-grained emotions using only textual data. in this paper, we present a transformer-based model with a fusion of adapter layers which leverages knowledge from more simple sentiment analysis tasks to improve the emotion detection task on large scale dataset, such as cmu-mosei, using the textual modality only. results show that our proposed method is competitive with other approaches. we obtained state-of-the-art results for emotion recognition on cmu-mosei even while using only the textual modality. ","1142":"most of us are not experts in specific fields, such as ornithology. nonetheless, we do have general image and language understanding capabilities that we use to match what we see to expert resources. this allows us to expand our knowledge and perform novel tasks without ad-hoc external supervision. on the contrary, machines have a much harder time consulting expert-curated knowledge bases unless trained specifically with that knowledge in mind. thus, in this paper we consider a new problem: fine-grained image recognition without expert annotations, which we address by leveraging the vast knowledge available in web encyclopedias. first, we learn a model to describe the visual appearance of objects using non-expert image descriptions. we then train a fine-grained textual similarity model that matches image descriptions with documents on a sentence-level basis. we evaluate the method on two datasets and compare with several strong baselines and the state of the art in cross-modal retrieval. code is available at: https:\/\/github.com\/subhc\/clever ","1143":"question answering models struggle to generalize to novel compositions of training patterns, such to longer sequences or more complex test structures. current end-to-end models learn a flat input embedding which can lose input syntax context. prior approaches improve generalization by learning permutation invariant models, but these methods do not scale to more complex train-test splits. we propose grounded graph decoding, a method to improve compositional generalization of language representations by grounding structured predictions with an attention mechanism. grounding enables the model to retain syntax information from the input in thereby significantly improving generalization over complex inputs. by predicting a structured graph containing conjunctions of query clauses, we learn a group invariant representation without making assumptions on the target domain. our model significantly outperforms state-of-the-art baselines on the compositional freebase questions (cfq) dataset, a challenging benchmark for compositional generalization in question answering. moreover, we effectively solve the mcd1 split with 98% accuracy. ","1144":"the problem of answering questions using knowledge from pre-trained language models (lms) and knowledge graphs (kgs) presents two challenges: given a qa context (question and answer choice), methods need to (i) identify relevant knowledge from large kgs, and (ii) perform joint reasoning over the qa context and kg. in this work, we propose a new model, qa-gnn, which addresses the above challenges through two key innovations: (i) relevance scoring, where we use lms to estimate the importance of kg nodes relative to the given qa context, and (ii) joint reasoning, where we connect the qa context and kg to form a joint graph, and mutually update their representations through graph neural networks. we evaluate our model on qa benchmarks in the commonsense (commonsenseqa, openbookqa) and biomedical (medqa-usmle) domains. qa-gnn outperforms existing lm and lm+kg models, and exhibits capabilities to perform interpretable and structured reasoning, e.g., correctly handling negation in questions. ","1145":"through anonymisation and accessibility, social media platforms have facilitated the proliferation of hate speech, prompting increased research in developing automatic methods to identify these texts. this paper explores the classification of sexism in text using a variety of deep neural network model architectures such as long-short-term memory (lstms) and convolutional neural networks (cnns). these networks are used in conjunction with transfer learning in the form of bidirectional encoder representations from transformers (bert) and distilbert models, along with data augmentation, to perform binary and multiclass sexism classification on the dataset of tweets and gabs from the sexism identification in social networks (exist) task in iberlef 2021. the models are seen to perform comparatively to those from the competition, with the best performances seen using bert and a multi-filter cnn model. data augmentation further improves these results for the multi-class classification task. this paper also explores the errors made by the models and discusses the difficulty in automatically classifying sexism due to the subjectivity of the labels and the complexity of natural language used in social media. ","1146":"cryptic crosswords, the dominant crossword variety in the uk, are a promising target for advancing nlp systems that seek to process semantically complex, highly compositional language. cryptic clues read like fluent natural language but are adversarially composed of two parts: a definition and a wordplay cipher requiring character-level manipulations. expert humans use creative intelligence to solve cryptics, flexibly combining linguistic, world, and domain knowledge. in this paper, we make two main contributions. first, we present a dataset of cryptic clues as a challenging new benchmark for nlp systems that seek to process compositional language in more creative, human-like ways. after showing that three non-neural approaches and t5, a state-of-the-art neural language model, do not achieve good performance, we make our second main contribution: a novel curriculum approach, in which the model is first fine-tuned on related tasks such as unscrambling words.we also introduce a challenging data split, examine the meta-linguistic capabilities of subword-tokenized models, and investigate model systematicity by perturbing the wordplay part of clues, showing that t5 exhibits behavior partially consistent with human solving strategies. although our curricular approach considerably improves on the t5 baseline, our best-performing model still fails to generalize to the extent that humans can. thus, cryptic crosswords remain an unsolved challenge for nlp systems and a potential source of future innovation. ","1147":"the extensive rise in consumption of online social media (osms) by a large number of people poses a critical problem of curbing the spread of hateful content on these platforms. with the growing usage of osms in multiple languages, the task of detecting and characterizing hate becomes more complex. the subtle variations of code-mixed texts along with switching scripts only add to the complexity. this paper presents a solution for the hasoc 2021 multilingual twitter hate-speech detection challenge by team precog iiit hyderabad. we adopt a multilingual transformer based approach and describe our architecture for all 6 subtasks as part of the challenge. out of the 6 teams that participated in all the subtasks, our submissions rank 3rd overall. ","1148":"in this paper, we study the multi-task sentiment classification problem in the continual learning setting, i.e., a model is sequentially trained to classifier the sentiment of reviews of products in a particular category. the use of common sentiment words in reviews of different product categories leads to large cross-task similarity, which differentiates it from continual learning in other domains. this knowledge sharing nature renders forgetting reduction focused approaches less effective for the problem under consideration. unlike existing approaches, where task-specific masks are learned with specifically presumed training objectives, we propose an approach called task-aware dropout (taskdrop) to generate masks in a random way. while the standard dropout generates and applies random masks for each training instance per epoch for effective regularization, taskdrop applies random masking for task-wise capacity allocation and reuse. we conducted experimental studies on three multi-task review datasets and made comparison to various baselines and state-of-the-art approaches. our empirical results show that regardless of simplicity, taskdrop overall achieved competitive performances for all the three datasets, especially after relative long term learning. this demonstrates that the proposed random capacity allocation mechanism works well for continual sentiment classification. ","1149":"automatic detection of click-bait and incongruent news headlines is crucial to maintaining the reliability of the web and has raised much research attention. however, most existing methods perform poorly when news headlines contain contextually important cardinal values, such as a quantity or an amount. in this work, we focus on this particular case and propose a neural attention based solution, which uses a novel cardinal part of speech (pos) tag pattern based hierarchical attention network, namely poshan, to learn effective representations of sentences in a news article. in addition, we investigate a novel cardinal phrase guided attention, which uses word embeddings of the contextually-important cardinal value and neighbouring words. in the experiments conducted on two publicly available datasets, we observe that the proposed methodgives appropriate significance to cardinal values and outperforms all the baselines. an ablation study of poshan shows that the cardinal pos-tag pattern-based hierarchical attention is very effective for the cases in which headlines contain cardinal values. ","1150":"the advancement in machine learning and artificial intelligence is promoting the testing and deployment of autonomous vehicles (avs) on public roads. the california department of motor vehicles (ca dmv) has launched the autonomous vehicle tester program, which collects and releases reports related to autonomous vehicle disengagement (avd) from autonomous driving. understanding the causes of avd is critical to improving the safety and stability of the av system and provide guidance for av testing and deployment. in this work, a scalable end-to-end pipeline is constructed to collect, process, model, and analyze the disengagement reports released from 2014 to 2020 using natural language processing deep transfer learning. the analysis of disengagement data using taxonomy, visualization and statistical tests revealed the trends of av testing, categorized cause frequency, and significant relationships between causes and effects of avd. we found that (1) manufacturers tested avs intensively during the spring and\/or winter, (2) test drivers initiated more than 80% of the disengagement while more than 75% of the disengagement were led by errors in perception, localization & mapping, planning and control of the av system itself, and (3) there was a significant relationship between the initiator of avd and the cause category. this study serves as a successful practice of deep transfer learning using pre-trained models and generates a consolidated disengagement database allowing further investigation for other researchers. ","1151":"slow emerging topic detection is a task between event detection, where we aggregate behaviors of different words on short period of time, and language evolution, where we monitor their long term evolution. in this work, we tackle the problem of early detection of slowly emerging new topics. to this end, we gather evidence of weak signals at the word level. we propose to monitor the behavior of words representation in an embedding space and use one of its geometrical properties to characterize the emergence of topics. as evaluation is typically hard for this kind of task, we present a framework for quantitative evaluation. we show positive results that outperform state-of-the-art methods on two public datasets of press and scientific articles. ","1152":"terms are linguistic signifiers of domain-specific concepts. automated recognition of multi-word terms (mwt) in free text is a sequence labelling problem, which is commonly addressed using supervised machine learning methods. their need for manual annotation of training data makes it difficult to port such methods across domains. flexiterm, on the other hand, is a fully unsupervised method for mwt recognition from domain-specific corpora. originally implemented in java as a proof of concept, it did not scale well, thus offering little practical value in the context of big data. in this paper, we describe its re-implementation in python and compare the performance of these two implementations. the results demonstrated major improvements in terms of efficiency, which allow flexiterm to transition from the proof of concept to the production-grade application. ","1153":"with the fast growth of mobile computing and web technologies, offensive language has become more prevalent on social networking platforms. since offensive language identification in local languages is essential to moderate the social media content, in this paper we work with three dravidian languages, namely malayalam, tamil, and kannada, that are under-resourced. we present an evaluation task at fire 2020- hasoc-dravidiancodemix and dravidianlangtech at eacl 2021, designed to provide a framework for comparing different approaches to this problem. this paper describes the data creation, defines the task, lists the participating systems, and discusses various methods. ","1154":"in natural language processing (nlp), the likelihood ratios (lrs) of n-grams are often estimated from the frequency information. however, a corpus contains only a fraction of the possible n-grams, and most of them occur infrequently. hence, we desire an lr estimator for low- and zero-frequency n-grams. one way to achieve this is to decompose the n-grams into discrete values, such as letters and words, and take the product of the lrs for the values. however, because this method deals with a large number of discrete values, the running time and memory usage for estimation are problematic. moreover, use of unnecessary discrete values causes deterioration of the estimation accuracy. therefore, this paper proposes combining the aforementioned method with the feature selection method used in document classification, and shows that our estimator provides effective and efficient estimation results for low- and zero-frequency n-grams. ","1155":"matching model is essential for image-text retrieval framework. existing research usually train the model with a triplet loss and explore various strategy to retrieve hard negative sentences in the dataset. we argue that current retrieval-based negative sample construction approach is limited in the scale of the dataset thus fail to identify negative sample of high difficulty for every image. we propose our tailoring negative sentences with discrimination and correction (tags-dc) to generate synthetic sentences automatically as negative samples. tags-dc is composed of masking and refilling to generate synthetic negative sentences with higher difficulty. to keep the difficulty during training, we mutually improve the retrieval and generation through parameter sharing. to further utilize fine-grained semantic of mismatch in the negative sentence, we propose two auxiliary tasks, namely word discrimination and word correction to improve the training. in experiments, we verify the effectiveness of our model on ms-coco and flickr30k compared with current state-of-the-art models and demonstrates its robustness and faithfulness in the further analysis. our code is available in https:\/\/github.com\/libertfan\/tags. ","1156":"verification of properties expressed as-regular languages such as ltl can benefit hugely from stutter-insensitivity, using a diverse set of reduction strategies. however properties that are not stutter-insensitive, for instance due to the use of the next operator of ltl or to some form of counting in the logic, are not covered by these techniques in general. we propose in this paper to study a weaker property than stutter-insensitivity. in a stutter insensitive language both adding and removing stutter to a word does not change its acceptance, any stuttering can be abstracted away; by decomposing this equivalence relation into two implications we obtain weaker conditions. we define a shortening insensitive language where any word that stutters less than a word in the language must also belong to the language. a lengthening insensitive language has the dual property. a semi-decision procedure is then introduced to reliably prove shortening insensitive properties or deny lengthening insensitive properties while working with a reduction of a system. a reduction has the property that it can only shorten runs. lipton's transaction reductions or petri net agglomerations are examples of eligible structural reduction strategies. an implementation and experimental evidence is provided showing most nonrandom properties sensitive to stutter are actually shortening or lengthening insensitive. performance of experiments on a large (random) benchmark from the model-checking competition indicate that despite being a semi-decision procedure, the approach can still improve state of the art verification tools. ","1157":"previous work mainly focuses on improving cross-lingual transfer for nlu tasks with a multilingual pretrained encoder (mpe), or improving the performance on supervised machine translation with bert. however, it is under-explored that whether the mpe can help to facilitate the cross-lingual transferability of nmt model. in this paper, we focus on a zero-shot cross-lingual transfer task in nmt. in this task, the nmt model is trained with parallel dataset of only one language pair and an off-the-shelf mpe, then it is directly tested on zero-shot language pairs. we propose sixt, a simple yet effective model for this task. sixt leverages the mpe with a two-stage training schedule and gets further improvement with a position disentangled encoder and a capacity-enhanced decoder. using this method, sixt significantly outperforms mbart, a pretrained multilingual encoder-decoder model explicitly designed for nmt, with an average improvement of 7.1 bleu on zero-shot any-to-english test sets across 14 source languages. furthermore, with much less training computation cost and training data, our model achieves better performance on 15 any-to-english test sets than criss and m2m-100, two strong multilingual nmt baselines. ","1158":"the rapid increase in fake news, which causes significant damage to society, triggers many fake news related studies, including the development of fake news detection and fact verification techniques. the resources for these studies are mainly available as public datasets taken from web data. we surveyed 118 datasets related to fake news research on a large scale from three perspectives: (1) fake news detection, (2) fact verification, and (3) other tasks; for example, the analysis of fake news and satire detection. we also describe in detail their utilization tasks and their characteristics. finally, we highlight the challenges in the fake news dataset construction and some research opportunities that address these challenges. our survey facilitates fake news research by helping researchers find suitable datasets without reinventing the wheel, and thereby, improves fake news studies in depth. ","1159":"grammatical error correction (gec) is a task of detecting and correcting grammatical errors in sentences. recently, neural machine translation systems have become popular approaches for this task. however, these methods lack the use of syntactic knowledge which plays an important role in the correction of grammatical errors. in this work, we propose a syntax-guided gec model (sg-gec) which adopts the graph attention mechanism to utilize the syntactic knowledge of dependency trees. considering the dependency trees of the grammatically incorrect source sentences might provide incorrect syntactic knowledge, we propose a dependency tree correction task to deal with it. combining with data augmentation method, our model achieves strong performances without using any large pre-trained models. we evaluate our model on public benchmarks of gec task and it achieves competitive results. ","1160":"dialogue summarization has been extensively studied and applied, where the prior works mainly focused on exploring superior model structures to align the input dialogue and the output summary. however, for professional dialogues (e.g., legal debate and medical diagnosis), semantic\/statistical alignment can hardly fill the logical\/factual gap between input dialogue discourse and summary output with external knowledge. in this paper, we mainly investigate the factual inconsistency problem for dialogue inspectional summarization (dis) under non-pretraining and pretraining settings. an innovative end-to-end dialogue summary generation framework is proposed with two auxiliary tasks: expectant factual aspect regularization (efar) and missing factual entity discrimination (mfed). comprehensive experiments demonstrate that the proposed model can generate a more readable summary with accurate coverage of factual aspects as well as informing the user with potential missing facts detected from the input dialogue for further human intervention. ","1161":"end-to-end (e2e) automatic speech recognition (asr) systems often have difficulty recognizing uncommon words, that appear infrequently in the training data. one promising method, to improve the recognition accuracy on such rare words, is to latch onto personalized\/contextual information at inference. in this work, we present a novel context-aware transformer transducer (catt) network that improves the state-of-the-art transformer-based asr system by taking advantage of such contextual signals. specifically, we propose a multi-head attention-based context-biasing network, which is jointly trained with the rest of the asr sub-networks. we explore different techniques to encode contextual data and to create the final attention context vectors. we also leverage both blstm and pretrained bert based models to encode contextual data and guide the network training. using an in-house far-field dataset, we show that catt, using a bert based context encoder, improves the word error rate of the baseline transformer transducer and outperforms an existing deep contextual model by 24.2% and 19.4% respectively. ","1162":"we propose a novel framework to understand the text by converting sentences or articles into video-like 3-dimensional tensors. each frame, corresponding to a slice of the tensor, is a word image that is rendered by the word's shape. the length of the tensor equals to the number of words in the sentence or article. the proposed transformation from the text to a 3-dimensional tensor makes it very convenient to implement an $n$-gram model with convolutional neural networks for text analysis. concretely, we impose a 3-dimensional convolutional kernel on the 3-dimensional text tensor. the first two dimensions of the convolutional kernel size equal the size of the word image and the last dimension of the kernel size is $n$. that is, every time when we slide the 3-dimensional kernel over a word sequence, the convolution covers $n$ word images and outputs a scalar. by iterating this process continuously for each $n$-gram along with the sentence or article with multiple kernels, we obtain a 2-dimensional feature map. a subsequent 1-dimensional max-over-time pooling is applied to this feature map, and three fully-connected layers are used for conducting text classification finally. experiments of several text classification datasets demonstrate surprisingly superior performances using the proposed model in comparison with existing methods. ","1163":"complex query answering (cqa) is an important reasoning task on knowledge graphs. current cqa learning models have been shown to be able to generalize from atomic operators to more complex formulas, which can be regarded as the combinatorial generalizability. in this paper, we present efo-1-qa, a new dataset to benchmark the combinatorial generalizability of cqa models by including 301 different queries types, which is 20 times larger than existing datasets. besides, our work, for the first time, provides a benchmark to evaluate and analyze the impact of different operators and normal forms by using (a) 7 choices of the operator systems and (b) 9 forms of complex queries. specifically, we provide the detailed study of the combinatorial generalizability of two commonly used operators, i.e., projection and intersection, and justify the impact of the forms of queries given the canonical choice of operators. our code and data can provide an effective pipeline to benchmark cqa models. ","1164":"to address a looming crisis of unreproducible evaluation for named entity recognition, we propose guidelines and introduce seqscore, a software package to improve reproducibility. the guidelines we propose are extremely simple and center around transparency regarding how chunks are encoded and scored. we demonstrate that despite the apparent simplicity of ner evaluation, unreported differences in the scoring procedure can result in changes to scores that are both of noticeable magnitude and statistically significant. we describe seqscore, which addresses many of the issues that cause replication failures. ","1165":"though there has been a large body of recent works in language modeling (lm) for high resource languages such as english and chinese, the area is still unexplored for low resource languages like bengali and hindi. we propose an end to end trainable memory efficient cnn architecture named cocnn to handle specific characteristics such as high inflection, morphological richness, flexible word order and phonetical spelling errors of bengali and hindi. in particular, we introduce two learnable convolutional sub-models at word and at sentence level that are end to end trainable. we show that state-of-the-art (sota) transformer models including pretrained bert do not necessarily yield the best performance for bengali and hindi. cocnn outperforms pretrained bert with 16x less parameters, and it achieves much better performance than sota lstm models on multiple real-world datasets. this is the first study on the effectiveness of different architectures drawn from three deep learning paradigms - convolution, recurrent, and transformer neural nets for modeling two widely used languages, bengali and hindi. ","1166":"with the rapid development of information technology, online platforms have produced enormous text resources. as a particular form of information extraction (ie), event extraction (ee) has gained increasing popularity due to its ability to automatically extract events from human language. however, there are limited literature surveys on event extraction. existing review works either spend much effort describing the details of various approaches or focus on a particular field. this study provides a comprehensive overview of the state-of-the-art event extraction methods and their applications from text, including closed-domain and open-domain event extraction. a trait of this survey is that it provides an overview in moderate complexity, avoiding involving too many details of particular approaches. this study focuses on discussing the common characters, application fields, advantages, and disadvantages of representative works, ignoring the specificities of individual approaches. finally, we summarize the common issues, current solutions, and future research directions. we hope this work could help researchers and practitioners obtain a quick overview of recent event extraction. ","1167":"we introduce language-informed latent actions (lila), a framework for learning natural language interfaces in the context of human-robot collaboration. lila falls under the shared autonomy paradigm: in addition to providing discrete language inputs, humans are given a low-dimensional controller $-$ e.g., a 2 degree-of-freedom (dof) joystick that can move left\/right and up\/down $-$ for operating the robot. lila learns to use language to modulate this controller, providing users with a language-informed control space: given an instruction like \"place the cereal bowl on the tray,\" lila may learn a 2-dof space where one dimension controls the distance from the robot's end-effector to the bowl, and the other dimension controls the robot's end-effector pose relative to the grasp point on the bowl. we evaluate lila with real-world user studies, where users can provide a language instruction while operating a 7-dof franka emika panda arm to complete a series of complex manipulation tasks. we show that lila models are not only more sample efficient and performant than imitation learning and end-effector control baselines, but that they are also qualitatively preferred by users. ","1168":"with a rise in false, inaccurate, and misleading information in propaganda, news, and social media, real-world question answering (qa) systems face the challenges of synthesizing and reasoning over contradicting information to derive correct answers. this urgency gives rise to the need to make qa systems robust to misinformation, a topic previously unexplored. we study the risk of misinformation to qa models by investigating the behavior of the qa model under contradicting contexts that are mixed with both real and fake information. we create the first large-scale dataset for this problem, namely contra-qa, which contains over 10k human-written and model-generated contradicting pairs of contexts. experiments show that qa models are vulnerable under contradicting contexts brought by misinformation. to defend against such a threat, we build a misinformation-aware qa system as a counter-measure that integrates question answering and misinformation detection in a joint fashion. ","1169":"for robots to understand human instructions and perform meaningful tasks in the near future, it is important to develop learned models that comprehend referential language to identify common objects in real-world 3d scenes. in this paper, we introduce a spatial-language model for a 3d visual grounding problem. specifically, given a reconstructed 3d scene in the form of point clouds with 3d bounding boxes of potential object candidates, and a language utterance referring to a target object in the scene, our model successfully identifies the target object from a set of potential candidates. specifically, languagerefer uses a transformer-based architecture that combines spatial embedding from bounding boxes with fine-tuned language embeddings from distilbert to predict the target object. we show that it performs competitively on visio-linguistic datasets proposed by referit3d. further, we analyze its spatial reasoning task performance decoupled from perception noise, the accuracy of view-dependent utterances, and viewpoint annotations for potential robotics applications. ","1170":"despite the widespread use of knowledge graph embeddings (kge), little is known about the security vulnerabilities that might disrupt their intended behaviour. we study data poisoning attacks against kge models for link prediction. these attacks craft adversarial additions or deletions at training time to cause model failure at test time. to select adversarial deletions, we propose to use the model-agnostic instance attribution methods from interpretable machine learning, which identify the training instances that are most influential to a neural model's predictions on test instances. we use these influential triples as adversarial deletions. we further propose a heuristic method to replace one of the two entities in each influential triple to generate adversarial additions. our experiments show that the proposed strategies outperform the state-of-art data poisoning attacks on kge models and improve the mrr degradation due to the attacks by up to 62% over the baselines. ","1171":"after a neural sequence model encounters an unexpected token, can its behavior be predicted? we show that rnn and transformer language models exhibit structured, consistent generalization in out-of-distribution contexts. we begin by introducing two idealized models of generalization in next-word prediction: a local context model in which generalization is consistent with the last word observed, and a global context model in which generalization is consistent with the global structure of the input. in experiments in english, finnish, mandarin, and random regular languages, we demonstrate that neural language models interpolate between these two forms of generalization: their predictions are well-approximated by a log-linear combination of local and global predictive distributions. we then show that, in some languages, noise mediates the two forms of generalization: noise applied to input tokens encourages global generalization, while noise in history representations encourages local generalization. finally, we offer a preliminary theoretical explanation of these results by proving that the observed interpolation behavior is expected in log-linear models with a particular feature correlation structure. these results help explain the effectiveness of two popular regularization schemes and show that aspects of sequence model generalization can be understood and controlled. ","1172":"neural agents trained in reinforcement learning settings can learn to communicate among themselves via discrete tokens, accomplishing as a team what agents would be unable to do alone. however, the current standard of using one-hot vectors as discrete communication tokens prevents agents from acquiring more desirable aspects of communication such as zero-shot understanding. inspired by word embedding techniques from natural language processing, we propose neural agent architectures that enables them to communicate via discrete tokens derived from a learned, continuous space. we show in a decision theoretic framework that our technique optimizes communication over a wide range of scenarios, whereas one-hot tokens are only optimal under restrictive assumptions. in self-play experiments, we validate that our trained agents learn to cluster tokens in semantically-meaningful ways, allowing them communicate in noisy environments where other techniques fail. lastly, we demonstrate both that agents using our method can effectively respond to novel human communication and that humans can understand unlabeled emergent agent communication, outperforming the use of one-hot communication. ","1173":"language-guided robots performing home and office tasks must navigate in and interact with the world. grounding language instructions against visual observations and actions to take in an environment is an open challenge. we present embodied bert (embert), a transformer-based model which can attend to high-dimensional, multi-modal inputs across long temporal horizons for language-conditioned task completion. additionally, we bridge the gap between successful object-centric navigation models used for non-interactive agents and the language-guided visual task completion benchmark, alfred, by introducing object navigation targets for embert training. we achieve competitive performance on the alfred benchmark, and embert marks the first transformer-based model to successfully handle the long-horizon, dense, multi-modal histories of alfred, and the first alfred model to utilize object-centric navigation targets. ","1174":"accessing the large volumes of information available in public knowledge bases might be complicated for those users unfamiliar with the sparql query language. automatic translation of questions posed in natural language in sparql has the potential of overcoming this problem. existing systems based on neural-machine translation are very effective but easily fail in recognizing words that are out of the vocabulary (oov) of the training set. this is a serious issue while querying large ontologies. in this paper, we combine named entity linking, named entity recognition, and neural machine translation to perform automatic translation of natural language questions into sparql queries. we demonstrate empirically that our approach is more effective and resilient to oov words than existing approaches by running the experiments on monument, qald-9, and lc-quad v1, which are well-known datasets for question answering over dbpedia. ","1175":"this paper presents a deep neural architecture, for natural language sentence matching (nlsm) by adding a deep recursive encoder to bert so called bert with deep recursive encoder (bert-dre). our analysis of model behavior shows that bert still does not capture the full complexity of text, so a deep recursive encoder is applied on top of bert. three bi-lstm layers with residual connection are used to design a recursive encoder and an attention module is used on top of this encoder. to obtain the final vector, a pooling layer consisting of average and maximum pooling is used. we experiment our model on four benchmarks, snli, farstail, multinli, scitail, and a novel persian religious questions dataset. this paper focuses on improving the bert results in the nlsm task. in this regard, comparisons between bert-dre and bert are conducted, and it is shown that in all cases, bert-dre outperforms bert. the bert algorithm on the religious dataset achieved an accuracy of 89.70%, and bert-dre architectures improved to 90.29% using the same dataset. ","1176":"the power of natural language generation models has provoked a flurry of interest in automatic methods to detect if a piece of text is human or machine-authored. the problem so far has been framed in a standard supervised way and consists in training a classifier on annotated data to predict the origin of one given new document. in this paper, we frame the problem in an unsupervised and distributional way: we assume that we have access to a large collection of unannotated documents, a big fraction of which is machine-generated. we propose a method to detect those machine-generated documents leveraging repeated higher-order n-grams, which we show over-appear in machine-generated text as compared to human ones. that weak signal is the starting point of a self-training setting where pseudo-labelled documents are used to train an ensemble of classifiers. our experiments show that leveraging that signal allows us to rank suspicious documents accurately. precision at 5000 is over 90% for top-k sampling strategies, and over 80% for nucleus sampling for the largest model we used (gpt2-large). the drop with increased size of model is small, which could indicate that the results hold for other current and future large language models. ","1177":"abstractive dialogue summarization is a challenging task for several reasons. first, most of the important pieces of information in a conversation are scattered across utterances through multi-party interactions with different textual styles. second, dialogues are often informal structures, wherein different individuals express personal perspectives, unlike text summarization, tasks that usually target formal documents such as news articles. to address these issues, we focused on the association between utterances from individual speakers and unique syntactic structures. speakers have unique textual styles that can contain linguistic information, such as voiceprint. therefore, we constructed a syntax-aware model by leveraging linguistic information (i.e., pos tagging), which alleviates the above issues by inherently distinguishing sentences uttered from individual speakers. we employed multi-task learning of both syntax-aware information and dialogue summarization. to the best of our knowledge, our approach is the first method to apply multi-task learning to the dialogue summarization task. experiments on a samsum corpus (a large-scale dialogue summarization corpus) demonstrated that our method improved upon the vanilla model. we further analyze the costs and benefits of our approach relative to baseline models. ","1178":"in recent years bert shows apparent advantages and great potential in natural language processing tasks. however, both training and applying bert requires intensive time and resources for computing contextual language representations, which hinders its universality and applicability. to overcome this bottleneck, we propose a deep bidirectional language model by using window masking mechanism at attention layer. this work computes contextual language representations without random masking as does in bert and maintains the deep bidirectional architecture like bert. to compute the same sentence representation, our method shows o(n) complexity less compared to other transformer-based models with o($n^2$). to further demonstrate its superiority, computing context language representations on cpu environments is conducted, by using the embeddings from the proposed method, logistic regression shows much higher accuracy in terms of sms classification. moverover, the proposed method also achieves significant higher performance in semantic similarity tasks. ","1179":"user-generated content from social media is produced in many languages, making it technically challenging to compare the discussed themes from one domain across different cultures and regions. it is relevant for domains in a globalized world, such as market research, where people from two nations and markets might have different requirements for a product. we propose a simple, modern, and effective method for building a single topic model with sentiment analysis capable of covering multiple languages simultanteously, based on a pre-trained state-of-the-art deep neural network for natural language understanding. to demonstrate its feasibility, we apply the model to newspaper articles and user comments of a specific domain, i.e., organic food products and related consumption behavior. the themes match across languages. additionally, we obtain an high proportion of stable and domain-relevant topics, a meaningful relation between topics and their respective textual contents, and an interpretable representation for social media documents. marketing can potentially benefit from our method, since it provides an easy-to-use means of addressing specific customer interests from different market regions around the globe. for reproducibility, we provide the code, data, and results of our study. ","1180":"while multi-agent reinforcement learning has been used as an effective means to study emergent communication between agents, existing work has focused almost exclusively on communication with discrete symbols. human communication often takes place (and emerged) over a continuous acoustic channel; human infants acquire language in large part through continuous signalling with their caregivers. we therefore ask: are we able to observe emergent language between agents with a continuous communication channel trained through reinforcement learning? and if so, what is the impact of channel characteristics on the emerging language? we propose an environment and training methodology to serve as a means to carry out an initial exploration of these questions. we use a simple messaging environment where a \"speaker\" agent needs to convey a concept to a \"listener\". the speaker is equipped with a vocoder that maps symbols to a continuous waveform, this is passed over a lossy continuous channel, and the listener needs to map the continuous signal to the concept. using deep q-learning, we show that basic compositionality emerges in the learned language representations. we find that noise is essential in the communication channel when conveying unseen concept combinations. and we show that we can ground the emergent communication by introducing a caregiver predisposed to \"hearing\" or \"speaking\" english. finally, we describe how our platform serves as a starting point for future work that uses a combination of deep reinforcement learning and multi-agent systems to study our questions of continuous signalling in language learning and emergence. ","1181":"in this paper we present the first system in spanish capable of answering questions about medicines for human use, called meqa (medicines question answering), a project created by the spanish agency for medicines and health products (aemps, for its acronym in spanish). online services that offer medical help have proliferated considerably, mainly due to the current pandemic situation due to covid-19. for example, websites such as doctoralia, savia, or saludonnet, offer doctor answers type consultations, in which patients or users can send questions to doctors and specialists, and receive an answer in less than 24 hours. many of the questions received are related to medicines for human use, and most can be answered through the leaflets. therefore, a system such as meqa capable of answering these types of questions automatically could alleviate the burden on these websites, and it would be of great use to such patients. ","1182":"we consider the use of automated supervised learning systems for data tables that not only contain numeric\/categorical columns, but one or more text fields as well. here we assemble 18 multimodal data tables that each contain some text fields and stem from a real business application. our publicly-available benchmark enables researchers to comprehensively evaluate their own methods for supervised learning with numeric, categorical, and text features. to ensure that any single modeling strategy which performs well over all 18 datasets will serve as a practical foundation for multimodal text\/tabular automl, the diverse datasets in our benchmark vary greatly in: sample size, problem types (a mix of classification and regression tasks), number of features (with the number of text columns ranging from 1 to 28 between datasets), as well as how the predictive signal is decomposed between text vs. numeric\/categorical features (and predictive interactions thereof). over this benchmark, we evaluate various straightforward pipelines to model such data, including standard two-stage approaches where nlp is used to featurize the text such that automl for tabular data can then be applied. compared with human data science teams, the fully automated methodology that performed best on our benchmark (stack ensembling a multimodal transformer with various tree models) also manages to rank 1st place when fit to the raw text\/tabular data in two machinehack prediction competitions and 2nd place (out of 2380 teams) in kaggle's mercari price suggestion challenge. ","1183":"language models are the underpin of all modern natural language processing (nlp) tasks. the introduction of the transformers architecture has contributed significantly into making language modeling very effective across many nlp task, leading to significant advancements in the field. however, transformers come with a big computational cost, which grows quadratically with respect to the input length. this presents a challenge as to understand long texts requires a lot of context. in this paper, we propose a fine-tuning framework, named corelm, that extends the architecture of current pretrained language models so that they incorporate explicit entity information. by introducing entity representations, we make available information outside the contextual space of the model, which results in a better language model for a fraction of the computational cost. we implement our approach using gpt2 and compare the fine-tuned model to the original. our proposed model achieves a lower perplexity in gumby and lambdada datasets when compared to gpt2 and a fine-tuned version of gpt2 without any changes. we also compare the models' performance in terms of accuracy in lambada and children's book test, with and without the use of model-created coreference annotations. ","1184":"voice conversion (vc) has been proposed to improve speech recognition systems in low-resource languages by using it to augment limited training data. but until recently, practical issues such as compute speed have limited the use of vc for this purpose. moreover, it is still unclear whether a vc model trained on one well-resourced language can be applied to speech from another low-resource language for the purpose of data augmentation. in this work we assess whether a vc system can be used cross-lingually to improve low-resource speech recognition. concretely, we combine several recent techniques to design and train a practical vc system in english, and then use this system to augment data for training a speech recognition model in several low-resource languages. we find that when using a sensible amount of augmented data, speech recognition performance is improved in all four low-resource languages considered. ","1185":"conversational semantic role labeling (csrl) is believed to be a crucial step towards dialogue understanding. however, it remains a major challenge for existing csrl parser to handle conversational structural information. in this paper, we present a simple and effective architecture for csrl which aims to address this problem. our model is based on a conversational structure-aware graph network which explicitly encodes the speaker dependent information. we also propose a multi-task learning method to further improve the model. experimental results on benchmark datasets show that our model with our proposed training objectives significantly outperforms previous baselines. ","1186":"in this work, we propose a new automatic speech recognition (asr) system based on feature learning and an end-to-end training procedure for air traffic control (atc) systems. the proposed model integrates the feature learning block, recurrent neural network (rnn), and connectionist temporal classification loss to build an end-to-end asr model. facing the complex environments of atc speech, instead of the handcrafted features, a learning block is designed to extract informative features from raw waveforms for acoustic modeling. both the sincnet and 1d convolution blocks are applied to process the raw waveforms, whose outputs are concatenated to the rnn layers for the temporal modeling. thanks to the ability to learn representations from raw waveforms, the proposed model can be optimized in a complete end-to-end manner, i.e., from waveform to text. finally, the multilingual issue in the atc domain is also considered to achieve the asr task by constructing a combined vocabulary of chinese characters and english letters. the proposed approach is validated on a multilingual real-world corpus (atcspeech), and the experimental results demonstrate that the proposed approach outperforms other baselines, achieving a 6.9\\% character error rate. ","1187":"in this paper, we present a manually annotated corpus of 10,000 tweets containing public reports of five covid-19 events, including positive and negative tests, deaths, denied access to testing, claimed cures and preventions. we designed slot-filling questions for each event type and annotated a total of 31 fine-grained slots, such as the location of events, recent travel, and close contacts. we show that our corpus can support fine-tuning bert-based classifiers to automatically extract publicly reported events and help track the spread of a new disease. we also demonstrate that, by aggregating events extracted from millions of tweets, we achieve surprisingly high precision when answering complex queries, such as \"which organizations have employees that tested positive in philadelphia?\" we will release our corpus (with user-information removed), automatic extraction models, and the corresponding knowledge base to the research community. ","1188":"much of the existing linguistic data in many languages of the world is locked away in non-digitized books and documents. optical character recognition (ocr) can be used to produce digitized text, and previous work has demonstrated the utility of neural post-correction methods that improve the results of general-purpose ocr systems on recognition of less-well-resourced languages. however, these methods rely on manually curated post-correction data, which are relatively scarce compared to the non-annotated raw images that need to be digitized.   in this paper, we present a semi-supervised learning method that makes it possible to utilize these raw images to improve performance, specifically through the use of self-training, a technique where a model is iteratively trained on its own outputs. in addition, to enforce consistency in the recognized vocabulary, we introduce a lexically-aware decoding method that augments the neural post-correction model with a count-based language model constructed from the recognized texts, implemented using weighted finite-state automata (wfsa) for efficient and effective decoding.   results on four endangered languages demonstrate the utility of the proposed method, with relative error reductions of 15-29%, where we find the combination of self-training and lexically-aware decoding essential for achieving consistent improvements. data and code are available at https:\/\/shrutirij.github.io\/ocr-el\/. ","1189":"my doctoral research focuses on understanding semantic knowledge in neural network models trained solely to predict natural language (referred to as language models, or lms), by drawing on insights from the study of concepts and categories grounded in cognitive science. i propose a framework inspired by 'inductive reasoning,' a phenomenon that sheds light on how humans utilize background knowledge to make inductive leaps and generalize from new pieces of information about concepts and their properties. drawing from experiments that study inductive reasoning, i propose to analyze semantic inductive generalization in lms using phenomena observed in human-induction literature, investigate inductive behavior on tasks such as implicit reasoning and emergent feature recognition, and analyze and relate induction dynamics to the learned conceptual representation space. ","1190":"robust state tracking for task-oriented dialogue systems currently remains restricted to a few popular languages. this paper shows that given a large-scale dialogue data set in one language, we can automatically produce an effective semantic parser for other languages using machine translation. we propose automatic translation of dialogue datasets with alignment to ensure faithful translation of slot values and eliminate costly human supervision used in previous benchmarks. we also propose a new contextual semantic parsing model, which encodes the formal slots and values, and only the last agent and user utterances. we show that the succinct representation reduces the compounding effect of translation errors, without harming the accuracy in practice.   we evaluate our approach on several dialogue state tracking benchmarks. on risawoz, crosswoz, crosswoz-en, and multiwoz-zh datasets we improve the state of the art by 11%, 17%, 20%, and 0.3% in joint goal accuracy. we present a comprehensive error analysis for all three datasets showing erroneous annotations can obscure judgments on the quality of the model.   finally, we present risawoz english and german datasets, created using our translation methodology. on these datasets, accuracy is within 11% of the original showing that high-accuracy multilingual dialogue datasets are possible without relying on expensive human annotations. ","1191":"most recent progress in natural language understanding (nlu) has been driven, in part, by benchmarks such as glue, superglue, squad, etc. in fact, many nlu models have now matched or exceeded \"human-level\" performance on many tasks in these benchmarks. most of these benchmarks, however, give models access to relatively large amounts of labeled data for training. as such, the models are provided far more data than required by humans to achieve strong performance. that has motivated a line of work that focuses on improving few-shot learning performance of nlu models. however, there is a lack of standardized evaluation benchmarks for few-shot nlu resulting in different experimental settings in different papers. to help accelerate this line of work, we introduce clues (constrained language understanding evaluation standard), a benchmark for evaluating the few-shot learning capabilities of nlu models. we demonstrate that while recent models reach human performance when they have access to large amounts of labeled data, there is a huge gap in performance in the few-shot setting for most tasks. we also demonstrate differences between alternative model families and adaptation techniques in the few shot setting. finally, we discuss several principles and choices in designing the experimental settings for evaluating the true few-shot learning performance and suggest a unified standardized approach to few-shot learning evaluation. we aim to encourage research on nlu models that can generalize to new tasks with a small number of examples. code and data for clues are available at https:\/\/github.com\/microsoft\/clues. ","1192":"existing abstractive summarization models lack explicit control mechanisms that would allow users to influence the stylistic features of the model outputs. this results in generating generic summaries that do not cater to the users needs or preferences. to address this issue we introduce hydrasum, a new summarization architecture that extends the single decoder framework of current models, e.g. bart, to a mixture-of-experts version consisting of multiple decoders. our proposed model encourages each expert, i.e. decoder, to learn and generate stylistically-distinct summaries along dimensions such as abstractiveness, length, specificity, and others. at each time step, hydrasum employs a gating mechanism that decides the contribution of each individual decoder to the next token's output probability distribution. through experiments on three summarization datasets (cnn, newsroom, xsum), we demonstrate that this gating mechanism automatically learns to assign contrasting summary styles to different hydrasum decoders under the standard training objective without the need for additional supervision. we further show that a guided version of the training process can explicitly govern which summary style is partitioned between decoders, e.g. high abstractiveness vs. low abstractiveness or high specificity vs. low specificity, and also increase the stylistic-difference between individual decoders. finally, our experiments demonstrate that our decoder framework is highly flexible: during inference, we can sample from individual decoders or mixtures of different subsets of the decoders to yield a diverse set of summaries and enforce single- and multi-style control over summary generation. ","1193":"athena 2.0 is an alexa prize socialbot that has been a finalist in the last two alexa prize grand challenges. one reason for athena's success is its novel dialogue management strategy, which allows it to dynamically construct dialogues and responses from component modules, leading to novel conversations with every interaction. here we describe athena's system design and performance in the alexa prize during the 20\/21 competition. a live demo of athena as well as video recordings will provoke discussion on the state of the art in conversational ai. ","1194":"labeling data can be an expensive task as it is usually performed manually by domain experts. this is cumbersome for deep learning, as it is dependent on large labeled datasets. active learning (al) is a paradigm that aims to reduce labeling effort by only using the data which the used model deems most informative. little research has been done on al in a text classification setting and next to none has involved the more recent, state-of-the-art natural language processing (nlp) models. here, we present an empirical study that compares different uncertainty-based algorithms with bert$_{base}$ as the used classifier. we evaluate the algorithms on two nlp classification datasets: stanford sentiment treebank and kvk-frontpages. additionally, we explore heuristics that aim to solve presupposed problems of uncertainty-based al; namely, that it is unscalable and that it is prone to selecting outliers. furthermore, we explore the influence of the query-pool size on the performance of al. whereas it was found that the proposed heuristics for al did not improve performance of al; our results show that using uncertainty-based al with bert$_{base}$ outperforms random sampling of data. this difference in performance can decrease as the query-pool size gets larger. ","1195":"backdoor attacks are a kind of emergent training-time threat to deep neural networks (dnns). they can manipulate the output of dnns and possess high insidiousness. in the field of natural language processing, some attack methods have been proposed and achieve very high attack success rates on multiple popular models. nevertheless, there are few studies on defending against textual backdoor attacks. in this paper, we propose a simple and effective textual backdoor defense named onion, which is based on outlier word detection and, to the best of our knowledge, is the first method that can handle all the textual backdoor attack situations. experiments demonstrate the effectiveness of our model in defending bilstm and bert against five different backdoor attacks. all the code and data of this paper can be obtained at https:\/\/github.com\/thunlp\/onion. ","1196":"this paper introduces the hmblogs corpus for persian, as a low resource language. this corpus has been prepared based on a collection of nearly 20 million blog posts over a period of about 15 years from a space of persian blogs and includes more than 6.8 billion tokens. it can be claimed that this corpus is currently the largest persian corpus that has been prepared independently for the persian language. this corpus is presented in both raw and preprocessed forms, and based on the preprocessed corpus some word embedding models are produced. by the provided models, the hmblogs is compared with some of the most important corpora available in persian, and the results show the superiority of the hmblogs corpus over the others. these evaluations also present the importance and effects of corpora, evaluation datasets, model production methods, different hyperparameters and even the evaluation methods. in addition to evaluating the corpus and its produced language models, this research also presents a semantic analogy dataset. ","1197":"we present a unified vision-language pretrained model (vlmo) that jointly learns a dual encoder and a fusion encoder with a modular transformer network. specifically, we introduce mixture-of-modality-experts (mome) transformer, where each block contains a pool of modality-specific experts and a shared self-attention layer. because of the modeling flexibility of mome, pretrained vlmo can be fine-tuned as a fusion encoder for vision-language classification tasks, or used as a dual encoder for efficient image-text retrieval. moreover, we propose a stagewise pre-training strategy, which effectively leverages large-scale image-only and text-only data besides image-text pairs. experimental results show that vlmo achieves state-of-the-art results on various vision-language tasks, including vqa and nlvr2. the code and pretrained models are available at https:\/\/aka.ms\/vlmo. ","1198":"this paper explores relational syllogistic logics, a family of logical systems related to reasoning about relations in extensions of the classical syllogistic. these are all decidable logical systems. we prove completeness theorems and complexity results for a natural subfamily of relational syllogistic logics, parametrized by constructors for terms and for sentences. ","1199":"sentiment analysis is often a crowdsourcing task prone to subjective labels given by many annotators. it is not yet fully understood how the annotation bias of each annotator can be modeled correctly with state-of-the-art methods. however, resolving annotator bias precisely and reliably is the key to understand annotators' labeling behavior and to successfully resolve corresponding individual misconceptions and wrongdoings regarding the annotation task. our contribution is an explanation and improvement for precise neural end-to-end bias modeling and ground truth estimation, which reduces an undesired mismatch in that regard of the existing state-of-the-art. classification experiments show that it has potential to improve accuracy in cases where each sample is annotated only by one single annotator. we provide the whole source code publicly and release an own domain-specific sentiment dataset containing 10,000 sentences discussing organic food products. these are crawled from social media and are singly labeled by 10 non-expert annotators. ","1200":"as a major social media platform, twitter publishes a large number of user-generated text (tweets) on a daily basis. mining such data can be used to address important social, public health, and emergency management issues that are infeasible through other means. an essential step in many text mining pipelines is named entity recognition (ner), which presents some special challenges for tweet data. among them are nonstandard expressions, extreme imbalanced classes, and lack of context information, etc. the track 3 of biocreative challenge vii (bc7) was organized to evaluate methods for detecting medication mentions in tweets. in this paper, we report our work on bc7 track 3, where we explored a pubmedbert-based classifier trained with a combination of multiple data augmentation approaches. our method achieved an f1 score of 0.762, which is substantially higher than the mean of all submissions (0.696). ","1201":"this paper reports on an experiment into text-based phishing detection using readily available resources and without the use of semantics. the developed algorithm is a modified version of previously published work that works with the same tools. the results obtained in recognizing phishing emails are considerably better than the previously reported work; but the rate of text falsely identified as phishing is slightly worse. it is expected that adding semantic component will reduce the false positive rate while preserving the detection accuracy. ","1202":"we look at how machine learning techniques that derive properties of items in a collection of independent media can be used to automatically embed stories into such collections. to do so, we use models that extract the tempo of songs to make a music playlist follow a narrative arc. our work specifies an open-source tool that uses pre-trained neural network models to extract the global tempo of a set of raw audio files and applies these measures to create a narrative-following playlist. this tool is available at https:\/\/github.com\/dylanashley\/playlist-story-builder\/releases\/tag\/v1.0.0 ","1203":"aspect-based sentiment analysis aims to identify the sentiment polarity of a specific aspect in product reviews. we notice that about 30% of reviews do not contain obvious opinion words, but still convey clear human-aware sentiment orientation, which is known as implicit sentiment. however, recent neural network-based approaches paid little attention to implicit sentiment entailed in the reviews. to overcome this issue, we adopt supervised contrastive pre-training on large-scale sentiment-annotated corpora retrieved from in-domain language resources. by aligning the representation of implicit sentiment expressions to those with the same sentiment label, the pre-training process leads to better capture of both implicit and explicit sentiment orientation towards aspects in reviews. experimental results show that our method achieves state-of-the-art performance on semeval2014 benchmarks, and comprehensive analysis validates its effectiveness on learning implicit sentiment. ","1204":"the audio-video based multimodal emotion recognition has attracted a lot of attention due to its robust performance. most of the existing methods focus on proposing different cross-modal fusion strategies. however, these strategies introduce redundancy in the features of different modalities without fully considering the complementary properties between modal information, and these approaches do not guarantee the non-loss of original semantic information during intra- and inter-modal interactions. in this paper, we propose a novel cross-modal fusion network based on self-attention and residual structure (cfn-sr) for multimodal emotion recognition. firstly, we perform representation learning for audio and video modalities to obtain the semantic features of the two modalities by efficient resnext and 1d cnn, respectively. secondly, we feed the features of the two modalities into the cross-modal blocks separately to ensure efficient complementarity and completeness of information through the self-attention mechanism and residual structure. finally, we obtain the output of emotions by splicing the obtained fused representation with the original representation. to verify the effectiveness of the proposed method, we conduct experiments on the ravdess dataset. the experimental results show that the proposed cfn-sr achieves the state-of-the-art and obtains 75.76% accuracy with 26.30m parameters. our code is available at https:\/\/github.com\/skeletonnn\/cfn-sr. ","1205":"modeling differential stress expressions in urban and rural regions in china can provide a better understanding of the effects of urbanization on psychological well-being in a country that has rapidly grown economically in the last two decades. this paper studies linguistic differences in the experiences and expressions of stress in urban-rural china from weibo posts from over 65,000 users across 329 counties using hierarchical mixed-effects models. we analyzed phrases, topical themes, and psycho-linguistic word choices in weibo posts mentioning stress to better understand appraisal differences surrounding psychological stress in urban and rural communities in china; we then compared them with large-scale polls from gallup. after controlling for socioeconomic and gender differences, we found that rural communities tend to express stress in emotional and personal themes such as relationships, health, and opportunity while users in urban areas express stress using relative, temporal, and external themes such as work, politics, and economics. these differences exist beyond controlling for gdp and urbanization, indicating a fundamentally different lifestyle between rural and urban residents in very specific environments, arguably having different sources of stress. we found corroborative trends in physical, financial, and social wellness with urbanization in gallup polls. ","1206":"this paper describes lingua custodia's submission to the wmt21 shared task on machine translation using terminologies. we consider three directions, namely english to french, russian, and chinese. we rely on a transformer-based architecture as a building block, and we explore a method which introduces two main changes to the standard procedure to handle terminologies. the first one consists in augmenting the training data in such a way as to encourage the model to learn a copy behavior when it encounters terminology constraint terms. the second change is constraint token masking, whose purpose is to ease copy behavior learning and to improve model generalization. empirical results show that our method satisfies most terminology constraints while maintaining high translation quality. ","1207":"multi-modal language-vision models trained on hundreds of millions of image-text pairs (e.g. clip, dall-e) gained a recent surge, showing remarkable capability to perform zero- or few-shot learning and transfer even in absence of per-sample labels on target image data. despite this trend, to date there has been no publicly available datasets of sufficient scale for training such models from scratch. to address this issue, in a community effort we build and release for public laion-400m, a dataset with clip-filtered 400 million image-text pairs, their clip embeddings and knn indices that allow efficient similarity search. ","1208":"we present two novel unsupervised methods for eliminating toxicity in text. our first method combines two recent ideas: (1) guidance of the generation process with small style-conditional language models and (2) use of paraphrasing models to perform style transfer. we use a well-performing paraphraser guided by style-trained language models to keep the text content and remove toxicity. our second method uses bert to replace toxic words with their non-offensive synonyms. we make the method more flexible by enabling bert to replace mask tokens with a variable number of words. finally, we present the first large-scale comparative study of style transfer models on the task of toxicity removal. we compare our models with a number of methods for style transfer. the models are evaluated in a reference-free way using a combination of unsupervised style transfer metrics. both methods we suggest yield new sota results. ","1209":"this report describes microsoft's machine translation systems for the wmt21 shared task on large-scale multilingual machine translation. we participated in all three evaluation tracks including large track and two small tracks where the former one is unconstrained and the latter two are fully constrained. our model submissions to the shared task were initialized with deltalm\\footnote{\\url{https:\/\/aka.ms\/deltalm}}, a generic pre-trained multilingual encoder-decoder model, and fine-tuned correspondingly with the vast collected parallel data and allowed data sources according to track settings, together with applying progressive learning and iterative back-translation approaches to further improve the performance. our final submissions ranked first on three tracks in terms of the automatic evaluation metric. ","1210":"automatic spoken instruction understanding (siu) of the controller-pilot conversations in the air traffic control (atc) requires not only recognizing the words and semantics of the speech but also determining the role of the speaker. however, few of the published works on the automatic understanding systems in air traffic communication focus on speaker role identification (sri). in this paper, we formulate the sri task of controller-pilot communication as a binary classification problem. furthermore, the text-based, speech-based, and speech and text based multi-modal methods are proposed to achieve a comprehensive comparison of the sri task. to ablate the impacts of the comparative approaches, various advanced neural network architectures are applied to optimize the implementation of text-based and speech-based methods. most importantly, a multi-modal speaker role identification network (mmsrinet) is designed to achieve the sri task by considering both the speech and textual modality features. to aggregate modality features, the modal fusion module is proposed to fuse and squeeze acoustic and textual representations by modal attention mechanism and self-attention pooling layer, respectively. finally, the comparative approaches are validated on the atcspeech corpus collected from a real-world atc environment. the experimental results demonstrate that all the comparative approaches are worked for the sri task, and the proposed mmsrinet shows the competitive performance and robustness than the other methods on both seen and unseen data, achieving 98.56%, and 98.08% accuracy, respectively. ","1211":"mining causality from text is a complex and crucial natural language understanding task corresponding to the human cognition. existing studies at its solution can be grouped into two primary categories: feature engineering based and neural model based methods. in this paper, we find that the former has incomplete coverage and inherent errors but provide prior knowledge; while the latter leverages context information but causal inference of which is insufficiency. to handle the limitations, we propose a novel causality detection model named mcdn to explicitly model causal reasoning process, and furthermore, to exploit the advantages of both methods. specifically, we adopt multi-head self-attention to acquire semantic feature at word level and develop the scrn to infer causality at segment level. to the best of our knowledge, with regards to the causality tasks, this is the first time that the relation network is applied. the experimental results show that: 1) the proposed approach performs prominent performance on causality detection; 2) further analysis manifests the effectiveness and robustness of mcdn. ","1212":"transformer models are permutation equivariant. to supply the order and type information of the input tokens, position and segment embeddings are usually added to the input. recent works proposed variations of positional encodings with relative position encodings achieving better performance. our analysis shows that the gain actually comes from moving positional information to attention layer from the input. motivated by this, we introduce decoupled positional attention for transformers (diet), a simple yet effective mechanism to encode position and segment information into the transformer models. the proposed method has faster training and inference time, while achieving competitive performance on glue, xtreme and wmt benchmarks. we further generalize our method to long-range transformers and show performance gain. ","1213":"the attention module, which is a crucial component in transformer, cannot scale efficiently to long sequences due to its quadratic complexity. many works focus on approximating the dot-then-exponentiate softmax function in the original attention, leading to sub-quadratic or even linear-complexity transformer architectures. however, we show that these methods cannot be applied to more powerful attention modules that go beyond the dot-then-exponentiate style, e.g., transformers with relative positional encoding (rpe). since in many state-of-the-art models, relative positional encoding is used as default, designing efficient transformers that can incorporate rpe is appealing. in this paper, we propose a novel way to accelerate attention calculation for transformers with rpe on top of the kernelized attention. based upon the observation that relative positional encoding forms a toeplitz matrix, we mathematically show that kernelized attention with rpe can be calculated efficiently using fast fourier transform (fft). with fft, our method achieves $\\mathcal{o}(n\\log n)$ time complexity. interestingly, we further demonstrate that properly using relative positional encoding can mitigate the training instability problem of vanilla kernelized attention. on a wide range of tasks, we empirically show that our models can be trained from scratch without any optimization issues. the learned model performs better than many efficient transformer variants and is faster than standard transformer in the long-sequence regime. ","1214":"prompt-learning has become a new paradigm in modern natural language processing, which directly adapts pre-trained language models (plms) to $cloze$-style prediction, autoregressive modeling, or sequence to sequence generation, resulting in promising performances on various tasks. however, no standard implementation framework of prompt-learning is proposed yet, and most existing prompt-learning codebases, often unregulated, only provide limited implementations for specific scenarios. since there are many details such as templating strategy, initializing strategy, and verbalizing strategy, etc. need to be considered in prompt-learning, practitioners face impediments to quickly adapting the desired prompt learning methods to their applications. in this paper, we present {openprompt}, a unified easy-to-use toolkit to conduct prompt-learning over plms. openprompt is a research-friendly framework that is equipped with efficiency, modularity, and extendibility, and its combinability allows the freedom to combine different plms, task formats, and prompting modules in a unified paradigm. users could expediently deploy prompt-learning frameworks and evaluate the generalization of them on different nlp tasks without constraints. openprompt is publicly released at {\\url{ https:\/\/github.com\/thunlp\/openprompt}}. ","1215":"interactive and non-interactive model are the two de-facto standard frameworks in vector-based cross-lingual information retrieval (v-clir), which embed queries and documents in synchronous and asynchronous fashions, respectively. from the retrieval accuracy and computational efficiency perspectives, each model has its own superiority and shortcoming. in this paper, we propose a novel framework to leverage the advantages of these two paradigms. concretely, we introduce semi-interactive mechanism, which builds our model upon non-interactive architecture but encodes each document together with its associated multilingual queries. accordingly, cross-lingual features can be better learned like an interactive model. besides, we further transfer knowledge from a well-trained interactive model to ours by reusing its word embeddings and adopting knowledge distillation. our model is initialized from a multilingual pre-trained language model m-bert, and evaluated on two open-resource clir datasets derived from wikipedia and an in-house dataset collected from a real-world search engine. extensive analyses reveal that our methods significantly boost the retrieval accuracy while maintaining the computational efficiency. ","1216":"we study the effectiveness of feature density (fd) using different linguistically-backed feature preprocessing methods in order to estimate dataset complexity, which in turn is used to comparatively estimate the potential performance of machine learning (ml) classifiers prior to any training. we hypothesise that estimating dataset complexity allows for the reduction of the number of required experiments iterations. this way we can optimize the resource-intensive training of ml models which is becoming a serious issue due to the increases in available dataset sizes and the ever rising popularity of models based on deep neural networks (dnn). the problem of constantly increasing needs for more powerful computational resources is also affecting the environment due to alarmingly-growing amount of co2 emissions caused by training of large-scale ml models. the research was conducted on multiple datasets, including popular datasets, such as yelp business review dataset used for training typical sentiment analysis models, as well as more recent datasets trying to tackle the problem of cyberbullying, which, being a serious social problem, is also a much more sophisticated problem form the point of view of linguistic representation. we use cyberbullying datasets collected for multiple languages, namely english, japanese and polish. the difference in linguistic complexity of datasets allows us to additionally discuss the efficacy of linguistically-backed word preprocessing. ","1217":"the quadratic computational and memory complexities of the transformer's attention mechanism have limited its scalability for modeling long sequences. in this paper, we propose luna, a linear unified nested attention mechanism that approximates softmax attention with two nested linear attention functions, yielding only linear (as opposed to quadratic) time and space complexity. specifically, with the first attention function, luna packs the input sequence into a sequence of fixed length. then, the packed sequence is unpacked using the second attention function. as compared to a more traditional attention mechanism, luna introduces an additional sequence with a fixed length as input and an additional corresponding output, which allows luna to perform attention operation linearly, while also storing adequate contextual information. we perform extensive evaluations on three benchmarks of sequence modeling tasks: long-context sequence modeling, neural machine translation and masked language modeling for large-scale pretraining. competitive or even better experimental results demonstrate both the effectiveness and efficiency of luna compared to a variety ","1218":"lipreading or visually recognizing speech from the mouth movements of a speaker is a challenging and mentally taxing task. unfortunately, multiple medical conditions force people to depend on this skill in their day-to-day lives for essential communication. patients suffering from amyotrophic lateral sclerosis (als) often lose muscle control, consequently their ability to generate speech and communicate via lip movements. existing large datasets do not focus on medical patients or curate personalized vocabulary relevant to an individual. collecting a large-scale dataset of a patient, needed to train mod-ern data-hungry deep learning models is, however, extremely challenging. in this work, we propose a personalized network to lipread an als patient using only one-shot examples. we depend on synthetically generated lip movements to augment the one-shot scenario. a variational encoder based domain adaptation technique is used to bridge the real-synthetic domain gap. our approach significantly improves and achieves high top-5accuracy with 83.2% accuracy compared to 62.6% achieved by comparable methods for the patient. apart from evaluating our approach on the als patient, we also extend it to people with hearing impairment relying extensively on lip movements to communicate. ","1219":"while recent work on automated fact-checking has focused mainly on verifying and explaining claims, for which the list of claims is readily available, identifying check-worthy claim sentences from a text remains challenging. current claim identification models rely on manual annotations for each sentence in the text, which is an expensive task and challenging to conduct on a frequent basis across multiple domains. this paper explores methodology to identify check-worthy claim sentences from fake news articles, irrespective of domain, without explicit sentence-level annotations. we leverage two internal supervisory signals - headline and the abstractive summary - to rank the sentences based on semantic similarity. we hypothesize that this ranking directly correlates to the check-worthiness of the sentences. to assess the effectiveness of this hypothesis, we build pipelines that leverage the ranking of sentences based on either the headline or the abstractive summary. the top-ranked sentences are used for the downstream fact-checking tasks of evidence retrieval and the article's veracity prediction by the pipeline. our findings suggest that the top 3 ranked sentences contain enough information for evidence-based fact-checking of a fake news article. we also show that while the headline has more gisting similarity with how a fact-checking website writes a claim, the summary-based pipeline is the most promising for an end-to-end fact-checking system. ","1220":"we introduce korean language understanding evaluation (klue) benchmark. klue is a collection of 8 korean natural language understanding (nlu) tasks, including topic classification, semantictextual similarity, natural language inference, named entity recognition, relation extraction, dependency parsing, machine reading comprehension, and dialogue state tracking. we build all of the tasks from scratch from diverse source corpora while respecting copyrights, to ensure accessibility for anyone without any restrictions. with ethical considerations in mind, we carefully design annotation protocols. along with the benchmark tasks and data, we provide suitable evaluation metrics and fine-tuning recipes for pretrained language models for each task. we furthermore release the pretrained language models (plm), klue-bert and klue-roberta, to help reproducing baseline models on klue and thereby facilitate future research. we make a few interesting observations from the preliminary experiments using the proposed klue benchmark suite, already demonstrating the usefulness of this new benchmark suite. first, we find klue-roberta-large outperforms other baselines, including multilingual plms and existing open-source korean plms. second, we see minimal degradation in performance even when we replace personally identifiable information from the pretraining corpus, suggesting that privacy and nlu capability are not at odds with each other. lastly, we find that using bpe tokenization in combination with morpheme-level pre-tokenization is effective in tasks involving morpheme-level tagging, detection and generation. in addition to accelerating korean nlp research, our comprehensive documentation on creating klue will facilitate creating similar resources for other languages in the future. klue is available at https:\/\/klue-benchmark.com. ","1221":"while different language models are ubiquitous in nlp, it is hard to contrast their outputs and identify which contexts one can handle better than the other. to address this question, we introduce lmdiff, a tool that visually compares probability distributions of two models that differ, e.g., through finetuning, distillation, or simply training with different parameter sizes. lmdiff allows the generation of hypotheses about model behavior by investigating text instances token by token and further assists in choosing these interesting text instances by identifying the most interesting phrases from large corpora. we showcase the applicability of lmdiff for hypothesis generation across multiple case studies. a demo is available at http:\/\/lmdiff.net . ","1222":"in recent years, low-resource machine reading comprehension (mrc) has made significant progress, with models getting remarkable performance on various language datasets. however, none of these models have been customized for the urdu language. this work explores the semi-automated creation of the urdu question answering dataset (uquad1.0) by combining machine-translated squad with human-generated samples derived from wikipedia articles and urdu rc worksheets from cambridge o-level books. uquad1.0 is a large-scale urdu dataset intended for extractive machine reading comprehension tasks consisting of 49k question answers pairs in question, passage, and answer format. in uquad1.0, 45000 pairs of qa were generated by machine translation of the original squad1.0 and approximately 4000 pairs via crowdsourcing. in this study, we used two types of mrc models: rule-based baseline and advanced transformer-based models. however, we have discovered that the latter outperforms the others; thus, we have decided to concentrate solely on transformer-based architectures. using xlmroberta and multi-lingual bert, we acquire an f1 score of 0.66 and 0.63, respectively. ","1223":"the enormous amount of data being generated on the web and social media has increased the demand for detecting online hate speech. detecting hate speech will reduce their negative impact and influence on others. a lot of effort in the natural language processing (nlp) domain aimed to detect hate speech in general or detect specific hate speech such as religion, race, gender, or sexual orientation. hate communities tend to use abbreviations, intentional spelling mistakes, and coded words in their communication to evade detection, adding more challenges to hate speech detection tasks. thus, word representation will play an increasingly pivotal role in detecting hate speech. this paper investigates the feasibility of leveraging domain-specific word embedding in bidirectional lstm based deep model to automatically detect\/classify hate speech. furthermore, we investigate the use of the transfer learning language model (bert) on hate speech problem as a binary classification task. the experiments showed that domainspecific word embedding with the bidirectional lstm based deep model achieved a 93% f1-score while bert achieved up to 96% f1-score on a combined balanced dataset from available hate speech datasets. ","1224":"in this work, we show a novel method for neural machine translation (nmt), using a denoising diffusion probabilistic model (ddpm), adjusted for textual data, following recent advances in the field. we show that it's possible to translate sentences non-autoregressively using a diffusion model conditioned on the source sentence. we also show that our model is able to translate between pairs of languages unseen during training (zero-shot learning). ","1225":"in this paper, we propose a system combination method for grammatical error correction (gec), based on nonlinear integer programming (ip). our method optimizes a novel f score objective based on error types, and combines multiple end-to-end gec systems. the proposed ip approach optimizes the selection of a single best system for each grammatical error type present in the data. experiments of the ip approach on combining state-of-the-art standalone gec systems show that the combined system outperforms all standalone systems. it improves f0.5 score by 3.61% when combining the two best participating systems in the bea 2019 shared task, and achieves f0.5 score of 73.08%. we also perform experiments to compare our ip approach with another state-of-the-art system combination method for gec, demonstrating ip's competitive combination capability. ","1226":"in spoken dialogue systems, we aim to deploy artificial intelligence to build automated dialogue agents that can converse with humans. dialogue systems are increasingly being designed to move beyond just imitating conversation and also improve from such interactions over time. in this survey, we present a broad overview of methods developed to build dialogue systems over the years. different use cases for dialogue systems ranging from task-based systems to open domain chatbots motivate and necessitate specific systems. starting from simple rule-based systems, research has progressed towards increasingly complex architectures trained on a massive corpus of datasets, like deep learning systems. motivated with the intuition of resembling human dialogues, progress has been made towards incorporating emotions into the natural language generator, using reinforcement learning. while we see a trend of highly marginal improvement on some metrics, we find that limited justification exists for the metrics, and evaluation practices are not uniform. to conclude, we flag these concerns and highlight possible research directions. ","1227":"reinforcement learning (rl) has been witnessed its potential for training a dialogue policy agent towards maximizing the accumulated rewards given from users. however, the reward can be very sparse for it is usually only provided at the end of a dialog session, which causes unaffordable interaction requirements for an acceptable dialog agent. distinguished from many efforts dedicated to optimizing the policy and recovering the reward alternatively which suffers from easily getting stuck in local optima and model collapse, we decompose the adversarial training into two steps: 1) we integrate a pre-trained language model as a discriminator to judge whether the current system action is good enough for the last user action (i.e., \\textit{next action prediction}); 2) the discriminator gives and extra local dense reward to guide the agent's exploration. the experimental result demonstrates that our method significantly improves the complete rate (~4.4\\%) and success rate (~8.0\\%) of the dialogue system. ","1228":"sentiment-aware intelligent systems are essential to a wide array of applications. these systems are driven by language models which broadly fall into two paradigms: lexicon-based and contextual. although recent contextual models are increasingly dominant, we still see demand for lexicon-based models because of their interpretability and ease of use. for example, lexicon-based models allow researchers to readily determine which words and phrases contribute most to a change in measured sentiment. a challenge for any lexicon-based approach is that the lexicon needs to be routinely expanded with new words and expressions. here, we propose two models for automatic lexicon expansion. our first model establishes a baseline employing a simple and shallow neural network initialized with pre-trained word embeddings using a non-contextual approach. our second model improves upon our baseline, featuring a deep transformer-based network that brings to bear word definitions to estimate their lexical polarity. our evaluation shows that both models are able to score new words with a similar accuracy to reviewers from amazon mechanical turk, but at a fraction of the cost. ","1229":"recently, there is a surge of interest in applying pre-trained language models (pr-lm) in automatic open-domain dialog evaluation. pr-lms offer a promising direction for addressing the multi-domain evaluation challenge. yet, the impact of different pr-lms on the performance of automatic metrics is not well-understood. this paper examines 8 different pr-lms and studies their impact on three typical automatic dialog evaluation metrics across three different dialog evaluation benchmarks. specifically, we analyze how the choice of pr-lms affects the performance of automatic metrics. extensive correlation analyses on each of the metrics are performed to assess the effects of different pr-lms along various axes, including pre-training objectives, dialog evaluation criteria, model size, and cross-dataset robustness. this study serves as the first comprehensive assessment of the effects of different pr-lms on automatic dialog evaluation. ","1230":"natural language understanding (nlu) has made massive progress driven by large benchmarks, paired with research on transfer learning to broaden its impact. benchmarks are dominated by a small set of frequent phenomena, leaving a long tail of infrequent phenomena underrepresented. in this work, we reflect on the question: have transfer learning methods sufficiently addressed performance of benchmark-trained models on the long tail? since benchmarks do not list included\/excluded phenomena, we conceptualize the long tail using macro-level dimensions such as underrepresented genres, topics, etc. we assess trends in transfer learning research through a qualitative meta-analysis of 100 representative papers on transfer learning for nlu. our analysis asks three questions: (i) which long tail dimensions do transfer learning studies target? (ii) which properties help adaptation methods improve performance on the long tail? (iii) which methodological gaps have greatest negative impact on long tail performance? our answers to these questions highlight major avenues for future research in transfer learning for the long tail. lastly, we present a case study comparing the performance of various adaptation methods on clinical narratives to show how systematically conducted meta-experiments can provide insights that enable us to make progress along these future avenues. ","1231":"speech processing systems currently do not support the vast majority of languages, in part due to the lack of data in low-resource languages. cross-lingual transfer offers a compelling way to help bridge this digital divide by incorporating high-resource data into low-resource systems. current cross-lingual algorithms have shown success in text-based tasks and speech-related tasks over some low-resource languages. however, scaling up speech systems to support hundreds of low-resource languages remains unsolved. to help bridge this gap, we propose a language similarity approach that can efficiently identify acoustic cross-lingual transfer pairs across hundreds of languages. we demonstrate the effectiveness of our approach in language family classification, speech recognition, and speech synthesis tasks. ","1232":"meta-learning considers the problem of learning an efficient learning process that can leverage its past experience to accurately solve new tasks. however, the efficacy of meta-learning crucially depends on the distribution of tasks available for training, and this is often assumed to be known a priori or constructed from limited supervised datasets. in this work, we aim to provide task distributions for meta-learning by considering self-supervised tasks automatically proposed from unlabeled text, to enable large-scale meta-learning in nlp. we design multiple distributions of self-supervised tasks by considering important aspects of task diversity, difficulty, type, domain, and curriculum, and investigate how they affect meta-learning performance. our analysis shows that all these factors meaningfully alter the task distribution, some inducing significant improvements in downstream few-shot accuracy of the meta-learned models. empirically, results on 20 downstream tasks show significant improvements in few-shot learning -- adding up to +4.2% absolute accuracy (on average) to the previous unsupervised meta-learning method, and perform comparably to supervised methods on the fewrel 2.0 benchmark. ","1233":"text classification is a fundamental language task in natural language processing. a variety of sequential models is capable making good predictions yet there is lack of connection between language semantics and prediction results. this paper proposes a novel influence score (i-score), a greedy search algorithm called backward dropping algorithm (bda), and a novel feature engineering technique called the \"dagger technique\". first, the paper proposes a novel influence score (i-score) to detect and search for the important language semantics in text document that are useful for making good prediction in text classification tasks. next, a greedy search algorithm called the backward dropping algorithm is proposed to handle long-term dependencies in the dataset. moreover, the paper proposes a novel engineering technique called the \"dagger technique\" that fully preserve the relationship between explanatory variable and response variable. the proposed techniques can be further generalized into any feed-forward artificial neural networks (anns) and convolutional neural networks (cnns), and any neural network. a real-world application on the internet movie database (imdb) is used and the proposed methods are applied to improve prediction performance with an 81% error reduction comparing with other popular peers if i-score and \"dagger technique\" are not implemented. ","1234":"recent years have witnessed the rapid development of concept map generation techniques due to their advantages in providing well-structured summarization of knowledge from free texts. traditional unsupervised methods do not generate task-oriented concept maps, whereas deep generative models require large amounts of training data. in this work, we present gt-d2g (graph translation based document-to-graph), an automatic concept map generation framework that leverages generalized nlp pipelines to derive semantic-rich initial graphs, and translates them into more concise structures under the weak supervision of document labels. the quality and interpretability of such concept maps are validated through human evaluation on three real-world corpora, and their utility in the downstream task is further demonstrated in the controlled experiments with scarce document labels. ","1235":"large, pre-trained transformer-based language models such as bert have drastically changed the natural language processing (nlp) field. we present a survey of recent work that uses these large language models to solve nlp tasks via pre-training then fine-tuning, prompting, or text generation approaches. we also present approaches that use pre-trained language models to generate data for training augmentation or other purposes. we conclude with discussions on limitations and suggested directions for future research. ","1236":"for over thirty years, researchers have developed and analyzed methods for latent tree induction as an approach for unsupervised syntactic parsing. nonetheless, modern systems still do not perform well enough compared to their supervised counterparts to have any practical use as structural annotation of text. in this work, we present a technique that uses distant supervision in the form of span constraints (i.e. phrase bracketing) to improve performance in unsupervised constituency parsing. using a relatively small number of span constraints we can substantially improve the output from diora, an already competitive unsupervised parsing system. compared with full parse tree annotation, span constraints can be acquired with minimal effort, such as with a lexicon derived from wikipedia, to find exact text matches. our experiments show span constraints based on entities improves constituency parsing on english wsj penn treebank by more than 5 f1. furthermore, our method extends to any domain where span constraints are easily attainable, and as a case study we demonstrate its effectiveness by parsing biomedical text from the craft dataset. ","1237":"code-switching (cs), a ubiquitous phenomenon due to the ease of communication it offers in multilingual communities still remains an understudied problem in language processing. the primary reasons behind this are: (1) minimal efforts in leveraging large pretrained multilingual models, and (2) the lack of annotated data. the distinguishing case of low performance of multilingual models in cs is the intra-sentence mixing of languages leading to switch points. we first benchmark two sequence labeling tasks -- pos and ner on 4 different language pairs with a suite of pretrained models to identify the problems and select the best performing model, char-bert, among them (addressing (1)). we then propose a self training method to repurpose the existing pretrained models using a switch-point bias by leveraging unannotated data (addressing (2)). we finally demonstrate that our approach performs well on both tasks by reducing the gap between the switch point performance while retaining the overall performance on two distinct language pairs in both the tasks. our code is available here: https:\/\/github.com\/pc09\/emnlp2021-switch-point-biased-self-training. ","1238":"intent classification (ic) and slot labeling (sl) models, which form the basis of dialogue systems, often encounter noisy data in real-word environments. in this work, we investigate how robust ic\/sl models are to noisy data. we collect and publicly release a test-suite for seven common noise types found in production human-to-bot conversations (abbreviations, casing, misspellings, morphological variants, paraphrases, punctuation and synonyms). on this test-suite, we show that common noise types substantially degrade the ic accuracy and sl f1 performance of state-of-the-art bert-based ic\/sl models. by leveraging cross-noise robustness transfer -- training on one noise type to improve robustness on another noise type -- we design aggregate data-augmentation approaches that increase the model performance across all seven noise types by +10.8% for ic accuracy and +15 points for sl f1 on average. to the best of our knowledge, this is the first work to present a single ic\/sl model that is robust to a wide range of noise phenomena. ","1239":"sound event detection (sed) in machine listening entails identifying the different sounds in an audio file and identifying the start and end time of a particular sound event in the audio. sed finds use in various applications such as audio surveillance, speech recognition, and context-based indexing and retrieval of data in a multimedia database. however, in real-life scenarios, the audios from various sources are seldom devoid of any interfering noise or disturbance. in this paper, we test the performance of the you only hear once (yoho) algorithm on noisy audio data. inspired by the you only look once (yolo) algorithm in computer vision, the yoho algorithm can match the performance of the various state-of-the-art algorithms on datasets such as music speech detection dataset, tut sound event, and urban-sed datasets but at lower inference times. in this paper, we explore the performance of the yoho algorithm on the voice dataset containing audio files with noise at different sound-to-noise ratios (snr). yoho could outperform or at least match the best performing sed algorithms reported in the voice dataset paper and make inferences in less time. ","1240":"current nlp datasets targeting ambiguity can be solved by a native speaker with relative ease. we present cryptonite, a large-scale dataset based on cryptic crosswords, which is both linguistically complex and naturally sourced. each example in cryptonite is a cryptic clue, a short phrase or sentence with a misleading surface reading, whose solving requires disambiguating semantic, syntactic, and phonetic wordplays, as well as world knowledge. cryptic clues pose a challenge even for experienced solvers, though top-tier experts can solve them with almost 100% accuracy. cryptonite is a challenging task for current models; fine-tuning t5-large on 470k cryptic clues achieves only 7.6% accuracy, on par with the accuracy of a rule-based clue solver (8.6%). ","1241":"much of natural language processing is focused on leveraging large capacity language models, typically trained over single messages with a task of predicting one or more tokens. however, modeling human language at higher-levels of context (i.e., sequences of messages) is under-explored. in stance detection and other social media tasks where the goal is to predict an attribute of a message, we have contextual data that is loosely semantically connected by authorship. here, we introduce message-level transformer (melt) -- a hierarchical message-encoder pre-trained over twitter and applied to the task of stance prediction. we focus on stance prediction as a task benefiting from knowing the context of the message (i.e., the sequence of previous messages). the model is trained using a variant of masked-language modeling; where instead of predicting tokens, it seeks to generate an entire masked (aggregated) message vector via reconstruction loss. we find that applying this pre-trained masked message-level transformer to the downstream task of stance detection achieves f1 performance of 67%. ","1242":"ecological momentary assessments (emas) are an important psychological data source for measuring current cognitive states, affect, behavior, and environmental factors from participants in mobile health (mhealth) studies and treatment programs. non-response, in which participants fail to respond to ema prompts, is an endemic problem. the ability to accurately predict non-response could be utilized to improve ema delivery and develop compliance interventions. prior work has explored classical machine learning models for predicting non-response. however, as increasingly large ema datasets become available, there is the potential to leverage deep learning models that have been effective in other fields. recently, transformer models have shown state-of-the-art performance in nlp and other domains. this work is the first to explore the use of transformers for ema data analysis. we address three key questions in applying transformers to ema data: 1. input representation, 2. encoding temporal information, 3. utility of pre-training on improving downstream prediction task performance. the transformer model achieves a non-response prediction auc of 0.77 and is significantly better than classical ml and lstm-based deep learning models. we will make our a predictive model trained on a corpus of 40k ema samples freely-available to the research community, in order to facilitate the development of future transformer-based ema analysis works. ","1243":"the largest dataset of arabic speech mispronunciation detections in egyptian dialogues is introduced. the dataset is composed of annotated audio files representing the top 100 words that are most frequently used in the arabic language, pronounced by 100 egyptian children (aged between 2 and 8 years old). the dataset is collected and annotated on segmental pronunciation error detections by expert listeners. ","1244":"during pretraining, the pre-layernorm transformer suffers from a gradient magnitude mismatch: gradients at early layers are much larger than at later layers. these issues can be alleviated by our proposed normformer architecture, which adds three normalization operations to each layer: a layer norm after self attention, head-wise scaling of self-attention outputs, and a layer norm after the first fully connected layer. the extra operations incur negligible compute cost (+0.4% parameter increase), but improve pretraining perplexity and downstream task performance for both causal and masked language models ranging from 125 million to 2.7 billion parameters. for example, adding normformer on top of our strongest 1.3b parameter baseline can reach equal perplexity 24% faster, or converge 0.27 perplexity better in the same compute budget. this model reaches gpt3-large (1.3b) zero shot performance 60% faster. for masked language modeling, normformer improves fine-tuned glue performance by 1.9% on average. code to train normformer models is available in fairseq https:\/\/github.com\/pytorch\/fairseq\/tree\/main\/examples\/normformer . ","1245":"question answering (qa) models are well-known to exploit data bias, e.g., the language prior in visual qa and the position bias in reading comprehension. recent debiasing methods achieve good out-of-distribution (ood) generalizability with a considerable sacrifice of the in-distribution (id) performance. therefore, they are only applicable in domains where the test distribution is known in advance. in this paper, we present a novel debiasing method called introspective distillation (introd) to make the best of both worlds for qa. our key technical contribution is to blend the inductive bias of ood and id by introspecting whether a training sample fits in the factual id world or the counterfactual ood one. experiments on visual qa datasets vqa v2, vqa-cp, and reading comprehension dataset squad demonstrate that our proposed introd maintains the competitive ood performance compared to other debiasing methods, while sacrificing little or even achieving better id performance compared to the non-debiasing ones. ","1246":"this paper shows that a popular approach to the supervised embedding of documents for classification, namely, contrastive word mover's embedding, can be significantly enhanced by adding interpretability. this interpretability is achieved by incorporating a clustering promoting mechanism into the contrastive loss. on several public datasets, we show that our method improves significantly upon existing baselines while providing interpretation to the clusters via identifying a set of keywords that are the most representative of a particular class. our approach was motivated in part by the need to develop natural language processing (nlp) methods for the \\textit{novel problem of assessing student work for scientific writing and thinking} - a problem that is central to the area of (educational) learning sciences (ls). in this context, we show that our approach leads to a meaningful assessment of the student work related to lab reports from a biology class and can help ls researchers gain insights into student understanding and assess evidence of scientific thought processes. ","1247":"sentiment analysis is the most basic nlp task to determine the polarity of text data. there has been a significant amount of work in the area of multilingual text as well. still hate and offensive speech detection faces a challenge due to inadequate availability of data, especially for indian languages like hindi and marathi. in this work, we consider hate and offensive speech detection in hindi and marathi texts. the problem is formulated as a text classification task using the state of the art deep learning approaches. we explore different deep learning architectures like cnn, lstm, and variations of bert like multilingual bert, indicbert, and monolingual roberta. the basic models based on cnn and lstm are augmented with fast text word embeddings. we use the hasoc 2021 hindi and marathi hate speech datasets to compare these algorithms. the marathi dataset consists of binary labels and the hindi dataset consists of binary as well as more-fine grained labels. we show that the transformer-based models perform the best and even the basic models along with fasttext embeddings give a competitive performance. moreover, with normal hyper-parameter tuning, the basic models perform better than bert-based models on the fine-grained hindi dataset. ","1248":"hate speech detection within a cross-lingual setting represents a paramount area of interest for all medium and large-scale online platforms. failing to properly address this issue on a global scale has already led over time to morally questionable real-life events, human deaths, and the perpetuation of hate itself. this paper illustrates the capabilities of fine-tuned altered multi-lingual transformer models (mbert, xlm-roberta) regarding this crucial social data science task with cross-lingual training from english to french, vice-versa and each language on its own, including sections about iterative improvement and comparative error analysis. ","1249":"in the recent past, social media platforms have helped people in connecting and communicating to a wider audience. but this has also led to a drastic increase in cyberbullying. it is essential to detect and curb hate speech to keep the sanity of social media platforms. also, code mixed text containing more than one language is frequently used on these platforms. we, therefore, propose automated techniques for hate speech detection in code mixed text from scraped twitter. we specifically focus on code mixed english-hindi text and transformer-based approaches. while regular approaches analyze the text independently, we also make use of content text in the form of parent tweets. we try to evaluate the performances of multilingual bert and indic-bert in single-encoder and dual-encoder settings. the first approach is to concatenate the target text and context text using a separator token and get a single representation from the bert model. the second approach encodes the two texts independently using a dual bert encoder and the corresponding representations are averaged. we show that the dual-encoder approach using independent representations yields better performance. we also employ simple ensemble methods to further improve the performance. using these methods we report the best f1 score of 73.07% on the hasoc 2021 ichcl code mixed data set. ","1250":"phone-level pronunciation scoring is a challenging task, with performance far from that of human annotators. standard systems generate a score for each phone in a phrase using models trained for automatic speech recognition (asr) with native data only. better performance has been shown when using systems that are trained specifically for the task using non-native data. yet, such systems face the challenge that datasets labelled for this task are scarce and usually small. in this paper, we present a transfer learning-based approach that leverages a model trained for asr, adapting it for the task of pronunciation scoring. we analyze the effect of several design choices and compare the performance with a state-of-the-art goodness of pronunciation (gop) system. our final system is 20% better than the gop system on epadb, a database for pronunciation scoring research, for a cost function that prioritizes low rates of unnecessary corrections. ","1251":"for knowledge graph completion, two major types of prediction models exist: one based on graph embeddings, and the other based on relation path rule induction. they have different advantages and disadvantages. to take advantage of both types, hybrid models have been proposed recently. one of the hybrid models, uniker, alternately augments training data by relation path rules and trains an embedding model. despite its high prediction accuracy, it does not take full advantage of relation path rules, as it disregards low-confidence rules in order to maintain the quality of augmented data. to mitigate this limitation, we propose transductive data augmentation by relation path rules and confidence-based weighting of augmented data. the results and analysis show that our proposed method effectively improves the performance of the embedding model by augmenting data that include true answers or entities similar to them. ","1252":"span extraction, aiming to extract text spans (such as words or phrases) from plain texts, is a fundamental process in information extraction. recent works introduce the label knowledge to enhance the text representation by formalizing the span extraction task into a question answering problem (qa formalization), which achieves state-of-the-art performance. however, qa formalization does not fully exploit the label knowledge and suffers from low efficiency in training\/inference. to address those problems, we introduce a new paradigm to integrate label knowledge and further propose a novel model to explicitly and efficiently integrate label knowledge into text representations. specifically, it encodes texts and label annotations independently and then integrates label knowledge into text representation with an elaborate-designed semantics fusion module. we conduct extensive experiments on three typical span extraction tasks: flat ner, nested ner, and event detection. the empirical results show that 1) our method achieves state-of-the-art performance on four benchmarks, and 2) reduces training time and inference time by 76% and 77% on average, respectively, compared with the qa formalization paradigm. our code and data are available at https:\/\/github.com\/akeepers\/lear. ","1253":"this paper reports on the evaluation of deep learning (dl) transformer architecture models for named-entity recognition (ner) on ten low-resourced south african (sa) languages. in addition, these dl transformer models were compared to other neural network and machine learning (ml) ner models. the findings show that transformer models significantly improve performance when applying discrete fine-tuning parameters per language. furthermore, fine-tuned transformer models outperform other neural network and machine learning models with ner on the low-resourced sa languages. for example, the transformer models generated the highest f-scores for six of the ten sa languages, including the highest average f-score surpassing the conditional random fields ml model. additional research could evaluate the more recent transformer architecture models on other natural language processing tasks and applications, such as phrase chunking, machine translation, and part-of-speech tagging. ","1254":"we present an unsupervised method to detect english unergative and unaccusative verbs. these categories allow us to identify verbs participating in the causative-inchoative alternation without knowing the semantic roles of the verb. the method is based on the generation of intransitive sentence variants of candidate verbs and probing a language model. we obtained results on par with similar approaches, with the added benefit of not relying on annotated resources. ","1255":"token embeddings in multilingual bert (m-bert) contain both language and semantic information. we find that the representation of a language can be obtained by simply averaging the embeddings of the tokens of the language. given this language representation, we control the output languages of multilingual bert by manipulating the token embeddings, thus achieving unsupervised token translation. we further propose a computationally cheap but effective approach to improve the cross-lingual ability of m-bert based on this observation. ","1256":"evaluation metrics are a key ingredient for progress of text generation systems. in recent years, several bert-based evaluation metrics have been proposed (including bertscore, moverscore, bleurt, etc.) which correlate much better with human assessment of text generation quality than bleu or rouge, invented two decades ago. however, little is known what these metrics, which are based on black-box language model representations, actually capture (it is typically assumed they model semantic similarity). in this work, we use a simple regression based global explainability technique to disentangle metric scores along linguistic factors, including semantics, syntax, morphology, and lexical overlap. we show that the different metrics capture all aspects to some degree, but that they are all substantially sensitive to lexical overlap, just like bleu and rouge. this exposes limitations of these novelly proposed metrics, which we also highlight in an adversarial test scenario. ","1257":"in this paper, we study the possibility of almost unsupervised multiple choices question answering (mcqa). starting from very basic knowledge, mcqa model knows that some choices have higher probabilities of being correct than the others. the information, though very noisy, guides the training of an mcqa model. the proposed method is shown to outperform the baseline approaches on race and even comparable with some supervised learning approaches on mc500. ","1258":"building of data for quality estimation (qe) training is expensive and requires significant human labor. in this study, we focus on a data-centric approach while performing qe, and subsequently propose a fully automatic pseudo-qe dataset generation tool that generates qe datasets by receiving only monolingual or parallel corpus as the input. consequently, the qe performance is enhanced either by data augmentation or by encouraging multiple language pairs to exploit the applicability of qe. further, we intend to publicly release this user friendly qe dataset generation tool as we believe this tool provides a new, inexpensive method to the community for developing qe datasets. ","1259":"currently, the most widespread neural network architecture for training language models is the so called bert which led to improvements in various natural language processing (nlp) tasks. in general, the larger the number of parameters in a bert model, the better the results obtained in these nlp tasks. unfortunately, the memory consumption and the training duration drastically increases with the size of these models. in this article, we investigate various training techniques of smaller bert models: we combine different methods from other bert variants like albert, roberta, and relative positional encoding. in addition, we propose two new fine-tuning modifications leading to better performance: class-start-end tagging and a modified form of linear chain conditional random fields. furthermore, we introduce whole-word attention which reduces berts memory usage and leads to a small increase in performance compared to classical multi-head-attention. we evaluate these techniques on five public german named entity recognition (ner) tasks of which two are introduced by this article. ","1260":"aspect sentiment triplet extraction (aste) aims to extract triplets from a sentence, including target entities, associated sentiment polarities, and opinion spans which rationalize the polarities. existing methods are short on building correlation between target-opinion pairs, and neglect the mutual interference among different sentiment triplets. to address these issues, we utilize a two-stage framework to enhance the correlation between targets and opinions: at stage one, we extract targets and opinions through sequence tagging; then we append a group of artificial tags named perceivable pair, which indicate the span of a specific target-opinion tuple, to the input sentence to obtain closer correlated target-opinion pair representation. meanwhile, we reduce the negative interference between triplets by restricting tokens' attention field. finally, the polarity is identified according to the representation of the perceivable pair. we conduct experiments on four datasets, and the experimental results show the effectiveness of our model. ","1261":"query graph building aims to build correct executable sparql over the knowledge graph for answering natural language questions. although recent approaches perform well by nn-based query graph ranking, more complex questions bring three new challenges: complicated sparql syntax, huge search space for ranking, and noisy query graphs with local ambiguity. this paper handles these challenges. initially, we regard common complicated sparql syntax as the sub-graphs comprising of vertices and edges and propose a new unified query graph grammar to adapt them. subsequently, we propose a new two-stage approach to build query graphs. in the first stage, the top-$k$ related instances (entities, relations, etc.) are collected by simple strategies, as the candidate instances. in the second stage, a graph generation model performs hierarchical generation. it first outlines a graph structure whose vertices and edges are empty slots, and then fills the appropriate instances into the slots, thereby completing the query graph. our approach decomposes the unbearable search space of entire query graphs into affordable sub-spaces of operations, meanwhile, leverages the global structural information to eliminate local ambiguity. the experimental results demonstrate that our approach greatly improves state-of-the-art on the hardest kgqa benchmarks and has an excellent performance on complex questions. ","1262":"the amount of information stored in the form of documents on the internet has been increasing rapidly. thus it has become a necessity to organize and maintain these documents in an optimum manner. text classification algorithms study the complex relationships between words in a text and try to interpret the semantics of the document. these algorithms have evolved significantly in the past few years. there has been a lot of progress from simple machine learning algorithms to transformer-based architectures. however, existing literature has analyzed different approaches on different data sets thus making it difficult to compare the performance of machine learning algorithms. in this work, we revisit long document classification using standard machine learning approaches. we benchmark approaches ranging from simple naive bayes to complex bert on six standard text classification datasets. we present an exhaustive comparison of different algorithms on a range of long document datasets. we re-iterate that long document classification is a simpler task and even basic algorithms perform competitively with bert-based approaches on most of the datasets. the bert-based models perform consistently well on all the datasets and can be blindly used for the document classification task when the computations cost is not a concern. in the shallow model's category, we suggest the usage of raw bilstm + max architecture which performs decently across all the datasets. even simpler glove + attention bag of words model can be utilized for simpler use cases. the importance of using sophisticated models is clearly visible in the imdb sentiment dataset which is a comparatively harder task. ","1263":"domain adaptation of embedding models, updating a generic embedding to the language of a specific domain, is a proven technique for domains that have insufficient data to train an effective model from scratch. chemistry publications is one such domain, where scientific jargon and overloaded terminology inhibit the performance of a general language model. the recent spherical embedding model (jose) proposed in arxiv:1911.01196 jointly learns word and document embeddings during training on the multi-dimensional unit sphere, which performs well for document classification and word correlation tasks. but, we show a non-convergence caused by global rotations during its training prevents it from domain adaptation. in this work, we develop methods to counter the global rotation of the embedding space and propose strategies to update words and documents during domain specific training. two new document classification data-sets are collated from general and chemistry scientific journals to compare the proposed update training strategies with benchmark models. we show that our strategies are able to reduce the performance cost of domain adaptation to a level similar to word2vec. ","1264":"unsupervised domain adaptation (uda) with pre-trained language models (prlm) has achieved promising results since these pre-trained models embed generic knowledge learned from various domains. however, fine-tuning all the parameters of the prlm on a small domain-specific corpus distort the learned generic knowledge, and it is also expensive to deployment a whole fine-tuned prlm for each domain. this paper explores an adapter-based fine-tuning approach for unsupervised domain adaptation. specifically, several trainable adapter modules are inserted in a prlm, and the embedded generic knowledge is preserved by fixing the parameters of the original prlm at fine-tuning. a domain-fusion scheme is introduced to train these adapters using a mix-domain corpus to better capture transferable features. elaborated experiments on two benchmark datasets are carried out, and the results demonstrate that our approach is effective with different tasks, dataset sizes, and domain similarities. ","1265":"as an essential component of human cognition, cause-effect relations appear frequently in text, and curating cause-effect relations from text helps in building causal networks for predictive tasks. existing causality extraction techniques include knowledge-based, statistical machine learning(ml)-based, and deep learning-based approaches. each method has its advantages and weaknesses. for example, knowledge-based methods are understandable but require extensive manual domain knowledge and have poor cross-domain applicability. statistical machine learning methods are more automated because of natural language processing (nlp) toolkits. however, feature engineering is labor-intensive, and toolkits may lead to error propagation. in the past few years, deep learning techniques attract substantial attention from nlp researchers because of its' powerful representation learning ability and the rapid increase in computational resources. their limitations include high computational costs and a lack of adequate annotated training data. in this paper, we conduct a comprehensive survey of causality extraction. we initially introduce primary forms existing in the causality extraction: explicit intra-sentential causality, implicit causality, and inter-sentential causality. next, we list benchmark datasets and modeling assessment methods for causal relation extraction. then, we present a structured overview of the three techniques with their representative systems. lastly, we highlight existing open challenges with their potential directions. ","1266":"in this research, we present our work participation for the drugprot task of biocreative vii challenge. drug-target interactions (dtis) are critical for drug discovery and repurposing, which are often manually extracted from the experimental articles. there are >32m biomedical articles on pubmed and manually extracting dtis from such a huge knowledge base is challenging. to solve this issue, we provide a solution for track 1, which aims to extract 10 types of interactions between drug and protein entities. we applied an ensemble classifier model that combines biomed-roberta, a state of art language model, with convolutional neural networks (cnn) to extract these relations. despite the class imbalances in the biocreative vii drugprot test corpus, our model achieves a good performance compared to the average of other submissions in the challenge, with the micro f1 score of 55.67% (and 63% on biocreative vi chemprot test corpus). the results show the potential of deep learning in extracting various types of dtis. ","1267":"language models (lms) for text data have been studied extensively for their usefulness in language generation and other downstream tasks. however, language modelling purely in the speech domain is still a relatively unexplored topic, with traditional speech lms often depending on auxiliary text lms for learning distributional aspects of the language. for the english language, these lms treat words as atomic units, which presents inherent challenges to language modelling in the speech domain. in this paper, we propose a novel lstm-based generative speech lm that is inspired by the cbow model and built on linguistic units including syllables and phonemes. this offers better acoustic consistency across utterances in the dataset, as opposed to single melspectrogram frames, or whole words. with a limited dataset, orders of magnitude smaller than that required by contemporary generative models, our model closely approximates babbling speech. we show the effect of training with auxiliary text lms, multitask learning objectives, and auxiliary articulatory features. through our experiments, we also highlight some well known, but poorly documented challenges in training generative speech lms, including the mismatch between the supervised learning objective with which these models are trained such as mean squared error (mse), and the true objective, which is speech quality. our experiments provide an early indication that while validation loss and mel cepstral distortion (mcd) are not strongly correlated with generated speech quality, traditional text language modelling metrics like perplexity and next-token-prediction accuracy might be. ","1268":"there is a key demand to automatically generate code for small tasks for developers. websites such as stackoverflow provide a simplistic way by offering solutions in small snippets which provide a complete answer to whatever task question the developer wants to code. natural language processing and particularly question-answering systems are very helpful in resolving and working on these tasks. in this paper, we develop a two-fold deep learning model: seq2seq and a binary classifier that takes in the intent (which is in natural language) and code snippets in python. we train both the intent and the code utterances in the seq2seq model, where we decided to compare the effect of the hidden layer embedding from the encoder for representing the intent and similarly, using the decoder's hidden layer embeddings for the code sequence. then we combine both these embeddings and then train a simple binary neural network classifier model for predicting if the intent is correctly answered by the predicted code sequence from the seq2seq model. we find that the hidden state layer's embeddings perform slightly better than regular standard embeddings from a constructed vocabulary. we experimented with our tests on the conala dataset in addition to the staqc database consisting of simple task-code snippet-based pairs. we empirically establish that using additional pre-trained embeddings for code snippets in python is less context-based in comparison to using hidden state context vectors from seq2seq models. ","1269":"improving user experience of a dialogue system often requires intensive developer effort to read conversation logs, run statistical analyses, and intuit the relative importance of system shortcomings. this paper presents a novel approach to automated analysis of conversation logs that learns the relationship between user-system interactions and overall dialogue quality. unlike prior work on utterance-level quality prediction, our approach learns the impact of each interaction from the overall user rating without utterance-level annotation, allowing resultant model conclusions to be derived on the basis of empirical evidence and at low cost. our model identifies interactions that have a strong correlation with the overall dialogue quality in a chatbot setting. experiments show that the automated analysis from our model agrees with expert judgments, making this work the first to show that such weakly-supervised learning of utterance-level quality prediction is highly achievable. ","1270":"we present a chatbot implementing a novel dialogue management approach based on logical inference. instead of framing conversation a sequence of response generation tasks, we model conversation as a collaborative inference process in which speakers share information to synthesize new knowledge in real time. our chatbot pipeline accomplishes this modelling in three broad stages. the first stage translates user utterances into a symbolic predicate representation. the second stage then uses this structured representation in conjunction with a larger knowledge base to synthesize new predicates using efficient graph matching. in the third and final stage, our bot selects a small subset of predicates and translates them into an english response. this approach lends itself to understanding latent semantics of user inputs, flexible initiative taking, and responses that are novel and coherent with the dialogue context. ","1271":"in this paper, we combine two independent detection methods for identifying fake news: the algorithm vago uses semantic rules combined with nlp techniques to measure vagueness and subjectivity in texts, while the classifier fake-clf relies on convolutional neural network classification and supervised deep learning to classify texts as biased or legitimate. we compare the results of the two methods on four corpora. we find a positive correlation between the vagueness and subjectivity measures obtained by vago, and the classification of text as biased by fake-clf. the comparison yields mutual benefits: vago helps explain the results of fake-clf. conversely fake-clf helps us corroborate and expand vago's database. the use of two complementary techniques (rule-based vs data-driven) proves a fruitful approach for the challenging problem of identifying fake news. ","1272":"distributed learning paradigms such as federated learning often involve transmission of model updates, or gradients, over a network, thereby avoiding transmission of private data. however, it is possible for sensitive information about the training data to be revealed from such gradients. prior works have demonstrated that labels can be revealed analytically from the last layer of certain models (e.g., resnet), or they can be reconstructed jointly with model inputs by using gradients matching [zhu et al'19] with additional knowledge about the current state of the model. in this work, we propose a method to discover the set of labels of training samples from only the gradient of the last layer and the id to label mapping. our method is applicable to a wide variety of model architectures across multiple domains. we demonstrate the effectiveness of our method for model training in two domains - image classification, and automatic speech recognition. furthermore, we show that existing reconstruction techniques improve their efficacy when used in conjunction with our method. conversely, we demonstrate that gradient quantization and sparsification can significantly reduce the success of the attack. ","1273":"estimating the quality of machine translation systems has been an ongoing challenge for researchers in this field. many previous attempts at using round-trip translation as a measure of quality have failed, and there is much disagreement as to whether it can be a viable method of quality estimation. in this paper, we revisit round-trip translation, proposing a system which aims to solve the previous pitfalls found with the approach. our method makes use of recent advances in language representation learning to more accurately gauge the similarity between the original and round-trip translated sentences. experiments show that while our approach does not reach the performance of current state of the art methods, it may still be an effective approach for some language pairs. ","1274":"in this paper, we explore the ability of sequence to sequence models to perform cross-domain reasoning. towards this, we present a prompt-template-filling approach to enable sequence to sequence models to perform cross-domain reasoning. we also present a case-study with commonsense and health and well-being domains, where we study how prompt-template-filling enables pretrained sequence to sequence models across domains. our experiments across several pretrained encoder-decoder models show that cross-domain reasoning is challenging for current models. we also show an in-depth error analysis and avenues for future research for reasoning across domains ","1275":"discrete adversarial attacks are symbolic perturbations to a language input that preserve the output label but lead to a prediction error. while such attacks have been extensively explored for the purpose of evaluating model robustness, their utility for improving robustness has been limited to offline augmentation only. concretely, given a trained model, attacks are used to generate perturbed (adversarial) examples, and the model is re-trained exactly once. in this work, we address this gap and leverage discrete attacks for online augmentation, where adversarial examples are generated at every training step, adapting to the changing nature of the model. we propose (i) a new discrete attack, based on best-first search, and (ii) random sampling attacks that unlike prior work are not based on expensive search-based procedures. surprisingly, we find that random sampling leads to impressive gains in robustness, outperforming the commonly-used offline augmentation, while leading to a speedup at training time of ~10x. furthermore, online augmentation with search-based attacks justifies the higher training cost, significantly improving robustness on three datasets. last, we show that our new attack substantially improves robustness compared to prior methods. ","1276":"causality detection draws plenty of attention in the field of natural language processing and linguistics research. it has essential applications in information retrieval, event prediction, question answering, financial analysis, and market research. in this study, we explore several methods to identify and extract cause-effect pairs in financial documents using transformers. for this purpose, we propose an approach that combines pos tagging with the bio scheme, which can be integrated with modern transformer models to address this challenge of identifying causality in a given text. our best methodology achieves an f1-score of 0.9551, and an exact match score of 0.8777 on the blind test in the fincausal-2021 shared task at the fincausal 2021 workshop. ","1277":"temporal moment localization (tml) in untrimmed videos is a challenging task in the field of multimedia, which aims at localizing the start and end points of the activity in the video, described by a sentence query. existing methods mainly focus on mining the correlation between video and sentence representations or investigating the fusion manner of the two modalities. these works mainly understand the video and sentence coarsely, ignoring the fact that a sentence can be understood from various semantics, and the dominant words affecting the moment localization in the semantics are the action and object reference. toward this end, we propose a hierarchical deep residual reasoning (hdrr) model, which decomposes the video and sentence into multi-level representations with different semantics to achieve a finer-grained localization. furthermore, considering that videos with different resolution and sentences with different length have different difficulty in understanding, we design the simple yet effective res-bigrus for feature fusion, which is able to grasp the useful information in a self-adapting manner. extensive experiments conducted on charades-sta and activitynet-captions datasets demonstrate the superiority of our hdrr model compared with other state-of-the-art methods. ","1278":"although speech recognition has become a widespread technology, inferring emotion from speech signals still remains a challenge. to address this problem, this paper proposes a quaternion convolutional neural network (qcnn) based speech emotion recognition (ser) model in which mel-spectrogram features of speech signals are encoded in an rgb quaternion domain. we show that our qcnn based ser model outperforms other real-valued methods in the ryerson audio-visual database of emotional speech and song (ravdess, 8-classes) dataset, achieving, to the best of our knowledge, state-of-the-art results. the qcnn also achieves comparable results with the state-of-the-art methods in the interactive emotional dyadic motion capture (iemocap 4-classes) and berlin emo-db (7-classes) datasets. specifically, the model achieves an accuracy of 77.87\\%, 70.46\\%, and 88.78\\% for the ravdess, iemocap, and emo-db datasets, respectively. in addition, our results show that the quaternion unit structure is better able to encode internal dependencies to reduce its model size significantly compared to other methods. ","1279":"spoken language understanding (slu) systems translate voice input commands to semantics which are encoded as an intent and pairs of slot tags and values. most current slu systems deploy a cascade of two neural models where the first one maps the input audio to a transcript (asr) and the second predicts the intent and slots from the transcript (nlu). in this paper, we introduce fans, a new end-to-end slu model that fuses an asr audio encoder to a multi-task nlu decoder to infer the intent, slot tags, and slot values directly from a given input audio, obviating the need for transcription. fans consists of a shared audio encoder and three decoders, two of which are seq-to-seq decoders that predict non null slot tags and slot values in parallel and in an auto-regressive manner. fans neural encoder and decoders architectures are flexible which allows us to leverage different combinations of lstm, self-attention, and attenders. our experiments show compared to the state-of-the-art end-to-end slu models, fans reduces icer and irer errors relatively by 30 % and 7 %, respectively, when tested on an in-house slu dataset and by 0.86 % and 2 % absolute when tested on a public slu dataset. ","1280":"subtle and overt racism is still present both in physical and online communities today and has impacted many lives in different segments of the society. in this short piece of work, we present how we're tackling this societal issue with natural language processing. we are releasing biascorp, a dataset containing 139,090 comments and news segment from three specific sources - fox news, breitbartnews and youtube. the first batch (45,000 manually annotated) is ready for publication. we are currently in the final phase of manually labeling the remaining dataset using amazon mechanical turk. bert has been used widely in several downstream tasks. in this work, we present hbert, where we modify certain layers of the pretrained bert model with the new hopfield layer. hbert generalizes well across different distributions with the added advantage of a reduced model complexity. we are also releasing a javascript library and a chrome extension application, to help developers make use of our trained model in web applications (say chat application) and for users to identify and report racially biased contents on the web respectively. ","1281":"research on adversarial attacks are becoming widely popular in the recent years. one of the unexplored areas where prior research is lacking is the effect of adversarial attacks on code-mixed data. therefore, in the present work, we have explained the first generalized framework on text perturbation to attack code-mixed classification models in a black-box setting. we rely on various perturbation techniques that preserve the semantic structures of the sentences and also obscure the attacks from the perception of a human user. the present methodology leverages the importance of a token to decide where to attack by employing various perturbation strategies. we test our strategies on various sentiment classification models trained on bengali-english and hindi-english code-mixed datasets, and reduce their f1-scores by nearly 51 % and 53 % respectively, which can be further reduced if a larger number of tokens are perturbed in a given sentence. ","1282":"in this paper, we introduce empbot: an end-to-end empathetic chatbot. empathetic conversational agents should not only understand what is being discussed, but also acknowledge the implied feelings of the conversation partner and respond appropriately. to this end, we propose a method based on a transformer pretrained language model (t5). specifically, during finetuning we propose to use three objectives: response language modeling, sentiment understanding, and empathy forcing. the first objective is crucial for generating relevant and coherent responses, while the next ones are significant for acknowledging the sentimental state of the conversational partner and for favoring empathetic responses. we evaluate our model on the empatheticdialogues dataset using both automated metrics and human evaluation. the inclusion of the sentiment understanding and empathy forcing auxiliary losses favor empathetic responses, as human evaluation results indicate, comparing with the current state-of-the-art. ","1283":"the natural language processing task of determining \"who did what to whom\" is called semantic role labeling. for english, recent methods based on transformer models have allowed for major improvements in this task over the previous state of the art. however, for low resource languages, like portuguese, currently available semantic role labeling models are hindered by scarce training data. in this paper, we explore a model architecture with only a pre-trained transformer-based model, a linear layer, softmax and viterbi decoding. we substantially improve the state-of-the-art performance in portuguese by over 15 f1. additionally, we improve semantic role labeling results in portuguese corpora by exploiting cross-lingual transfer learning using multilingual pre-trained models, and transfer learning from dependency parsing in portuguese, evaluating the various proposed approaches empirically. ","1284":"identifying emotions from text is crucial for a variety of real world tasks. we consider the two largest now-available corpora for emotion classification: goemotions, with 58k messages labelled by readers, and vent, with 33m writer-labelled messages. we design a benchmark and evaluate several feature spaces and learning algorithms, including two simple yet novel models on top of bert that outperform previous strong baselines on goemotions. through an experiment with human participants, we also analyze the differences between how writers express emotions and how readers perceive them. our results suggest that emotions expressed by writers are harder to identify than emotions that readers perceive. we share a public web interface for researchers to explore our models. ","1285":"prerequisite chain learning helps people acquire new knowledge efficiently. while people may quickly determine learning paths over concepts in a domain, finding such paths in other domains can be challenging. we introduce domain-adversarial variational graph autoencoders (davgae) to solve this cross-domain prerequisite chain learning task efficiently. our novel model consists of a variational graph autoencoder (vgae) and a domain discriminator. the vgae is trained to predict concept relations through link prediction, while the domain discriminator takes both source and target domain data as input and is trained to predict domain labels. most importantly, this method only needs simple homogeneous graphs as input, compared with the current state-of-the-art model. we evaluate our model on the lecturebankcd dataset, and results show that our model outperforms recent graph-based benchmarks while using only 1\/10 of graph scale and 1\/3 computation time. ","1286":"logical reasoning over knowledge graphs (kgs) is a fundamental technique that can provide efficient querying mechanism over large and incomplete databases. current approaches employ spatial geometries such as boxes to learn query representations that encompass the answer entities and model the logical operations of projection and intersection. however, their geometry is restrictive and leads to non-smooth strict boundaries, which further results in ambiguous answer entities. furthermore, previous works propose transformation tricks to handle unions which results in non-closure and, thus, cannot be chained in a stream. in this paper, we propose a probabilistic entity representation model (perm) to encode entities as a multivariate gaussian density with mean and covariance parameters to capture its semantic position and smooth decision boundary, respectively. additionally, we also define the closed logical operations of projection, intersection, and union that can be aggregated using an end-to-end objective function. on the logical query reasoning problem, we demonstrate that the proposed perm significantly outperforms the state-of-the-art methods on various public benchmark kg datasets on standard evaluation metrics. we also evaluate perm's competence on a covid-19 drug-repurposing case study and show that our proposed work is able to recommend drugs with substantially better f1 than current methods. finally, we demonstrate the working of our perm's query answering process through a low-dimensional visualization of the gaussian representations. ","1287":"finding the appropriate words to convey concepts (i.e., lexical access) is essential for effective communication. reverse dictionaries fulfill this need by helping individuals to find the word(s) which could relate to a specific concept or idea. to the best of our knowledge, this resource has not been available for the persian language. in this paper, we compare four different architectures for implementing a persian reverse dictionary (predict).   we evaluate our models using (phrase,word) tuples extracted from the only persian dictionaries available online, namely amid, moein, and dehkhoda where the phrase describes the word. given the phrase, a model suggests the most relevant word(s) in terms of the ability to convey the concept. the model is considered to perform well if the correct word is one of its top suggestions.   our experiments show that a model consisting of long short-term memory (lstm) units enhanced by an additive attention mechanism is enough to produce suggestions comparable to (or in some cases better than) the word in the original dictionary. the study also reveals that the model sometimes produces the synonyms of the word as its output which led us to introduce a new metric for the evaluation of reverse dictionaries called synonym accuracy accounting for the percentage of times the event of producing the word or a synonym of it occurs. the assessment of the best model using this new metric also indicates that at least 62% of the times, it produces an accurate result within the top 100 suggestions. ","1288":"the use of phonological features (pfs) potentially allows language-specific phones to remain linked in training, which is highly desirable for information sharing for multilingual and crosslingual speech recognition methods for low-resourced languages. a drawback suffered by previous methods in using phonological features is that the acoustic-to-pf extraction in a bottom-up way is itself difficult. in this paper, we propose to join phonology driven phone embedding (top-down) and deep neural network (dnn) based acoustic feature extraction (bottom-up) to calculate phone probabilities. the new method is called joinap (joining of acoustics and phonology). remarkably, no inversion from acoustics to phonological features is required for speech recognition. for each phone in the ipa (international phonetic alphabet) table, we encode its phonological features to a phonological-vector, and then apply linear or nonlinear transformation of the phonological-vector to obtain the phone embedding. a series of multilingual and crosslingual (both zero-shot and few-shot) speech recognition experiments are conducted on the commonvoice dataset (german, french, spanish and italian) and the aishll-1 dataset (mandarin), and demonstrate the superiority of joinap with nonlinear phone embeddings over both joinap with linear phone embeddings and the traditional method with flat phone embeddings. ","1289":"pre-training and then fine-tuning large language models is commonly used to achieve state-of-the-art performance in natural language processing (nlp) tasks. however, most pre-trained models suffer from low inference speed. deploying such large models to applications with latency constraints is challenging. in this work, we focus on accelerating the inference via conditional computations. to achieve this, we propose a novel idea, magic pyramid (mp), to reduce both width-wise and depth-wise computation via token pruning and early exiting for transformer-based models, particularly bert. the former manages to save the computation via removing non-salient tokens, while the latter can fulfill the computation reduction by terminating the inference early before reaching the final layer, if the exiting condition is met. our empirical studies demonstrate that compared to previous state of arts, mp is not only able to achieve a speed-adjustable inference but also to surpass token pruning and early exiting by reducing up to 70% giga floating point operations (gflops) with less than 0.5% accuracy drop. token pruning and early exiting express distinctive preferences to sequences with different lengths. however, mp is capable of achieving an average of 8.06x speedup on two popular text classification tasks, regardless of the sizes of the inputs. ","1290":"building agents capable of understanding language instructions is critical to effective and robust human-ai collaboration. recent work focuses on training these agents via reinforcement learning in environments with synthetic language; however, instructions often define long-horizon, sparse-reward tasks, and learning policies requires many episodes of experience. we introduce ella: exploration through learned language abstraction, a reward shaping approach geared towards boosting sample efficiency in sparse reward environments by correlating high-level instructions with simpler low-level constituents. ella has two key elements: 1) a termination classifier that identifies when agents complete low-level instructions, and 2) a relevance classifier that correlates low-level instructions with success on high-level tasks. we learn the termination classifier offline from pairs of instructions and terminal states. notably, in departure from prior work in language and abstraction, we learn the relevance classifier online, without relying on an explicit decomposition of high-level instructions to low-level instructions. on a suite of complex babyai environments with varying instruction complexities and reward sparsity, ella shows gains in sample efficiency relative to language-based shaping and traditional rl methods. ","1291":"pre-trained general-purpose language models have been a dominating component in enabling real-world natural language processing (nlp) applications. however, a pre-trained model with backdoor can be a severe threat to the applications. most existing backdoor attacks in nlp are conducted in the fine-tuning phase by introducing malicious triggers in the targeted class, thus relying greatly on the prior knowledge of the fine-tuning task. in this paper, we propose a new approach to map the inputs containing triggers directly to a predefined output representation of the pre-trained nlp models, e.g., a predefined output representation for the classification token in bert, instead of a target label. it can thus introduce backdoor to a wide range of downstream tasks without any prior knowledge. additionally, in light of the unique properties of triggers in nlp, we propose two new metrics to measure the performance of backdoor attacks in terms of both effectiveness and stealthiness. our experiments with various types of triggers show that our method is widely applicable to different fine-tuning tasks (classification and named entity recognition) and to different models (such as bert, xlnet, bart), which poses a severe threat. furthermore, by collaborating with the popular online model repository hugging face, the threat brought by our method has been confirmed. finally, we analyze the factors that may affect the attack performance and share insights on the causes of the success of our backdoor attack. ","1292":"generative commonsense reasoning is the capability of a language model to generate a sentence with a given concept-set that is based on commonsense knowledge. however, generative language models still struggle to provide outputs, and the training set does not contain patterns that are sufficient for generative commonsense reasoning. in this paper, we propose a data-centric method that uses automatic knowledge augmentation to extend commonsense knowledge using a machine knowledge generator. this method can generate semi-golden sentences that improve the generative commonsense reasoning of a language model without architecture modifications. furthermore, this approach is a model-agnostic method and does not require human effort for data construction. ","1293":"this paper proposes a tool for efficiently constructing high-quality parallel corpora with minimizing human labor and making this tool publicly available. our proposed construction process is based on neural machine translation (nmt) to allow for it to not only coexist with human translation, but also improve its efficiency by combining data quality control with human translation in a data-centric approach. ","1294":"dialogue-based relation extraction (diare) aims to detect the structural information from unstructured utterances in dialogues. existing relation extraction models may be unsatisfactory under such a conversational setting, due to the entangled logic and information sparsity issues in utterances involving multiple speakers. to this end, we introduce sols, a novel model which can explicitly induce speaker-oriented latent structures for better diare. specifically, we learn latent structures to capture the relationships among tokens beyond the utterance boundaries, alleviating the entangled logic issue. during the learning process, our speaker-specific regularization method progressively highlights speaker-related key clues and erases the irrelevant ones, alleviating the information sparsity issue. experiments on three public datasets demonstrate the effectiveness of our proposed approach. ","1295":"short text classification is a fundamental task in natural language processing. it is hard due to the lack of context information and labeled data in practice. in this paper, we propose a new method called shine, which is based on graph neural network (gnn), for short text classification. first, we model the short text dataset as a hierarchical heterogeneous graph consisting of word-level component graphs which introduce more semantic and syntactic information. then, we dynamically learn a short document graph that facilitates effective label propagation among similar short texts. thus, compared with existing gnn-based methods, shine can better exploit interactions between nodes of the same types and capture similarities between short texts. extensive experiments on various benchmark short text datasets show that shine consistently outperforms state-of-the-art methods, especially with fewer labels. ","1296":"gigantic pre-trained models have become central to natural language processing (nlp), serving as the starting point for fine-tuning towards a range of downstream tasks. however, two pain points persist for this paradigm: (a) as the pre-trained models grow bigger (e.g., 175b parameters for gpt-3), even the fine-tuning process can be time-consuming and computationally expensive; (b) the fine-tuned model has the same size as its starting point by default, which is neither sensible due to its more specialized functionality, nor practical since many fine-tuned models will be deployed in resource-constrained environments. to address these pain points, we propose a framework for resource- and parameter-efficient fine-tuning by leveraging the sparsity prior in both weight updates and the final model weights. our proposed framework, dubbed dually sparsity-embedded efficient tuning (dsee), aims to achieve two key objectives: (i) parameter efficient fine-tuning - by enforcing sparsity-aware weight updates on top of the pre-trained weights; and (ii) resource-efficient inference - by encouraging a sparse weight structure towards the final fine-tuned model. we leverage sparsity in these two directions by exploiting both unstructured and structured sparse patterns in pre-trained language models via magnitude-based pruning and $\\ell_1$ sparse regularization. extensive experiments and in-depth investigations, with diverse network backbones (i.e., bert, gpt-2, and deberta) on dozens of datasets, consistently demonstrate highly impressive parameter-\/training-\/inference-efficiency, while maintaining competitive downstream transfer performance. for instance, our dsee-bert obtains about $35\\%$ inference flops savings with <1% trainable parameters and comparable performance to conventional fine-tuning. codes are available in https:\/\/github.com\/vita-group\/dsee. ","1297":"transformers are expensive to train due to the quadratic time and space complexity in the self-attention mechanism. on the other hand, although kernel machines suffer from the same computation bottleneck in pairwise dot products, several approximation schemes have been successfully incorporated to considerably reduce their computational cost without sacrificing too much accuracy. in this work, we leverage the computation methods for kernel machines to alleviate the high computational cost and introduce skyformer, which replaces the softmax structure with a gaussian kernel to stabilize the model training and adapts the nystr\\\"om method to a non-positive semidefinite matrix to accelerate the computation. we further conduct theoretical analysis by showing that the matrix approximation error of our proposed method is small in the spectral norm. experiments on long range arena benchmark show that the proposed method is sufficient in getting comparable or even better performance than the full self-attention while requiring fewer computation resources. ","1298":"in this paper, we consider the task of spotting spoken keywords in silent video sequences -- also known as visual keyword spotting. to this end, we investigate transformer-based models that ingest two streams, a visual encoding of the video and a phonetic encoding of the keyword, and output the temporal location of the keyword if present. our contributions are as follows: (1) we propose a novel architecture, the transpotter, that uses full cross-modal attention between the visual and phonetic streams; (2) we show through extensive evaluations that our model outperforms the prior state-of-the-art visual keyword spotting and lip reading methods on the challenging lrw, lrs2, lrs3 datasets by a large margin; (3) we demonstrate the ability of our model to spot words under the extreme conditions of isolated mouthings in sign language videos. ","1299":"unsupervised constituency parsing has been explored much but is still far from being solved. conventional unsupervised constituency parser is only able to capture the unlabeled structure of sentences. towards unsupervised full constituency parsing, we propose an unsupervised and training-free labeling procedure by exploiting the property of a recently introduced metric, neighboring distribution divergence (ndd), which evaluates semantic similarity between sentences before and after editions. for implementation, we develop ndd into dual pos-ndd (dp-ndd) and build \"molds\" to detect constituents and their labels in sentences. we show that dp-ndd not only labels constituents precisely but also inducts more accurate unlabeled constituency trees than all previous unsupervised methods with simpler rules. with two frameworks for labeled constituency trees inference, we set both the new state-of-the-art for unlabeled f1 and strong baselines for labeled f1. in contrast with the conventional predicting-and-evaluating scenario, our method acts as an plausible example to inversely apply evaluating metrics for prediction. ","1300":"this document presents in detail the work done for the sexism detection task at exist2021 workshop. our methodology is built on ensembles of transformer-based models which are trained on different background and corpora and fine-tuned on the provided dataset from the exist2021 workshop. we report accuracy of 0.767 for the binary classification task (task1), and f1 score 0.766, and for the multi-class task (task2) accuracy 0.623 and f1-score 0.535. ","1301":"for their attractiveness, comprehensiveness and dynamic coverage of relevant topics, community-based question answering sites such as stack overflow heavily rely on the engagement of their communities: questions on new technologies, technology features as well as technology versions come up and have to be answered as technology evolves (and as community members gather experience with it). at the same time, other questions cease in importance over time, finally becoming irrelevant to users. beyond filtering low-quality questions, \"forgetting\" questions, which have become redundant, is an important step for keeping the stack overflow content concise and useful. in this work, we study this managed forgetting task for stack overflow. our work is based on data from more than a decade (2008 - 2019) - covering 18.1m questions, that are made publicly available by the site itself. for establishing a deeper understanding, we first analyze and characterize the set of questions about to be forgotten, i.e., questions that get a considerable number of views in the current period but become unattractive in the near future. subsequently, we examine the capability of a wide range of features in predicting such forgotten questions in different categories. we find some categories in which those questions are more predictable. we also discover that the text-based features are surprisingly not helpful in this prediction task, while the meta information is much more predictive. ","1302":"current dense text retrieval models face two typical challenges. first, it adopts a siamese dual-encoder architecture to encode query and document independently for fast indexing and searching, whereas neglecting the finer-grained term-wise interactions. this results in a sub-optimal recall performance. second, it highly relies on a negative sampling technique to build up the negative documents in its contrastive loss. to address these challenges, we present adversarial retriever-ranker (ar2), which consists of a dual-encoder retriever plus a cross-encoder ranker. the two models are jointly optimized according to a minimax adversarial objective: the retriever learns to retrieve negative documents to cheat the ranker, while the ranker learns to rank a collection of candidates including both the ground-truth and the retrieved ones, as well as providing progressive direct feedback to the dual-encoder retriever. through this adversarial game, the retriever gradually produces harder negative documents to train a better ranker, whereas the cross-encoder ranker provides progressive feedback to improve retriever. we evaluate ar2 on three benchmarks. experimental results show that ar2 consistently and significantly outperforms existing dense retriever methods and achieves new state-of-the-art results on all of them. this includes the improvements on natural questions r@5 to 77.9%(+2.1%), triviaqa r@5 to 78.2%(+1.4), and ms-marco mrr@10 to 39.5%(+1.3%). we will make our code, models, and data publicly available. ","1303":"we develop a unified system to answer directly from text open-domain questions that may require a varying number of retrieval steps. we employ a single multi-task transformer model to perform all the necessary subtasks -- retrieving supporting facts, reranking them, and predicting the answer from all retrieved documents -- in an iterative fashion. we avoid crucial assumptions of previous work that do not transfer well to real-world settings, including exploiting knowledge of the fixed number of retrieval steps required to answer each question or using structured metadata like knowledge bases or web links that have limited availability. instead, we design a system that can answer open-domain questions on any text collection without prior knowledge of reasoning complexity. to emulate this setting, we construct a new benchmark, called beerqa, by combining existing one- and two-step datasets with a new collection of 530 questions that require three wikipedia pages to answer, unifying wikipedia corpora versions in the process. we show that our model demonstrates competitive performance on both existing benchmarks and this new benchmark. we make the new benchmark available at https:\/\/beerqa.github.io\/. ","1304":"in low-resource settings, model transfer can help to overcome a lack of labeled data for many tasks and domains. however, predicting useful transfer sources is a challenging problem, as even the most similar sources might lead to unexpected negative transfer results. thus, ranking methods based on task and text similarity -- as suggested in prior work -- may not be sufficient to identify promising sources. to tackle this problem, we propose a new approach to automatically determine which and how many sources should be exploited. for this, we study the effects of model transfer on sequence labeling across various domains and tasks and show that our methods based on model similarity and support vector machines are able to predict promising sources, resulting in performance increases of up to 24 f1 points. ","1305":"combining several embeddings typically improves performance in downstream tasks as different embeddings encode different information. it has been shown that even models using embeddings from transformers still benefit from the inclusion of standard word embeddings. however, the combination of embeddings of different types and dimensions is challenging. as an alternative to attention-based meta-embeddings, we propose feature-based adversarial meta-embeddings (fame) with an attention function that is guided by features reflecting word-specific properties, such as shape and frequency, and show that this is beneficial to handle subword-based embeddings. in addition, fame uses adversarial training to optimize the mappings of differently-sized embeddings to the same space. we demonstrate that fame works effectively across languages and domains for sequence labeling and sentence classification, in particular in low-resource settings. fame sets the new state of the art for pos tagging in 27 languages, various ner settings and question classification in different domains. ","1306":"when faced with self-regulation challenges, children have been known the use their language to inhibit their emotions and behaviors. yet, to date, there has been a critical lack of evidence regarding what patterns in their speech children use during these moments of frustration. in this paper, extreme gradient boosting, random forest, long short-term memory recurrent neural networks, and elastic net regression, have all been used to forecast these language patterns in children. based on the results of a comparative analysis between these methods, the study reveals that when dealing with high-dimensional and dense data, with very irregular and abnormal distributions, as is the case with self-regulation patterns in children, decision tree-based algorithms are able to outperform traditional regression and neural network methods in their shortcomings. ","1307":"healthcare is becoming a more and more important research topic recently. with the growing data in the healthcare domain, it offers a great opportunity for deep learning to improve the quality of medical service. however, the complexity of electronic health records (ehr) data is a challenge for the application of deep learning. specifically, the data produced in the hospital admissions are monitored by the ehr system, which includes structured data like daily body temperature, and unstructured data like free text and laboratory measurements. although there are some preprocessing frameworks proposed for specific ehr data, the clinical notes that contain significant clinical value are beyond the realm of their consideration. besides, whether these different data from various views are all beneficial to the medical tasks and how to best utilize these data remain unclear. therefore, in this paper, we first extract the accompanying clinical notes from ehr and propose a method to integrate these data, we also comprehensively study the different models and the data leverage methods for better medical task prediction. the results on two medical prediction tasks show that our fused model with different data outperforms the state-of-the-art method that without clinical notes, which illustrates the importance of our fusion method and the value of clinical note features. our code is available at https: \/\/github.com\/emnlp-mimic\/mimic. ","1308":"the recognition of hate speech and offensive language (hof) is commonly formulated as a classification task to decide if a text contains hof. we investigate whether hof detection can profit by taking into account the relationships between hof and similar concepts: (a) hof is related to sentiment analysis because hate speech is typically a negative statement and expresses a negative opinion; (b) it is related to emotion analysis, as expressed hate points to the author experiencing (or pretending to experience) anger while the addressees experience (or are intended to experience) fear. (c) finally, one constituting element of hof is the mention of a targeted person or group. on this basis, we hypothesize that hof detection shows improvements when being modeled jointly with these concepts, in a multi-task learning setup. we base our experiments on existing data sets for each of these concepts (sentiment, emotion, target of hof) and evaluate our models as a participant (as team ims-sinai) in the hasoc fire 2021 english subtask 1a. based on model-selection experiments in which we consider multiple available resources and submissions to the shared task, we find that the combination of the crowdflower emotion corpus, the semeval 2016 sentiment corpus, and the offenseval 2019 target detection data leads to an f1 =.79 in a multi-head multi-task learning model based on bert, in comparison to .7895 of plain bert. on the hasoc 2019 test data, this result is more substantial with an increase by 2pp in f1 and a considerable increase in recall. across both data sets (2019, 2021), the recall is particularly increased for the class of hof (6pp for the 2019 data and 3pp for the 2021 data), showing that mtl with emotion, sentiment, and target identification is an appropriate approach for early warning systems that might be deployed in social media platforms. ","1309":"this paper summarizes the main findings of the adobo 2021 shared task, proposed in the context of iberlef 2021. in this task, we invited participants to detect lexical borrowings (coming mostly from english) in spanish newswire texts. this task was framed as a sequence classification problem using bio encoding. we provided participants with an annotated corpus of lexical borrowings which we split into training, development and test splits. we received submissions from 4 teams with 9 different system runs overall. the results, which range from f1 scores of 37 to 85, suggest that this is a challenging task, especially when out-of-domain or oov words are considered, and that traditional methods informed with lexicographic information would benefit from taking advantage of current nlp trends. ","1310":"in task-oriented dialogue systems, recent dialogue state tracking methods tend to perform one-pass generation of the dialogue state based on the previous dialogue state. the mistakes of these models made at the current turn are prone to be carried over to the next turn, causing error propagation. in this paper, we propose a novel amendable generation for dialogue state tracking (ag-dst), which contains a two-pass generation process: (1) generating a primitive dialogue state based on the dialogue of the current turn and the previous dialogue state, and (2) amending the primitive dialogue state from the first pass. with the additional amending generation pass, our model is tasked to learn more robust dialogue state tracking by amending the errors that still exist in the primitive dialogue state, which plays the role of reviser in the double-checking process and alleviates unnecessary error propagation. experimental results show that ag-dst significantly outperforms previous works in two active dst datasets (multiwoz 2.2 and woz 2.0), achieving new state-of-the-art performances. ","1311":"the multi-relational knowledge base question answering (kbqa) system performs multi-hop reasoning over the knowledge graph (kg) to achieve the answer. recent approaches attempt to introduce the knowledge graph embedding (kge) technique to handle the kg incompleteness but only consider the triple facts and neglect the significant semantic correlation between paths and multi-relational questions. in this paper, we propose a path and knowledge embedding-enhanced multi-relational question answering model (pkeeqa), which leverages multi-hop paths between entities in the kg to evaluate the ambipolar correlation between a path embedding and a multi-relational question embedding via a customizable path representation mechanism, benefiting for achieving more accurate answers from the perspective of both the triple facts and the extra paths. experimental results illustrate that pkeeqa improves kbqa models' performance for multi-relational question answering with explainability to some extent derived from paths. ","1312":"mental health is a critical issue in modern society, and mental disorders could sometimes turn to suicidal ideation without adequate treatment. early detection of mental disorders and suicidal ideation from social content provides a potential way for effective social intervention. recent advances in pretrained contextualized language representations have promoted the development of several domain-specific pretrained models and facilitated several downstream applications. however, there are no existing pretrained language models for mental healthcare. this paper trains and release two pretrained masked language models, i.e., mentalbert and mentalroberta, to benefit machine learning for the mental healthcare research community. besides, we evaluate our trained domain-specific models and several variants of pretrained language models on several mental disorder detection benchmarks and demonstrate that language representations pretrained in the target domain improve the performance of mental health detection tasks. ","1313":"writing messages is key to expressing feelings. this study adopts cognitive network science to reconstruct how individuals report their feelings in clinical narratives like suicide notes or mental health posts. we achieve this by reconstructing syntactic\/semantic associations between conceptsin texts as co-occurrences enriched with affective data. we transform 142 suicide notes and 77,000 reddit posts from the r\/anxiety, r\/depression, r\/schizophrenia, and r\/do-it-your-own (r\/diy) forums into 5 cognitive networks, each one expressing meanings and emotions as reported by authors. these networks reconstruct the semantic frames surrounding 'feel', enabling a quantification of prominent associations and emotions focused around feelings. we find strong feelings of sadness across all clinical reddit boards, added to fear r\/depression, and replaced by joy\/anticipation in r\/diy. semantic communities and topic modelling both highlight key narrative topics of 'regret', 'unhealthy lifestyle' and 'low mental well-being'. importantly, negative associations and emotions co-existed with trustful\/positive language, focused on 'getting better'. this emotional polarisation provides quantitative evidence that online clinical boards possess a complex structure, where users mix both positive and negative outlooks. this dichotomy is absent in the r\/diy reference board and in suicide notes, where negative emotional associations about regret and pain persist but are overwhelmed by positive jargon addressing loved ones. our quantitative comparisons provide strong evidence that suicide notes encapsulate different ways of expressing feelings compared to online reddit boards, the latter acting more like personal diaries and relief valve. our findings provide an interpretable, quantitative aid for supporting psychological inquiries of human feelings in digital and clinical settings. ","1314":"the aim of the case 2021 shared task 1 (h\\\"urriyeto\\u{g}lu et al., 2021) was to detect and classify socio-political and crisis event information at document, sentence, cross-sentence, and token levels in a multilingual setting, with each of these subtasks being evaluated separately in each test language. our submission contained entries in all of the subtasks, and the scores obtained validated our research finding: that the multilingual aspect of the tasks should be embraced, so that modeling and training regimes use the multilingual nature of the tasks to their mutual benefit, rather than trying to tackle the different languages separately. our code is available at https:\/\/github.com\/handshakesbydc\/case2021\/ ","1315":"keyphrase provides accurate information of document content that is highly compact, concise, full of meanings, and widely used for discourse comprehension, organization, and text retrieval. though previous studies have made substantial efforts for automated keyphrase extraction and generation, surprisingly, few studies have been made for \\textit{keyphrase completion} (kpc). kpc aims to generate more keyphrases for document (e.g. scientific publication) taking advantage of document content along with a very limited number of known keyphrases, which can be applied to improve text indexing system, etc. in this paper, we propose a novel kpc method with an encoder-decoder framework. we name it \\textit{deep keyphrase completion} (dkpc) since it attempts to capture the deep semantic meaning of the document content together with known keyphrases via a deep learning framework. specifically, the encoder and the decoder in dkpc play different roles to make full use of the known keyphrases. the former considers the keyphrase-guiding factors, which aggregates information of known keyphrases into context. on the contrary, the latter considers the keyphrase-inhibited factor to inhibit semantically repeated keyphrase generation. extensive experiments on benchmark datasets demonstrate the efficacy of our proposed model. ","1316":"mathematical reasoning would be one of the next frontiers for artificial intelligence to make significant progress. the ongoing surge to solve math word problems (mwps) and hence achieve better mathematical reasoning ability would continue to be a key line of research in the coming time. we inspect non-neural and neural methods to solve math word problems narrated in a natural language. we also highlight the ability of these methods to be generalizable, mathematically reasonable, interpretable, and explainable. neural approaches dominate the current state of the art, and we survey them highlighting three strategies to mwp solving: (1) direct answer generation, (2) expression tree generation for inferring answers, and (3) template retrieval for answer computation. moreover, we discuss technological approaches, review the evolution of intuitive design choices to solve mwps, and examine them for mathematical reasoning ability. we finally identify several gaps that warrant the need for external knowledge and knowledge-infused learning, among several other opportunities in solving mwps. ","1317":"sign language is a main communication channel among hearing disability community. automatic sign language transcription could facilitate better communication and understanding between hearing disability community and hearing majority. as a recent work in automatic sign language transcription has discussed, effectively handling or identifying a non-sign posture is one of the key issues. a non-sign posture is a posture unintended for sign reading and does not belong to any valid sign. a non-sign posture may arise during sign transition or simply from an unaware posture. confidence ratio has been proposed to mitigate the issue. confidence ratio is simple to compute and readily available without extra training. however, confidence ratio is reported to only partially address the problem. in addition, confidence ratio formulation is susceptible to computational instability. this article proposes alternative formulations to confidence ratio, investigates an issue of non-sign identification for thai finger spelling recognition, explores potential solutions and has found a promising direction. not only does this finding address the issue of non-sign identification, it also provide some insight behind a well-learned inference machine, revealing hidden meaning and new interpretation of the underlying mechanism. our proposed methods are evaluated and shown to be effective for non-sign detection. ","1318":"predicting linearized abstract meaning representation (amr) graphs using pre-trained sequence-to-sequence transformer models has recently led to large improvements on amr parsing benchmarks. these parsers are simple and avoid explicit modeling of structure but lack desirable properties such as graph well-formedness guarantees or built-in graph-sentence alignments. in this work we explore the integration of general pre-trained sequence-to-sequence language models and a structure-aware transition-based approach. we depart from a pointer-based transition system and propose a simplified transition set, designed to better exploit pre-trained language models for structured fine-tuning. we also explore modeling the parser state within the pre-trained encoder-decoder architecture and different vocabulary strategies for the same purpose. we provide a detailed comparison with recent progress in amr parsing and show that the proposed parser retains the desirable properties of previous transition-based approaches, while being simpler and reaching the new parsing state of the art for amr 2.0, without the need for graph re-categorization. ","1319":"understanding protein sequences is vital and urgent for biology, healthcare, and medicine. labeling approaches are expensive yet time-consuming, while the amount of unlabeled data is increasing quite faster than that of the labeled data due to low-cost, high-throughput sequencing methods. in order to extract knowledge from these unlabeled data, representation learning is of significant value for protein-related tasks and has great potential for helping us learn more about protein functions and structures. the key problem in the protein sequence representation learning is to capture the co-evolutionary information reflected by the inter-residue co-variation in the sequences. instead of leveraging multiple sequence alignment as is usually done, we propose a novel method to capture this information directly by pre-training via a dedicated language model, i.e., pairwise masked language model (pmlm). in a conventional masked language model, the masked tokens are modeled by conditioning on the unmasked tokens only, but processed independently to each other. however, our proposed pmlm takes the dependency among masked tokens into consideration, i.e., the probability of a token pair is not equal to the product of the probability of the two tokens. by applying this model, the pre-trained encoder is able to generate a better representation for protein sequences. our result shows that the proposed method can effectively capture the inter-residue correlations and improves the performance of contact prediction by up to 9% compared to the mlm baseline under the same setting. the proposed model also significantly outperforms the msa baseline by more than 7% on the tape contact prediction benchmark when pre-trained on a subset of the sequence database which the msa is generated from, revealing the potential of the sequence pre-training method to surpass msa based methods in general. ","1320":"since the beginning of covid pandemic, there have been around 700000 scientific papers published on the subject. a human researcher cannot possibly get acquainted with such a huge text corpus -- and therefore developing ai-based tools to help navigating this corpus and deriving some useful insights from it is highly needed. in this paper, we will use text analytics for health pre-trained service together with some cloud tools to extract some knowledge from scientific papers, gain insights, and build a tool to help researcher navigate the paper collection in a meaningful way. ","1321":"noise robustness is essential for deploying automatic speech recognition (asr) systems in real-world environments. one way to reduce the effect of noise interference is to employ a preprocessing module that conducts speech enhancement, and then feed the enhanced speech to an asr backend. in this work, instead of suppressing background noise with a conventional cascaded pipeline, we employ a noise-robust representation learned by a refined self-supervised framework for noisy speech recognition. we propose to combine a reconstruction module with contrastive learning and perform multi-task continual pre-training on noisy data. the reconstruction module is used for auxiliary learning to improve the noise robustness of the learned representation and thus is not required during inference. experiments demonstrate the effectiveness of our proposed method. our model substantially reduces the word error rate (wer) for the synthesized noisy librispeech test sets, and yields around 4.1\/7.5% wer reduction on noisy clean\/other test sets compared to data augmentation. for the real-world noisy speech from the chime-4 challenge (1-channel track), we have obtained the state of the art asr performance without any denoising front-end. moreover, we achieve comparable performance to the best supervised approach reported with only 16% of labeled data. ","1322":"we propose to tackle data-to-text generation tasks by directly splicing together retrieved segments of text from \"neighbor\" source-target pairs. unlike recent work that conditions on retrieved neighbors but generates text token-by-token, left-to-right, we learn a policy that directly manipulates segments of neighbor text, by inserting or replacing them in partially constructed generations. standard techniques for training such a policy require an oracle derivation for each generation, and we prove that finding the shortest such derivation can be reduced to parsing under a particular weighted context-free grammar. we find that policies learned in this way perform on par with strong baselines in terms of automatic and human evaluation, but allow for more interpretable and controllable generation. ","1323":"medication timelines have been shown to be effective in helping physicians visualize complex patient medication information. a key feature in many such designs is a longitudinal representation of a medication's daily dosage and its changes over time. however, daily dosage as a discrete value is generally not provided and needs to be derived from free text instructions (sig). existing works in daily dosage extraction are narrow in scope, targeting dosage extraction for a single drug from clinical notes. here, we present an automated approach to calculate daily dosage for all medications, combining deep learning-based named entity extractor with lexicon dictionaries and regular expressions, achieving 0.98 precision and 0.95 recall on an expert-generated dataset of 1,000 sigs. we also analyze our expert-generated dataset, discuss the challenges in understanding the complex information contained in sigs, and provide insights to guide future work in the general-purpose daily dosage calculation task. ","1324":"every day people ask short questions through smart devices or online forums to seek answers to all kinds of queries. with the increasing number of questions collected it becomes difficult to provide answers to each of them, which is one of the reasons behind the growing interest in automated question answering. some questions are similar to existing ones that have already been answered, while others could be answered by an external knowledge source such as wikipedia. an important question is what can be revealed by analysing a large set of questions. in 2017, \"we the curious\" science centre in bristol started a project to capture the curiosity of bristolians: the project collected more than 10,000 questions on various topics. as no rules were given during collection, the questions are truly open-domain, and ranged across a variety of topics. one important aim for the science centre was to understand what concerns its visitors had beyond science, particularly on societal and cultural issues. we addressed this question by developing an artificial intelligence tool that can be used to perform various processing tasks: detection of equivalence between questions; detection of topic and type; and answering of the question. as we focused on the creation of a \"generalist\" tool, we trained it with labelled data from different datasets. we called the resulting model qbert. this paper describes what information we extracted from the automated analysis of the wtc corpus of open-domain questions. ","1325":"communication requires having a common language, a lingua franca, between agents. this language could emerge via a consensus process, but it may require many generations of trial and error. alternatively, the lingua franca can be given by the environment, where agents ground their language in representations of the observed world. we demonstrate a simple way to ground language in learned representations, which facilitates decentralized multi-agent communication and coordination. we find that a standard representation learning algorithm -- autoencoding -- is sufficient for arriving at a grounded common language. when agents broadcast these representations, they learn to understand and respond to each other's utterances and achieve surprisingly strong task performance across a variety of multi-agent communication environments. ","1326":"natural language processing (nlp) has recently achieved success by using huge pre-trained transformer networks. however, these models often contain hundreds of millions or even billions of parameters, bringing challenges to online deployment due to latency constraints. recently, hardware manufacturers have introduced dedicated hardware for nxm sparsity to provide the flexibility of unstructured pruning with the runtime efficiency of structured approaches. nxm sparsity permits arbitrarily selecting m parameters to retain from a contiguous group of n in the dense representation. however, due to the extremely high complexity of pre-trained models, the standard sparse fine-tuning techniques often fail to generalize well on downstream tasks, which have limited data resources. to address such an issue in a principled manner, we introduce a new learning framework, called nxmtransformer, to induce nxm semi-structured sparsity on pretrained language models for natural language understanding to obtain better performance. in particular, we propose to formulate the nxm sparsity as a constrained optimization problem and use alternating direction method of multipliers (admm) to optimize the downstream tasks while taking the underlying hardware constraints into consideration. admm decomposes the nxm sparsification problem into two sub-problems that can be solved sequentially, generating sparsified transformer networks that achieve high accuracy while being able to effectively execute on newly released hardware. we apply our approach to a wide range of nlp tasks, and our proposed method is able to achieve 1.7 points higher accuracy in glue score than current practices. moreover, we perform detailed analysis on our approach and shed light on how admm affects fine-tuning accuracy for downstream tasks. finally, we illustrate how nxmtransformer achieves performance improvement with knowledge distillation. ","1327":"clarification resolution plays an important role in various information retrieval tasks such as interactive question answering and conversational search. in such context, the user often formulates their information needs as short and ambiguous queries, some popular search interfaces then prompt the user to confirm her intent (e.g. \"did you mean ... ?\") or to rephrase if needed. when it comes to dialogue systems, having fluid user-bot exchanges is key to good user experience. in the absence of such clarification mechanism, one of the following responses is given to the user: 1) a direct answer, which can potentially be non-relevant if the intent was not clear, 2) a generic fallback message informing the user that the retrieval tool is incapable of handling the query. both scenarios might raise frustration and degrade the user experience. to this end, we propose a multi-stage clarification mechanism for prompting clarification and query selection in the context of a question answering dialogue system. we show that our proposed mechanism improves the overall user experience and outperforms competitive baselines with two datasets, namely the public in-scope out-of-scope dataset and a commercial dataset based on real user logs. ","1328":"while wav2vec 2.0 has been proposed for speech recognition (asr), it can also be used for speech emotion recognition (ser); its performance can be significantly improved using different fine-tuning strategies. two baseline methods, vanilla fine-tuning (v-ft) and task adaptive pretraining (tapt) are first presented. we show that v-ft is able to outperform state-of-the-art models on the iemocap dataset. tapt, an existing nlp fine-tuning strategy, further improves the performance on ser. we also introduce a novel fine-tuning method termed p-tapt, which modifies the tapt objective to learn contextualized emotion representations. experiments show that p-tapt performs better than tapt especially under low-resource settings. compared to prior works in this literature, our top-line system achieved a 7.4% absolute improvement on unweighted accuracy (ua) over the state-of-the-art performance on iemocap. our code is publicly available. ","1329":"masked language models have recently been interpreted as energy-based sequence models that can be generated from using a metropolis--hastings sampler. this short paper demonstrates how this can be instrumentalized for constrained composition and explores the poetics implied by such a usage. our focus on constraints makes it especially apt to understand the generated text through the poetics of the oulipo movement. ","1330":"grammatical error correction (gec) is the task of detecting and correcting errors in a written text. the idea of combining multiple system outputs has been successfully used in gec. to achieve successful system combination, multiple component systems need to produce corrected sentences that are both diverse and of comparable quality. however, most existing state-of-the-art gec approaches are based on similar sequence-to-sequence neural networks, so the gains are limited from combining the outputs of component systems similar to one another. in this paper, we present diversity-driven combination (ddc) for gec, a system combination strategy that encourages diversity among component systems. we evaluate our system combination strategy on the conll-2014 shared task and the bea-2019 shared task. on both benchmarks, ddc achieves significant performance gain with a small number of training examples and outperforms the component systems by a large margin. our source code is available at https:\/\/github.com\/nusnlp\/gec-ddc. ","1331":"a growing body of recent evidence has highlighted the limitations of natural language processing (nlp) datasets and classifiers. these include the presence of annotation artifacts in datasets, classifiers relying on shallow features like a single word (e.g., if a movie review has the word \"romantic\", the review tends to be positive), or unnecessary words (e.g., learning a proper noun to classify a movie as positive or negative). the presence of such artifacts has subsequently led to the development of challenging datasets to force the model to generalize better. while a variety of heuristic strategies, such as counterfactual examples and contrast sets, have been proposed, the theoretical justification about what makes these examples difficult for the classifier is often lacking or unclear. in this paper, using tools from information geometry, we propose a theoretical way to quantify the difficulty of an example in nlp. using our approach, we explore difficult examples for several deep learning architectures. we discover that both bert, cnn and fasttext are susceptible to word substitutions in high difficulty examples. these classifiers tend to perform poorly on the fim test set. (generated by sampling and perturbing difficult examples, with accuracy dropping below 50%). we replicate our experiments on 5 nlp datasets (yelpreviewpolarity, agnews, sogounews, yelpreviewfull and yahoo answers). on yelpreviewpolarity we observe a correlation coefficient of -0.4 between resilience to perturbations and the difficulty score. similarly we observe a correlation of 0.35 between the difficulty score and the empirical success probability of random substitutions. our approach is simple, architecture agnostic and can be used to study the fragilities of text classification models. all the code used will be made publicly available, including a tool to explore the difficult examples for other datasets. ","1332":"commonly, introductory programming courses in higher education institutions have hundreds of participating students eager to learn to program. the manual effort for reviewing the submitted source code and for providing feedback can no longer be managed. manually reviewing the submitted homework can be subjective and unfair, particularly if many tutors are responsible for grading. different autograders can help in this situation; however, there is a lack of knowledge about how autograders can impact students' overall perception of programming classes and teaching. this is relevant for course organizers and institutions to keep their programming courses attractive while coping with increasing students.   this paper studies the answers to the standardized university evaluation questionnaires of multiple large-scale foundational computer science courses which recently introduced autograding. the differences before and after this intervention are analyzed. by incorporating additional observations, we hypothesize how the autograder might have contributed to the significant changes in the data, such as, improved interactions between tutors and students, improved overall course quality, improved learning success, increased time spent, and reduced difficulty. this qualitative study aims to provide hypotheses for future research to define and conduct quantitative surveys and data analysis. the autograder technology can be validated as a teaching method to improve student satisfaction with programming courses. ","1333":"high-quality web tables are rich sources of information that can be used to populate knowledge graphs (kg). the focus of this paper is an evaluation of methods for table-to-class annotation, which is a sub-task of table interpretation (ti). we provide a formal definition for table classification as a machine learning task. we propose an experimental setup and we evaluate 5 fundamentally different approaches to find the best method for generating vector table representations. our findings indicate that although transfer learning methods achieve high f1 score on the table classification task, dedicated table encoding models are a promising direction as they appear to capture richer semantics. ","1334":"the popularity of online shopping is steadily increasing. at the same time, fake product reviewsare published widely and have the potential to affect consumer purchasing behavior. in response,previous work has developed automated methods for the detection of deceptive product reviews.however, studies vary considerably in terms of classification performance, and many use data thatcontain potential confounds, which makes it difficult to determine their validity. two possibleconfounds are data-origin (i.e., the dataset is composed of more than one source) and productownership (i.e., reviews written by individuals who own or do not own the reviewed product). inthe present study, we investigate the effect of both confounds for fake review detection. using anexperimental design, we manipulate data-origin, product ownership, review polarity, and veracity.supervised learning analysis suggests that review veracity (60.26 - 69.87%) is somewhat detectablebut reviews additionally confounded with product-ownership (66.19 - 74.17%), or with data-origin(84.44 - 86.94%) are easier to classify. review veracity is most easily classified if confounded withproduct-ownership and data-origin combined (87.78 - 88.12%), suggesting overestimations of thetrue performance in other work. these findings are moderated by review polarity. ","1335":"to unfold the tremendous amount of multimedia data uploaded daily to social media platforms, effective topic modeling techniques are needed. existing work tends to apply topic models on written text datasets. in this paper, we propose a topic extractor on video transcripts. exploiting neural word embeddings through graph-based clustering, we aim to improve usability and semantic coherence. unlike most topic models, this approach works without knowing the true number of topics, which is important when no such assumption can or should be made. experimental results on the real-life multimodal dataset muse-car demonstrates that our approach graphtmt extracts coherent and meaningful topics and outperforms baseline methods. furthermore, we successfully demonstrate the applicability of our approach on the popular citysearch corpus. ","1336":"machine translation (mt) system aims to translate source language into target language. recent studies on mt systems mainly focus on neural machine translation (nmt). one factor that significantly affects the performance of nmt is the availability of high-quality parallel corpora. however, high-quality parallel corpora concerning korean are relatively scarce compared to those associated with other high-resource languages, such as german or italian. to address this problem, ai hub recently released seven types of parallel corpora for korean. in this study, we conduct an in-depth verification of the quality of corresponding parallel corpora through linguistic inquiry and word count (liwc) and several relevant experiments. liwc is a word-counting software program that can analyze corpora in multiple ways and extract linguistic features as a dictionary base. to the best of our knowledge, this study is the first to use liwc to analyze parallel corpora in the field of nmt. our findings suggest the direction of further research toward obtaining the improved quality parallel corpora through our correlation analysis in liwc and nmt performance. ","1337":"consumer event-cause extraction, the task aimed at extracting the potential causes behind certain events in the text, has gained much attention in recent years due to its wide applications. the icdm 2020 conference sets up an evaluation competition that aims to extract events and the causes of the extracted events with a specified subject (a brand or product). in this task, we mainly focus on how to construct an end-to-end model, and extract multiple event types and event-causes simultaneously. to this end, we introduce a fresh perspective to revisit the relational event-cause extraction task and propose a novel sequence tagging framework, instead of extracting event types and events-causes separately. experiments show our framework outperforms baseline methods even when its encoder module uses an initialized pre-trained bert encoder, showing the power of the new tagging framework. in this competition, our team achieved 1st place in the first stage leaderboard, and 3rd place in the final stage leaderboard. ","1338":"recognizing a speaker's emotion from their speech can be a key element in emergency call centers. end-to-end deep learning systems for speech emotion recognition now achieve equivalent or even better results than conventional machine learning approaches. in this paper, in order to validate the performance of our neural network architecture for emotion recognition from speech, we first trained and tested it on the widely used corpus accessible by the community, iemocap. we then used the same architecture as the real life corpus, cemo, composed of 440 dialogs (2h16m) from 485 speakers. the most frequent emotions expressed by callers in these real life emergency dialogues are fear, anger and positive emotions such as relief. in the iemocap general topic conversations, the most frequent emotions are sadness, anger and happiness. using the same end-to-end deep learning architecture, an unweighted accuracy recall (ua) of 63% is obtained on iemocap and a ua of 45.6% on cemo, each with 4 classes. using only 2 classes (anger, neutral), the results for cemo are 76.9% ua compared to 81.1% ua for iemocap. we expect that these encouraging results with cemo can be improved by combining the audio channel with the linguistic channel. real-life emotions are clearly more complex than acted ones, mainly due to the large diversity of emotional expressions of speakers. index terms-emotion detection, end-to-end deep learning architecture, call center, real-life database, complex emotions. ","1339":"variational autoencoders trained to minimize the reconstruction error are sensitive to the posterior collapse problem, that is the proposal posterior distribution is always equal to the prior. we propose a novel regularization method based on fraternal dropout to prevent posterior collapse. we evaluate our approach using several metrics and observe improvements in all the tested configurations. ","1340":"transformers provide a class of expressive architectures that are extremely effective for sequence modeling. however, the key limitation of transformers is their quadratic memory and time complexity $\\mathcal{o}(l^2)$ with respect to the sequence length in attention layers, which restricts application in extremely long sequences. most existing approaches leverage sparsity or low-rank assumptions in the attention matrix to reduce cost, but sacrifice expressiveness. instead, we propose combiner, which provides full attention capability in each attention head while maintaining low computation and memory complexity. the key idea is to treat the self-attention mechanism as a conditional expectation over embeddings at each location, and approximate the conditional distribution with a structured factorization. each location can attend to all other locations, either via direct attention, or through indirect attention to abstractions, which are again conditional expectations of embeddings from corresponding local regions. we show that most sparse attention patterns used in existing sparse transformers are able to inspire the design of such factorization for full attention, resulting in the same sub-quadratic cost ($\\mathcal{o}(l\\log(l))$ or $\\mathcal{o}(l\\sqrt{l})$). combiner is a drop-in replacement for attention layers in existing transformers and can be easily implemented in common frameworks. an experimental evaluation on both autoregressive and bidirectional sequence tasks demonstrates the effectiveness of this approach, yielding state-of-the-art results on several image and text modeling tasks. ","1341":"the transformer architecture has improved the performance of deep learning models in domains such as computer vision and natural language processing. together with better performance come larger model sizes. this imposes challenges to the memory wall of the current accelerator hardware such as gpu. it is never ideal to train large models such as vision transformer, bert, and gpt on a single gpu or a single machine. there is an urgent demand to train models in a distributed environment. however, distributed training, especially model parallelism, often requires domain expertise in computer systems and architecture. it remains a challenge for ai researchers to implement complex distributed training solutions for their models.   in this paper, we introduce colossal-ai, which is a unified parallel training system designed to seamlessly integrate different paradigms of parallelization techniques including data parallelism, pipeline parallelism, multiple tensor parallelism, and sequence parallelism. colossal-ai aims to support the ai community to write distributed models in the same way as how they write models normally. this allows them to focus on developing the model architecture and separates the concerns of distributed training from the development process. the documentations can be found at https:\/\/www.colossalai.org and the source code can be found at https:\/\/github.com\/hpcaitech\/colossalai. ","1342":"are end-to-end text-to-speech (tts) models over-parametrized? to what extent can these models be pruned, and what happens to their synthesis capabilities? this work serves as a starting point to explore pruning both spectrogram prediction networks and vocoders. we thoroughly investigate the tradeoffs between sparsity and its subsequent effects on synthetic speech. additionally, we explored several aspects of tts pruning: amount of finetuning data versus sparsity, tts-augmentation to utilize unspoken text, and combining knowledge distillation and pruning. our findings suggest that not only are end-to-end tts models highly prunable, but also, perhaps surprisingly, pruned tts models can produce synthetic speech with equal or higher naturalness and intelligibility, with similar prosody. all of our experiments are conducted on publicly available models, and findings in this work are backed by large-scale subjective tests and objective measures. code and 200 pruned models are made available to facilitate future research on efficiency in tts. ","1343":"e-commerce voice ordering systems need to recognize multiple product name entities from ordering utterances. existing voice ordering systems such as amazon alexa can capture only a single product name entity. this restrains users from ordering multiple items with one utterance. in recent years, pre-trained language models, e.g., bert and gpt-2, have shown promising results on nlp benchmarks like super-glue. however, they can't perfectly generalize to this multiple product name entity recognition (mpner) task due to the ambiguity in voice ordering utterances. to fill this research gap, we propose entity transformer (et) neural network architectures which recognize up to 10 items in an utterance. in our evaluation, the best et model (convert + ngram + et) has a performance improvement of 12% on our test set compared to the non-neural model, and outperforms bert with et as well. this helps customers finalize their shopping cart via voice dialog, which improves shopping efficiency and experience. ","1344":"social stereotypes negatively impact individuals' judgements about different groups and may have a critical role in how people understand language directed toward minority social groups. here, we assess the role of social stereotypes in the automated detection of hateful language by examining the relation between individual annotator biases and erroneous classification of texts by hate speech classifiers. specifically, in study 1 we investigate the impact of novice annotators' stereotypes on their hate-speech-annotation behavior. in study 2 we examine the effect of language-embedded stereotypes on expert annotators' aggregated judgements in a large annotated corpus. finally, in study 3 we demonstrate how language-embedded stereotypes are associated with systematic prediction errors in a neural-network hate speech classifier. our results demonstrate that hate speech classifiers learn human-like biases which can further perpetuate social inequalities when propagated at scale. this framework, combining social psychological and computational linguistic methods, provides insights into additional sources of bias in hate speech moderation, informing ongoing debates regarding fairness in machine learning. ","1345":"automatically describing images using natural sentences is an important task to support visually impaired people's inclusion onto the internet. it is still a big challenge that requires understanding the relation of the objects present in the image and their attributes and actions they are involved in. then, visual interpretation methods are needed, but linguistic models are also necessary to verbally describe the semantic relations. this problem is known as image captioning. although many datasets were proposed in the literature, the majority contains only english captions, whereas datasets with captions described in other languages are scarce. recently, a movement called pracegover arose on the internet, stimulating users from social media to publish images, tag #pracegover and add a short description of their content. thus, inspired by this movement, we have proposed the #pracegover, a multi-modal dataset with portuguese captions based on posts from instagram. it is the first large dataset for image captioning in portuguese with freely annotated images. further, the captions in our dataset bring additional challenges to the problem: first, in contrast to popular datasets such as ms coco captions, #pracegover has only one reference to each image; also, both mean and variance of our reference sentence length are significantly greater than those in the ms coco captions. these two characteristics contribute to making our dataset interesting due to the linguistic aspect and the challenges that it introduces to the image captioning problem. we publicly-share the dataset at https:\/\/github.com\/gabrielsantosrv\/pracegover. ","1346":"we present cross-lingual open-retrieval answer generation (cora), the first unified many-to-many question answering (qa) model that can answer questions across many languages, even for ones without language-specific annotated data or knowledge sources. we introduce a new dense passage retrieval algorithm that is trained to retrieve documents across languages for a question. combined with a multilingual autoregressive generation model, cora answers directly in the target language without any translation or in-language retrieval modules as used in prior work. we propose an iterative training method that automatically extends annotated data available only in high-resource languages to low-resource ones. our results show that cora substantially outperforms the previous state of the art on multilingual open qa benchmarks across 26 languages, 9 of which are unseen during training. our analyses show the significance of cross-lingual retrieval and generation in many languages, particularly under low-resource settings. ","1347":"disagreement is essential to scientific progress. however, the extent of disagreement in science, its evolution over time, and the fields in which it happens, remains poorly understood. leveraging a massive collection of english-language scientific texts, we develop a cue-phrase based approach to identify instances of disagreement citations across more than four million scientific articles. using this method, we construct an indicator of disagreement across scientific fields over the 2000-2015 period. in contrast with black-box text classification methods, our framework is transparent and easily interpretable. we reveal a disciplinary spectrum of disagreement, with higher disagreement in the social sciences and lower disagreement in physics and mathematics. however, detailed disciplinary analysis demonstrates heterogeneity across sub-fields, revealing the importance of local disciplinary cultures and epistemic characteristics of disagreement. paper-level analysis reveals notable episodes of disagreement in science, and illustrates how methodological artifacts can confound analyses of scientific texts. these findings contribute to a broader understanding of disagreement and establish a foundation for future research to understanding key processes underlying scientific progress. ","1348":"topic model evaluation, like evaluation of other unsupervised methods, can be contentious. however, the field has coalesced around automated estimates of topic coherence, which rely on the frequency of word co-occurrences in a reference corpus. contemporary neural topic models surpass classical ones according to these metrics. at the same time, topic model evaluation suffers from a validation gap: automated coherence, developed for classical models, has not been validated using human experimentation for neural models. in addition, a meta-analysis of topic modeling literature reveals a substantial standardization gap in automated topic modeling benchmarks. to address the validation gap, we compare automated coherence with the two most widely accepted human judgment tasks: topic rating and word intrusion. to address the standardization gap, we systematically evaluate a dominant classical model and two state-of-the-art neural models on two commonly used datasets. automated evaluations declare a winning model when corresponding human evaluations do not, calling into question the validity of fully automatic evaluations independent of human judgments. ","1349":"feature importance (fi) estimates are a popular form of explanation, and they are commonly created and evaluated by computing the change in model confidence caused by removing certain input features at test time. for example, in the standard sufficiency metric, only the top-k most important tokens are kept. in this paper, we study several under-explored dimensions of fi explanations, providing conceptual and empirical improvements for this form of explanation. first, we advance a new argument for why it can be problematic to remove features from an input when creating or evaluating explanations: the fact that these counterfactual inputs are out-of-distribution (ood) to models implies that the resulting explanations are socially misaligned. the crux of the problem is that the model prior and random weight initialization influence the explanations (and explanation metrics) in unintended ways. to resolve this issue, we propose a simple alteration to the model training process, which results in more socially aligned explanations and metrics. second, we compare among five approaches for removing features from model inputs. we find that some methods produce more ood counterfactuals than others, and we make recommendations for selecting a feature-replacement function. finally, we introduce four search-based methods for identifying fi explanations and compare them to strong baselines, including lime, anchors, and integrated gradients. through experiments with six diverse text classification datasets, we find that the only method that consistently outperforms random search is a parallel local search (pls) that we introduce. improvements over the second-best method are as large as 5.4 points for sufficiency and 17 points for comprehensiveness. all supporting code for experiments in this paper is publicly available at https:\/\/github.com\/peterbhase\/explanationsearch. ","1350":"alzheimer's disease (ad) constitutes a neurodegenerative disease with serious consequences to peoples' everyday lives, if it is not diagnosed early since there is no available cure. because of the cost of examinations for diagnosing dementia, i.e., magnetic resonance imaging (mri), electroencephalogram (eeg) signals etc., current work has been focused on diagnosing dementia from spontaneous speech. however, little work has been done regarding the conversion of speech data to log-mel spectrograms and mel-frequency cepstral coefficients (mfccs) and the usage of pretrained models. concurrently, little work has been done in terms of both the usage of transformer networks and the way the two modalities, i.e., speech and transcripts, are combined in a single neural network. to address these limitations, first we employ several pretrained models, with vision transformer (vit) achieving the highest evaluation results. secondly, we propose multimodal models. more specifically, our introduced models include gated multimodal unit in order to control the influence of each modality towards the final classification and crossmodal attention so as to capture in an effective way the relationships between the two modalities. extensive experiments conducted on the adress challenge dataset demonstrate the effectiveness of the proposed models and their superiority over state-of-the-art approaches. ","1351":"the capabilities of natural language models trained on large-scale data have increased immensely over the past few years. open source libraries such as huggingface have made these models easily available and accessible. while prior research has identified biases in large language models, this paper considers biases contained in the most popular versions of these models when applied `out-of-the-box' for downstream tasks. we focus on generative language models as they are well-suited for extracting biases inherited from training data. specifically, we conduct an in-depth analysis of gpt-2, which is the most downloaded text generation model on huggingface, with over half a million downloads per month. we assess biases related to occupational associations for different protected categories by intersecting gender with religion, sexuality, ethnicity, political affiliation, and continental name origin. using a template-based data collection pipeline, we collect 396k sentence completions made by gpt-2 and find: (i) the machine-predicted jobs are less diverse and more stereotypical for women than for men, especially for intersections; (ii) intersectional interactions are highly relevant for occupational associations, which we quantify by fitting 262 logistic models; (iii) for most occupations, gpt-2 reflects the skewed gender and ethnicity distribution found in us labor bureau data, and even pulls the societally-skewed distribution towards gender parity in cases where its predictions deviate from real labor market observations. this raises the normative question of what language models should learn - whether they should reflect or correct for existing inequalities. ","1352":"anomaly detection or outlier detection is a common task in various domains, which has attracted significant research efforts in recent years. existing works mainly focus on structured data such as numerical or categorical data; however, anomaly detection on unstructured textual data is less attended. in this work, we target the textual anomaly detection problem and propose a deep anomaly-injected support vector data description (ai-svdd) framework. ai-svdd not only learns a more compact representation of the data hypersphere but also adopts a small number of known anomalies to increase the discriminative power. to tackle text input, we employ a multilayer perceptron (mlp) network in conjunction with bert to obtain enriched text representations. we conduct experiments on three text anomaly detection applications with multiple datasets. experimental results show that the proposed ai-svdd is promising and outperforms existing works. ","1353":"recent advances in self-supervised learning have dramatically improved the state of the art on a wide variety of tasks. however, research in language model pre-training has mostly focused on natural languages, and it is unclear whether models like bert and its variants provide the best pre-training when applied to other modalities, such as source code. in this paper, we introduce a new pre-training objective, dobf, that leverages the structural aspect of programming languages and pre-trains a model to recover the original version of obfuscated source code. we show that models pre-trained with dobf significantly outperform existing approaches on multiple downstream tasks, providing relative improvements of up to 13% in unsupervised code translation, and 24% in natural language code search. incidentally, we found that our pre-trained model is able to de-obfuscate fully obfuscated source files, and to suggest descriptive variable names. ","1354":"there is an increasing interest in continuous learning (cl), as data privacy is becoming a priority for real-world machine learning applications. meanwhile, there is still a lack of academic nlp benchmarks that are applicable for realistic cl settings, which is a major challenge for the advancement of the field. in this paper we discuss some of the unrealistic data characteristics of public datasets, study the challenges of realistic single-task continuous learning as well as the effectiveness of data rehearsal as a way to mitigate accuracy loss. we construct a cl ner dataset from an existing publicly available dataset and release it along with the code to the research community. ","1355":"we present indonli, the first human-elicited nli dataset for indonesian. we adapt the data collection protocol for mnli and collect nearly 18k sentence pairs annotated by crowd workers and experts. the expert-annotated data is used exclusively as a test set. it is designed to provide a challenging test-bed for indonesian nli by explicitly incorporating various linguistic phenomena such as numerical reasoning, structural changes, idioms, or temporal and spatial reasoning. experiment results show that xlm-r outperforms other pre-trained models in our data. the best performance on the expert-annotated data is still far below human performance (13.4% accuracy gap), suggesting that this test set is especially challenging. furthermore, our analysis shows that our expert-annotated data is more diverse and contains fewer annotation artifacts than the crowd-annotated data. we hope this dataset can help accelerate progress in indonesian nlp research. ","1356":"the predominant approach for language modeling is to process sequences from left to right, but this eliminates a source of information: the order by which the sequence was generated. one strategy to recover this information is to decode both the content and ordering of tokens. existing approaches supervise content and ordering by designing problem-specific loss functions and pre-training with an ordering pre-selected. other recent works use iterative search to discover problem-specific orderings for training, but suffer from high time complexity and cannot be efficiently parallelized. we address these limitations with an unsupervised parallelizable learner that discovers high-quality generation orders purely from training data -- no domain knowledge required. the learner contains an encoder network and decoder language model that perform variational inference with autoregressive orders (represented as permutation matrices) as latent variables. the corresponding elbo is not differentiable, so we develop a practical algorithm for end-to-end optimization using policy gradients. we implement the encoder as a transformer with non-causal attention that outputs permutations in one forward pass. permutations then serve as target generation orders for training an insertion-based transformer language model. empirical results in language modeling tasks demonstrate that our method is context-aware and discovers orderings that are competitive with or even better than fixed orders. ","1357":"in this paper, we introduce the kaizen framework that uses a continuously improving teacher to generate pseudo-labels for semi-supervised speech recognition (asr). the proposed approach uses a teacher model which is updated as the exponential moving average (ema) of the student model parameters. we demonstrate that it is critical for ema to be accumulated with full-precision floating point. the kaizen framework can be seen as a continuous version of the iterative pseudo-labeling approach for semi-supervised training. it is applicable for different training criteria, and in this paper we demonstrate its effectiveness for frame-level hybrid hidden markov model-deep neural network (hmm-dnn) systems as well as sequence-level connectionist temporal classification (ctc) based models.   for large scale real-world unsupervised public videos in uk english and italian languages the proposed approach i) shows more than 10% relative word error rate (wer) reduction over standard teacher-student training; ii) using just 10 hours of supervised data and a large amount of unsupervised data closes the gap to the upper-bound supervised asr system that uses 650h or 2700h respectively. ","1358":"to consider hawrami and zaza (zazaki) standalone languages or dialects of a language have been discussed and debated for a while among linguists active in studying iranian languages. the question of whether those languages\/dialects belong to the kurdish language or if they are independent descendants of iranian languages was answered by mackenzie (1961). however, a majority of people who speak the dialects are against that answer. their disapproval mainly seems to be based on the sociological, cultural, and historical relationship among the speakers of the dialects. while the case of hawrami and zaza has remained unexplored and under-examined, an almost unanimous agreement exists about the classification of kurmanji and sorani as kurdish dialects. the related studies to address the mentioned cases are primarily qualitative. however, computational linguistics could approach the question from a quantitative perspective. in this research, we look into three questions from a linguistic distance point of view. first, how similar or dissimilar hawrami and zaza are, considering no common geographical coexistence between the two. second, what about kurmanji and sorani that have geographical overlap. finally, what is the distance among all these dialects, pair by pair? we base our computation on phonetic presentations of these dialects (languages), and we calculate various linguistic distances among the pairs. we analyze the data and discuss the results to conclude. ","1359":"a wide variety of nlp applications, such as machine translation, summarization, and dialog, involve text generation. one major challenge for these applications is how to evaluate whether such generated texts are actually fluent, accurate, or effective. in this work, we conceptualize the evaluation of generated text as a text generation problem, modeled using pre-trained sequence-to-sequence models. the general idea is that models trained to convert the generated text to\/from a reference output or the source text will achieve higher scores when the generated text is better. we operationalize this idea using bart, an encoder-decoder based pre-trained model, and propose a metric bartscore with a number of variants that can be flexibly applied in an unsupervised fashion to evaluation of text from different perspectives (e.g. informativeness, fluency, or factuality). bartscore is conceptually simple and empirically effective. it can outperform existing top-scoring metrics in 16 of 22 test settings, covering evaluation of 16 datasets (e.g., machine translation, text summarization) and 7 different perspectives (e.g., informativeness, factuality). code to calculate bartscore is available at https:\/\/github.com\/neulab\/bartscore, and we have released an interactive leaderboard for meta-evaluation at http:\/\/explainaboard.nlpedia.ai\/leaderboard\/task-meval\/ on the explainaboard platform, which allows us to interactively understand the strengths, weaknesses, and complementarity of each metric. ","1360":"the detection of perceived prominence in speech has attracted approaches ranging from the design of linguistic knowledge-based acoustic features to the automatic feature learning from suprasegmental attributes such as pitch and intensity contours. we present here, in contrast, a system that operates directly on segmented speech waveforms to learn features relevant to prominent word detection for children's oral fluency assessment. the chosen crnn (convolutional recurrent neural network) framework, incorporating both word-level features and sequence information, is found to benefit from the perceptually motivated sincnet filters as the first convolutional layer. we further explore the benefits of the linguistic association between the prosodic events of phrase boundary and prominence with different multi-task architectures. matching the previously reported performance on the same dataset of a random forest ensemble predictor trained on carefully chosen hand-crafted acoustic features, we evaluate further the possibly complementary information from hand-crafted acoustic and pre-trained lexical features. ","1361":"state-of-the-art approaches to reasoning and question answering over knowledge graphs (kgs) usually scale with the number of edges and can only be applied effectively on small instance-dependent subgraphs. in this paper, we address this issue by showing that multi-hop and more complex logical reasoning can be accomplished separately without losing expressive power. motivated by this insight, we propose an approach to multi-hop reasoning that scales linearly with the number of relation types in the graph, which is usually significantly smaller than the number of edges or nodes. this produces a set of candidate solutions that can be provably refined to recover the solution to the original problem. our experiments on knowledge-based question answering show that our approach solves the multi-hop metaqa dataset, achieves a new state-of-the-art on the more challenging webquestionssp, is orders of magnitude more scalable than competitive approaches, and can achieve compositional generalization out of the training distribution. ","1362":"in this work, our goal is to train agents that can coordinate with seen, unseen as well as human partners in a multi-agent communication environment involving natural language. previous work using a single set of agents has shown great progress in generalizing to known partners, however it struggles when coordinating with unfamiliar agents. to mitigate that, recent work explored the use of population-based approaches, where multiple agents interact with each other with the goal of learning more generic protocols. these methods, while able to result in good coordination between unseen partners, still only achieve so in cases of simple languages, thus failing to adapt to human partners using natural language. we attribute this to the use of static populations and instead propose a dynamic population-based meta-learning approach that builds such a population in an iterative manner. we perform a holistic evaluation of our method on two different referential games, and show that our agents outperform all prior work when communicating with seen partners and humans. furthermore, we analyze the natural language generation skills of our agents, where we find that our agents also outperform strong baselines. finally, we test the robustness of our agents when communicating with out-of-population agents and carefully test the importance of each component of our method through ablation studies. ","1363":"it is well known that, within the latin production of written text, peculiar metric schemes were followed not only in poetic compositions, but also in many prose works. such metric patterns were based on so-called syllabic quantity, i.e., on the length of the involved syllables, and there is substantial evidence suggesting that certain authors had a preference for certain metric patterns over others. in this research we investigate the possibility to employ syllabic quantity as a base for deriving rhythmic features for the task of computational authorship attribution of latin prose texts. we test the impact of these features on the authorship attribution task when combined with other topic-agnostic features. our experiments, carried out on three different datasets, using two different machine learning methods, show that rhythmic features based on syllabic quantity are beneficial in discriminating among latin prose authors. ","1364":"transformer-based models have proven to be powerful in many natural language, computer vision, and speech recognition applications. it is expensive to train these types of models due to unfixed input length, complex computation, and large numbers of parameters. existing systems either only focus on efficient inference or optimize only bert-like encoder models. in this paper, we present lightseq2, a system for efficient training of transformer-based models on gpus. we propose a series of gpu optimization techniques tailored to computation flow and memory access patterns of neural layers in transformers. lightseq2 supports a variety of network architectures, including bert (encoder-only), gpt (decoder-only), and transformer (encoder-decoder). our experiments on gpus with varying models and datasets show that lightseq2 is 1.4-3.5x faster than previous systems. in particular, it gains 308% training speedup compared with existing systems on a large public machine translation benchmark (wmt14 english-german). ","1365":"many applications of generative models rely on the marginalization of their high-dimensional output probability distributions. normalization functions that yield sparse probability distributions can make exact marginalization more computationally tractable. however, sparse normalization functions usually require alternative loss functions for training since the log-likelihood is undefined for sparse probability distributions. furthermore, many sparse normalization functions often collapse the multimodality of distributions. in this work, we present $\\textit{ev-softmax}$, a sparse normalization function that preserves the multimodality of probability distributions. we derive its properties, including its gradient in closed-form, and introduce a continuous family of approximations to $\\textit{ev-softmax}$ that have full support and can be trained with probabilistic loss functions such as negative log-likelihood and kullback-leibler divergence. we evaluate our method on a variety of generative models, including variational autoencoders and auto-regressive architectures. our method outperforms existing dense and sparse normalization techniques in distributional accuracy. we demonstrate that $\\textit{ev-softmax}$ successfully reduces the dimensionality of probability distributions while maintaining multimodality. ","1366":"we study acquisition functions for active learning (al) for text classification. the expected loss reduction (elr) method focuses on a bayesian estimate of the reduction in classification error, recently updated with mean objective cost of uncertainty (mocu). we convert the elr framework to estimate the increase in (strictly proper) scores like log probability or negative mean square error, which we call bayesian estimate of mean proper scores (bemps). we also prove convergence results borrowing techniques used with mocu. in order to allow better experimentation with the new acquisition functions, we develop a complementary batch al algorithm, which encourages diversity in the vector of expected changes in scores for unlabelled data. to allow high performance text classifiers, we combine ensembling and dynamic validation set construction on pretrained language models. extensive experimental evaluation then explores how these different acquisition functions perform. the results show that the use of mean square error and log probability with bemps yields robust acquisition functions, which consistently outperform the others tested. ","1367":"we present a self-supervised learning framework, coco-lm, that pretrains language models by correcting and contrasting corrupted text sequences. following electra-style pretraining, coco-lm employs an auxiliary language model to corrupt text sequences, upon which it constructs two new tasks for pretraining the main model. the first token-level task, corrective language modeling, is to detect and correct tokens replaced by the auxiliary model, in order to better capture token-level semantics. the second sequence-level task, sequence contrastive learning, is to align text sequences originated from the same source input while ensuring uniformity in the representation space. experiments on glue and squad demonstrate that coco-lm not only outperforms recent state-of-the-art pretrained models in accuracy, but also improves pretraining efficiency. it achieves the mnli accuracy of electra with 50% of its pretraining gpu hours. with the same pretraining steps of standard base\/large-sized models, coco-lm outperforms the previous best models by 1+ glue average points. ","1368":"we translate a closed text that is known in advance and available in many languages into a new and severely low resource language. most human translation efforts adopt a portion-based approach to translate consecutive pages\/chapters in order, which may not suit machine translation. we compare the portion-based approach that optimizes coherence of the text locally with the random sampling approach that increases coverage of the text globally. our results show that the random sampling approach performs better. when training on a seed corpus of ~1,000 lines from the bible and testing on the rest of the bible (~30,000 lines), random sampling gives a performance gain of +11.0 bleu using english as a simulated low resource language, and +4.9 bleu using eastern pokomchi, a mayan language. furthermore, we compare three ways of updating machine translation models with increasing amount of human post-edited data through iterations. we find that adding newly post-edited data to training after vocabulary update without self-supervision performs the best. we propose an algorithm for human and machine to work together seamlessly to translate a closed text into a severely low resource language. ","1369":"word sense disambiguation (wsd) aims to automatically identify the exact meaning of one word according to its context. existing supervised models struggle to make correct predictions on rare word senses due to limited training data and can only select the best definition sentence from one predefined word sense inventory (e.g., wordnet). to address the data sparsity problem and generalize the model to be independent of one predefined inventory, we propose a gloss alignment algorithm that can align definition sentences (glosses) with the same meaning from different sense inventories to collect rich lexical knowledge. we then train a model to identify semantic equivalence between a target word in context and one of its glosses using these aligned inventories, which exhibits strong transfer capability to many wsd tasks. experiments on benchmark datasets show that the proposed method improves predictions on both frequent and rare word senses, outperforming prior work by 1.2% on the all-words wsd task and 4.3% on the low-shot wsd task. evaluation on wic task also indicates that our method can better capture word meanings in context. ","1370":"despite success in many domains, neural models struggle in settings where train and test examples are drawn from different distributions. in particular, in contrast to humans, conventional sequence-to-sequence (seq2seq) models fail to generalize systematically, i.e., interpret sentences representing novel combinations of concepts (e.g., text segments) seen in training. traditional grammar formalisms excel in such settings by implicitly encoding alignments between input and output segments, but are hard to scale and maintain. instead of engineering a grammar, we directly model segment-to-segment alignments as discrete structured latent variables within a neural seq2seq model. to efficiently explore the large space of alignments, we introduce a reorder-first align-later framework whose central component is a neural reordering module producing {\\it separable} permutations. we present an efficient dynamic programming algorithm performing exact marginal inference of separable permutations, and, thus, enabling end-to-end differentiable training of our model. the resulting seq2seq model exhibits better systematic generalization than standard models on synthetic problems and nlp tasks (i.e., semantic parsing and machine translation). ","1371":"the growing use of social media has led to the development of several machine learning (ml) and natural language processing(nlp) tools to process the unprecedented amount of social media content to make actionable decisions. however, these mland nlp algorithms have been widely shown to be vulnerable to adversarial attacks. these vulnerabilities allow adversaries to launch a diversified set of adversarial attacks on these algorithms in different applications of social media text processing. in this paper, we provide a comprehensive review of the main approaches for adversarial attacks and defenses in the context of social media applications with a particular focus on key challenges and future research directions. in detail, we cover literature on six key applications, namely (i) rumors detection, (ii) satires detection, (iii) clickbait & spams identification, (iv) hate speech detection, (v)misinformation detection, and (vi) sentiment analysis. we then highlight the concurrent and anticipated future research questions and provide recommendations and directions for future work. ","1372":"diachronic text mining has frequently been applied to long-term linguistic surveys of word meaning and usage shifts over time. in this paper we apply short-term diachronic text mining to a rapidly growing corpus of scientific publications on covid-19 captured in the cord-19 dataset in order to identify co-occurrences and analyze the behavior of potential candidate treatments. we used a data set associated with a covid-19 drug re-purposing study from oak ridge national laboratory. this study identified existing candidate coronavirus treatments, including drugs and approved compounds, which had been analyzed and ranked according to their potential for blocking the ability of the sars-cov-2 virus to invade human cells. we investigated the occurrence of these candidates in temporal instances of the cord-19 corpus. we found that at least 25% of the identified terms occurred in temporal instances of the corpus to the extent that their frequency and contextual dynamics could be evaluated. we identified three classes of behaviors: those where frequency and contextual shifts were small and positively correlated; those where there was no correlation between frequency and contextual changes; and those where there was a negative correlation between frequency and contextual shift. we speculate that the latter two patterns are indicative that a target candidate therapeutics is undergoing active evaluation. the patterns we detected demonstrate the potential benefits of using diachronic text mining techniques with a large dynamic text corpus to track drug-repurposing activities across international clinical and laboratory settings. ","1373":"selective rationalization explains the prediction of complex neural networks by finding a small subset of the input that is sufficient to predict the neural model output. the selection mechanism is commonly integrated into the model itself by specifying a two-component cascaded system consisting of a rationale generator, which makes a binary selection of the input features (which is the rationale), and a predictor, which predicts the output based only on the selected features. the components are trained jointly to optimize prediction performance. in this paper, we reveal a major problem with such cooperative rationalization paradigm -- model interlocking. interlocking arises when the predictor overfits to the features selected by the generator thus reinforcing the generator's selection even if the selected rationales are sub-optimal. the fundamental cause of the interlocking problem is that the rationalization objective to be minimized is concave with respect to the generator's selection policy. we propose a new rationalization framework, called a2r, which introduces a third component into the architecture, a predictor driven by soft attention as opposed to selection. the generator now realizes both soft and hard attention over the features and these are fed into the two different predictors. while the generator still seeks to support the original predictor performance, it also minimizes a gap between the two predictors. as we will show theoretically, since the attention-based predictor exhibits a better convexity property, a2r can overcome the concavity barrier. our experiments on two synthetic benchmarks and two real datasets demonstrate that a2r can significantly alleviate the interlock problem and find explanations that better align with human judgments. we release our code at https:\/\/github.com\/gorov\/understanding_interlocking. ","1374":"speech-to-speech translation combines machine translation with speech synthesis, introducing evaluation challenges not present in either task alone. how to automatically evaluate speech-to-speech translation is an open question which has not previously been explored. translating to speech rather than to text is often motivated by unwritten languages or languages without standardized orthographies. however, we show that the previously used automatic metric for this task is best equipped for standardized high-resource languages only. in this work, we first evaluate current metrics for speech-to-speech translation, and second assess how translation to dialectal variants rather than to standardized languages impacts various evaluation methods. ","1375":"self-supervised speech representation learning (speech ssl) has demonstrated the benefit of scale in learning rich representations for automatic speech recognition (asr) with limited paired data, such as wav2vec 2.0. we investigate the existence of sparse subnetworks in pre-trained speech ssl models that achieve even better low-resource asr results. however, directly applying widely adopted pruning methods such as the lottery ticket hypothesis (lth) is suboptimal in the computational cost needed. moreover, we show that the discovered subnetworks yield minimal performance gain compared to the original dense network. we present prune-adjust-re-prune (parp), which discovers and finetunes subnetworks for much better performance, while only requiring a single downstream asr finetuning run. parp is inspired by our surprising observation that subnetworks pruned for pre-training tasks need merely a slight adjustment to achieve a sizeable performance boost in downstream asr tasks. extensive experiments on low-resource asr verify (1) sparse subnetworks exist in mono-lingual\/multi-lingual pre-trained speech ssl, and (2) the computational advantage and performance gain of parp over baseline pruning methods. in particular, on the 10min librispeech split without lm decoding, parp discovers subnetworks from wav2vec 2.0 with an absolute 10.9%\/12.6% wer decrease compared to the full model. we further demonstrate the effectiveness of parp via: cross-lingual pruning without any phone recognition degradation, the discovery of a multi-lingual subnetwork for 10 spoken languages in 1 finetuning run, and its applicability to pre-trained bert\/xlnet for natural language tasks. ","1376":"automated story generation remains a difficult area of research because it lacks strong objective measures. generated stories may be linguistically sound, but in many cases suffer poor narrative coherence required for a compelling, logically-sound story. to address this, we present fabula entropy indexing (fei), an evaluation method to assess story coherence by measuring the degree to which human participants agree with each other when answering true\/false questions about stories. we devise two theoretically grounded measures of reader question-answering entropy, the entropy of world coherence (ewc), and the entropy of transitional coherence (etc), focusing on global and local coherence, respectively. we evaluate these metrics by testing them on human-written stories and comparing against the same stories that have been corrupted to introduce incoherencies. we show that in these controlled studies, our entropy indices provide a reliable objective measure of story coherence. ","1377":"recent advances in large-scale language models (raffel et al., 2019; brown et al., 2020) have brought significant qualitative and quantitative improvements in machine-driven text generation. despite this, generation and evaluation of machine-generated narrative text remains a challenging problem. objective evaluation of computationally-generated stories may be prohibitively expensive, require meticulously annotated datasets, or may not adequately measure the logical coherence of a generated story's narratological structure.   informed by recent advances in contrastive learning (radford et al., 2021), we present contrastive authoring and reviewing pairing (carp): a scalable, efficient method for performing qualitatively superior, zero-shot evaluation of stories. we show a strong correlation between human evaluation of stories and those of carp. model outputs more significantly correlate with corresponding human input than those language-model based methods which utilize finetuning or prompt engineering approaches. we also present and analyze the story-critique dataset, a new corpora composed of 1.3 million aligned story-critique pairs derived from over 80,000 stories. we expect this corpus to be of interest to nlp researchers. ","1378":"the distances between words calculated in word units are studied and compared with the distributions of the random matrix theory (rmt). it is found that the distribution of distance between the same words can be well described by the single-parameter brody distribution. using the brody distribution fit, we found that the distance between given words in a set of texts can show mixed dynamics, coexisting regular and chaotic regimes. it is found that distributions correctly fitted by the brody distribution with a certain goodness of the fit threshold can be identifid as stop words, usually considered as the uninformative part of the text. by applying various threshold values for the goodness of fit, we can extract uninformative words from the texts under analysis to the desired extent. on this basis we formulate a fully agnostic recipe that can be used in the creation of a customized set of stop words for texts in any language based on words. ","1379":"neural networks have achieved success in a wide array of perceptual tasks but often fail at tasks involving both perception and higher-level reasoning. on these more challenging tasks, bespoke approaches (such as modular symbolic components, independent dynamics models or semantic parsers) targeted towards that specific type of task have typically performed better. the downside to these targeted approaches, however, is that they can be more brittle than general-purpose neural networks, requiring significant modification or even redesign according to the particular task at hand. here, we propose a more general neural-network-based approach to dynamic visual reasoning problems that obtains state-of-the-art performance on three different domains, in each case outperforming bespoke modular approaches tailored specifically to the task. our method relies on learned object-centric representations, self-attention and self-supervised dynamics learning, and all three elements together are required for strong performance to emerge. the success of this combination suggests that there may be no need to trade off flexibility for performance on problems involving spatio-temporal or causal-style reasoning. with the right soft biases and learning objectives in a neural network we may be able to attain the best of both worlds. ","1380":"our world is open-ended, non-stationary, and constantly evolving; thus what we talk about and how we talk about it change over time. this inherent dynamic nature of language contrasts with the current static language modelling paradigm, which trains and evaluates models on utterances from overlapping time periods. despite impressive recent progress, we demonstrate that transformer-xl language models perform worse in the realistic setup of predicting future utterances from beyond their training period, and that model performance becomes increasingly worse with time. we find that, while increasing model size alone -- a key driver behind recent progress -- does not solve this problem, having models that continually update their knowledge with new information can indeed mitigate this performance degradation over time. hence, given the compilation of ever-larger language modelling datasets, combined with the growing list of language-model-based nlp applications that require up-to-date factual knowledge about the world, we argue that now is the right time to rethink the static way in which we currently train and evaluate our language models, and develop adaptive language models that can remain up-to-date with respect to our ever-changing and non-stationary world. we publicly release our dynamic, streaming language modelling benchmarks for wmt and arxiv to facilitate language model evaluation that takes temporal dynamics into account. ","1381":"recent impressive improvements in nlp, largely based on the success of contextual neural language models, have been mostly demonstrated on at most a couple dozen high-resource languages. building language models and, more generally, nlp systems for non-standardized and low-resource languages remains a challenging task. in this work, we focus on north-african colloquial dialectal arabic written using an extension of the latin script, called narabizi, found mostly on social media and messaging communication. in this low-resource scenario with data displaying a high level of variability, we compare the downstream performance of a character-based language model on part-of-speech tagging and dependency parsing to that of monolingual and multilingual models. we show that a character-based model trained on only 99k sentences of narabizi and fined-tuned on a small treebank of this language leads to performance close to those obtained with the same architecture pre-trained on large multilingual and monolingual models. confirming these results a on much larger data set of noisy french user-generated content, we argue that such character-based language models can be an asset for nlp in low-resource and high language variability set-tings. ","1382":"large language models (lms) are known to encode world knowledge in their parameters as they pretrain on a vast amount of web corpus, which is often utilized for performing knowledge-dependent downstream tasks such as question answering, fact-checking, and open dialogue. in real-world scenarios, the world knowledge stored in the lms can quickly become outdated as the world changes, but it is non-trivial to avoid catastrophic forgetting and reliably acquire new knowledge while preserving invariant knowledge. to push the community towards better maintenance of ever-changing lms, we formulate a new continual learning (cl) problem called continual knowledge learning (ckl). we construct a new benchmark and metric to quantify the retention of time-invariant world knowledge, the update of outdated knowledge, and the acquisition of new knowledge. we adopt applicable recent methods from literature to create several strong baselines. through extensive experiments, we find that ckl exhibits unique challenges that are not addressed in previous cl setups, where parameter expansion is necessary to reliably retain and learn knowledge simultaneously. by highlighting the critical causes of knowledge forgetting, we show that ckl is a challenging and important problem that helps us better understand and train ever-changing lms. the benchmark datasets, evaluation script, and baseline code to reproduce our results are available at https:\/\/github.com\/joeljang\/continual-knowledge-learning. ","1383":"unsupervised pretraining is an integral part of many natural language processing systems, and transfer learning with language models has achieved remarkable results in many downstream tasks. in the clinical application of medical code assignment, diagnosis and procedure codes are inferred from lengthy clinical notes such as hospital discharge summaries. however, it is not clear if pretrained models are useful for medical code prediction without further architecture engineering. this paper conducts a comprehensive quantitative analysis of various contextualized language models' performance, pretrained in different domains, for medical code assignment from clinical notes. we propose a hierarchical fine-tuning architecture to capture interactions between distant words and adopt label-wise attention to exploit label information. contrary to current trends, we demonstrate that a carefully trained classical cnn outperforms attention-based models on a mimic-iii subset with frequent codes. our empirical findings suggest directions for improving the medical code assignment application. ","1384":"most current affect scales and sentiment analysis on written text focus on quantifying valence (sentiment) -- the most primary dimension of emotion. however, emotions are broader and more complex than valence. distinguishing negative emotions of similar valence could be important in contexts such as mental health. this project proposes a semi-supervised machine learning model (dasentimental) to extract depression, anxiety and stress from written text. first, we trained the model to spot how sequences of recalled emotion words by $n=200$ individuals correlated with their responses to the depression anxiety stress scale (dass-21). within the framework of cognitive network science, we model every list of recalled emotions as a walk over a networked mental representation of semantic memory, with emotions connected according to free associations in people's memory. among several tested machine learning approaches, we find that a multilayer perceptron neural network trained on word sequences and semantic network distances can achieve state-of-art, cross-validated predictions for depression ($r = 0.7$), anxiety ($r = 0.44$) and stress ($r = 0.52$). though limited by sample size, this first-of-its-kind approach enables quantitative explorations of key semantic dimensions behind das levels. we find that semantic distances between recalled emotions and the dyad \"sad-happy\" are crucial features for estimating depression levels but are less important for anxiety and stress. we also find that semantic distance of recalls from \"fear\" can boost the prediction of anxiety but it becomes redundant when the \"sad-happy\" dyad is considered. adopting dasentimental as a semi-supervised learning tool to estimate das in text, we apply it to a dataset of 142 suicide notes. we conclude by discussing key directions for future research enabled by artificial intelligence detecting stress, anxiety and depression. ","1385":"most of the existing work that focus on the identification of implicit knowledge in arguments generally represent implicit knowledge in the form of commonsense or factual knowledge. however, such knowledge is not sufficient to understand the implicit reasoning link between individual argumentative components (i.e., claim and premise). in this work, we focus on identifying the implicit knowledge in the form of argumentation knowledge which can help in understanding the reasoning link in arguments. being inspired by the argument from consequences scheme, we propose a semi-structured template to represent such argumentation knowledge that explicates the implicit reasoning in arguments via causality. we create a novel two-phase annotation process with simplified guidelines and show how to collect and filter high-quality implicit reasonings via crowdsourcing. we find substantial inter-annotator agreement for quality evaluation between experts, but find evidence that casts a few questions on the feasibility of collecting high-quality semi-structured implicit reasoning through our crowdsourcing process. we release our materials(i.e., crowdsourcing guidelines and collected implicit reasonings) to facilitate further research towards the structured representation of argumentation knowledge. ","1386":"intent classification (ic) and slot filling (sf) are critical building blocks in task-oriented dialogue systems. these two tasks are closely-related and can flourish each other. since only a few utterances can be utilized for identifying fast-emerging new intents and slots, data scarcity issue often occurs when implementing ic and sf. however, few ic\/sf models perform well when the number of training samples per class is quite small. in this paper, we propose a novel explicit-joint and supervised-contrastive learning framework for few-shot intent classification and slot filling. its highlights are as follows. (i) the model extracts intent and slot representations via bidirectional interactions, and extends prototypical network to achieve explicit-joint learning, which guarantees that ic and sf tasks can mutually reinforce each other. (ii) the model integrates with supervised contrastive learning, which ensures that samples from same class are pulled together and samples from different classes are pushed apart. in addition, the model follows a not common but practical way to construct the episode, which gets rid of the traditional setting with fixed way and shot, and allows for unbalanced datasets. extensive experiments on three public datasets show that our model can achieve promising performance. ","1387":"constructing large-scaled medical knowledge graphs can significantly boost healthcare applications for medical surveillance, bring much attention from recent research. an essential step in constructing large-scale mkg is extracting information from medical reports. recently, information extraction techniques have been proposed and show promising performance in biomedical information extraction. however, these methods only consider limited types of entity and relation due to the noisy biomedical text data with complex entity correlations. thus, they fail to provide enough information for constructing mkgs and restrict the downstream applications. to address this issue, we propose biomedical information extraction, a hybrid neural network to extract relations from biomedical text and unstructured medical reports. our model utilizes a multi-head attention enhanced graph convolutional network to capture the complex relations and context information while resisting the noise from the data. we evaluate our model on two major biomedical relationship extraction tasks, chemical-disease relation and chemical-protein interaction, and a cross-hospital pan-cancer pathology report corpus. the results show that our method achieves superior performance than baselines. furthermore, we evaluate the applicability of our method under a transfer learning setting and show that bioie achieves promising performance in processing medical text from different formats and writing styles. ","1388":"pretrained bidirectional transformers, such as bert, have achieved significant improvements in a wide variety of language understanding tasks, while it is not straightforward to directly apply them for natural language generation. in this paper, we present a sequence-to-sequence fine-tuning toolkit s2s-ft, which adopts pretrained transformers for conditional generation tasks. inspired by unilm, we implement three sequence-to-sequence fine-tuning algorithms, namely, causal fine-tuning, masked fine-tuning, and pseudo-masked fine-tuning. by leveraging the existing pretrained bidirectional transformers, experimental results show that s2s-ft achieves strong performance on several benchmarks of abstractive summarization, and question generation. moreover, we demonstrate that the package s2s-ft supports both monolingual and multilingual nlg tasks. the s2s-ft toolkit is available at https:\/\/github.com\/microsoft\/unilm\/tree\/master\/s2s-ft. ","1389":"reasoning machine reading comprehension (r-mrc) aims to answer complex questions that require discrete reasoning based on text. to support discrete reasoning, evidence, typically the concise textual fragments that describe question-related facts, including topic entities and attribute values, are crucial clues from question to answer. however, previous end-to-end methods that achieve state-of-the-art performance rarely solve the problem by paying enough emphasis on the modeling of evidence, missing the opportunity to further improve the model's reasoning ability for r-mrc. to alleviate the above issue, in this paper, we propose an evidence-emphasized discrete reasoning approach (evidr), in which sentence and clause level evidence is first detected based on distant supervision, and then used to drive a reasoning module implemented with a relational heterogeneous graph convolutional network to derive answers. extensive experiments are conducted on drop (discrete reasoning over paragraphs) dataset, and the results demonstrate the effectiveness of our proposed approach. in addition, qualitative analysis verifies the capability of the proposed evidence-emphasized discrete reasoning for r-mrc. ","1390":"data augmentation has attracted a lot of research attention in the deep learning era for its ability in alleviating data sparseness. the lack of labeled data for unseen evaluation databases is exactly the major challenge for cross-domain text-to-sql parsing. previous works either require human intervention to guarantee the quality of generated data, or fail to handle complex sql queries. this paper presents a simple yet effective data augmentation framework. first, given a database, we automatically produce a large number of sql queries based on an abstract syntax tree grammar. for better distribution matching, we require that at least 80% of sql patterns in the training data are covered by generated queries. second, we propose a hierarchical sql-to-question generation model to obtain high-quality natural language questions, which is the major contribution of this work. finally, we design a simple sampling strategy that can greatly improve training efficiency given large amounts of generated data. experiments on three cross-domain datasets, i.e., wikisql and spider in english, and dusql in chinese, show that our proposed data augmentation framework can consistently improve performance over strong baselines, and the hierarchical generation component is the key for the improvement. ","1391":"rules have a number of desirable properties. it is easy to understand, infer new knowledge, and communicate with other inference systems. one weakness of the previous rule induction systems is that they only find rules within a knowledge base (kb) and therefore cannot generalize to more open and complex real-world rules. recently, the language model (lm)-based rule generation are proposed to enhance the expressive power of the rules. in this paper, we revisit the differences between kb-based rule induction and lm-based rule generation. we argue that, while kb-based methods inducted rules by discovering data commonalities, the current lm-based methods are \"learning rules from rules\". this limits these methods to only produce \"canned\" rules whose patterns are constrained by the annotated rules, while discarding the rich expressive power of lms for free text.   therefore, in this paper, we propose the open rule induction problem, which aims to induce open rules utilizing the knowledge in lms. besides, we propose the orion (\\underline{o}pen \\underline{r}ule \\underline{i}nducti\\underline{on}) system to automatically mine open rules from lms without supervision of annotated rules. we conducted extensive experiments to verify the quality and quantity of the inducted open rules. surprisingly, when applying the open rules in downstream tasks (i.e. relation extraction), these automatically inducted rules even outperformed the manually annotated rules. ","1392":"the current mode of use of electronic health record (ehr) elicits text redundancy. clinicians often populate new documents by duplicating existing notes, then updating accordingly. data duplication can lead to a propagation of errors, inconsistencies and misreporting of care. therefore, quantifying information redundancy can play an essential role in evaluating innovations that operate on clinical narratives.   this work is a quantitative examination of information redundancy in ehr notes. we present and evaluate two strategies to measure redundancy: an information-theoretic approach and a lexicosyntactic and semantic model. we evaluate the measures by training large transformer-based language models using clinical text from a large openly available us-based icu dataset and a large multi-site uk based trust. by comparing the information-theoretic content of the trained models with open-domain language models, the language models trained using clinical text have shown ~1.5x to ~3x less efficient than open-domain corpora. manual evaluation shows a high correlation with lexicosyntactic and semantic redundancy, with averages ~43 to ~65%. ","1393":"this study develops a calibrated beam-based algorithm with awareness of the global attention distribution for neural abstractive summarization, aiming to improve the local optimality problem of the original beam search in a rigorous way. specifically, a novel global protocol is proposed based on the attention distribution to stipulate how a global optimal hypothesis should attend to the source. a global scoring mechanism is then developed to regulate beam search to generate summaries in a near-global optimal fashion. this novel design enjoys a distinctive property, i.e., the global attention distribution could be predicted before inference, enabling step-wise improvements on the beam search through the global scoring mechanism. extensive experiments on nine datasets show that the global (attention)-aware inference significantly improves state-of-the-art summarization models even using empirical hyper-parameters. the algorithm is also proven robust as it remains to generate meaningful texts with corrupted attention distributions. the codes and a comprehensive set of examples are available. ","1394":"contracts are a common type of legal document that frequent in several day-to-day business workflows. however, there has been very limited nlp research in processing such documents, and even lesser in generating them. these contracts are made up of clauses, and the unique nature of these clauses calls for specific methods to understand and generate such documents. in this paper, we introduce the task of clause recommendation, asa first step to aid and accelerate the author-ing of contract documents. we propose a two-staged pipeline to first predict if a specific clause type is relevant to be added in a contract, and then recommend the top clauses for the given type based on the contract context. we pretrain bert on an existing library of clauses with two additional tasks and use it for our prediction and recommendation. we experiment with classification methods and similarity-based heuristics for clause relevance prediction, and generation-based methods for clause recommendation, and evaluate the results from various methods on several clause types. we provide analyses on the results, and further outline the advantages and limitations of the various methods for this line of research. ","1395":"we study the problem of quantitative facts extraction for text with percentages. for example, given the sentence \"30 percent of americans like watching football, while 20% prefer to watch nba.\", our goal is to obtain a deep understanding of the percentage numbers (\"30 percent\" and \"20%\") by extracting their quantitative facts: part (\"like watching football\" and \"prefer to watch nba\") and whole (\"americans). these quantitative facts can empower new applications like automated infographic generation. we formulate part and whole extraction as a sequence tagging problem. due to the large gap between part\/whole and its corresponding percentage, we introduce skip mechanism in sequence modeling, and achieved improved performance on both our task and the conll-2003 named entity recognition task. experimental results demonstrate that learning to skip in sequence tagging is promising. ","1396":"the premises of an argument give evidence or other reasons to support a conclusion. however, the amount of support required depends on the generality of a conclusion, the nature of the individual premises, and similar. an argument whose premises make its conclusion rationally worthy to be drawn is called sufficient in argument quality research. previous work tackled sufficiency assessment as a standard text classification problem, not modeling the inherent relation of premises and conclusion. in this paper, we hypothesize that the conclusion of a sufficient argument can be generated from its premises. to study this hypothesis, we explore the potential of assessing sufficiency based on the output of large-scale pre-trained language models. our best model variant achieves an f1-score of .885, outperforming the previous state-of-the-art and being on par with human experts. while manual evaluation reveals the quality of the generated conclusions, their impact remains low ultimately. ","1397":"simultaneous translation is a task in which translation begins before the speaker has finished speaking, so it is important to decide when to start the translation process. however, deciding whether to read more input words or start to translate is difficult for language pairs with different word orders such as english and japanese. motivated by the concept of pre-reordering, we propose a couple of simple decision rules using the label of the next constituent predicted by incremental constituent label prediction. in experiments on english-to-japanese simultaneous translation, the proposed method outperformed baselines in the quality-latency trade-off. ","1398":"in this paper, inspired by the successes of visionlanguage pre-trained models and the benefits from training with adversarial attacks, we present a novel transformerbased cross-modal fusion modeling by incorporating the both notions for vqa challenge 2021. specifically, the proposed model is on top of the architecture of vinvl model [19], and the adversarial training strategy [4] is applied to make the model robust and generalized. moreover, two implementation tricks are also used in our system to obtain better results. the experiments demonstrate that the novel framework can achieve 76.72% on vqav2 test-std set. ","1399":"multi-hop qa requires the machine to answer complex questions through finding multiple clues and reasoning, and provide explanatory evidence to demonstrate the machine reasoning process. we propose relation extractor-reader and comparator (rerc), a three-stage framework based on complex question decomposition, which is the first work that the rerc model has been proposed and applied in solving the multi-hop qa challenges. the relation extractor decomposes the complex question, and then the reader answers the sub-questions in turn, and finally the comparator performs numerical comparison and summarizes all to get the final answer, where the entire process itself constitutes a complete reasoning evidence path. in the 2wikimultihopqa dataset, our rerc model has achieved the most advanced performance, with a winning joint f1 score of 53.58 on the leaderboard. all indicators of our rerc are close to human performance, with only 1.95 behind the human level in f1 score of support fact. at the same time, the evidence path provided by our rerc framework has excellent readability and faithfulness. ","1400":"we investigate the problem of chinese grammatical error correction (cgec) and present a new framework named tail-to-tail (\\textbf{ttt}) non-autoregressive sequence prediction to address the deep issues hidden in cgec. considering that most tokens are correct and can be conveyed directly from source to target, and the error positions can be estimated and corrected based on the bidirectional context information, thus we employ a bert-initialized transformer encoder as the backbone model to conduct information modeling and conveying. considering that only relying on the same position substitution cannot handle the variable-length correction cases, various operations such substitution, deletion, insertion, and local paraphrasing are required jointly. therefore, a conditional random fields (crf) layer is stacked on the up tail to conduct non-autoregressive sequence prediction by modeling the token dependencies. since most tokens are correct and easily to be predicted\/conveyed to the target, then the models may suffer from a severe class imbalance issue. to alleviate this problem, focal loss penalty strategies are integrated into the loss functions. moreover, besides the typical fix-length error correction datasets, we also construct a variable-length corpus to conduct experiments. experimental results on standard datasets, especially on the variable-length datasets, demonstrate the effectiveness of ttt in terms of sentence-level accuracy, precision, recall, and f1-measure on tasks of error detection and correction. ","1401":"continuous speech separation using a microphone array was shown to be promising in dealing with the speech overlap problem in natural conversation transcription. this paper proposes vararray, an array-geometry-agnostic speech separation neural network model. the proposed model is applicable to any number of microphones without retraining while leveraging the nonlinear correlation between the input channels. the proposed method adapts different elements that were proposed before separately, including transform-average-concatenate, conformer speech separation, and inter-channel phase differences, and combines them in an efficient and cohesive way. large-scale evaluation was performed with two real meeting transcription tasks by using a fully developed transcription system requiring no prior knowledge such as reference segmentations, which allowed us to measure the impact that the continuous speech separation system could have in realistic settings. the proposed model outperformed a previous approach to array-geometry-agnostic modeling for all of the geometry configurations considered, achieving asclite-based speaker-agnostic word error rates of 17.5% and 20.4% for the ami development and evaluation sets, respectively, in the end-to-end setting using no ground-truth segmentations. ","1402":"during the fine-tuning phase of transfer learning, the pretrained vocabulary remains unchanged, while model parameters are updated. the vocabulary generated based on the pretrained data is suboptimal for downstream data when domain discrepancy exists. we propose to consider the vocabulary as an optimizable parameter, allowing us to update the vocabulary by expanding it with domain-specific vocabulary based on a tokenization statistic. furthermore, we preserve the embeddings of the added words from overfitting to downstream data by utilizing knowledge learned from a pretrained language model with a regularization term. our method achieved consistent performance improvements on diverse domains (i.e., biomedical, computer science, news, and reviews). ","1403":"although deep learning models have driven state-of-the-art performance on a wide array of tasks, they are prone to spurious correlations that should not be learned as predictive clues. to mitigate this problem, we propose a causality-based training framework to reduce the spurious correlations caused by observed confounders. we give theoretical analysis on the underlying general structural causal model (scm) and propose to perform maximum likelihood estimation (mle) on the interventional distribution instead of the observational distribution, namely counterfactual maximum likelihood estimation (cmle). as the interventional distribution, in general, is hidden from the observational data, we then derive two different upper bounds of the expected negative log-likelihood and propose two general algorithms, implicit cmle and explicit cmle, for causal predictions of deep learning models using observational data. we conduct experiments on both simulated data and two real-world tasks: natural language inference (nli) and image captioning. the results show that cmle methods outperform the regular mle method in terms of out-of-domain generalization performance and reducing spurious correlations, while maintaining comparable performance on the regular evaluations. ","1404":"this manuscript provides general descriptions on transliteration of foreign words in the burmese language. phenomena caused by phonetic and orthographic issues are discussed. based on this work, we expect to gradually establish prescriptive guidelines to normalize the transliteration on modern words in burmese. ","1405":"aspect-based sentiment analysis (absa) aims to determine the sentiment polarity towards an aspect. because of the expensive and limited labelled data, the pretraining strategy has become the de-facto standard for absa. however, there always exists severe domain shift between the pretraining and downstream absa datasets, hindering the effective knowledge transfer when directly finetuning and making the downstream task performs sub-optimal. to mitigate such domain shift, we introduce a unified alignment pretraining framework into the vanilla pretrain-finetune pipeline with both instance- and knowledge-level alignments. specifically, we first devise a novel coarse-to-fine retrieval sampling approach to select target domain-related instances from the large-scale pretraining dataset, thus aligning the instances between pretraining and target domains (\\textit{first stage}). then, we introduce a knowledge guidance-based strategy to further bridge the domain gap at the knowledge level. in practice, we formulate the model pretrained on the sampled instances into a knowledge guidance model and a learner model, respectively. on the target dataset, we design an on-the-fly teacher-student joint fine-tuning approach to progressively transfer the knowledge from the knowledge guidance model to the learner model (\\textit{second stage}). thereby, the learner model can maintain more domain-invariant knowledge when learning new knowledge from the target dataset. in the \\textit{third stage,} the learner model is finetuned to better adapt its learned knowledge to the target dataset. extensive experiments and analyses on several absa benchmarks demonstrate the effectiveness and universality of our proposed pretraining framework. notably, our pretraining framework pushes several strong baseline models up to the new state-of-the-art records. we release our code and models. ","1406":"two task-specific dependency-based word embedding methods are proposed for text classification in this work. in contrast with universal word embedding methods that work for generic tasks, we design task-specific word embedding methods to offer better performance in a specific task. our methods follow the ppmi matrix factorization framework and derive word contexts from the dependency parse tree. the first one, called the dependency-based word embedding (dwe), chooses keywords and neighbor words of a target word in the dependency parse tree as contexts to build the word-context matrix. the second method, named class-enhanced dependency-based word embedding (cedwe), learns from word-context as well as word-class co-occurrence statistics. dwe and cedwe are evaluated on popular text classification datasets to demonstrate their effectiveness. it is shown by experimental results they outperform several state-of-the-art word embedding methods. ","1407":"the learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating convergence and improving generalization for adaptive stochastic optimization algorithms like rmsprop and adam. here, we study its mechanism in details. pursuing the theory behind warmup, we identify a problem of the adaptive learning rate (i.e., it has problematically large variance in the early stage), suggest warmup works as a variance reduction technique, and provide both empirical and theoretical evidence to verify our hypothesis. we further propose radam, a new variant of adam, by introducing a term to rectify the variance of the adaptive learning rate. extensive experimental results on image classification, language modeling, and neural machine translation verify our intuition and demonstrate the effectiveness and robustness of our proposed method. all implementations are available at: https:\/\/github.com\/liyuanlucasliu\/radam. ","1408":"understanding robustness and sensitivity of bert models predicting alzheimer's disease from text is important for both developing better classification models and for understanding their capabilities and limitations. in this paper, we analyze how a controlled amount of desired and undesired text alterations impacts performance of bert. we show that bert is robust to natural linguistic variations in text. on the other hand, we show that bert is not sensitive to removing clinically important information from text. ","1409":"the fourth industrial revolution (4ir) is likely to have a substantial impact on the economy. companies need to build up capabilities to implement new technologies, and automation may make some occupations obsolete. however, where, when, and how the change will happen remain to be determined. robust empirical indicators of technological progress linked to occupations can help to illuminate this change. with this aim, we provide such an indicator based on patent data. using natural language processing, we calculate patent exposure scores for more than 900 occupations, which represent the technological progress related to them. to provide a lens on the impact of the 4ir, we differentiate between traditional and 4ir patent exposure. our method differs from previous approaches in that it both accounts for the diversity of task-level patent exposures within an occupation and reflects work activities more accurately. we find that exposure to 4ir patents differs from traditional patent exposure. manual tasks, and accordingly occupations such as construction and production, are exposed mainly to traditional (non-4ir) patents but have low exposure to 4ir patents. the analysis suggests that 4ir technologies may have a negative impact on job growth; this impact appears 10 to 20 years after patent filing. further, we compared the 4ir exposure to other automation and ai exposure scores. whereas many measures refer to theoretical automation potential, our patent-based indicator reflects actual technology diffusion. our work not only allows analyses of the impact of 4ir technologies as a whole, but also provides exposure scores for more than 300 technology fields, such as ai and smart office technologies. finally, the work provides a general mapping of patents to tasks and occupations, which enables future researchers to construct individual exposure measures. ","1410":"attribute extrapolation in sample generation is challenging for deep neural networks operating beyond the training distribution. we formulate a new task for extrapolation in sequence generation, focusing on natural language and proteins, and propose genhance, a generative framework that enhances attributes through a learned latent space. trained on movie reviews and a computed protein stability dataset, genhance can generate strongly-positive text reviews and highly stable protein sequences without being exposed to similar data during training. we release our benchmark tasks and models to contribute to the study of generative modeling extrapolation and data-driven design in biology and chemistry. ","1411":"the shout crisis text line provides individuals undergoing mental health crises an opportunity to have an anonymous text message conversation with a trained crisis volunteer (cv). this project partners with shout and its parent organisation, mental health innovations, to explore the applications of machine learning in understanding shout's conversations and improving its service. the overarching aim of this project is to develop a proof-of-concept model to demonstrate the potential of applying deep learning to crisis text messages.   specifically, this project aims to use deep learning to (1) predict an individual's risk of suicide or self-harm, (2) assess conversation success and cv skill using robust metrics, and (3) extrapolate demographic information from a texter survey to conversations where the texter did not complete the survey. to these ends, contributions to deep learning include a modified transformer-over-bert model; a framework for multitask learning to improve generalisation in the presence of sparse labels; and a mathematical model for using imperfect machine learning models to estimate population parameters from a biased training set.   key results include a deep learning model with likely better performance at predicting suicide risk than trained cvs and the ability to predict whether a texter is 21 or under with 88.4% accuracy. we produce three metrics for conversation success and evaluate the validity and usefulness for each. finally, reversal of participation bias provides evidence that women, who make up 80.3% of conversations with an associated texter survey, make up closer to 73.5%- 74.8% of all conversations; and that if, after every conversation, the texter had shared whether they found their conversation helpful, affirmative answers would fall from 85.1% to 45.45% - 46.51%. ","1412":"we present a novel technique for zero-shot paraphrase generation. the key contribution is an end-to-end multilingual paraphrasing model that is trained using translated parallel corpora to generate paraphrases into \"meaning spaces\" -- replacing the final softmax layer with word embeddings. this architectural modification, plus a training procedure that incorporates an autoencoding objective, enables effective parameter sharing across languages for more fluent monolingual rewriting, and facilitates fluency and diversity in generation. our continuous-output paraphrase generation models outperform zero-shot paraphrasing baselines when evaluated on two languages using a battery of computational metrics as well as in human assessment. ","1413":"design of dialogue systems has witnessed many advances lately, yet acquiring huge set of data remains an hindrance to their fast development for a new task or language. besides, training interactive systems with batch data is not satisfactory. on-line learning is pursued in this paper as a convenient way to alleviate these difficulties. after the system modules are initiated, a single process handles data collection, annotation and use in training algorithms. a new challenge is to control the cost of the on-line learning borne by the user. our work focuses on learning the semantic parsing and dialogue management modules (speech recognition and synthesis offer ready-for-use solutions). in this context we investigate several variants of simultaneous learning which are tested in user trials. in our experiments, with varying merits, they can all achieve good performance with only a few hundreds of training dialogues and overstep a handcrafted system. the analysis of these experiments gives us some insights, discussed in the paper, into the difficulty for the system's trainers to establish a coherent and constant behavioural strategy to enable a fast and good-quality training phase. ","1414":"this paper describes sciclops, a method to help combat online scientific misinformation. although automated fact-checking methods have gained significant attention recently, they require pre-existing ground-truth evidence, which, in the scientific context, is sparse and scattered across a constantly-evolving scientific literature. existing methods do not exploit this literature, which can effectively contextualize and combat science-related fallacies. furthermore, these methods rarely require human intervention, which is essential for the convoluted and critical domain of scientific misinformation. sciclops involves three main steps to process scientific claims found in online news articles and social media postings: extraction, clustering, and contextualization. first, the extraction of scientific claims takes place using a domain-specific, fine-tuned transformer model. second, similar claims extracted from heterogeneous sources are clustered together with related scientific literature using a method that exploits their content and the connections among them. third, check-worthy claims, broadcasted by popular yet unreliable sources, are highlighted together with an enhanced fact-checking context that includes related verified claims, news articles, and scientific papers. extensive experiments show that sciclops tackles sufficiently these three steps, and effectively assists non-expert fact-checkers in the verification of complex scientific claims, outperforming commercial fact-checking systems. ","1415":"the introduction of pretrained cross-lingual language models brought decisive improvements to multilingual nlp tasks. however, the lack of labelled task data necessitates a variety of methods aiming to close the gap to high-resource languages. zero-shot methods in particular, often use translated task data as a training signal to bridge the performance gap between the source and target language(s). we introduce xeroalign, a simple method for task-specific alignment of cross-lingual pretrained transformers such as xlm-r. xeroalign uses translated task data to encourage the model to generate similar sentence embeddings for different languages. the xeroaligned xlm-r, called xlm-ra, shows strong improvements over the baseline models to achieve state-of-the-art zero-shot results on three multilingual natural language understanding tasks. xlm-ra's text classification accuracy exceeds that of xlm-r trained with labelled data and performs on par with state-of-the-art models on a cross-lingual adversarial paraphrasing task. ","1416":"the quality of artificially generated texts has considerably improved with the advent of transformers. the question of using these models to generate learning data for supervised learning tasks naturally arises. in this article, this question is explored under 3 aspects: (i) are artificial data an efficient complement? (ii) can they replace the original data when those are not available or cannot be distributed for confidentiality reasons? (iii) can they improve the explainability of classifiers? different experiments are carried out on web-related classification tasks -- namely sentiment analysis on product reviews and fake news detection -- using artificially generated data by fine-tuned gpt-2 models. the results show that such artificial data can be used in a certain extend but require pre-processing to significantly improve performance. we show that bag-of-word approaches benefit the most from such data augmentation. ","1417":"in this paper we define and investigate the problem of \\emph{persona authentication}: learning a conversational policy to verify the consistency of persona models. we propose a learning objective and prove (under some mild assumptions) that local density estimators trained under this objective maximize the mutual information between persona information and dialog trajectory. based on the proposed objective, we develop a method of learning an authentication model that adaptively outputs personalized questions to reveal the underlying persona of its partner throughout the course of multi-turn conversation. experiments show that our authentication method discovers effective question sequences that generalize to unseen persona profiles. ","1418":"adversarial example generation has been a hot spot in recent years because it can cause deep neural networks (dnns) to misclassify the generated adversarial examples, which reveals the vulnerability of dnns, motivating us to find good solutions to improve the robustness of dnn models. due to the extensiveness and high liquidity of natural language over the social networks, various natural language based adversarial attack algorithms have been proposed in the literature. these algorithms generate adversarial text examples with high semantic quality. however, the generated adversarial text examples may be maliciously or illegally used. in order to tackle with this problem, we present a general framework for generating watermarked adversarial text examples. for each word in a given text, a set of candidate words are determined to ensure that all the words in the set can be used to either carry secret bits or facilitate the construction of adversarial example. by applying a word-level adversarial text generation algorithm, the watermarked adversarial text example can be finally generated. experiments show that the adversarial text examples generated by the proposed method not only successfully fool advanced dnn models, but also carry a watermark that can effectively verify the ownership and trace the source of the adversarial examples. moreover, the watermark can still survive after attacked with adversarial example generation algorithms, which has shown the applicability and superiority. ","1419":"dialog management (dm) is a crucial component in a task-oriented dialog system. given the dialog history, dm predicts the dialog state and decides the next action that the dialog agent should take. recently, dialog policy learning has been widely formulated as a reinforcement learning (rl) problem, and more works focus on the applicability of dm. in this paper, we survey recent advances and challenges within three critical topics for dm: (1) improving model scalability to facilitate dialog system modeling in new scenarios, (2) dealing with the data scarcity problem for dialog policy learning, and (3) enhancing the training efficiency to achieve better task-completion performance . we believe that this survey can shed a light on future research in dialog management. ","1420":"pretrained multilingual models have become a de facto default approach for zero-shot cross-lingual transfer. previous work has shown that these models are able to achieve cross-lingual representations when pretrained on two or more languages with shared parameters. in this work, we provide evidence that a model can achieve language-agnostic representations even when pretrained on a single language. that is, we find that monolingual models pretrained and finetuned on different languages achieve competitive performance compared to the ones that use the same target language. surprisingly, the models show a similar performance on a same task regardless of the pretraining language. for example, models pretrained on distant languages such as german and portuguese perform similarly on english tasks. ","1421":"lexical semantic change (detecting shifts in the meaning and usage of words) is an important task for social and cultural studies as well as for natural language processing applications. diachronic word embeddings (time-sensitive vector representations of words that preserve their meaning) have become the standard resource for this task. however, given the significant computational resources needed for their generation, very few resources exist that make diachronic word embeddings available to the scientific community.   in this paper we present dukweb, a set of large-scale resources designed for the diachronic analysis of contemporary english. dukweb was created from the jisc uk web domain dataset (1996-2013), a very large archive which collects resources from the internet archive that were hosted on domains ending in `.uk'. dukweb consists of a series word co-occurrence matrices and two types of word embeddings for each year in the jisc uk web domain dataset. we show the reuse potential of dukweb and its quality standards via a case study on word meaning change detection. ","1422":"we describe our single submission to task 1 of coliee 2021. our vanilla bm25 got second place, well above the median of submissions. code is available at https:\/\/github.com\/neuralmind-ai\/coliee. ","1423":"computational humour (ch) has attracted the interest of natural language processing and computational linguistics communities. creating datasets for automatic measurement of humour quotient is difficult due to multiple possible interpretations of the content. in this work, we create a multi-modal humour-annotated dataset ($\\sim$40 hours) using stand-up comedy clips. we devise a novel scoring mechanism to annotate the training data with a humour quotient score using the audience's laughter. the normalized duration (laughter duration divided by the clip duration) of laughter in each clip is used to compute this humour coefficient score on a five-point scale (0-4). this method of scoring is validated by comparing with manually annotated scores, wherein a quadratic weighted kappa of 0.6 is obtained. we use this dataset to train a model that provides a \"funniness\" score, on a five-point scale, given the audio and its corresponding text. we compare various neural language models for the task of humour-rating and achieve an accuracy of $0.813$ in terms of quadratic weighted kappa (qwk). our \"open mic\" dataset is released for further research along with the code. ","1424":"recent empirical studies show that adversarial topic models (atm) can successfully capture semantic patterns of the document by differentiating a document with another dissimilar sample. however, utilizing that discriminative-generative architecture has two important drawbacks: (1) the architecture does not relate similar documents, which has the same document-word distribution of salient words; (2) it restricts the ability to integrate external information, such as sentiments of the document, which has been shown to benefit the training of neural topic model. to address those issues, we revisit the adversarial topic architecture in the viewpoint of mathematical analysis, propose a novel approach to re-formulate discriminative goal as an optimization problem, and design a novel sampling method which facilitates the integration of external variables. the reformulation encourages the model to incorporate the relations among similar samples and enforces the constraint on the similarity among dissimilar ones; while the sampling method, which is based on the internal input and reconstructed output, helps inform the model of salient words contributing to the main topic. experimental results show that our framework outperforms other state-of-the-art neural topic models in three common benchmark datasets that belong to various domains, vocabulary sizes, and document lengths in terms of topic coherence. ","1425":"this paper describes neural models developed for the hate speech and offensive content identification in english and indo-aryan languages shared task 2021. our team called neuro-utmn-thales participated in two tasks on binary and fine-grained classification of english tweets that contain hate, offensive, and profane content (english subtasks a & b) and one task on identification of problematic content in marathi (marathi subtask a). for english subtasks, we investigate the impact of additional corpora for hate speech detection to fine-tune transformer models. we also apply a one-vs-rest approach based on twitter-roberta to discrimination between hate, profane and offensive posts. our models ranked third in english subtask a with the f1-score of 81.99% and ranked second in english subtask b with the f1-score of 65.77%. for the marathi tasks, we propose a system based on the language-agnostic bert sentence embedding (labse). this model achieved the second result in marathi subtask a obtaining an f1 of 88.08%. ","1426":"previous dialogue summarization datasets mainly focus on open-domain chitchat dialogues, while summarization datasets for the broadly used task-oriented dialogue haven't been explored yet. automatically summarizing such task-oriented dialogues can help a business collect and review needs to improve the service. besides, previous datasets pay more attention to generate good summaries with higher rouge scores, but they hardly understand the structured information of dialogues and ignore the factuality of summaries. in this paper, we introduce a large-scale public task-oriented dialogue summarization dataset, todsum, which aims to summarize the key points of the agent completing certain tasks with the user. compared to existing work, todsum suffers from severe scattered information issues and requires strict factual consistency, which makes it hard to directly apply recent dialogue summarization models. therefore, we introduce additional dialogue state knowledge for todsum to enhance the faithfulness of generated summaries. we hope a better understanding of conversational content helps summarization models generate concise and coherent summaries. meanwhile, we establish a comprehensive benchmark for todsum and propose a state-aware structured dialogue summarization model to integrate dialogue state information and dialogue history. exhaustive experiments and qualitative analysis prove the effectiveness of dialogue structure guidance. finally, we discuss the current issues of todsum and potential development directions for future work. ","1427":"recent expeditious developments in deep learning algorithms, distributed training, and even hardware design for large models have enabled training extreme-scale models, say gpt-3 and switch transformer possessing hundreds of billions or even trillions of parameters. however, under limited resources, extreme-scale model training that requires enormous amounts of computes and memory footprint suffers from frustratingly low efficiency in model convergence. in this paper, we propose a simple training strategy called \"pseudo-to-real\" for high-memory-footprint-required large models. pseudo-to-real is compatible with large models with architecture of sequential layers. we demonstrate a practice of pretraining unprecedented 10-trillion-parameter model, an order of magnitude larger than the state-of-the-art, on solely 512 gpus within 10 days. besides demonstrating the application of pseudo-to-real, we also provide a technique, granular cpu offloading, to manage cpu memory for training large model and maintain high gpu utilities. fast training of extreme-scale models on a decent amount of resources can bring much smaller carbon footprint and contribute to greener ai. ","1428":"dialogue disentanglement aims to group utterances in a long and multi-participant dialogue into threads. this is useful for discourse analysis and downstream applications such as dialogue response selection, where it can be the first step to construct a clean context\/response set. unfortunately, labeling all~\\emph{reply-to} links takes quadratic effort w.r.t the number of utterances: an annotator must check all preceding utterances to identify the one to which the current utterance is a reply. in this paper, we are the first to propose a~\\textbf{zero-shot} dialogue disentanglement solution. firstly, we train a model on a multi-participant response selection dataset harvested from the web which is not annotated; we then apply the trained model to perform zero-shot dialogue disentanglement. without any labeled data, our model can achieve a cluster f1 score of 25. we also fine-tune the model using various amounts of labeled data. experiments show that with only 10\\% of the data, we achieve nearly the same performance of using the full dataset\\footnote{code is released at \\url{https:\/\/github.com\/chijames\/zero_shot_dialogue_disentanglement}}. ","1429":"most of existing extractive multi-document summarization (mds) methods score each sentence individually and extract salient sentences one by one to compose a summary, which have two main drawbacks: (1) neglecting both the intra and cross-document relations between sentences; (2) neglecting the coherence and conciseness of the whole summary. in this paper, we propose a novel mds framework (sgsum) to formulate the mds task as a sub-graph selection problem, in which source documents are regarded as a relation graph of sentences (e.g., similarity graph or discourse graph) and the candidate summaries are its sub-graphs. instead of selecting salient sentences, sgsum selects a salient sub-graph from the relation graph as the summary. comparing with traditional methods, our method has two main advantages: (1) the relations between sentences are captured by modeling both the graph structure of the whole document set and the candidate sub-graphs; (2) directly outputs an integrate summary in the form of sub-graph which is more informative and coherent. extensive experiments on multinews and duc datasets show that our proposed method brings substantial improvements over several strong baselines. human evaluation results also demonstrate that our model can produce significantly more coherent and informative summaries compared with traditional mds methods. moreover, the proposed architecture has strong transfer ability from single to multi-document input, which can reduce the resource bottleneck in mds tasks. our code and results are available at: \\url{https:\/\/github.com\/paddlepaddle\/research\/tree\/master\/nlp\/emnlp2021-sgsum}. ","1430":"neural network models have achieved state-of-the-art performances in a wide range of natural language processing (nlp) tasks. however, a long-standing criticism against neural network models is the lack of interpretability, which not only reduces the reliability of neural nlp systems but also limits the scope of their applications in areas where interpretability is essential (e.g., health care applications). in response, the increasing interest in interpreting neural nlp models has spurred a diverse array of interpretation methods over recent years. in this survey, we provide a comprehensive review of various interpretation methods for neural models in nlp. we first stretch out a high-level taxonomy for interpretation methods in nlp, i.e., training-based approaches, test-based approaches, and hybrid approaches. next, we describe sub-categories in each category in detail, e.g., influence-function based methods, knn-based methods, attention-based models, saliency-based methods, perturbation-based methods, etc. we point out deficiencies of current methods and suggest some avenues for future research. ","1431":"researchers use figures to communicate rich, complex information in scientific papers. the captions of these figures are critical to conveying effective messages. however, low-quality figure captions commonly occur in scientific articles and may decrease understanding. in this paper, we propose an end-to-end neural framework to automatically generate informative, high-quality captions for scientific figures. to this end, we introduce scicap, a large-scale figure-caption dataset based on computer science arxiv papers published between 2010 and 2020. after pre-processing - including figure-type classification, sub-figure identification, text normalization, and caption text selection - scicap contained more than two million figures extracted from over 290,000 papers. we then established baseline models that caption graph plots, the dominant (19.2%) figure type. the experimental results showed both opportunities and steep challenges of generating captions for scientific figures. ","1432":"entity alignment (ea) plays an important role in automatically integrating knowledge graphs (kgs) from multiple sources. recent approaches based on graph neural network (gnn) obtain entity representation from relation information and have achieved promising results. besides, more and more methods introduce semi-supervision to ask for more labeled training data. however, two challenges still exist in gnn-based ea methods: (1) deeper gnn encoder: the gnn encoder of current methods has limited depth (usually 2-layers). (2) low-quality bootstrapping: the generated semi-supervised data is of low quality. in this paper, we propose a novel framework, echo entity alignment (echoea), which leverages 4-levels self-attention mechanism to spread entity information to relations and echo back to entities. furthermore, we propose attribute-combined bi-directional global-filtered strategy (abgs) to improve bootstrapping, reduce false samples and generate high-quality training data. the experimental results on three real-world cross-lingual datasets are stable at around 96\\% at hits@1 on average, showing that our approach not only significantly outperforms the state-of-the-art gnn-based methods, but also is universal and transferable for existing ea methods. ","1433":"the one billion word benchmark is a dataset derived from the wmt 2011 news crawl, commonly used to measure language modeling ability in natural language processing. we train models solely on common crawl web scrapes partitioned by year, and demonstrate that they perform worse on this task over time due to distributional shift. analysis of this corpus reveals that it contains several examples of harmful text, as well as outdated references to current events. we suggest that the temporal nature of news and its distribution shift over time makes it poorly suited for measuring language modeling ability, and discuss potential impact and considerations for researchers building language models and evaluation datasets. ","1434":"time is an important dimension in our physical world. lots of facts can evolve with respect to time. for example, the u.s. president might change every four years. therefore, it is important to consider the time dimension and empower the existing qa models to reason over time. however, the existing qa datasets contain rather few time-sensitive questions, hence not suitable for diagnosing or benchmarking the model's temporal reasoning capability. in order to promote research in this direction, we propose to construct a time-sensitive qa dataset. the dataset is constructed by 1) mining time-evolving facts from wikidata and aligning them to their corresponding wikipedia page, 2) employing crowd workers to verify and calibrate these noisy facts, 3) generating question-answer pairs based on the annotated time-sensitive facts. our dataset poses challenges in the aspect of both temporal understanding and temporal reasoning. we evaluate different sota long-document qa systems like bigbird and fid on our dataset. the best-performing model fid can only achieve 46\\% accuracy, still far behind the human performance of 87\\%. we demonstrate that these models are still lacking the ability to perform consistent temporal reasoning. therefore, we believe that our dataset could serve as a benchmark to develop nlp models more sensitive to temporal shifts. the dataset and code are released in~\\url{https:\/\/github.com\/wenhuchen\/time-sensitive-qa}. ","1435":"the neural attention mechanism has been incorporated into deep neural networks to achieve state-of-the-art performance in various domains. most such models use multi-head self-attention which is appealing for the ability to attend to information from different perspectives. this paper introduces alignment attention that explicitly encourages self-attention to match the distributions of the key and query within each head. the resulting alignment attention networks can be optimized as an unsupervised regularization in the existing attention framework. it is simple to convert any models with self-attention, including pre-trained ones, to the proposed alignment attention. on a variety of language understanding tasks, we show the effectiveness of our method in accuracy, uncertainty estimation, generalization across domains, and robustness to adversarial attacks. we further demonstrate the general applicability of our approach on graph attention and visual question answering, showing the great potential of incorporating our alignment method into various attention-related tasks. ","1436":"this work explores the capacities of character-based neural machine translation to translate noisy user-generated content (ugc) with a strong focus on exploring the limits of such approaches to handle productive ugc phenomena, which almost by definition, cannot be seen at training time. within a strict zero-shot scenario, we first study the detrimental impact on translation performance of various user-generated content phenomena on a small annotated dataset we developed, and then show that such models are indeed incapable of handling unknown letters, which leads to catastrophic translation failure once such characters are encountered. we further confirm this behavior with a simple, yet insightful, copy task experiment and highlight the importance of reducing the vocabulary size hyper-parameter to increase the robustness of character-based models for machine translation. ","1437":"this work takes a critical look at the evaluation of user-generated content automatic translation, the well-known specificities of which raise many challenges for mt. our analyses show that measuring the average-case performance using a standard metric on a ugc test set falls far short of giving a reliable image of the ugc translation quality. that is why we introduce a new data set for the evaluation of ugc translation in which ugc specificities have been manually annotated using a fine-grained typology. using this data set, we conduct several experiments to measure the impact of different kinds of ugc specificities on translation quality, more precisely than previously possible. ","1438":"relation extraction in the biomedical domain is a challenging task due to a lack of labeled data and a long-tail distribution of fact triples. many works leverage distant supervision which automatically generates labeled data by pairing a knowledge graph with raw textual data. distant supervision produces noisy labels and requires additional techniques, such as multi-instance learning (mil), to denoise the training signal. however, mil requires multiple instances of data and struggles with very long-tail datasets such as those found in the biomedical domain. in this work, we propose a novel reformulation of mil for biomedical relation extraction that abstractifies biomedical entities into their corresponding semantic types. by grouping entities by types, we are better able to take advantage of the benefits of mil and further denoise the training signal. we show this reformulation, which we refer to as abstractified multi-instance learning (amil), improves performance in biomedical relationship extraction. we also propose a novel relationship embedding architecture that further improves model performance. ","1439":"as digital social platforms and mobile technologies are becoming more prevalent and robust, the use of artificial intelligence (ai) in facilitating human communication will grow. this, in turn, will pave the way for the development of intuitive, adaptive, and effective empathic ai interfaces that better address the needs of socially and culturally diverse communities. i believe such developments must consider a principled framework that includes the human perceptual senses in the digital design process right from the start, for a more accurate, as well as a more aesthetic, memorable, and soothing experience. in this position paper, i suggest features, identify some challenges that need to be addressed in the process, and propose some future research directions that i think should be part of the design and implementation. such an approach will allow various communities of practice to investigate the areas of intersection between artificial intelligence, on one side, and human communication, perceptual needs and social and cultural values, on the other. ","1440":"to solve the existing sentence punctuation problem for collaborative commentary generation in esports live-streaming, this paper presents two strategies for sentence punctuation for text sequences of game commentary, that is, punctuating sentences by two or three text sequence(s) originally punctuated by youtube to obtain a complete sentence of commentary. we conducted comparative experiments utilizing and fine-tuning a state-of-the-art pre-trained generative language model among two strategies and the baseline to generate collaborative commentary. both objective evaluations by automatic metrics and subjective analyses showed that our strategy of punctuating sentences by two text sequences outperformed the baseline. ","1441":"goal oriented dialogue systems have become a prominent customer-care interaction channel for most businesses. however, not all interactions are smooth, and customer intent misunderstanding is a major cause of dialogue failure. we show that intent prediction can be improved by training a deep text-to-text neural model to generate successive user utterances from unlabeled dialogue data. for that, we define a multi-task training regime that utilizes successive user-utterance generation to improve the intent prediction. our approach achieves the reported improvement due to two complementary factors: first, it uses a large amount of unlabeled dialogue data for an auxiliary generation task. second, it uses the generated user utterance as an additional signal for the intent prediction model. lastly, we present a novel look-ahead approach that uses user utterance generation to improve intent prediction in inference time. specifically, we generate counterfactual successive user utterances for conversations with ambiguous predicted intents, and disambiguate the prediction by reassessing the concatenated sequence of available and generated utterances. ","1442":"we present the task of automated punishment extraction (ape) in sentencing decisions from criminal court cases in hebrew. addressing ape will enable the identification of sentencing patterns and constitute an important stepping stone for many follow up legal nlp applications in hebrew, including the prediction of sentencing decisions. we curate a dataset of sexual assault sentencing decisions and a manually-annotated evaluation dataset, and implement rule-based and supervised models. we find that while supervised models can identify the sentence containing the punishment with good accuracy, rule-based approaches outperform them on the full ape task. we conclude by presenting a first analysis of sentencing patterns in our dataset and analyze common models' errors, indicating avenues for future work, such as distinguishing between probation and actual imprisonment punishment. we will make all our resources available upon request, including data, annotation, and first benchmark models. ","1443":"we present models which complete missing text given transliterations of ancient mesopotamian documents, originally written on cuneiform clay tablets (2500 bce - 100 ce). due to the tablets' deterioration, scholars often rely on contextual cues to manually fill in missing parts in the text in a subjective and time-consuming process. we identify that this challenge can be formulated as a masked language modelling task, used mostly as a pretraining objective for contextualized language models. following, we develop several architectures focusing on the akkadian language, the lingua franca of the time. we find that despite data scarcity (1m tokens) we can achieve state of the art performance on missing tokens prediction (89% hit@5) using a greedy decoding scheme and pretraining on data from other languages and different time periods. finally, we conduct human evaluations showing the applicability of our models in assisting experts to transcribe texts in extinct languages. ","1444":"kurdish is written in different scripts. the two most popular scripts are latin and persian-arabic. however, not all kurdish readers are familiar with both mentioned scripts that could be resolved by automatic transliterators. so far, the developed tools mostly transliterate persian-arabic scripts into latin. we present a transliterator to transliterate kurdish texts in latin into persian-arabic script. we also discuss the issues that should be considered in the transliteration process. the tool is a part of kurdish blark, and it is publicly available for non-commercial use ","1445":"we present the system description for our submission towards the key point analysis shared task at argmining 2021. track 1 of the shared task requires participants to develop methods to predict the match score between each pair of arguments and keypoints, provided they belong to the same topic under the same stance. we leveraged existing state of the art pre-trained language models along with incorporating additional data and features extracted from the inputs (topics, key points, and arguments) to improve performance. we were able to achieve map strict and map relaxed score of 0.872 and 0.966 respectively in the evaluation phase, securing 5th place on the leaderboard. in the post evaluation phase, we achieved a map strict and map relaxed score of 0.921 and 0.982 respectively. all the codes to generate reproducible results on our models are available on github. ","1446":"few-shot relation extraction (fsre) focuses on recognizing novel relations by learning with merely a handful of annotated instances. meta-learning has been widely adopted for such a task, which trains on randomly generated few-shot tasks to learn generic data representations. despite impressive results achieved, existing models still perform suboptimally when handling hard fsre tasks, where the relations are fine-grained and similar to each other. we argue this is largely because existing models do not distinguish hard tasks from easy ones in the learning process. in this paper, we introduce a novel approach based on contrastive learning that learns better representations by exploiting relation label information. we further design a method that allows the model to adaptively learn how to focus on hard tasks. experiments on two standard datasets demonstrate the effectiveness of our method. ","1447":"defeasible reasoning is the mode of reasoning where conclusions can be overturned by taking into account new evidence. existing cognitive science literature on defeasible reasoning suggests that a person forms a mental model of the problem scenario before answering questions. our research goal asks whether neural models can similarly benefit from envisioning the question scenario before answering a defeasible query. our approach is, given a question, to have a model first create a graph of relevant influences, and then leverage that graph as an additional input when answering the question. our system, curious, achieves a new state-of-the-art on three different defeasible reasoning datasets. this result is significant as it illustrates that performance can be improved by guiding a system to \"think about\" a question and explicitly model the scenario, rather than answering reflexively. code, data, and pre-trained models are located at https:\/\/github.com\/madaan\/thinkaboutit. ","1448":"a framework and method are proposed for the study of constituent composition in fmri. the method produces estimates of neural patterns encoding complex linguistic structures, under the assumption that the contributions of individual constituents are additive. like usual techniques for modeling compositional structure in fmri, the proposed method employs pattern superposition to synthesize complex structures from their parts. unlike these techniques, superpositions are sensitive to the structural positions of constituents, making them irreducible to structure-indiscriminate (\"bag-of-words\") models of composition. reanalyzing data from a study by frankland and greene (2015), it is shown that comparison of neural predictive models with differing specifications can illuminate aspects of neural representational contents that are not apparent when composition is not modelled. the results indicate that the neural instantiations of the binding of fillers to thematic roles in a sentence are non-orthogonal, and therefore spatially overlapping. ","1449":"we present harmonic memory networks (hmem), a neural architecture for knowledge base completion that models entities as weighted sums of pairwise bindings between an entity's neighbors and corresponding relations. since entities are modeled as aggregated neighborhoods, representations of unseen entities can be generated on the fly. we demonstrate this with two new datasets: wngen and fbgen. experiments show that the model is sota on benchmarks, and flexible enough to evolve without retraining as the knowledge graph grows. ","1450":"chinese traditional poetry is an important intangible cultural heritage of china and an artistic carrier of thought, culture, spirit and emotion. however, due to the strict rules of ancient poetry, it is very difficult to write poetry by machine. this paper proposes an automatic generation method of chinese traditional poetry based on deep learning technology, which extracts keywords from each poem and matches them with the previous text to make the poem conform to the theme, and when a user inputs a paragraph of text, the machine obtains the theme and generates poem sentence by sentence. using the classic word2vec model as the preprocessing model, the chinese characters which are not understood by the computer are transformed into matrix for processing. bi-directional long short-term memory is used as the neural network model to generate chinese characters one by one and make the meaning of chinese characters as accurate as possible. at the same time, tf-idf and textrank are used to extract keywords. using the attention mechanism based encoding-decoding model, we can solve practical problems by transforming the model, and strengthen the important information of long-distance information, so as to grasp the key points without losing important information. in the aspect of emotion judgment, long short-term memory network is used. the final result shows that it can get good poetry outputs according to the user input text. ","1451":"webpage information extraction (wie) is an important step to create knowledge bases. for this, classical wie methods leverage the document object model (dom) tree of a website. however, use of the dom tree poses significant challenges as context and appearance are encoded in an abstract manner. to address this challenge we propose to reformulate wie as a context-aware webpage object detection task. specifically, we develop a context-aware visual attention-based (cova) detection pipeline which combines appearance features with syntactical structure from the dom tree. to study the approach we collect a new large-scale dataset of e-commerce websites for which we manually annotate every web element with four labels: product price, product title, product image and background. on this dataset we show that the proposed cova approach is a new challenging baseline which improves upon prior state-of-the-art methods. ","1452":"we present a method for using adverb phrases to adjust skill parameters via learned adverb-skill groundings. these groundings allow an agent to use adverb feedback provided by a human to directly update a skill policy, in a manner similar to traditional local policy search methods. we show that our method can be used as a drop-in replacement for these policy search methods when dense reward from the environment is not available but human language feedback is. we demonstrate improved sample efficiency over modern policy search methods in two experiments. ","1453":"language models (lms) are sentence-completion engines trained on massive corpora. lms have emerged as a significant breakthrough in natural-language processing, providing capabilities that go far beyond sentence completion including question answering, summarization, and natural-language inference. while many of these capabilities have potential application to cognitive systems, exploiting language models as a source of task knowledge, especially for task learning, offers significant, near-term benefits. we introduce language models and the various tasks to which they have been applied and then review methods of knowledge extraction from language models. the resulting analysis outlines both the challenges and opportunities for using language models as a new knowledge source for cognitive systems. it also identifies possible ways to improve knowledge extraction from language models using the capabilities provided by cognitive systems. central to success will be the ability of a cognitive agent to itself learn an abstract model of the knowledge implicit in the lm as well as methods to extract high-quality knowledge effectively and efficiently. to illustrate, we introduce a hypothetical robot agent and describe how language models could extend its task knowledge and improve its performance and the kinds of knowledge and methods the agent can use to exploit the knowledge within a language model. ","1454":"we present the prepositions annotated with supersense tags in reddit international english (\"pastrie\") corpus, a new dataset containing manually annotated preposition supersenses of english data from presumed speakers of four l1s: english, french, german, and spanish. the annotations are comprehensive, covering all preposition types and tokens in the sample. along with the corpus, we provide analysis of distributional patterns across the included l1s and a discussion of the influence of l1s on l2 preposition choice. ","1455":"ai is widely thought to be poised to transform business, yet current perceptions of the scope of this transformation may be myopic. recent progress in natural language processing involving transformer language models (tlms) offers a potential avenue for ai-driven business and societal transformation that is beyond the scope of what most currently foresee. we review this recent progress as well as recent literature utilizing text mining in top is journals to develop an outline for how future is research can benefit from these new techniques. our review of existing is literature reveals that suboptimal text mining techniques are prevalent and that the more advanced tlms could be applied to enhance and increase is research involving text data, and to enable new is research topics, thus creating more value for the research community. this is possible because these techniques make it easier to develop very powerful custom systems and their performance is superior to existing methods for a wide range of tasks and applications. further, multilingual language models make possible higher quality text analytics for research in multiple languages. we also identify new avenues for is research, like language user interfaces, that may offer even greater potential for future is research. ","1456":"there are many language models for the english language according to its worldwide relevance. however, for the spanish language, even if it is a widely spoken language, there are very few spanish language models which result to be small and too general. legal slang could be think of a spanish variant on its own as it is very complicated in vocabulary, semantics and phrase understanding. for this work we gathered legal-domain corpora from different sources, generated a model and evaluated against spanish general domain tasks. the model provides reasonable results in those tasks. ","1457":"we introduce a high-quality and large-scale vietnamese-english parallel dataset of 3.02m sentence pairs, which is 2.9m pairs larger than the benchmark vietnamese-english machine translation corpus iwslt15. we conduct experiments comparing strong neural baselines and well-known automatic translation engines on our dataset and find that in both automatic and human evaluations: the best performance is obtained by fine-tuning the pre-trained sequence-to-sequence denoising auto-encoder mbart. to our best knowledge, this is the first large-scale vietnamese-english machine translation study. we hope our publicly available dataset and study can serve as a starting point for future research and applications on vietnamese-english machine translation. ","1458":"unlike the courts in western countries, public records of indian judiciary are completely unstructured and noisy. no large scale publicly available annotated datasets of indian legal documents exist till date. this limits the scope for legal analytics research. in this work, we propose a new dataset consisting of over 10,000 judgements delivered by the supreme court of india and their corresponding hand written summaries. the proposed dataset is pre-processed by normalising common legal abbreviations, handling spelling variations in named entities, handling bad punctuations and accurate sentence tokenization. each sentence is tagged with their rhetorical roles. we also annotate each judgement with several attributes like date, names of the plaintiffs, defendants and the people representing them, judges who delivered the judgement, acts\/statutes that are cited and the most common citations used to refer the judgement. further, we propose an automatic labelling technique for identifying sentences which have summary worthy information. we demonstrate that this auto labeled data can be used effectively to train a weakly supervised sentence extractor with high accuracy. some possible applications of this dataset besides legal document summarization can be in retrieval, citation analysis and prediction of decisions by a particular judge. ","1459":"explainable recommendation systems provide explanations for recommendation results to improve their transparency and persuasiveness. the existing explainable recommendation methods generate textual explanations without explicitly considering the user's preferences on different aspects of the item. in this paper, we propose a novel explanation generation framework, named hierarchical aspect-guided explanation generation (hag), for explainable recommendation. specifically, hag employs a review-based syntax graph to provide a unified view of the user\/item details. an aspect-guided graph pooling operator is proposed to extract the aspect-relevant information from the review-based syntax graphs to model the user's preferences on an item at the aspect level. then, a hierarchical explanation decoder is developed to generate aspects and aspect-relevant explanations based on the attention mechanism. the experimental results on three real datasets indicate that hag outperforms state-of-the-art explanation generation methods in both single-aspect and multi-aspect explanation generation tasks, and also achieves comparable or even better preference prediction accuracy than strong baseline methods. ","1460":"automatic speech recognition (asr) systems have found their use in numerous industrial applications in very diverse domains. since domain-specific systems perform better than their generic counterparts on in-domain evaluation, the need for memory and compute-efficient domain adaptation is obvious. particularly, adapting parameter-heavy transformer-based language models used for rescoring asr hypothesis is challenging. in this work, we overcome the problem using prompt-tuning, a methodology that trains a small number of domain token embedding parameters to prime a transformer-based lm to a particular domain. with just a handful of extra parameters per domain, we achieve much better perplexity scores over the baseline of using an unadapted lm. despite being parameter-efficient, these improvements are comparable to those of fully-fine-tuned models with hundreds of millions of parameters. we replicate our findings in perplexity numbers to word error rate in a domain-specific asr system for one such domain. ","1461":"data augmentation has been shown to effectively improve the performance of multimodal machine learning models. this paper introduces a generative model for data augmentation by leveraging the correlations among multiple modalities. different from conventional data augmentation approaches that apply low-level operations with deterministic heuristics, our method learns a generator that generates samples of the target modality conditioned on observed modalities in the variational auto-encoder framework. additionally, the proposed model is able to quantify the confidence of augmented data by its generative probability, and can be jointly optimised with a downstream task. experiments on visual question answering as downstream task demonstrate the effectiveness of the proposed generative model, which is able to improve strong updn-based models to achieve state-of-the-art performance. ","1462":"pretrained multilingual language models have become a common tool in transferring nlp capabilities to low-resource languages, often with adaptations. in this work, we study the performance, extensibility, and interaction of two such adaptations: vocabulary augmentation and script transliteration. our evaluations on part-of-speech tagging, universal dependency parsing, and named entity recognition in nine diverse low-resource languages uphold the viability of these approaches while raising new questions around how to optimally adapt multilingual models to low-resource settings. ","1463":"over the recent years, large pretrained language models (lm) have revolutionized the field of natural language processing (nlp). however, while pretraining on general language has been shown to work very well for common language, it has been observed that niche language poses problems. in particular, climate-related texts include specific language that common lms can not represent accurately. we argue that this shortcoming of today's lms limits the applicability of modern nlp to the broad field of text processing of climate-related texts. as a remedy, we propose climatebert, a transformer-based language model that is further pretrained on over 1.6 million paragraphs of climate-related texts, crawled from various sources such as common news, research articles, and climate reporting of companies. we find that climatebertleads to a 46% improvement on a masked language model objective which, in turn, leads to lowering error rates by 3.57% to 35.71% for various climate-related downstream tasks like text classification, sentiment analysis, and fact-checking. ","1464":"reading comprehension, which has been defined as gaining an understanding of written text through a process of translating grapheme into meaning, is an important academic skill. other language learning skills - writing, speaking and listening, all are connected to reading comprehension. there have been several measures proposed by researchers to automate the assessment of comprehension skills for second language (l2) learners, especially english as second language (esl) and english as foreign language (efl) learners. however, current methods measure particular skills without analysing the impact of reading frequency on comprehension skills. in this dissertation, we show how different skills could be measured and scored automatically. we also demonstrate, using example experiments on multiple forms of learners' responses, how frequent reading practices could impact on the variables of multimodal skills (reading pattern, writing, and oral fluency).   this thesis comprises of five studies. the first and second studies are based on eye-tracking data collected from efl readers in repeated reading (rr) sessions. the third and fourth studies are to evaluate free-text summary written by efl readers in repeated reading sessions. the fifth and last study, described in the sixth chapter of the thesis, is to evaluate recorded oral summaries recited by efl readers in repeated reading sessions.   in a nutshell, through this dissertation, we show that multimodal skills of learners could be assessed to measure their comprehension skills as well as to measure the effect of repeated readings on these skills in the course of time, by finding significant features and by applying machine learning techniques with a combination of statistical models such as lmer. ","1465":"substantial amounts of work are required to clean large collections of digitized books for nlp analysis, both because of the presence of errors in the scanned text and the presence of duplicate volumes in the corpora. in this paper, we consider the issue of deduplication in the presence of optical character recognition (ocr) errors. we present methods to handle these errors, evaluated on a collection of 19,347 texts from the project gutenberg dataset and 96,635 texts from the hathitrust library. we demonstrate that improvements in language models now enable the detection and correction of ocr errors without consideration of the scanning image itself. the inconsistencies found by aligning pairs of scans of the same underlying work provides training data to build models for detecting and correcting errors. we identify the canonical version for each of 17,136 repeatedly-scanned books from 58,808 scans. finally, we investigate methods to detect and correct errors in single-copy texts. we show that on average, our method corrects over six times as many errors as it introduces. we also provide interesting analysis on the relation between scanning quality and other factors such as location and publication year. ","1466":"explaining how important each input feature is to a classifier's decision is critical in high-stake applications. an underlying principle behind dozens of explanation methods is to take the prediction difference between before-and-after an input feature (here, a token) is removed as its attribution - the individual treatment effect in causal inference. a recent method called input marginalization (im) (kim et al., 2020) uses bert to replace a token - i.e. simulating the do(.) operator - yielding more plausible counterfactuals. however, our rigorous evaluation using five metrics and on three datasets found im explanations to be consistently more biased, less accurate, and less plausible than those derived from simply deleting a word. ","1467":"we focus on multimodal machine reading comprehension (m3c) where a model is expected to answer questions based on given passage (or context), and the context and the questions can be in different modalities. previous works such as recipeqa have proposed datasets and cloze-style tasks for evaluation. however, we identify three critical biases stemming from the question-answer generation process and memorization capabilities of large deep models. these biases makes it easier for a model to overfit by relying on spurious correlations or naive data patterns. we propose a systematic framework to address these biases through three control-knobs that enable us to generate a test bed of datasets of progressive difficulty levels. we believe that our benchmark (referred to as meta-recipeqa) will provide, for the first time, a fine grained estimate of a model's generalization capabilities. we also propose a general m3c model that is used to realize several prior sota models and motivate a novel hierarchical transformer based reasoning network (htrn). we perform a detailed evaluation of these models with different language and visual features on our benchmark. we observe a consistent improvement with htrn over sota (~18% in visual cloze task and ~13% in average over all the tasks). we also observe a drop in performance across all the models when testing on recipeqa and proposed meta-recipeqa (e.g. 83.6% versus 67.1% for htrn), which shows that the proposed dataset is relatively less biased. we conclude by highlighting the impact of the control knobs with some quantitative results. ","1468":"we devise a multimodal conversation system for dialogue utterances composed of text, image or both modalities. we leverage auxiliary unsupervised visual and textual data (audited). to improve the performance of text-based task, we utilize translations of target sentences from english to french to form the assisted supervision. for the image-based task, we employ the deepfashion dataset in which we seek nearest neighbor images of positive and negative target images of the mmd data. these nearest neighbors form the nearest neighbor embedding providing an external context for target images. we form two methods to create neighbor embedding vectors, namely neighbor embedding by hard assignment (neha) and neighbor embedding by soft assignment (nesa) which generate context subspaces per target image. subsequently, these subspaces are learnt by our pipeline as a context for the target data. we also propose a discriminator which switches between the image- and text-based tasks. we show improvements over baselines on the large-scale multimodal dialogue dataset (mmd) and simmc. ","1469":"language models are known to produce vague and generic outputs. we propose two unsupervised decoding strategies based on either word-frequency or point-wise mutual information to increase the specificity of any model that outputs a probability distribution over its vocabulary at generation time. we test the strategies in a prompt completion task; with human evaluations, we find that both strategies increase the specificity of outputs with only modest decreases in sensibility. we also briefly present a summarization use case, where these strategies can produce more specific summaries. ","1470":"key point analysis is the task of extracting a set of concise and high-level statements from a given collection of arguments, representing the gist of these arguments. this paper presents our proposed approach to the key point analysis shared task, collocated with the 8th workshop on argument mining. the approach integrates two complementary components. one component employs contrastive learning via a siamese neural network for matching arguments to key points; the other is a graph-based extractive summarization model for generating key points. in both automatic and manual evaluation, our approach was ranked best among all submissions to the shared task. ","1471":"generative flows and diffusion models have been predominantly trained on ordinal data, for example natural images. this paper introduces two extensions of flows and diffusion for categorical data such as language or image segmentation: argmax flows and multinomial diffusion. argmax flows are defined by a composition of a continuous distribution (such as a normalizing flow), and an argmax function. to optimize this model, we learn a probabilistic inverse for the argmax that lifts the categorical data to a continuous space. multinomial diffusion gradually adds categorical noise in a diffusion process, for which the generative denoising process is learned. we demonstrate that our method outperforms existing dequantization approaches on text modelling and modelling on image segmentation maps in log-likelihood. ","1472":"question answering (qa) is a high-level ability of natural language processing. most extractive ma-chine reading comprehension models focus on factoid questions (e.g., who, when, where) and restrict the output answer as a short and continuous span in the original passage. however, in real-world scenarios, many questions are non-factoid (e.g., how, why) and their answers are organized in the list format that contains multiple non-contiguous spans. naturally, existing extractive models are by design unable to answer such questions. to address this issue, this paper proposes listreader, a neural ex-tractive qa model for list-form answer. in addition to learning the alignment between the question and content, we introduce a heterogeneous graph neural network to explicitly capture the associations among candidate segments. moreover, our model adopts a co-extraction setting that can extract either span- or sentence-level answers, allowing better applicability. two large-scale datasets of different languages are constructed to support this study. experimental results show that our model considerably outperforms various strong baselines. further discussions provide an intuitive understanding of how our model works and where the performance gain comes from. ","1473":"multimodal sentiment analysis (muse) 2021 is a challenge focusing on the tasks of sentiment and emotion, as well as physiological-emotion and emotion-based stress recognition through more comprehensively integrating the audio-visual, language, and biological signal modalities. the purpose of muse 2021 is to bring together communities from different disciplines; mainly, the audio-visual emotion recognition community (signal-based), the sentiment analysis community (symbol-based), and the health informatics community. we present four distinct sub-challenges: muse-wilder and muse-stress which focus on continuous emotion (valence and arousal) prediction; muse-sent, in which participants recognise five classes each for valence and arousal; and muse-physio, in which the novel aspect of `physiological-emotion' is to be predicted. for this years' challenge, we utilise the muse-car dataset focusing on user-generated reviews and introduce the ulm-tsst dataset, which displays people in stressful depositions. this paper also provides detail on the state-of-the-art feature sets extracted from these datasets for utilisation by our baseline model, a long short-term memory-recurrent neural network. for each sub-challenge, a competitive baseline for participants is set; namely, on test, we report a concordance correlation coefficient (ccc) of .4616 ccc for muse-wilder; .4717 ccc for muse-stress, and .4606 ccc for muse-physio. for muse-sent an f1 score of 32.82 % is obtained. ","1474":"we aim to highlight an interesting trend to contribute to the ongoing debate around advances within legal natural language processing. recently, the focus for most legal text classification tasks has shifted towards large pre-trained deep learning models such as bert. in this paper, we show that a more traditional approach based on support vector machine classifiers reaches surprisingly competitive performance with bert-based models on the classification tasks in the lexglue benchmark. we also highlight that error reduction obtained by using specialised bert-based models over baselines is noticeably smaller in the legal domain when compared to general language tasks. we present and discuss three hypotheses as potential explanations for these results to support future discussions. ","1475":"assessing the personality of software engineers may help to match individual traits with the characteristics of development activities such as code review and testing, as well as support managers in team composition. however, self-assessment questionnaires are not a practical solution for collecting multiple observations on a large scale. instead, automatic personality detection, while overcoming these limitations, is based on off-the-shelf solutions trained on non-technical corpora, which might not be readily applicable to technical domains like software engineering (se). in this paper, we first assess the performance of general-purpose personality detection tools when applied to a technical corpus of developers' emails retrieved from the public archives of the apache software foundation. we observe a general low accuracy of predictions and an overall disagreement among the tools. second, we replicate two previous research studies in se by replacing the personality detection tool used to infer developers' personalities from pull-request discussions and emails. we observe that the original results are not confirmed, i.e., changing the tool used in the original study leads to diverging conclusions. our results suggest a need for personality detection tools specially targeted for the software engineering domain. ","1476":"we propose to express the forward-backward algorithm in terms of operations between sparse matrices in a specific semiring. this new perspective naturally leads to a gpu-friendly algorithm which is easy to implement in julia or any programming languages with native support of semiring algebra. we use this new implementation to train a tdnn with the lf-mmi objective function and we compare the training time of our system with pychain - a recently introduced c++\/cuda implementation of the lf-mmi loss. our implementation is about two times faster while not having to use any approximation such as the \"leaky-hmm\". ","1477":"one of the most popular paradigms of applying large pre-trained nlp models such as bert is to fine-tune it on a smaller dataset. however, one challenge remains as the fine-tuned model often overfits on smaller datasets. a symptom of this phenomenon is that irrelevant or misleading words in the sentence, which are easy to understand for human beings, can substantially degrade the performance of these finetuned bert models. in this paper, we propose a novel technique, called self-supervised attention (ssa) to help facilitate this generalization challenge. specifically, ssa automatically generates weak, token-level attention labels iteratively by probing the fine-tuned model from the previous iteration. we investigate two different ways of integrating ssa into bert and propose a hybrid approach to combine their benefits. empirically, through a variety of public datasets, we illustrate significant performance improvement using our ssa-enhanced bert model. ","1478":"we study the problem of generating counterfactual text for a classifier as a means for understanding and debugging classification. given a textual input and a classification model, we aim to minimally alter the text to change the model's prediction. white-box approaches have been successfully applied to similar problems in vision where one can directly optimize the continuous input. optimization-based approaches become difficult in the language domain due to the discrete nature of text. we bypass this issue by directly optimizing in the latent space and leveraging a language model to generate candidate modifications from optimized latent representations. we additionally use shapley values to estimate the combinatoric effect of multiple changes. we then use these estimates to guide a beam search for the final counterfactual text. we achieve favorable performance compared to recent white-box and black-box baselines using human and automatic evaluations. ablation studies show that both latent optimization and the use of shapley values improve success rate and the quality of the generated counterfactuals. ","1479":"although exposure bias has been widely studied in some nlp tasks, it faces its unique challenges in dialogue response generation, the representative one-to-various generation scenario. in real human dialogue, there are many appropriate responses for the same context, not only with different expressions, but also with different topics. therefore, due to the much bigger gap between various ground-truth responses and the generated synthetic response, exposure bias is more challenging in dialogue generation task. what's more, as mle encourages the model to only learn the common words among different ground-truth responses, but ignores the interesting and specific parts, exposure bias may further lead to the common response generation problem, such as \"i don't know\" and \"haha?\" in this paper, we propose a novel adaptive switching mechanism, which learns to automatically transit between ground-truth learning and generated learning regarding the word-level matching score, such as the cosine similarity. experimental results on both chinese stc dataset and english reddit dataset, show that our adaptive method achieves a significant improvement in terms of metric-based evaluation and human evaluation, as compared with the state-of-the-art exposure bias approaches. further analysis on nmt task also shows that our model can achieve a significant improvement. ","1480":"we propose a new model, dochopper, that iteratively attends to different parts of long, hierarchically structured documents to answer complex questions. similar to multi-hop question-answering (qa) systems, at each step, dochopper uses a query $q$ to attend to information from a document, combines this ``retrieved'' information with $q$ to produce the next query. however, in contrast to most previous multi-hop qa systems, dochopper is able to ``retrieve'' either short passages or long sections of the document, thus emulating a multi-step process of ``navigating'' through a long document to answer a question. to enable this novel behavior, dochopper does not combine document information with $q$ by concatenating text to the text of $q$, but by combining a compact neural representation of $q$ with a compact neural representation of a hierarchical part of the document, which can potentially be quite large. we experiment with dochopper on four different qa tasks that require reading long and complex documents to answer multi-hop questions, and show that dochopper achieves state-of-the-art results on three of the datasets. additionally, dochopper is efficient at inference time, being 3--10 times faster than the baselines. ","1481":"as humans, we understand events in the visual world contextually, performing multimodal reasoning across time to make inferences about the past, present, and future. we introduce merlot, a model that learns multimodal script knowledge by watching millions of youtube videos with transcribed speech -- in an entirely label-free, self-supervised manner. by pretraining with a mix of both frame-level (spatial) and video-level (temporal) objectives, our model not only learns to match images to temporally corresponding words, but also to contextualize what is happening globally over time. as a result, merlot exhibits strong out-of-the-box representations of temporal commonsense, and achieves state-of-the-art performance on 12 different video qa datasets when finetuned. it also transfers well to the world of static images, allowing models to reason about the dynamic context behind visual scenes. on visual commonsense reasoning, merlot answers questions correctly with 80.6% accuracy, outperforming state-of-the-art models of similar size by over 3%, even those that make heavy use of auxiliary supervised data (like object bounding boxes).   ablation analyses demonstrate the complementary importance of: 1) training on videos versus static images; 2) scaling the magnitude and diversity of the pretraining video corpus; and 3) using diverse objectives that encourage full-stack multimodal reasoning, from the recognition to cognition level. ","1482":"in this paper we explore the use of symbolic knowledge and machine teaching to reduce human data labeling efforts in building neural task bots. we propose synergy, a hybrid learning framework where a task bot is developed in two steps: (i) symbolic knowledge to neural networks: large amounts of simulated dialog sessions are generated based on task-specific symbolic knowledge which is represented as a task schema consisting of dialog flows and task-oriented databases. then a pre-trained neural dialog model, soloist, is fine-tuned on the simulated dialogs to build a bot for the task. (ii) neural learning: the fine-tuned neural dialog model is continually refined with a handful of real task-specific dialogs via machine teaching, where training samples are generated by human teachers interacting with the task bot. we validate synergy on four dialog tasks. experimental results show that synergy maps task-specific knowledge into neural dialog models achieving greater diversity and coverage of dialog flows, and continually improves model performance with machine teaching, thus demonstrating strong synergistic effects of symbolic knowledge and machine teaching. ","1483":"predicting the chemical properties of a molecule is of great importance in many applications, including drug discovery and material design. machine learning based molecular property prediction holds the promise of enabling accurate predictions at much less computationally complex cost when compared to, for example, density functional theory (dft) calculations. various representation learning methods in a supervised setting, including the features extracted using graph neural nets, have emerged for such tasks. however, the vast chemical space and the limited availability of labels make supervised learning challenging, calling for learning a general-purpose molecular representation. recently, pre-trained transformer-based language models on large unlabeled corpus have produced state-of-the-art results in many downstream natural language processing tasks. inspired by this development, we present molecular embeddings obtained by training an efficient transformer encoder model, molformer. this model employs a linear attention mechanism coupled with highly parallelized training on smiles sequences of 1.1 billion unlabeled molecules from the pubchem and zinc datasets. experiments show that the learned molecular representation outperforms supervised and unsupervised graph neural net baselines on several regression and classification tasks from 10 benchmark datasets, while performing competitively on others. further analyses, specifically through the lens of attention, demonstrate that molformer indeed learns a molecule's local and global structural aspects. these results provide encouraging evidence that large-scale molecular language models can capture sufficient structural information to be able to predict diverse molecular properties, including quantum-chemical properties ","1484":"the design of widespread vision-and-language datasets and pre-trained encoders directly adopts, or draws inspiration from, the concepts and images of imagenet. while one can hardly overestimate how much this benchmark contributed to progress in computer vision, it is mostly derived from lexical databases and image queries in english, resulting in source material with a north american or western european bias. therefore, we devise a new protocol to construct an imagenet-style hierarchy representative of more languages and cultures. in particular, we let the selection of both concepts and images be entirely driven by native speakers, rather than scraping them automatically. specifically, we focus on a typologically diverse set of languages, namely, indonesian, mandarin chinese, swahili, tamil, and turkish. on top of the concepts and images obtained through this new protocol, we create a multilingual dataset for {m}ulticultur{a}l {r}easoning over {v}ision and {l}anguage (marvl) by eliciting statements from native speaker annotators about pairs of images. the task consists of discriminating whether each grounded statement is true or false. we establish a series of baselines using state-of-the-art models and find that their cross-lingual transfer performance lags dramatically behind supervised performance in english. these results invite us to reassess the robustness and accuracy of current state-of-the-art models beyond a narrow domain, but also open up new exciting challenges for the development of truly multilingual and multicultural systems. ","1485":"vaccine hesitancy has a long history but has been recently driven by the anti-vaccine narratives shared online, which significantly degrades the efficacy of vaccination strategies, such as those for covid-19. despite broad agreement in the medical community about the safety and efficacy of available vaccines, a large number of social media users continue to be inundated with false information about vaccines and, partly because of this, became indecisive or unwilling to be vaccinated. the goal of this study is to better understand anti-vaccine sentiment, and work to reduce its impact, by developing a system capable of automatically identifying the users responsible for spreading anti-vaccine narratives. we introduce a publicly available python package capable of analyzing twitter profiles to assess how likely that profile is to spread anti-vaccine sentiment in the future. the software package is built using text embedding methods, neural networks, and automated dataset generation. it is trained on over one hundred thousand accounts and several million tweets. this model will help researchers and policy-makers understand anti-vaccine discussion and misinformation strategies, which can further help tailor targeted campaigns seeking to inform and debunk the harmful anti-vaccination myths currently being spread. additionally, we leverage the data on such users to understand what are the moral and emotional characteristics of anti-vaccine spreaders. ","1486":"while large pre-trained models have enabled impressive results on a variety of downstream tasks, the largest existing models still make errors, and even accurate predictions may become outdated over time. because detecting all such failures at training time is impossible, enabling both developers and end users of such models to correct inaccurate outputs while leaving the model otherwise intact is desirable. however, the distributed, black-box nature of the representations learned by large neural networks makes producing such targeted edits difficult. if presented with only a single problematic input and new desired output, fine-tuning approaches tend to overfit; other editing algorithms are either computationally infeasible or simply ineffective when applied to very large models. to enable easy post-hoc editing at scale, we propose model editor networks with gradient decomposition (mend), a collection of small auxiliary editing networks that use a single desired input-output pair to make fast, local edits to a pre-trained model. mend learns to transform the gradient obtained by standard fine-tuning, using a low-rank decomposition of the gradient to make the parameterization of this transformation tractable. mend can be trained on a single gpu in less than a day even for 10 billion+ parameter models; once trained mend enables rapid application of new edits to the pre-trained model. our experiments with t5, gpt, bert, and bart models show that mend is the only approach to model editing that produces effective edits for models with tens of millions to over 10 billion parameters. implementation available at https:\/\/sites.google.com\/view\/mend-editing. ","1487":"sentence matching is a fundamental task of natural language processing with various applications. most recent approaches adopt attention-based neural models to build word- or phrase-level alignment between two sentences. however, these models usually ignore the inherent structure within the sentences and fail to consider various dependency relationships among text units. to address these issues, this paper proposes a graph-based approach for sentence matching. first, we represent a sentence pair as a graph with several carefully design strategies. we then employ a novel gated graph attention network to encode the constructed graph for sentence matching. experimental results demonstrate that our method substantially achieves state-of-the-art performance on two datasets across tasks of natural language and paraphrase identification. further discussions show that our model can learn meaningful graph structure, indicating its superiority on improved interpretability. ","1488":"a critical point of multi-document summarization (mds) is to learn the relations among various documents. in this paper, we propose a novel abstractive mds model, in which we represent multiple documents as a heterogeneous graph, taking semantic nodes of different granularities into account, and then apply a graph-to-sequence framework to generate summaries. moreover, we employ a neural topic model to jointly discover latent topics that can act as cross-document semantic units to bridge different documents and provide global information to guide the summary generation. since topic extraction can be viewed as a special type of summarization that \"summarizes\" texts into a more abstract format, i.e., a topic distribution, we adopt a multi-task learning strategy to jointly train the topic and summarization module, allowing the promotion of each other. experimental results on the multi-news dataset demonstrate that our model outperforms previous state-of-the-art mds models on both rouge metrics and human evaluation, meanwhile learns high-quality topics. ","1489":"large-scale distributed training of deep acoustic models plays an important role in today's high-performance automatic speech recognition (asr). in this paper we investigate a variety of asynchronous decentralized distributed training strategies based on data parallel stochastic gradient descent (sgd) to show their superior performance over the commonly-used synchronous distributed training via allreduce, especially when dealing with large batch sizes. specifically, we study three variants of asynchronous decentralized parallel sgd (adpsgd), namely, fixed and randomized communication patterns on a ring as well as a delay-by-one scheme. we introduce a mathematical model of adpsgd, give its theoretical convergence rate, and compare the empirical convergence behavior and straggler resilience properties of the three variants. experiments are carried out on an ibm supercomputer for training deep long short-term memory (lstm) acoustic models on the 2000-hour switchboard dataset. recognition and speedup performance of the proposed strategies are evaluated under various training configurations. we show that adpsgd with fixed and randomized communication patterns cope well with slow learners. when learners are equally fast, adpsgd with the delay-by-one strategy has the fastest convergence with large batches. in particular, using the delay-by-one strategy, we can train the acoustic model in less than 2 hours using 128 v100 gpus with competitive word error rates. ","1490":"in recent years, significant effort has been invested verifying the reproducibility and robustness of research claims in social and behavioral sciences (sbs), much of which has involved resource-intensive replication projects. in this paper, we investigate prediction of the reproducibility of sbs papers using machine learning methods based on a set of features. we propose a framework that extracts five types of features from scholarly work that can be used to support assessments of reproducibility of published research claims. bibliometric features, venue features, and author features are collected from public apis or extracted using open source machine learning libraries with customized parsers. statistical features, such as p-values, are extracted by recognizing patterns in the body text. semantic features, such as funding information, are obtained from public apis or are extracted using natural language processing models. we analyze pairwise correlations between individual features and their importance for predicting a set of human-assessed ground truth labels. in doing so, we identify a subset of 9 top features that play relatively more important roles in predicting the reproducibility of sbs papers in our corpus. results are verified by comparing performances of 10 supervised predictive classifiers trained on different sets of features. ","1491":"there has recently been an explosion of work on spoken dialogue systems, along with an increased interest in open-domain systems that engage in casual conversations on popular topics such as movies, books and music. these systems aim to socially engage, entertain, and even empathize with their users. since the achievement of such social goals is hard to measure, recent research has used dialogue length or human ratings as evaluation metrics, and developed methods for automatically calculating novel metrics, such as coherence, consistency, relevance and engagement. here we develop a paradise model for predicting the performance of athena, a dialogue system that has participated in thousands of conversations with real users, while competing as a finalist in the alexa prize. we use both user ratings and dialogue length as metrics for dialogue quality, and experiment with predicting these metrics using automatic features that are both system dependent and independent. our goal is to learn a general objective function that can be used to optimize the dialogue choices of any alexa prize system in real time and evaluate its performance. our best model for predicting user ratings gets an r$^2$ of .136 with a distilbert model, and the best model for predicting length with system independent features gets an r$^2$ of .865, suggesting that conversation length may be a more reliable measure for automatic training of dialogue systems. ","1492":"while pre-trained language models have achieved great success on various natural language understanding tasks, how to effectively leverage them into non-autoregressive generation tasks remains a challenge. to solve this problem, we present a non-autoregressive generation model based on pre-trained transformer models. to bridge the gap between autoregressive and non-autoregressive models, we propose a simple and effective iterative training method called mix source and pseudo target (mist). unlike other iterative decoding methods, which sacrifice the inference speed to achieve better performance based on multiple decoding iterations, mist works in the training stage and has no effect on inference time. our experiments on three generation benchmarks including question generation, summarization and paraphrase generation, show that the proposed framework achieves the new state-of-the-art results for fully non-autoregressive models. we also demonstrate that our method can be used to a variety of pre-trained models. for instance, mist based on the small pre-trained model also obtains comparable performance with seq2seq models. ","1493":"the evaluation of question answering models compares ground-truth annotations with model predictions. however, as of today, this comparison is mostly lexical-based and therefore misses out on answers that have no lexical overlap but are still semantically similar, thus treating correct answers as false. this underestimation of the true performance of models hinders user acceptance in applications and complicates a fair comparison of different models. therefore, there is a need for an evaluation metric that is based on semantics instead of pure string similarity. in this short paper, we present sas, a cross-encoder-based metric for the estimation of semantic answer similarity, and compare it to seven existing metrics. to this end, we create an english and a german three-way annotated evaluation dataset containing pairs of answers along with human judgment of their semantic similarity, which we release along with an implementation of the sas metric and the experiments. we find that semantic similarity metrics based on recent transformer models correlate much better with human judgment than traditional lexical similarity metrics on our two newly created datasets and one dataset from related work. ","1494":"we present logical optimal actions (loa), an action decision architecture of reinforcement learning applications with a neuro-symbolic framework which is a combination of neural network and symbolic knowledge acquisition approach for natural language interaction games. the demonstration for loa experiments consists of a web-based interactive platform for text-based games and visualization for acquired knowledge for improving interpretability for trained rules. this demonstration also provides a comparison module with other neuro-symbolic approaches as well as non-symbolic state-of-the-art agent models on the same text-based games. our loa also provides open-sourced implementation in python for the reinforcement learning environment to facilitate an experiment for studying neuro-symbolic agents. code: https:\/\/github.com\/ibm\/loa ","1495":"deep reinforcement learning (rl) methods often require many trials before convergence, and no direct interpretability of trained policies is provided. in order to achieve fast convergence and interpretability for the policy in rl, we propose a novel rl method for text-based games with a recent neuro-symbolic framework called logical neural network, which can learn symbolic and interpretable rules in their differentiable network. the method is first to extract first-order logical facts from text observation and external word meaning network (conceptnet), then train a policy in the network with directly interpretable logical operators. our experimental results show rl training with the proposed method converges significantly faster than other state-of-the-art neuro-symbolic methods in a textworld benchmark. ","1496":"beam search is the default decoding strategy for many sequence generation tasks in nlp. the set of approximate k-best items returned by the algorithm is a useful summary of the distribution for many applications; however, the candidates typically exhibit high overlap and may give a highly biased estimate for expectations under our model. these problems can be addressed by instead using stochastic decoding strategies. in this work, we propose a new method for turning beam search into a stochastic process: conditional poisson stochastic beam search. rather than taking the maximizing set at each iteration, we sample k candidates without replacement according to the conditional poisson sampling design. we view this as a more natural alternative to kool et. al. 2019's stochastic beam search (sbs). furthermore, we show how samples generated under the cpsbs design can be used to build consistent estimators and sample diverse sets from sequence models. in our experiments, we observe cpsbs produces lower variance and more efficient estimators than sbs, even showing improvements in high entropy settings. ","1497":"automatic text summarization aims to produce a brief but crucial summary for the input documents. both extractive and abstractive methods have witnessed great success in english datasets in recent years. however, there has been a minimal exploration of text summarization in chinese, limited by the lack of large-scale datasets. in this paper, we present a large-scale chinese news summarization dataset cnewsum, which consists of 304,307 documents and human-written summaries for the news feed. it has long documents with high-abstractive summaries, which can encourage document-level understanding and generation for current summarization models. an additional distinguishing feature of cnewsum is that its test set contains adequacy and deducibility annotations for the summaries. the adequacy level measures the degree of summary information covered by the document, and the deducibility indicates the reasoning ability the model needs to generate the summary. these annotations can help researchers analyze and target their model performance bottleneck. we examine recent methods on cnewsum and release our dataset to provide a solid testbed for automatic chinese summarization research. ","1498":"embedding-based entity alignment (eea) has recently received great attention. despite significant performance improvement, few efforts have been paid to facilitate understanding of eea methods. most existing studies rest on the assumption that a small number of pre-aligned entities can serve as anchors connecting the embedding spaces of two kgs. nevertheless, no one investigates the rationality of such an assumption. to fill the research gap, we define a typical paradigm abstracted from existing eea methods and analyze how the embedding discrepancy between two potentially aligned entities is implicitly bounded by a predefined margin in the scoring function. further, we find that such a bound cannot guarantee to be tight enough for alignment learning. we mitigate this problem by proposing a new approach, named neoea, to explicitly learn kg-invariant and principled entity embeddings. in this sense, an eea model not only pursues the closeness of aligned entities based on geometric distance, but also aligns the neural ontologies of two kgs by eliminating the discrepancy in embedding distribution and underlying ontology knowledge. our experiments demonstrate consistent and significant improvement in performance against the best-performing eea methods. ","1499":"many text generation systems benefit from using a retriever to retrieve passages from a textual knowledge corpus (e.g., wikipedia) which are then provided as additional context to the generator. for open-ended generation tasks (like generating informative utterances in conversations) many varied passages may be equally relevant and we find that existing methods that jointly train the retriever and generator underperform: the retriever may not find relevant passages even amongst the top-10 and hence the generator may not learn a preference to ground its generated output in them. we propose using an additional guide retriever that is allowed to use the target output and \"in hindsight\" retrieve relevant passages during training. we model the guide retriever after the posterior distribution q of passages given the input and the target output and train it jointly with the standard retriever and the generator by maximizing the evidence lower bound (elbo) in expectation over q. for informative conversations from the wizard of wikipedia dataset, with posterior-guided training, the retriever finds passages with higher relevance in the top-10 (23% relative improvement), the generator's responses are more grounded in the retrieved passage (19% relative improvement) and the end-to-end system produces better overall output (6.4% relative improvement). ","1500":"existing neural information retrieval (ir) models have often been studied in homogeneous and narrow settings, which has considerably limited insights into their out-of-distribution (ood) generalization capabilities. to address this, and to facilitate researchers to broadly evaluate the effectiveness of their models, we introduce benchmarking-ir (beir), a robust and heterogeneous evaluation benchmark for information retrieval. we leverage a careful selection of 18 publicly available datasets from diverse text retrieval tasks and domains and evaluate 10 state-of-the-art retrieval systems including lexical, sparse, dense, late-interaction and re-ranking architectures on the beir benchmark. our results show bm25 is a robust baseline and re-ranking and late-interaction-based models on average achieve the best zero-shot performances, however, at high computational costs. in contrast, dense and sparse-retrieval models are computationally more efficient but often underperform other approaches, highlighting the considerable room for improvement in their generalization capabilities. we hope this framework allows us to better evaluate and understand existing retrieval systems, and contributes to accelerating progress towards better robust and generalizable systems in the future. beir is publicly available at https:\/\/github.com\/ukplab\/beir. ","1501":"while much research has been done in text-to-image synthesis, little work has been done to explore the usage of linguistic structure of the input text. such information is even more important for story visualization since its inputs have an explicit narrative structure that needs to be translated into an image sequence (or visual story). prior work in this domain has shown that there is ample room for improvement in the generated image sequence in terms of visual quality, consistency and relevance. in this paper, we first explore the use of constituency parse trees using a transformer-based recurrent architecture for encoding structured input. second, we augment the structured input with commonsense information and study the impact of this external knowledge on the generation of visual story. third, we also incorporate visual structure via bounding boxes and dense captioning to provide feedback about the characters\/objects in generated images within a dual learning setup. we show that off-the-shelf dense-captioning models trained on visual genome can improve the spatial structure of images from a different target domain without needing fine-tuning. we train the model end-to-end using intra-story contrastive loss (between words and image sub-regions) and show significant improvements in several metrics (and human evaluation) for multiple datasets. finally, we provide an analysis of the linguistic and visuo-spatial information. code and data: https:\/\/github.com\/adymaharana\/vlcstorygan. ","1502":"next generation task-oriented dialog systems need to understand conversational contexts with their perceived surroundings, to effectively help users in the real-world multimodal environment. existing task-oriented dialog datasets aimed towards virtual assistance fall short and do not situate the dialog in the user's multimodal context. to overcome, we present a new dataset for situated and interactive multimodal conversations, simmc 2.0, which includes 11k task-oriented user<->assistant dialogs (117k utterances) in the shopping domain, grounded in immersive and photo-realistic scenes.   the dialogs are collected using a two-phase pipeline: (1) a novel multimodal dialog simulator generates simulated dialog flows, with an emphasis on diversity and richness of interactions, (2) manual paraphrasing of the generated utterances to collect diverse referring expressions. we provide an in-depth analysis of the collected dataset, and describe in detail the four main benchmark tasks we propose. our baseline model, powered by the state-of-the-art language model, shows promising results, and highlights new challenges and directions for the community to study. ","1503":"we provide a hands-on introduction to optimized textual sentiment indexation using the r package sentometrics. textual sentiment analysis is increasingly used to unlock the potential information value of textual data. the sentometrics package implements an intuitive framework to efficiently compute sentiment scores of numerous texts, to aggregate the scores into multiple time series, and to use these time series to predict other variables. the workflow of the package is illustrated with a built-in corpus of news articles from two major u.s. journals to forecast the cboe volatility index. ","1504":"recent progress in pretrained transformer-based language models has shown great success in learning contextual representation of text. however, due to the quadratic self-attention complexity, most of the pretrained transformers models can only handle relatively short text. it is still a challenge when it comes to modeling very long documents. in this work, we propose to use a graph attention network on top of the available pretrained transformers model to learn document embeddings. this graph attention network allows us to leverage the high-level semantic structure of the document. in addition, based on our graph document model, we design a simple contrastive learning strategy to pretrain our models on a large amount of unlabeled corpus. empirically, we demonstrate the effectiveness of our approaches in document classification and document retrieval tasks. ","1505":"why do models often attend to salient words, and how does this evolve throughout training? we approximate model training as a two stage process: early on in training when the attention weights are uniform, the model learns to translate individual input word `i` to `o` if they co-occur frequently. later, the model learns to attend to `i` while the correct output is $o$ because it knows `i` translates to `o`. to formalize, we define a model property, knowledge to translate individual words (ktiw) (e.g. knowing that `i` translates to `o`), and claim that it drives the learning of the attention. this claim is supported by the fact that before the attention mechanism is learned, ktiw can be learned from word co-occurrence statistics, but not the other way around. particularly, we can construct a training distribution that makes ktiw hard to learn, the learning of the attention fails, and the model cannot even learn the simple task of copying the input words to the output. our approximation explains why models sometimes attend to salient words, and inspires a toy example where a multi-head attention model can overcome the above hard training distribution by improving learning dynamics rather than expressiveness. we end by discussing the limitation of our approximation framework and suggest future directions. ","1506":"generating texts in scientific papers requires not only capturing the content contained within the given input but also frequently acquiring the external information called \\textit{context}. we push forward the scientific text generation by proposing a new task, namely \\textbf{context-aware text generation} in the scientific domain, aiming at exploiting the contributions of context in generated texts. to this end, we present a novel challenging large-scale \\textbf{sci}entific paper dataset for conte\\textbf{x}t-aware text \\textbf{gen}eration (scixgen), consisting of well-annotated 205,304 papers with full references to widely-used objects (e.g., tables, figures, algorithms) in a paper. we comprehensively benchmark, using state-of-the-arts, the efficacy of our newly constructed scixgen dataset in generating description and paragraph. our dataset and benchmarks will be made publicly available to hopefully facilitate the scientific text generation research. ","1507":"evaluation in nlp is usually done by comparing the scores of competing systems independently averaged over a common set of test instances. in this work, we question the use of averages for aggregating evaluation scores into a final number used to decide which system is best, since the average, as well as alternatives such as the median, ignores the pairing arising from the fact that systems are evaluated on the same test instances. we illustrate the importance of taking the instance-level pairing of evaluation scores into account and demonstrate, both theoretically and empirically, the advantages of aggregation methods based on pairwise comparisons, such as the bradley-terry (bt) model, a mechanism based on the estimated probability that a given system scores better than another on the test set. by re-evaluating 296 real nlp evaluation setups across four tasks and 18 evaluation metrics, we show that the choice of aggregation mechanism matters and yields different conclusions as to which systems are state of the art in about 30% of the setups. to facilitate the adoption of pairwise evaluation, we release a practical tool for performing the full analysis of evaluation scores with the mean, median, bt, and two variants of bt (elo and trueskill), alongside functionality for appropriate statistical testing. ","1508":"world models improve a learning agent's ability to efficiently operate in interactive and situated environments. this work focuses on the task of building world models of text-based game environments. text-based games, or interactive narratives, are reinforcement learning environments in which agents perceive and interact with the world using textual natural language. these environments contain long, multi-step puzzles or quests woven through a world that is filled with hundreds of characters, locations, and objects. our world model learns to simultaneously: (1) predict changes in the world caused by an agent's actions when representing the world as a knowledge graph; and (2) generate the set of contextually relevant natural language actions required to operate in the world. we frame this task as a set of sequences generation problem by exploiting the inherent structure of knowledge graphs and actions and introduce both a transformer-based multi-task architecture and a loss function to train it. a zero-shot ablation study on never-before-seen textual worlds shows that our methodology significantly outperforms existing textual world modeling techniques as well as the importance of each of our contributions. ","1509":"while the field of style transfer (st) has been growing rapidly, it has been hampered by a lack of standardized practices for automatic evaluation. in this paper, we evaluate leading st automatic metrics on the oft-researched task of formality style transfer. unlike previous evaluations, which focus solely on english, we expand our focus to brazilian-portuguese, french, and italian, making this work the first multilingual evaluation of metrics in st. we outline best practices for automatic evaluation in (formality) style transfer and identify several models that correlate well with human judgments and are robust across languages. we hope that this work will help accelerate development in st, where human evaluation is often challenging to collect. ","1510":"we describe the 2021 key point analysis (kpa-2021) shared task on key point analysis that we organized as a part of the 8th workshop on argument mining (argmining 2021) at emnlp 2021. we outline various approaches and discuss the results of the shared task. we expect the task and the findings reported in this paper to be relevant for researchers working on text summarization and argument mining. ","1511":"recent research in opinion mining proposed word embedding-based topic modeling methods that provide superior coherence compared to traditional topic modeling. in this paper, we demonstrate how these methods can be used to display correlated topic models on social media texts using socialvistum, our proposed interactive visualization toolkit. it displays a graph with topics as nodes and their correlations as edges. further details are displayed interactively to support the exploration of large text collections, e.g., representative words and sentences of topics, topic and sentiment distributions, hierarchical topic clustering, and customizable, predefined topic labels. the toolkit optimizes automatically on custom data for optimal coherence. we show a working instance of the toolkit on data crawled from english social media discussions about organic food consumption. the visualization confirms findings of a qualitative consumer research study. socialvistum and its training procedures are accessible online. ","1512":"popular dialog datasets such as multiwoz are created by providing crowd workers an instruction, expressed in natural language, that describes the task to be accomplished. crowd workers play the role of a user and an agent to generate dialogs to accomplish tasks involving booking restaurant tables, calling a taxi etc. in this paper, we present a data creation strategy that uses the pre-trained language model, gpt2, to simulate the interaction between crowd workers by creating a user bot and an agent bot. we train the simulators using a smaller percentage of actual crowd-generated conversations and their corresponding instructions. we demonstrate that by using the simulated data, we achieve significant improvements in low-resource settings on two publicly available datasets - the multiwoz dataset and the persona chat dataset. ","1513":"aspect-category sentiment analysis (acsa) aims to predict the aspect categories mentioned in texts and their corresponding sentiment polarities. some joint models have been proposed to address this task. given a text, these joint models detect all the aspect categories mentioned in the text and predict the sentiment polarities toward them at once. although these joint models obtain promising performances, they train separate parameters for each aspect category and therefore suffer from data deficiency of some aspect categories. to solve this problem, we propose a novel joint model which contains a shared sentiment prediction layer. the shared sentiment prediction layer transfers sentiment knowledge between aspect categories and alleviates the problem caused by data deficiency. experiments conducted on semeval-2016 datasets demonstrate the effectiveness of our model. ","1514":"truly real-life data presents a strong, but exciting challenge for sentiment and emotion research. the high variety of possible `in-the-wild' properties makes large datasets such as these indispensable with respect to building robust machine learning models. a sufficient quantity of data covering a deep variety in the challenges of each modality to force the exploratory analysis of the interplay of all modalities has not yet been made available in this context. in this contribution, we present muse-car, a first of its kind multimodal dataset. the data is publicly available as it recently served as the testing bed for the 1st multimodal sentiment analysis challenge, and focused on the tasks of emotion, emotion-target engagement, and trustworthiness recognition by means of comprehensively integrating the audio-visual and language modalities. furthermore, we give a thorough overview of the dataset in terms of collection and annotation, including annotation tiers not used in this year's muse 2020. in addition, for one of the sub-challenges - predicting the level of trustworthiness - no participant outperformed the baseline model, and so we propose a simple, but highly efficient multi-head-attention network that exceeds using multimodal fusion the baseline by around 0.2 ccc (almost 50 % improvement). ","1515":"we introduce the muse-toolbox - a python-based open-source toolkit for creating a variety of continuous and discrete emotion gold standards. in a single framework, we unify a wide range of fusion methods and propose the novel rater aligned annotation weighting (raaw), which aligns the annotations in a translation-invariant way before weighting and fusing them based on the inter-rater agreements between the annotations. furthermore, discrete categories tend to be easier for humans to interpret than continuous signals. with this in mind, the muse-toolbox provides the functionality to run exhaustive searches for meaningful class clusters in the continuous gold standards. to our knowledge, this is the first toolkit that provides a wide selection of state-of-the-art emotional gold standard methods and their transformation to discrete classes. experimental results indicate that muse-toolbox can provide promising and novel class formations which can be better predicted than hard-coded classes boundaries with minimal human intervention. the implementation (1) is out-of-the-box available with all dependencies using a docker container (2). ","1516":"this paper proposes a technique for adding a new source or target language to an existing multilingual nmt model without re-training it on the initial set of languages. it consists in replacing the shared vocabulary with a small language-specific vocabulary and fine-tuning the new embeddings on the new language's parallel data. some additional language-specific components may be trained to improve performance (e.g., transformer layers or adapter modules). because the parameters of the original model are not modified, its performance on the initial languages does not degrade. we show on two sets of experiments (small-scale on ted talks, and large-scale on paracrawl) that this approach performs as well or better as the more costly alternatives; and that it has excellent zero-shot performance: training on english-centric data is enough to translate between the new language and any of the initial languages. ","1517":"we consider the problem of multilingual unsupervised machine translation, translating to and from languages that only have monolingual data by using auxiliary parallel language pairs. for this problem the standard procedure so far to leverage the monolingual data is back-translation, which is computationally costly and hard to tune.   in this paper we propose instead to use denoising adapters, adapter layers with a denoising objective, on top of pre-trained mbart-50. in addition to the modularity and flexibility of such an approach we show that the resulting translations are on-par with back-translating as measured by bleu, and furthermore it allows adding unseen languages incrementally. ","1518":"an exciting frontier in natural language understanding (nlu) and generation (nlg) calls for (vision-and-) language models that can efficiently access external structured knowledge repositories. however, many existing knowledge bases only cover limited domains, or suffer from noisy data, and most of all are typically hard to integrate into neural language pipelines. to fill this gap, we release visualsem: a high-quality knowledge graph (kg) which includes nodes with multilingual glosses, multiple illustrative images, and visually relevant relations. we also release a neural multi-modal retrieval model that can use images or sentences as inputs and retrieves entities in the kg. this multi-modal retrieval model can be integrated into any (neural network) model pipeline. we encourage the research community to use visualsem for data augmentation and\/or as a source of grounding, among other possible uses. visualsem as well as the multi-modal retrieval models are publicly available and can be downloaded in this url: https:\/\/github.com\/iacercalixto\/visualsem ","1519":"in order to achieve deep natural language understanding, syntactic constituent parsing is a vital step, highly demanded by many artificial intelligence systems to process both text and speech. one of the most recent proposals is the use of standard sequence-to-sequence models to perform constituent parsing as a machine translation task, instead of applying task-specific parsers. while they show a competitive performance, these text-to-parse transducers are still lagging behind classic techniques in terms of accuracy, coverage and speed. to close the gap, we here extend the framework of sequence-to-sequence models for constituent parsing, not only by providing a more powerful neural architecture for improving their performance, but also by enlarging their coverage to handle the most complex syntactic phenomena: discontinuous structures. to that end, we design several novel linearizations that can fully produce discontinuities and, for the first time, we test a sequence-to-sequence model on the main discontinuous benchmarks, obtaining competitive results on par with task-specific discontinuous constituent parsers and achieving state-of-the-art scores on the (discontinuous) english penn treebank. ","1520":"the remarkable performance of the pre-trained language model (lm) using self-supervised learning has led to a major paradigm shift in the study of natural language processing. in line with these changes, leveraging the performance of speech recognition systems with massive deep learning-based lms is a major topic of speech recognition research. among the various methods of applying lms to speech recognition systems, in this paper, we focus on a cross-modal knowledge distillation method that transfers knowledge between two types of deep neural networks with different modalities. we propose an acoustic model structure with multiple auxiliary output layers for cross-modal distillation and demonstrate that the proposed method effectively compensates for the shortcomings of the existing label-interpolation-based distillation method. in addition, we extend the proposed method to a hierarchical distillation method using lms trained in different units (senones, monophones, and subwords) and reveal the effectiveness of the hierarchical distillation method through an ablation study. ","1521":"nowadays, data analysis has become a problem as the amount of data is constantly increasing. in order to overcome this problem in textual data, many models and methods are used in natural language processing. the topic modeling field is one of these methods. topic modeling allows determining the semantic structure of a text document. latent dirichlet allocation (lda) is the most common method among topic modeling methods. in this article, the proposed n-stage lda method, which can enable the lda method to be used more effectively, is explained in detail. the positive effect of the method has been demonstrated by the applied english and turkish studies. since the method focuses on reducing the word count in the dictionary, it can be used language-independently. you can access the open-source code of the method and the example: https:\/\/github.com\/anil1055\/n-stage_lda ","1522":"monitoring progress on the united nations sustainable development goals (sdgs) is important for both academic and non-academic organizations. existing approaches to monitoring sdgs have focused on specific data types, namely, publications listed in proprietary research databases. we present the text2sdg r package, a user-friendly, open-source package that detects sdgs in any kind of text data using several different query systems from any text source. the text2sdg package thereby facilitates the monitoring of sdgs for a wide array of text sources and provides a much-needed basis for validating and improving extant methods to detect sdgs from text. ","1523":"recently, the development of pre-trained language models has brought natural language processing (nlp) tasks to the new state-of-the-art. in this paper we explore the efficiency of various pre-trained language models. we pre-train a list of transformer-based models with the same amount of text and the same training steps. the experimental results shows that the most improvement upon the origin bert is adding the rnn-layer to capture more contextual information for short text understanding. ","1524":"in this paper, we propose sentiment classification models based on bert integrated with dro (distributionally robust classifiers) to improve model performance on datasets with distributional shifts. we added 2-layer bi-lstm, projection layer (onto simplex or lp ball), and linear layer on top of bert to achieve distributionally robustness. we considered one form of distributional shift (from imdb dataset to rotten tomatoes dataset). we have confirmed through experiments that our dro model does improve performance on our test set with distributional shift from the training set. ","1525":"existing text- and image-based multimodal dialogue systems use the traditional hierarchical recurrent encoder-decoder (hred) framework, which has an utterance-level encoder to model utterance representation and a context-level encoder to model context representation. although pioneer efforts have shown promising performances, they still suffer from the following challenges: (1) the interaction between textual features and visual features is not fine-grained enough. (2) the context representation can not provide a complete representation for the context. to address the issues mentioned above, we propose a non-hierarchical attention network with modality dropout, which abandons the hred framework and utilizes attention modules to encode each utterance and model the context representation. to evaluate our proposed model, we conduct comprehensive experiments on a public multimodal dialogue dataset. automatic and human evaluation demonstrate that our proposed model outperforms the existing methods and achieves state-of-the-art performance. ","1526":"this paper presents an approach to measuring business sentiment based on textual data. business sentiment has been measured by traditional surveys, which are costly and time-consuming to conduct. to address the issues, we take advantage of daily newspaper articles and adopt a self-attention-based model to define a business sentiment index, named s-apir, where outlier detection models are investigated to properly handle various genres of news articles. moreover, we propose a simple approach to temporally analyzing how much any given event contributed to the predicted business sentiment index. to demonstrate the validity of the proposed approach, an extensive analysis is carried out on 12 years' worth of newspaper articles. the analysis shows that the s-apir index is strongly and positively correlated with established survey-based index (up to correlation coefficient r=0.937) and that the outlier detection is effective especially for a general newspaper. also, s-apir is compared with a variety of economic indices, revealing the properties of s-apir that it reflects the trend of the macroeconomy as well as the economic outlook and sentiment of economic agents. moreover, to illustrate how s-apir could benefit economists and policymakers, several events are analyzed with respect to their impacts on business sentiment over time. ","1527":"we propose a new approach for learning contextualised cross-lingual word embeddings based on a small parallel corpus (e.g. a few hundred sentence pairs). our method obtains word embeddings via an lstm encoder-decoder model that simultaneously translates and reconstructs an input sentence. through sharing model parameters among different languages, our model jointly trains the word embeddings in a common cross-lingual space. we also propose to combine word and subword embeddings to make use of orthographic similarities across different languages. we base our experiments on real-world data from endangered languages, namely yongning na, shipibo-konibo, and griko. our experiments on bilingual lexicon induction and word alignment tasks show that our model outperforms existing methods by a large margin for most language pairs. these results demonstrate that, contrary to common belief, an encoder-decoder translation model is beneficial for learning cross-lingual representations even in extremely low-resource conditions. furthermore, our model also works well on high-resource conditions, achieving state-of-the-art performance on a german-english word-alignment task. ","1528":"unsupervised pre-training is now the predominant approach for both text and speech understanding. self-attention models pre-trained on large amounts of unannotated data have been hugely successful when fine-tuned on downstream tasks from a variety of domains and languages. this paper takes the universality of unsupervised language pre-training one step further, by unifying speech and text pre-training within a single model. we build a single encoder with the bert objective on unlabeled text together with the w2v-bert objective on unlabeled speech. to further align our model representations across modalities, we leverage alignment losses, specifically translation language modeling (tlm) and speech text matching (stm) that make use of supervised speech-text recognition data. we demonstrate that incorporating both speech and text data during pre-training can significantly improve downstream quality on covost~2 speech translation, by around 1 bleu compared to single-modality pre-trained models, while retaining close to sota performance on librispeech and speechstew asr tasks. on four glue tasks and text-normalization, we observe evidence of capacity limitations and interference between the two modalities, leading to degraded performance compared to an equivalent text-only model, while still being competitive with bert. through extensive empirical analysis we also demonstrate the importance of the choice of objective function for speech pre-training, and the beneficial effect of adding additional supervised signals on the quality of the learned representations. ","1529":"change captioning is to use a natural language sentence to describe the fine-grained disagreement between two similar images. viewpoint change is the most typical distractor in this task, because it changes the scale and location of the objects and overwhelms the representation of real change. in this paper, we propose a relation-embedded representation reconstruction network (r$^3$net) to explicitly distinguish the real change from the large amount of clutter and irrelevant changes. specifically, a relation-embedded module is first devised to explore potential changed objects in the large amount of clutter. then, based on the semantic similarities of corresponding locations in the two images, a representation reconstruction module (rrm) is designed to learn the reconstruction representation and further model the difference representation. besides, we introduce a syntactic skeleton predictor (ssp) to enhance the semantic interaction between change localization and caption generation. extensive experiments show that the proposed method achieves the state-of-the-art results on two public datasets. ","1530":"while large-scale pretrained language models have been shown to learn effective linguistic representations for many nlp tasks, there remain many real-world contextual aspects of language that current approaches do not capture. for instance, consider a cloze-test \"i enjoyed the ____ game this weekend\": the correct answer depends heavily on where the speaker is from, when the utterance occurred, and the speaker's broader social milieu and preferences. although language depends heavily on the geographical, temporal, and other social contexts of the speaker, these elements have not been incorporated into modern transformer-based language models. we propose a simple but effective approach to incorporate speaker social context into the learned representations of large-scale language models. our method first learns dense representations of social contexts using graph representation learning algorithms and then primes language model pretraining with these social context representations. we evaluate our approach on geographically-sensitive language-modeling tasks and show a substantial improvement (more than 100% relative lift on mrr) compared to baselines. ","1531":"we evaluate a simple approach to improving zero-shot multilingual transfer of mbert on social media corpus by adding a pretraining task called translation pair prediction (tpp), which predicts whether a pair of cross-lingual texts are a valid translation. our approach assumes access to translations (exact or approximate) between source-target language pairs, where we fine-tune a model on source language task data and evaluate the model in the target language. in particular, we focus on language pairs where transfer learning is difficult for mbert: those where source and target languages are different in script, vocabulary, and linguistic typology. we show improvements from tpp pretraining over mbert alone in zero-shot transfer from english to hindi, arabic, and japanese on two social media tasks: ner (a 37% average relative improvement in f1 across target languages) and sentiment classification (12% relative improvement in f1) on social media text, while also benchmarking on a non-social media task of universal dependency pos tagging (6.7% relative improvement in accuracy). our results are promising given the lack of social media bitext corpus. our code can be found at: https:\/\/github.com\/twitter-research\/multilingual-alignment-tpp. ","1532":"to capture the semantic graph structure from raw text, most existing summarization approaches are built on gnns with a pre-trained model. however, these methods suffer from cumbersome procedures and inefficient computations for long-text documents. to mitigate these issues, this paper proposes hetformer, a transformer-based pre-trained model with multi-granularity sparse attentions for long-text extractive summarization. specifically, we model different types of semantic nodes in raw text as a potential heterogeneous graph and directly learn heterogeneous relationships (edges) among nodes by transformer. extensive experiments on both single- and multi-document summarization tasks show that hetformer achieves state-of-the-art performance in rouge f1 while using less memory and fewer parameters. ","1533":"drug prescriptions are essential information that must be encoded in electronic medical records. however, much of this information is hidden within free-text reports. this is why the medication extraction task has emerged. to date, most of the research effort has focused on small amount of data and has only recently considered deep learning methods. in this paper, we present an independent and comprehensive evaluation of state-of-the-art neural architectures on the i2b2 medical prescription extraction task both in the supervised and semi-supervised settings. the study shows the very competitive performance of simple dnn models on the task as well as the high interest of pre-trained models. adapting the latter models on the i2b2 dataset enables to push medication extraction performances above the state-of-the-art. finally, the study also confirms that semi-supervised techniques are promising to leverage large amounts of unlabeled data in particular in low resource setting when labeled data is too costly to acquire. ","1534":"in this article, we will present an nlp application in text classifying process using the content-based router. the ultimate goal throughout this article is to predict the event described by a legal ad from the plain text of the ad. this problem is purely a supervised problem that will involve the use of nlp techniques and conventional modeling methodologies through the use of the multi-label residual convolutional neural network for text classification. we will explain the approach put in place to solve the problem of classified ads, the difficulties encountered and the experimental results. ","1535":"geometric organization of objects into semantically meaningful arrangements pervades the built world. as such, assistive robots operating in warehouses, offices, and homes would greatly benefit from the ability to recognize and rearrange objects into these semantically meaningful structures. to be useful, these robots must contend with previously unseen objects and receive instructions without significant programming. while previous works have examined recognizing pairwise semantic relations and sequential manipulation to change these simple relations none have shown the ability to arrange objects into complex structures such as circles or table settings. to address this problem we propose a novel transformer-based neural network, structformer, which takes as input a partial-view point cloud of the current object arrangement and a structured language command encoding the desired object configuration. we show through rigorous experiments that structformer enables a physical robot to rearrange novel objects into semantically meaningful structures with multi-object relational constraints inferred from the language command. ","1536":"table2text systems generate textual output based on structured data utilizing machine learning. these systems are essential for fluent natural language interfaces in tools such as virtual assistants; however, left to generate freely these ml systems often produce misleading or unexpected outputs. genni (generation negotiation interface) is an interactive visual system for high-level human-ai collaboration in producing descriptive text. the tool utilizes a deep learning model designed with explicit control states. these controls allow users to globally constrain model generations, without sacrificing the representation power of the deep learning models. the visual interface makes it possible for users to interact with ai systems following a refine-forecast paradigm to ensure that the generation system acts in a manner human users find suitable. we report multiple use cases on two experiments that improve over uncontrolled generation approaches, while at the same time providing fine-grained control. a demo and source code are available at https:\/\/genni.vizhub.ai . ","1537":"since visual perception can give rich information beyond text descriptions for world understanding, there has been increasing interest in leveraging visual grounding for language learning. recently, vokenization (tan and bansal, 2020) has attracted attention by using the predictions of a text-to-image retrieval model as labels for language model supervision. despite its success, the method suffers from approximation error of using finite image labels and the lack of vocabulary diversity of a small image-text dataset. to overcome these limitations, we present vidlankd, a video-language knowledge distillation method for improving language understanding. we train a multi-modal teacher model on a video-text dataset, and then transfer its knowledge to a student language model with a text dataset. to avoid approximation error, we propose to use different knowledge distillation objectives. in addition, the use of a large-scale video-text dataset helps learn diverse and richer vocabularies. in our experiments, vidlankd achieves consistent improvements over text-only language models and vokenization models, on several downstream language understanding tasks including glue, squad, and swag. we also demonstrate the improved world knowledge, physical reasoning, and temporal reasoning capabilities of our model by evaluating on the glue-diagnostics, piqa, and tracie datasets. lastly, we present comprehensive ablation studies as well as visualizations of the learned text-to-video grounding results of our teacher and student language models. our code and models are available at: https:\/\/github.com\/zinengtang\/vidlankd ","1538":"pre-training visual and textual representations from large-scale image-text pairs is becoming a standard approach for many downstream vision-language tasks. the transformer-based models learn inter and intra-modal attention through a list of self-supervised learning tasks. this paper proposes laviter, a novel architecture for visual and textual representation learning. the main module, visual textual alignment (vta) will be assisted by two auxiliary tasks, gan-based image synthesis and image captioning. we also propose a new evaluation metric measuring the similarity between the learnt visual and textual embedding. the experimental results on two public datasets, cub and ms-coco, demonstrate superior visual and textual representation alignment in the joint feature embedding space ","1539":"idiomatic expressions are an integral part of natural language and constantly being added to a language. owing to their non-compositionality and their ability to take on a figurative or literal meaning depending on the sentential context, they have been a classical challenge for nlp systems. to address this challenge, we study the task of detecting whether a sentence has an idiomatic expression and localizing it. prior art for this task had studied specific classes of idiomatic expressions offering limited views of their generalizability to new idioms. we propose a multi-stage neural architecture with the attention flow mechanism for identifying these expressions. the network effectively fuses contextual and lexical information at different levels using word and sub-word representations. empirical evaluations on three of the largest benchmark datasets with idiomatic expressions of varied syntactic patterns and degrees of non-compositionality show that our proposed model achieves new state-of-the-art results. a salient feature of the model is its ability to identify idioms unseen during training with gains from 1.4% to 30.8% over competitive baselines on the largest dataset. ","1540":"the challenge of climate change and biome conservation is one of the most pressing issues of our time - particularly in brazil, where key environmental reserves are located. given the availability of large textual databases on ecological themes, it is natural to resort to question answering (qa) systems to increase social awareness and understanding about these topics. in this work, we introduce multiple qa systems that combine in novel ways the bm25 algorithm, a sparse retrieval technique, with ptt5, a pre-trained state-of-the-art language model. our qa systems focus on the portuguese language, thus offering resources not found elsewhere in the literature. as training data, we collected questions from open-domain datasets, as well as content from the portuguese wikipedia and news from the press. we thus contribute with innovative architectures and novel applications, attaining an f1-score of 36.2 with our best model. ","1541":"we model here an epistemic bias we call \\textit{interpretive blindness} (ib). ib is a special problem for learning from testimony, in which one acquires information only from text or conversation. we show that ib follows from a co-dependence between background beliefs and interpretation in a bayesian setting and the nature of contemporary testimony. we argue that a particular characteristic contemporary testimony, \\textit{argumentative completeness}, can preclude learning in hierarchical bayesian settings, even in the presence of constraints that are designed to promote good epistemic practices. ","1542":"previous works on key information extraction from visually rich documents (vrds) mainly focus on labeling the text within each bounding box (i.e., semantic entity), while the relations in-between are largely unexplored. in this paper, we adapt the popular dependency parsing model, the biaffine parser, to this entity relation extraction task. being different from the original dependency parsing model which recognizes dependency relations between words, we identify relations between groups of words with layout information instead. we have compared different representations of the semantic entity, different vrd encoders, and different relation decoders. the results demonstrate that our proposed model achieves 65.96% f1 score on the funsd dataset. as for the real-world application, our model has been applied to the in-house customs data, achieving reliable performance in the production setting. ","1543":"intelligent personal assistants (ipa) enable voice applications that facilitate people's daily tasks. however, due to the complexity and ambiguity of voice requests, some requests may not be handled properly by the standard natural language understanding (nlu) component. in such cases, a simple reply like \"sorry, i don't know\" hurts the user's experience and limits the functionality of ipa. in this paper, we propose a two-stage shortlister-reranker recommender system to match third-party voice applications (skills) to unhandled utterances. in this approach, a skill shortlister is proposed to retrieve candidate skills from the skill catalog by calculating both lexical and semantic similarity between skills and user requests. we also illustrate how to build a new system by using observed data collected from a baseline rule-based system, and how the exposure biases can generate discrepancy between offline and human metrics. lastly, we present two relabeling methods that can handle the incomplete ground truth, and mitigate exposure bias. we demonstrate the effectiveness of our proposed system through extensive offline experiments. furthermore, we present online a\/b testing results that show a significant boost on user experience satisfaction. ","1544":"this study explores the role of external audiences in determining the importance of family firm brands and the relationship with firm performance. drawing on text mining and social network analysis techniques, and considering the brand prevalence, diversity, and connectivity dimensions, we use the semantic brand score to measure the importance the media give to family firm brands. the analysis of a sample of 52,555 news articles published in 2017 about 63 italian entrepreneurial families reveals that brand importance is positively associated with family firm revenues, and this relationship is stronger when there is identity match between the family and the firm. this study advances current literature by offering a rich and multifaceted perspective on how external audiences perceptions of the brand shape family firm performance. ","1545":"open-domain extractive question answering works well on textual data by first retrieving candidate texts and then extracting the answer from those candidates. however, some questions cannot be answered by text alone but require information stored in tables. in this paper, we present an approach for retrieving both texts and tables relevant to a question by jointly encoding texts, tables and questions into a single vector space. to this end, we create a new multi-modal dataset based on text and table datasets from related work and compare the retrieval performance of different encoding schemata. we find that dense vector embeddings of transformer models outperform sparse embeddings on four out of six evaluation datasets. comparing different dense embedding models, tri-encoders with one encoder for each question, text and table, increase retrieval performance compared to bi-encoders with one encoder for the question and one for both text and tables. we release the newly created multi-modal dataset to the community so that it can be used for training and evaluation. ","1546":"the principle of independent causal mechanisms (icm) states that generative processes of real world data consist of independent modules which do not influence or inform each other. while this idea has led to fruitful developments in the field of causal inference, it is not widely-known in the nlp community. in this work, we argue that the causal direction of the data collection process bears nontrivial implications that can explain a number of published nlp findings, such as differences in semi-supervised learning (ssl) and domain adaptation (da) performance across different settings. we categorize common nlp tasks according to their causal direction and empirically assay the validity of the icm principle for text data using minimum description length. we conduct an extensive meta-analysis of over 100 published ssl and 30 da studies, and find that the results are consistent with our expectations based on causal insights. this work presents the first attempt to analyze the icm principle in nlp, and provides constructive suggestions for future modeling choices. code available at https:\/\/github.com\/zhijing-jin\/icm4nlp ","1547":"an overarching goal of natural language processing is to enable machines to communicate seamlessly with humans. however, natural language can be ambiguous or unclear. in cases of uncertainty, humans engage in an interactive process known as repair: asking questions and seeking clarification until their uncertainty is resolved. we propose a framework for building a visually grounded question-asking model capable of producing polar (yes-no) clarification questions to resolve misunderstandings in dialogue. our model uses an expected information gain objective to derive informative questions from an off-the-shelf image captioner without requiring any supervised question-answer data. we demonstrate our model's ability to pose questions that improve communicative success in a goal-oriented 20 questions game with synthetic and human answerers. ","1548":"a creative image-and-text generative ai system mimics humans' extraordinary abilities to provide users with diverse and comprehensive caption suggestions, as well as rich image creations. in this work, we demonstrate such an ai creation system to produce both diverse captions and rich images. when users imagine an image and associate it with multiple captions, our system paints a rich image to reflect all captions faithfully. likewise, when users upload an image, our system depicts it with multiple diverse captions. we propose a unified multi-modal framework to achieve this goal. specifically, our framework jointly models image-and-text representations with a transformer network, which supports rich image creation by accepting multiple captions as input. we consider the relations among input captions to encourage diversity in training and adopt a non-autoregressive decoding strategy to enable real-time inference. based on these, our system supports both diverse captions and rich images generations. our code is available online. ","1549":"we study the joint learning of image-to-text and text-to-image generations, which are naturally bi-directional tasks. typical existing works design two separate task-specific models for each task, which impose expensive design efforts. in this work, we propose a unified image-and-text generative framework based on a single multimodal model to jointly study the bi-directional tasks. we adopt transformer as our unified architecture for its strong performance and task-agnostic design. specifically, we formulate both tasks as sequence generation tasks, where we represent images and text as unified sequences of tokens, and the transformer learns multimodal interactions to generate sequences. we further propose two-level granularity feature representations and sequence-level training to improve the transformer-based unified framework. experiments show that our approach significantly improves previous transformer-based model x-lxmert's fid from 37.0 to 29.9 (lower is better) for text-to-image generation, and improves cider-d score from 100.9% to 122.6% for fine-tuned image-to-text generation on the ms-coco dataset. our code is available online. ","1550":"humans are remarkably flexible when understanding new sentences that include combinations of concepts they have never encountered before. recent work has shown that while deep networks can mimic some human language abilities when presented with novel sentences, systematic variation uncovers the limitations in the language-understanding abilities of networks. we demonstrate that these limitations can be overcome by addressing the generalization challenges in the gscan dataset, which explicitly measures how well an agent is able to interpret novel linguistic commands grounded in vision, e.g., novel pairings of adjectives and nouns. the key principle we employ is compositionality: that the compositional structure of networks should reflect the compositional structure of the problem domain they address, while allowing other parameters to be learned end-to-end. we build a general-purpose mechanism that enables agents to generalize their language understanding to compositional domains. crucially, our network has the same state-of-the-art performance as prior work while generalizing its knowledge when prior work does not. our network also provides a level of interpretability that enables users to inspect what each part of networks learns. robust grounded language understanding without dramatic failures and without corner cases is critical to building safe and fair robots; we demonstrate the significant role that compositionality can play in achieving that goal. ","1551":"multimodal deep learning has garnered much interest, and transformers have triggered novel approaches, thanks to the cross-attention mechanism. here we propose an approach to deal with two key existing challenges: the high computational resource demanded and the issue of missing modalities. we introduce for the first time the concept of knowledge distillation in transformers to use only one modality at inference time. we report a full study analyzing multiple student-teacher configurations, levels at which distillation is applied, and different methodologies. with the best configuration, we improved the state-of-the-art accuracy by 3%, we reduced the number of parameters by 2.5 times and the inference time by 22%. such performance-computation tradeoff can be exploited in many applications and we aim at opening a new research area where the deployment of complex models with limited resources is demanded. ","1552":"in this study, we explore how language captures the meaning of words, in particular meaning related to sensory experiences learned from statistical distributions across texts. we focus on the most frequent perception verbs of english analyzed from an and agentive vs. experiential distinction across the five basic sensory modalities: visual (to look vs. to see), auditory (to listen vs. to hear), tactile (to touch vs. to feel), olfactory (to smell), and gustatory (to taste). in this study we report on a data-driven approach based on distributional-semantic word embeddings and clustering models to identify and uncover the descriptor sensory spaces of the perception verbs. in the analysis, we identified differences and similarities of the generated descriptors based on qualitative and quantitative differences of the perceptual experience they denote. for instance, our results show that while the perceptual spaces of the experiential verbs like to see, to hear show a more detached, logical way of knowing and learning, their agentive counterparts (to look, listen) provide a more intentional as well as more intimate and intuitive way of discovering and interacting with the world around us. we believe that such an approach has a high potential to expand our understanding and the applicability of such sensory spaces to different fields of social and cultural analysis. research on the semantic organization of sensory spaces for various applications might benefit from an the agentive\/experiential account to address the complexity of multiple senses wired with each other in still unexplored ways. ","1553":"this study reports on the semantic organization of english sensory descriptors of the five basic senses of sight, hearing, touch, taste, and smell in a large corpus of over 8,000 fiction books. we introduce a large-scale text data-driven approach based on distributional-semantic word embeddings to identify and extract these descriptors as well as analyze their mixing interconnections in the resulting conceptual and sensory space. the findings are relevant for research on concept acquisition and representation, as well as for applications that can benefit from a better understanding of perceptual spaces of sensory experiences, in fiction, in particular, and in language in general. ","1554":"this paper presents halo 1.0, an open-ended extensible multi-agent software framework that implements a set of proposed hardware-agnostic accelerator orchestration (halo) principles. halo implements a novel compute-centric message passing interface (c^2mpi) specification for enabling the performance-portable execution of a hardware-agnostic host application across heterogeneous accelerators. the experiment results of evaluating eight widely used hpc subroutines based on intel xeon e5-2620 cpus, intel arria 10 gx fpgas, and nvidia geforce rtx 2080 ti gpus show that halo 1.0 allows for a unified control flow for host programs to run across all the computing devices with a consistently top performance portability score, which is up to five orders of magnitude higher than the opencl-based solution. ","1555":"to quantitatively and intuitively explore the generalization ability of pre-trained language models (plms), we have designed several tasks of arithmetic and logical reasoning. we both analyse how well plms generalize when the test data is in the same distribution as the train data and when it is different, for the latter analysis, we have also designed a cross-distribution test set other than the in-distribution test set. we conduct experiments on one of the most advanced and publicly released generative plm - bart. our research finds that the plms can easily generalize when the distribution is the same, however, it is still difficult for them to generalize out of the distribution. ","1556":"end-to-end tts suffers from high data requirements as it is difficult for both costly speech corpora to cover all necessary knowledge and neural models to learn the knowledge, hence additional knowledge needs to be injected manually. for example, to capture pronunciation knowledge on languages without regular orthography, a complicated grapheme-to-phoneme pipeline needs to be built based on a structured, large pronunciation lexicon, leading to extra, sometimes high, costs to extend neural tts to such languages. in this paper, we propose a framework to learn to extract knowledge from unstructured external resources using token2knowledge attention modules. the framework is applied to build a novel end-to-end tts model named neural lexicon reader that extracts pronunciations from raw lexicon texts. experiments support the potential of our framework that the model significantly reduces pronunciation errors in low-resource, end-to-end chinese tts, and the lexicon-reading capability can be transferred to other languages with a smaller amount of data. ","1557":"machine question answering is an essential yet challenging task in natural language processing. recently, pre-trained contextual embeddings (pce) models like bidirectional encoder representations from transformers (bert) and a lite bert (albert) have attracted lots of attention due to their great performance in a wide range of nlp tasks. in our paper, we utilized the fine-tuned albert models and implemented combinations of additional layers (e.g. attention layer, rnn layer) on top of them to improve model performance on stanford question answering dataset (squad 2.0). we implemented four different models with different layers on top of albert-base model, and two other models based on albert-xlarge and albert-xxlarge. we compared their performance to our baseline model albert-base-v2 + albert-squad-out with details. our best-performing individual model is albert-xxlarge + albert-squad-out, which achieved an f1 score of 88.435 on the dev set. furthermore, we have implemented three different ensemble algorithms to boost overall performance. by passing in several best-performing models' results into our weighted voting ensemble algorithm, our final result ranks first on the stanford cs224n test pce squad leaderboard with f1 = 90.123. ","1558":"recent work in simultaneous machine translation is often trained with conventional full sentence translation corpora, leading to either excessive latency or necessity to anticipate as-yet-unarrived words, when dealing with a language pair whose word orders significantly differ. this is unlike human simultaneous interpreters who produce largely monotonic translations at the expense of the grammaticality of a sentence being translated. in this paper, we thus propose an algorithm to reorder and refine the target side of a full sentence translation corpus, so that the words\/phrases between the source and target sentences are aligned largely monotonically, using word alignment and non-autoregressive neural machine translation. we then train a widely used wait-k simultaneous translation model on this reordered-and-refined corpus. the proposed approach improves bleu scores and resulting translations exhibit enhanced monotonicity with source sentences. ","1559":"it has been argued that fake news and the spread of false information pose a threat to societies throughout the world, from influencing the results of elections to hindering the efforts to manage the covid-19 pandemic. to combat this threat, a number of natural language processing (nlp) approaches have been developed. these leverage a number of datasets, feature extraction\/selection techniques and machine learning (ml) algorithms to detect fake news before it spreads. while these methods are well-documented, there is less evidence regarding their efficacy in this domain. by systematically reviewing the literature, this paper aims to delineate the approaches for fake news detection that are most performant, identify limitations with existing approaches, and suggest ways these can be mitigated. the analysis of the results indicates that ensemble methods using a combination of news content and socially-based features are currently the most effective. finally, it is proposed that future research should focus on developing approaches that address generalisability issues (which, in part, arise from limitations with current datasets), explainability and bias. ","1560":"in this paper, we study training of automatic speech recognition system in a weakly supervised setting where the order of words in transcript labels of the audio training data is not known. we train a word-level acoustic model which aggregates the distribution of all output frames using logsumexp operation and uses a cross-entropy loss to match with the ground-truth words distribution. using the pseudo-labels generated from this model on the training set, we then train a letter-based acoustic model using connectionist temporal classification loss. our system achieves 2.3%\/4.6% on test-clean\/test-other subsets of librispeech, which closely matches with the supervised baseline's performance. ","1561":"adapter layers are lightweight, learnable units inserted between transformer layers. recent work explores using such layers for neural machine translation (nmt), to adapt pre-trained models to new domains or language pairs, training only a small set of parameters for each new setting (language pair or domain). in this work we study the compositionality of language and domain adapters in the context of machine translation. we aim to study, 1) parameter-efficient adaptation to multiple domains and languages simultaneously (full-resource scenario) and 2) cross-lingual transfer in domains where parallel data is unavailable for certain language pairs (partial-resource scenario). we find that in the partial resource scenario a naive combination of domain-specific and language-specific adapters often results in `catastrophic forgetting' of the missing languages. we study other ways to combine the adapters to alleviate this issue and maximize cross-lingual transfer. with our best adapter combinations, we obtain improvements of 3-4 bleu on average for source languages that do not have in-domain data. for target languages without in-domain data, we achieve a similar improvement by combining adapters with back-translation. supplementary material is available at https:\/\/tinyurl.com\/r66stbxj ","1562":"in the world of advice and financial planning, there is seldom one right answer. while traditional algorithms have been successful in solving linear problems, its success often depends on choosing the right features from a dataset, which can be a challenge for nuanced financial planning scenarios. reinforcement learning is a machine learning approach that can be employed with complex data sets where picking the right features can be nearly impossible. in this paper, we will explore the use of machine learning for financial forecasting, predicting economic indicators, and creating a savings strategy. vanguard ml algorithm for goals-based financial planning is based on deep reinforcement learning that identifies optimal savings rates across multiple goals and sources of income to help clients achieve financial success. vanguard learning algorithms are trained to identify market indicators and behaviors too complex to capture with formulas and rules, instead, it works to model the financial success trajectory of investors and their investment outcomes as a markov decision process. we believe that reinforcement learning can be used to create value for advisors and end-investors, creating efficiency, more personalized plans, and data to enable customized solutions. ","1563":"relation classification (sometimes called 'extraction') requires trustworthy datasets for fine-tuning large language models, as well as for evaluation. data collection is challenging for indian languages, because they are syntactically and morphologically diverse, as well as different from resource-rich languages like english. despite recent interest in deep generative models for indian languages, relation classification is still not well served by public data sets. in response, we present indore, a dataset with 21k entity and relation tagged gold sentences in three indian languages, plus english. we start with a multilingual bert (mbert) based system that captures entity span positions and type information and provides competitive monolingual relation classification. using this system, we explore and compare transfer mechanisms between languages. in particular, we study the accuracy efficiency tradeoff between expensive gold instances vs. translated and aligned 'silver' instances. we release the dataset for future research. ","1564":"recent efforts to create challenge benchmarks that test the abilities of natural language understanding models have largely depended on human annotations. in this work, we introduce the \"break, perturb, build\" (bpb) framework for automatic reasoning-oriented perturbation of question-answer pairs. bpb represents a question by decomposing it into the reasoning steps that are required to answer it, symbolically perturbs the decomposition, and then generates new question-answer pairs. we demonstrate the effectiveness of bpb by creating evaluation sets for three reading comprehension (rc) benchmarks, generating thousands of high-quality examples without human intervention. we evaluate a range of rc models on our evaluation sets, which reveals large performance gaps on generated examples compared to the original data. moreover, symbolic perturbations enable fine-grained analysis of the strengths and limitations of models. last, augmenting the training data with examples generated by bpb helps close the performance gaps, without any drop on the original data distribution. ","1565":"with internet users constantly leaving a trail of text, whether through blogs, emails, or social media posts, the ability to write and protest anonymously is being eroded because artificial intelligence, when given a sample of previous work, can match text with its author out of hundreds of possible candidates. existing approaches to authorship anonymization, also known as authorship obfuscation, often focus on protecting binary demographic attributes rather than identity as a whole. even those that do focus on obfuscating identity require manual feedback, lose the coherence of the original sentence, or only perform well given a limited subset of authors. in this paper, we develop a new approach to authorship anonymization by constructing a generative adversarial network that protects identity and optimizes for three different losses corresponding to anonymity, fluency, and content preservation. our fully automatic method achieves comparable results to other methods in terms of content preservation and fluency, but greatly outperforms baselines in regards to anonymization. moreover, our approach is able to generalize well to an open-set context and anonymize sentences from authors it has not encountered before. ","1566":"we propose bermo, an architectural modification to bert, which makes predictions based on a hierarchy of surface, syntactic and semantic language features. we use linear combination scheme proposed in embeddings from language models (elmo) to combine the scaled internal representations from different network depths. our approach has two-fold benefits: (1) improved gradient flow for the downstream task as every layer has a direct connection to the gradients of the loss function and (2) increased representative power as the model no longer needs to copy the features learned in the shallower layer which are necessary for the downstream task. further, our model has a negligible parameter overhead as there is a single scalar parameter associated with each layer in the network. experiments on the probing task from senteval dataset show that our model performs up to $4.65\\%$ better in accuracy than the baseline with an average improvement of $2.67\\%$ on the semantic tasks. when subject to compression techniques, we find that our model enables stable pruning for compressing small datasets like sst-2, where the bert model commonly diverges. we observe that our approach converges $1.67\\times$ and $1.15\\times$ faster than the baseline on mnli and qqp tasks from glue dataset. moreover, our results show that our approach can obtain better parameter efficiency for penalty based pruning approaches on qqp task. ","1567":"sota transformer and dnn short text sentiment classifiers report over 97% accuracy on narrow domains like imdb movie reviews. real-world performance is significantly lower because traditional models overfit benchmarks and generalize poorly to different or more open domain texts. this paper introduces sentimentarcs, a new self-supervised time series sentiment analysis methodology that addresses the two main limitations of traditional supervised sentiment analysis: limited labeled training datasets and poor generalization. a large ensemble of diverse models provides a synthetic ground truth for self-supervised learning. novel metrics jointly optimize an exhaustive search across every possible corpus:model combination. the joint optimization over both the corpus and model solves the generalization problem. simple visualizations exploit the temporal structure in narratives so domain experts can quickly spot trends, identify key features, and note anomalies over hundreds of arcs and millions of data points. to our knowledge, this is the first self-supervised method for time series sentiment analysis and the largest survey directly comparing real-world model performance on long-form narratives. ","1568":"se of machine learning for automatic analysis of job interview videos has recently seen increased interest. despite claims of fair output regarding sensitive information such as gender or ethnicity of the candidates, the current approaches rarely provide proof of unbiased decision-making, or that sensitive information is not used. recently, adversarial methods have been proved to effectively remove sensitive information from the latent representation of neural networks. however, these methods rely on the use of explicitly labeled protected variables (e.g. gender), which cannot be collected in the context of recruiting in some countries (e.g. france). in this article, we propose a new adversarial approach to remove sensitive information from the latent representation of neural networks without the need to collect any sensitive variable. using only a few frames of the interview, we train our model to not be able to find the face of the candidate related to the job interview in the inner layers of the model. this, in turn, allows us to remove relevant private information from these layers. comparing our approach to a standard baseline on a public dataset with gender and ethnicity annotations, we show that it effectively removes sensitive information from the main network. moreover, to the best of our knowledge, this is the first application of adversarial techniques for obtaining a multimodal fair representation in the context of video job interviews. in summary, our contributions aim at improving fairness of the upcoming automatic systems processing videos of job interviews for equality in job selection. ","1569":"the population is aging, and becoming more tech-savvy. the united nations predicts that by 2050, one in six people in the world will be over age 65 (up from one in 11 in 2019), and this increases to one in four in europe and northern america. meanwhile, the proportion of american adults over 65 who own a smartphone has risen 24 percentage points from 2013-2017, and the majority have internet in their homes. smart devices and smart home technology have profound potential to transform how people age, their ability to live independently in later years, and their interactions with their circle of care. cognitive health is a key component to independence and well-being in old age, and smart homes present many opportunities to measure cognitive status in a continuous, unobtrusive manner. in this article, we focus on speech as a measurement instrument for cognitive health. existing methods of cognitive assessment suffer from a number of limitations that could be addressed through smart home speech sensing technologies. we begin with a brief tutorial on measuring cognitive status from speech, including some pointers to useful open-source software toolboxes for the interested reader. we then present an overview of the preliminary results from pilot studies on active and passive smart home speech sensing for the measurement of cognitive health, and conclude with some recommendations and challenge statements for the next wave of work in this area, to help overcome both technical and ethical barriers to success. ","1570":"social media has become a bedrock for people to voice their opinions worldwide. due to the greater sense of freedom with the anonymity feature, it is possible to disregard social etiquette online and attack others without facing severe consequences, inevitably propagating hate speech. the current measures to sift the online content and offset the hatred spread do not go far enough. one factor contributing to this is the prevalence of regional languages in social media and the paucity of language flexible hate speech detectors. the proposed work focuses on analyzing hate speech in hindi-english code-switched language. our method explores transformation techniques to capture precise text representation. to contain the structure of data and yet use it with existing algorithms, we developed moh or map only hindi, which means \"love\" in hindi. moh pipeline consists of language identification, roman to devanagari hindi transliteration using a knowledge base of roman hindi words. finally, it employs the fine-tuned multilingual bert and muril language models. we conducted several quantitative experiment studies on three datasets and evaluated performance using precision, recall, and f1 metrics. the first experiment studies moh mapped text's performance with classical machine learning models and shows an average increase of 13% in f1 scores. the second compares the proposed work's scores with those of the baseline models and offers a rise in performance by 6%. finally, the third reaches the proposed moh technique with various data simulations using the existing transliteration library. here, moh outperforms the rest by 15%. our results demonstrate a significant improvement in the state-of-the-art scores on all three datasets. ","1571":"recent commonsense-reasoning tasks are typically discriminative in nature, where a model answers a multiple-choice question for a certain context. discriminative tasks are limiting because they fail to adequately evaluate the model's ability to reason and explain predictions with underlying commonsense knowledge. they also allow such models to use reasoning shortcuts and not be \"right for the right reasons\". in this work, we present explagraphs, a new generative and structured commonsense-reasoning task (and an associated dataset) of explanation graph generation for stance prediction. specifically, given a belief and an argument, a model has to predict if the argument supports or counters the belief and also generate a commonsense-augmented graph that serves as non-trivial, complete, and unambiguous explanation for the predicted stance. we collect explanation graphs through a novel create-verify-and-refine graph collection framework that improves the graph quality (up to 90%) via multiple rounds of verification and refinement. a significant 79% of our graphs contain external commonsense nodes with diverse structures and reasoning depths. next, we propose a multi-level evaluation framework, consisting of automatic metrics and human evaluation, that check for the structural and semantic correctness of the generated graphs and their degree of match with ground-truth graphs. finally, we present several structured, commonsense-augmented, and text generation models as strong starting points for this explanation graph generation task, and observe that there is a large gap with human performance, thereby encouraging future work for this new challenging task. explagraphs will be publicly available at https:\/\/explagraphs.github.io. ","1572":"to improve the performance of state-of-the-art automatic speech recognition systems it is common practice to include external knowledge sources such as language models or prior corrections. this is usually done via log-linear model combination using separate scaling parameters for each model. typically these parameters are manually optimized on some held-out data.   in this work we propose to optimize these scaling parameters via automatic differentiation and stochastic gradient decent similar to the neural network model parameters. we show on the librispeech (lbs) and switchboard (swb) corpora that the model scales for a combination of attentionbased encoder-decoder acoustic model and language model can be learned as effectively as with manual tuning. we further extend this approach to subword dependent model scales which could not be tuned manually which leads to 7% improvement on lbs and 3% on swb. we also show that joint training of scales and model parameters is possible and gives additional 6% improvement on lbs. ","1573":"gender bias in natural language processing (nlp) applications, particularly machine translation, has been receiving increasing attention. much of the research on this issue has focused on mitigating gender bias in english nlp models and systems. addressing the problem in poorly resourced, and\/or morphologically rich languages has lagged behind, largely due to the lack of datasets and resources. in this paper, we introduce a new corpus for gender identification and rewriting in contexts involving one or two target users (i and\/or you) -- first and second grammatical persons with independent grammatical gender preferences. we focus on arabic, a gender-marking morphologically rich language. the corpus has multiple parallel components: four combinations of 1st and 2nd person in feminine and masculine grammatical genders, as well as english, and english to arabic machine translation output. this corpus expands on habash et al. (2019)'s arabic parallel gender corpus (apgc v1.0) by adding second person targets as well as increasing the total number of sentences over 6.5 times, reaching over 590k words. our new dataset will aid the research and development of gender identification, controlled text generation, and post-editing rewrite systems that could be used to personalize nlp applications and provide users with the correct outputs based on their grammatical gender preferences. we make the arabic parallel gender corpus (apgc v2.0) publicly available. ","1574":"how to best integrate linguistic and perceptual processing in multi-modal tasks that involve language and vision is an important open problem. in this work, we argue that the common practice of using language in a top-down manner, to direct visual attention over high-level visual features, may not be optimal. we hypothesize that the use of language to also condition the bottom-up processing from pixels to high-level features can provide benefits to the overall performance. to support our claim, we propose a model for language-vision problems involving dense prediction, and perform experiments on two different multi-modal tasks: image segmentation from referring expressions and language-guided image colorization. we compare results where either one or both of the top-down and bottom-up visual branches are conditioned on language. our experiments reveal that using language to control the filters for bottom-up visual processing in addition to top-down attention leads to better results on both tasks and achieves state-of-the-art performance. our analysis of different word types in input expressions suggest that the bottom-up conditioning is especially helpful in the presence of low level visual concepts like color. ","1575":"speech recognition systems have made tremendous progress since the last few decades. they have developed significantly in identifying the speech of the speaker. however, there is a scope of improvement in speech recognition systems in identifying the nuances and accents of a speaker. it is known that any specific natural language may possess at least one accent. despite the identical word phonemic composition, if it is pronounced in different accents, we will have sound waves, which are different from each other. differences in pronunciation, in accent and intonation of speech in general, create one of the most common problems of speech recognition. if there are a lot of accents in language we should create the acoustic model for each separately. we carry out a systematic analysis of the problem in the accurate classification of accents. we use traditional machine learning techniques and convolutional neural networks, and show that the classical techniques are not sufficiently efficient to solve this problem. using spectrograms of speech signals, we propose a multi-class classification framework for accent recognition. in this paper, we focus our attention on the french accent. we also identify its limitation by understanding the impact of french idiosyncrasies on its spectrograms. ","1576":"international phonetic alphabet (ipa) has been widely used in cross-lingual text-to-speech (tts) to achieve cross-lingual voice cloning (cl vc). however, ipa itself has been understudied in cross-lingual tts. in this paper, we report some empirical findings of building a cross-lingual tts model using ipa as inputs. experiments show that the way to process the ipa and suprasegmental sequence has a negligible impact on the cl vc performance. furthermore, we find that using a dataset including one speaker per language to build an ipa-based tts system would fail cl vc since the language-unique ipa and tone\/stress symbols could leak the speaker information. in addition, we experiment with different combinations of speakers in the training dataset to further investigate the effect of the number of speakers on the cl vc performance. ","1577":"natural language processing (nlp) systems are increasingly trained to generate open-ended text rather than classifying between responses. this makes research on evaluation metrics for generated language -- functions that score system output given the context and\/or human reference responses -- of critical importance. however, different metrics have different strengths and biases, and reflect human intuitions better on some tasks than others. there is currently no simple, unified way to compare, analyse or evaluate metrics across a representative set of tasks. here, we describe the benchmark to evaluate automatic metrics (beametrics), a resource to make research into new metrics itself easier to evaluate. beametrics users can quickly compare existing and new metrics with human judgements across a diverse set of tasks, quality dimensions (fluency vs. coherence vs. informativeness etc), and languages. as generation experts might predict, beametrics reveals stark task-dependent differences between existing metrics, and consistently poor performance on tasks with complex answer spaces or high reliance on general knowledge. while this analysis highlights a critical issue facing current research practice, beametrics also contribute to its resolution by facilitating research into better metrics -- particularly those that can account for the complex interaction between context and general knowledge inherent to many modern nlp applications. beametrics is available under the mit license: https:\/\/github.com\/thomasscialom\/beametrics ","1578":"an effective approach to automatically predict the subjective rating for synthetic speech is to train on a listening test dataset with human-annotated scores. although each speech sample in the dataset is rated by several listeners, most previous works only used the mean score as the training target. in this work, we present ldnet, a unified framework for mean opinion score (mos) prediction that predicts the listener-wise perceived quality given the input speech and the listener identity. we reflect recent advances in ld modeling, including design choices of the model architecture, and propose two inference methods that provide more stable results and efficient computation. we conduct systematic experiments on the voice conversion challenge (vcc) 2018 benchmark and a newly collected large-scale mos dataset, providing an in-depth analysis of the proposed framework. results show that the mean listener inference method is a better way to utilize the mean scores, whose effectiveness is more obvious when having more ratings per sample. ","1579":"scenic is an open-source jax library with a focus on transformer-based models for computer vision research and beyond. the goal of this toolkit is to facilitate rapid experimentation, prototyping, and research of new vision architectures and models. scenic supports a diverse range of vision tasks (e.g., classification, segmentation, detection)and facilitates working on multi-modal problems, along with gpu\/tpu support for multi-host, multi-device large-scale training. scenic also offers optimized implementations of state-of-the-art research models spanning a wide range of modalities. scenic has been successfully used for numerous projects and published papers and continues serving as the library of choice for quick prototyping and publication of new research ideas. ","1580":"in this era of abundant digital information, customer satisfaction has become one of the prominent factors in the success of any business. customers want a one-click solution for almost everything. they tend to get unsatisfied if they have to call about something which they could have done online. moreover, incoming calls are a high-cost component for any business. thus, it is essential to develop a framework capable of mining the reasons and motivators behind customer calls. this paper proposes two models. firstly, an attention-based stacked bidirectional long short term memory network followed by hierarchical clustering for extracting these reasons from transcripts of inbound calls. secondly, a set of ensemble models based on probabilities from support vector machines and logistic regression. it is capable of detecting factors that led to these calls. extensive evaluation proves the effectiveness of these models. ","1581":"in recent years, end-to-end (e2e) based automatic speech recognition (asr) systems have achieved great success due to their simplicity and promising performance. neural transducer based models are increasingly popular in streaming e2e based asr systems and have been reported to outperform the traditional hybrid system in some scenarios. however, the joint optimization of acoustic model, lexicon and language model in neural transducer also brings about challenges to utilize pure text for language model adaptation. this drawback might prevent their potential applications in practice. in order to address this issue, in this paper, we propose a novel model, factorized neural transducer, by factorizing the blank and vocabulary prediction, and adopting a standalone language model for the vocabulary prediction. it is expected that this factorization can transfer the improvement of the standalone language model to the transducer for speech recognition, which allows various language model adaptation techniques to be applied. we demonstrate that the proposed factorized neural transducer yields 15% to 20% wer improvements when out-of-domain text data is used for language model adaptation, at the cost of a minor degradation in wer on a general test set. ","1582":"we introduce efficientcl, a memory-efficient continual pretraining method that applies contrastive learning with novel data augmentation and curriculum learning. for data augmentation, we stack two types of operation sequentially: cutoff and pca jittering. while pretraining steps proceed, we apply curriculum learning by incrementing the augmentation degree for each difficulty step. after data augmentation is finished, contrastive learning is applied on projected embeddings of original and augmented examples. when finetuned on glue benchmark, our model outperforms baseline models, especially for sentence-level tasks. additionally, this improvement is capable with only 70% of computational memory compared to the baseline model. ","1583":"speech representation learning plays a vital role in speech processing. among them, self-supervised learning (ssl) has become an important research direction. it has been shown that an ssl pretraining model can achieve excellent performance in various downstream tasks of speech processing. on the other hand, supervised multi-task learning (mtl) is another representation learning paradigm, which has been proven effective in computer vision (cv) and natural language processing (nlp). however, there is no systematic research on the general representation learning model trained by supervised mtl in speech processing. in this paper, we show that mtl finetuning can further improve ssl pretraining. we analyze the generalizability of supervised mtl finetuning to examine if the speech representation learned by mtl finetuning can generalize to unseen new tasks. ","1584":"in multiple-choice exams, students select one answer from among typically four choices and can explain why they made that particular choice. students are good at understanding natural language questions and based on their domain knowledge can easily infer the question's answer by 'connecting the dots' across various pertinent facts.   considering automated reasoning for elementary science question answering, we address the novel task of generating explanations for answers from human-authored facts. for this, we examine the practically scalable framework of feature-rich support vector machines leveraging domain-targeted, hand-crafted features. explanations are created from a human-annotated set of nearly 5,000 candidate facts in the worldtree corpus. our aim is to obtain better matches for valid facts of an explanation for the correct answer of a question over the available fact candidates. to this end, our features offer a comprehensive linguistic and semantic unification paradigm. the machine learning problem is the preference ordering of facts, for which we test pointwise regression versus pairwise learning-to-rank.   our contributions are: (1) a case study in which two preference ordering approaches are systematically compared; (2) it is a practically competent approach that can outperform some variants of bert-based reranking models; and (3) the human-engineered features make it an interpretable machine learning model for the task. ","1585":"error correction is widely used in automatic speech recognition (asr) to post-process the generated sentence, and can further reduce the word error rate (wer). although multiple candidates are generated by an asr system through beam search, current error correction approaches can only correct one sentence at a time, failing to leverage the voting effect from multiple candidates to better detect and correct error tokens. in this work, we propose fastcorrect 2, an error correction model that takes multiple asr candidates as input for better correction accuracy. fastcorrect 2 adopts non-autoregressive generation for fast inference, which consists of an encoder that processes multiple source sentences and a decoder that generates the target sentence in parallel from the adjusted source sentence, where the adjustment is based on the predicted duration of each source token. however, there are some issues when handling multiple source sentences. first, it is non-trivial to leverage the voting effect from multiple source sentences since they usually vary in length. thus, we propose a novel alignment algorithm to maximize the degree of token alignment among multiple sentences in terms of token and pronunciation similarity. second, the decoder can only take one adjusted source sentence as input, while there are multiple source sentences. thus, we develop a candidate predictor to detect the most suitable candidate for the decoder. experiments on our inhouse dataset and aishell-1 show that fastcorrect 2 can further reduce the wer over the previous correction model with single candidate by 3.2% and 2.6%, demonstrating the effectiveness of leveraging multiple candidates in asr error correction. fastcorrect 2 achieves better performance than the cascaded re-scoring and correction pipeline and can serve as a unified post-processing module for asr. ","1586":"language identification greatly impacts the success of downstream tasks such as automatic speech recognition. recently, self-supervised speech representations learned by wav2vec 2.0 have been shown to be very effective for a range of speech tasks. we extend previous self-supervised work on language identification by experimenting with pre-trained models which were learned on real-world unconstrained speech in multiple languages and not just on english. we show that models pre-trained on many languages perform better and enable language identification systems that require very little labeled data to perform well. results on a 26 languages setup show that with only 10 minutes of labeled data per language, a cross-lingually pre-trained model can achieve over 89.2% accuracy. ","1587":"recently, neural natural language models have attained state-of-the-art performance on a wide variety of tasks, but the high performance can result from superficial, surface-level cues (bender and koller, 2020; niven and kao, 2020). these surface cues, as the ``shortcuts'' inherent in the datasets, do not contribute to the *task-specific information* (tsi) of the classification tasks. while it is essential to look at the model performance, it is also important to understand the datasets. in this paper, we consider this question: apart from the information introduced by the shortcut features, how much task-specific information is required to classify a dataset? we formulate this quantity in an information-theoretic framework. while this quantity is hard to compute, we approximate it with a fast and stable method. tsi quantifies the amount of linguistic knowledge modulo a set of predefined shortcuts -- that contributes to classifying a sample from each dataset. this framework allows us to compare across datasets, saying that, apart from a set of ``shortcut features'', classifying each sample in the multi-nli task involves around 0.4 nats more tsi than in the quora question pair. ","1588":"recent studies in big data analytics and natural language processing develop automatic techniques in analyzing sentiment in the social media information. in addition, the growing user base of social media and the high volume of posts also provide valuable sentiment information to predict the price fluctuation of the cryptocurrency. this research is directed to predicting the volatile price movement of cryptocurrency by analyzing the sentiment in social media and finding the correlation between them. while previous work has been developed to analyze sentiment in english social media posts, we propose a method to identify the sentiment of the chinese social media posts from the most popular chinese social media platform sina-weibo. we develop the pipeline to capture weibo posts, describe the creation of the crypto-specific sentiment dictionary, and propose a long short-term memory (lstm) based recurrent neural network along with the historical cryptocurrency price movement to predict the price trend for future time frames. the conducted experiments demonstrate the proposed approach outperforms the state of the art auto regressive based model by 18.5% in precision and 15.4% in recall. ","1589":"in the last half-decade, the field of natural language processing (nlp) has undergone two major transitions: the switch to neural networks as the primary modeling paradigm and the homogenization of the training regime (pre-train, then fine-tune). amidst this process, language models have emerged as nlp's workhorse, displaying increasingly fluent generation capabilities and proving to be an indispensable means of knowledge transfer downstream. due to the otherwise opaque, black-box nature of such models, researchers have employed aspects of linguistic theory in order to characterize their behavior. questions central to syntax -- the study of the hierarchical structure of language -- have factored heavily into such work, shedding invaluable insights about models' inherent biases and their ability to make human-like generalizations. in this paper, we attempt to take stock of this growing body of literature. in doing so, we observe a lack of clarity across numerous dimensions, which influences the hypotheses that researchers form, as well as the conclusions they draw from their findings. to remedy this, we urge researchers make careful considerations when investigating coding properties, selecting representations, and evaluating via downstream tasks. furthermore, we outline the implications of the different types of research questions exhibited in studies on syntax, as well as the inherent pitfalls of aggregate metrics. ultimately, we hope that our discussion adds nuance to the prospect of studying language models and paves the way for a less monolithic perspective on syntax in this context. ","1590":"recent advancements in nlp have given us models like mbert and xlmr that can serve over 100 languages. the languages that these models are evaluated on, however, are very few in number, and it is unlikely that evaluation datasets will cover all the languages that these models support. potential solutions to the costly problem of dataset creation are to translate datasets to new languages or use template-filling based techniques for creation. this paper proposes an alternate solution for evaluating a model across languages which make use of the existing performance scores of the model on languages that a particular task has test sets for. we train a predictor on these performance scores and use this predictor to predict the model's performance in different evaluation settings. our results show that our method is effective in filling the gaps in the evaluation for an existing set of languages, but might require additional improvements if we want it to generalize to unseen languages. ","1591":"the covid-19 pandemic triggered a wave of novel scientific literature that is impossible to inspect and study in a reasonable time frame manually. current machine learning methods offer to project such body of literature into the vector space, where similar documents are located close to each other, offering an insightful exploration of scientific papers and other knowledge sources associated with covid-19. however, to start searching, such texts need to be appropriately annotated, which is seldom the case due to the lack of human resources. in our system, the current body of covid-19-related literature is annotated using unsupervised keyphrase extraction, facilitating the initial queries to the latent space containing the learned document embeddings (low-dimensional representations). the solution is accessible through a web server capable of interactive search, term ranking, and exploration of potentially interesting literature. we demonstrate the usefulness of the approach via case studies from the medicinal chemistry domain. ","1592":"opinion summarization aims to profile a target by extracting opinions from multiple documents. most existing work approaches the task in a semi-supervised manner due to the difficulty of obtaining high-quality annotation from thousands of documents. among them, some use aspect and sentiment analysis as a proxy for identifying opinions. in this work, we propose a new framework, finesum, which advances this frontier in three aspects: (1) minimal supervision, where only aspect names and a few aspect\/sentiment keywords are available; (2) fine-grained opinion analysis, where sentiment analysis drills down to the sub-aspect level; and (3) phrase-based summarization, where opinion is summarized in the form of phrases. finesum automatically identifies opinion phrases from the raw corpus, classifies them into different aspects and sentiments, and constructs multiple fine-grained opinion clusters under each aspect\/sentiment. each cluster consists of semantically coherent phrases, expressing uniform opinions towards certain sub-aspect or characteristics (e.g., positive feelings for ``burgers'' in the ``food'' aspect). an opinion-oriented spherical word embedding space is trained to provide weak supervision for the phrase classifier, and phrase clustering is performed using the aspect-aware contextualized embedding generated from the phrase classifier. both automatic evaluation on the benchmark and quantitative human evaluation validate the effectiveness of our approach. ","1593":"identification of user's opinions from natural language text has become an exciting field of research due to its growing applications in the real world. the research field is known as sentiment analysis and classification, where aspect category detection (acd) and aspect category polarity (acp) are two important sub-tasks of aspect-based sentiment analysis. the goal in acd is to specify which aspect of the entity comes up in opinion while acp aims to specify the polarity of each aspect category from the acd task. the previous works mostly propose separate solutions for these two sub-tasks. this paper focuses on the acd and acp sub-tasks to solve both problems simultaneously. the proposed method carries out multi-label classification where four different deep models were employed and comparatively evaluated to examine their performance. a dataset of persian reviews was collected from cinematicket website including 2200 samples from 14 categories. the developed models were evaluated using the collected dataset in terms of example-based and label-based metrics. the results indicate the high applicability and preference of the cnn and gru models in comparison to lstm and bi-lstm. ","1594":"incremental language learning with pseudo-data can alleviate catastrophic forgetting in neural networks. however, to obtain better performance, former methods have higher demands for pseudo-data of the previous tasks. the performance dramatically decreases when fewer pseudo-data are employed. in addition, the distribution of pseudo-data gradually deviates from the real data with the sequential learning of different tasks. the deviation will be greater with more tasks learned, which results in more serious catastrophic forgetting. to address these issues, we propose reminding incremental language model via data-free self-distillation (dfsd), which includes self-distillation based on the earth mover's distance and hidden data augmentation. by estimating the knowledge distribution in all layers of gpt-2 and transforming it from teacher model to student model, the self-distillation based on the earth mover's distance can significantly reduce the demand for pseudo-data. hidden data augmentation can greatly alleviate the catastrophic forgetting caused by deviations via modeling the generation of pseudo-data as a hidden data augmentation process, where each sample is a mixture of all trained task data. the experimental results demonstrate that our dfsd can exceed the previous state-of-the-art methods even if the maximum decrease in pseudo-data is 90%. ","1595":"human coders assign standardized medical codes to clinical documents generated during patients' hospitalization, which is error-prone and labor-intensive. automated medical coding approaches have been developed using machine learning methods such as deep neural networks. nevertheless, automated medical coding is still challenging because of the imbalanced class problem, complex code association, and noise in lengthy documents. to solve these issues, we propose a novel neural network called multitask balanced and recalibrated neural network. significantly, the multitask learning scheme shares the relationship knowledge between different code branches to capture the code association. a recalibrated aggregation module is developed by cascading convolutional blocks to extract high-level semantic features that mitigate the impact of noise in documents. also, the cascaded structure of the recalibrated module can benefit the learning from lengthy notes. to solve the class imbalanced problem, we deploy the focal loss to redistribute the attention of low and high-frequency medical codes. experimental results show that our proposed model outperforms competitive baselines on a real-world clinical dataset mimic-iii. ","1596":"multi-head attention is a driving force behind state-of-the-art transformers which achieve remarkable performance across a variety of natural language processing (nlp) and computer vision tasks. it has been observed that for many applications, those attention heads learn redundant embedding, and most of them can be removed without degrading the performance of the model. inspired by this observation, we propose transformer with a mixture of gaussian keys (transformer-mgk), a novel transformer architecture that replaces redundant heads in transformers with a mixture of keys at each head. these mixtures of keys follow a gaussian mixture model and allow each attention head to focus on different parts of the input sequence efficiently. compared to its conventional transformer counterpart, transformer-mgk accelerates training and inference, has fewer parameters, and requires less flops to compute while achieving comparable or better accuracy across tasks. transformer-mgk can also be easily extended to use with linear attentions. we empirically demonstrate the advantage of transformer-mgk in a range of practical applications including language modeling and tasks that involve very long sequences. on the wikitext-103 and long range arena benchmark, transformer-mgks with 4 heads attain comparable or better performance to the baseline transformers with 8 heads. ","1597":"an important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. as we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. using gpt-3 175b as an example -- deploying independent instances of fine-tuned models, each with 175b parameters, is prohibitively expensive. we propose low-rank adaptation, or lora, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. compared to gpt-3 175b fine-tuned with adam, lora can reduce the number of trainable parameters by 10,000 times and the gpu memory requirement by 3 times. lora performs on-par or better than fine-tuning in model quality on roberta, deberta, gpt-2, and gpt-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. we also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of lora. we release a package that facilitates the integration of lora with pytorch models and provide our implementations and model checkpoints for roberta, deberta, and gpt-2 at https:\/\/github.com\/microsoft\/lora. ","1598":"aspect-based sentiment classification (absc) is a challenging sub-task of traditional sentiment analysis. due to the difficulty of handling potential correlations among sentiment polarities of multiple aspects, i.e., sentiment dependency, recent popular works tend to exploit syntactic information guiding sentiment dependency parsing. however, syntax information (e.g., syntactic dependency trees) usually occupies expensive computational resources in terms of the operation of the adjacent matrix. instead, we define the consecutive aspects with the same sentiment as the sentiment cluster in the case that we find that most sentiment dependency occurs between adjacent aspects. motivated by this finding, we propose the sentiment patterns (sp) to guide the model dependency learning. thereafter, we introduce the local sentiment aggregating (lsa) mechanism to focus on learning the sentiment dependency in the sentiment cluster. the lsa is more efficient than existing dependency tree-based models due to the absence of additional dependency matrix constructing and modeling. furthermore, we propose differential weighting for aggregation window building to measure the importance of sentiment dependency. experiments on four public datasets show that our models achieve state-of-the-art performance with especially improvement on learning sentiment cluster. ","1599":"popular asr benchmarks such as librispeech and switchboard are limited in the diversity of settings and speakers they represent. we introduce a set of benchmarks matching real-life conditions, aimed at spotting possible biases and weaknesses in models. we have found out that even though recent models do not seem to exhibit a gender bias, they usually show important performance discrepancies by accent, and even more important ones depending on the socio-economic status of the speakers. finally, all tested models show a strong performance drop when tested on conversational speech, and in this precise context even a language model trained on a dataset as big as common crawl does not seem to have significant positive effect which reiterates the importance of developing conversational language models ","1600":"sequence labeling is a fundamental task in natural language processing and has been widely studied. recently, rnn-based sequence labeling models have increasingly gained attentions. despite superior performance achieved by learning the long short-term (i.e., successive) dependencies, the way of sequentially processing inputs might limit the ability to capture the non-continuous relations over tokens within a sentence. to tackle the problem, we focus on how to effectively model successive and discrete dependencies of each token for enhancing the sequence labeling performance. specifically, we propose an innovative attention-based model (called position-aware selfattention, i.e., psa) as well as a well-designed self-attentional context fusion layer within a neural network architecture, to explore the positional information of an input sequence for capturing the latent relations among tokens. extensive experiments on three classical tasks in sequence labeling domain, i.e., partof-speech (pos) tagging, named entity recognition (ner) and phrase chunking, demonstrate our proposed model outperforms the state-of-the-arts without any external knowledge, in terms of various metrics. ","1601":"fast and reliable evaluation metrics are key to r&d progress. while traditional natural language generation metrics are fast, they are not very reliable. conversely, new metrics based on large pretrained language models are much more reliable, but require significant computational resources. in this paper, we propose frugalscore, an approach to learn a fixed, low cost version of any expensive nlg metric, while retaining most of its original performance. experiments with bertscore and moverscore on summarization and translation show that frugalscore is on par with the original metrics (and sometimes better), while having several orders of magnitude less parameters and running several times faster. on average over all learned metrics, tasks, and variants, frugalscore retains 96.8% of the performance, runs 24 times faster, and has 35 times less parameters than the original metrics. we make our trained metrics publicly available, to benefit the entire nlp community and in particular researchers and practitioners with limited resources. ","1602":"access to large pre-trained models of varied architectures, in many different languages, is central to the democratization of nlp. we introduce pagnol, a collection of french gpt models. using scaling laws, we efficiently train pagnol-xl (1.5b parameters) with the same computational budget as camembert, a model 13 times smaller. pagnol-xl is the largest model trained to date for the french language. we plan to train increasingly large and performing versions of pagnol, exploring the capabilities of french extreme-scale models.   for this first release, we focus on the pre-training and scaling calculations underlining pagnol. we fit a scaling law for compute for the french language, and compare it with its english counterpart. we find the pre-training dataset significantly conditions the quality of the outputs, with common datasets such as oscar leading to low-quality offensive text. we evaluate our models on discriminative and generative tasks in french, comparing to other state-of-the-art french and multilingual models, and reaching the state of the art in the abstract summarization task. our research was conducted on the public genci jean zay supercomputer, and our models up to the large are made publicly available. ","1603":"on many natural language processing tasks, large pre-trained language models (plms) have shown overwhelming performances compared with traditional neural network methods. nevertheless, their huge model size and low inference speed have hindered the deployment on resource-limited devices in practice. in this paper, we target to compress plms with knowledge distillation, and propose a hierarchical relational knowledge distillation (hrkd) method to capture both hierarchical and domain relational information. specifically, to enhance the model capability and transferability, we leverage the idea of meta-learning and set up domain-relational graphs to capture the relational information across different domains. and to dynamically select the most representative prototypes for each domain, we propose a hierarchical compare-aggregate mechanism to capture hierarchical relationships. extensive experiments on public multi-domain datasets demonstrate the superior performance of our hrkd method as well as its strong few-shot learning ability. for reproducibility, we release the code at https:\/\/github.com\/cheneydon\/hrkd. ","1604":"transformer models have been used in automatic speech recognition (asr) successfully and yields state-of-the-art results. however, its performance is still affected by speaker mismatch between training and test data. further finetuning a trained model with target speaker data is the most natural approach for adaptation, but it takes a lot of compute and may cause catastrophic forgetting to the existing speakers. in this work, we propose a unified speaker adaptation approach consisting of feature adaptation and model adaptation. for feature adaptation, we employ a speaker-aware persistent memory model which generalizes better to unseen test speakers by making use of speaker i-vectors to form a persistent memory. for model adaptation, we use a novel gradual pruning method to adapt to target speakers without changing the model architecture, which to the best of our knowledge, has never been explored in asr. specifically, we gradually prune less contributing parameters on model encoder to a certain sparsity level, and use the pruned parameters for adaptation, while freezing the unpruned parameters to keep the original model performance. we conduct experiments on the librispeech dataset. our proposed approach brings relative 2.74-6.52% word error rate (wer) reduction on general speaker adaptation. on target speaker adaptation, our method outperforms the baseline with up to 20.58% relative wer reduction, and surpasses the finetuning method by up to relative 2.54%. besides, with extremely low-resource adaptation data (e.g., 1 utterance), our method could improve the wer by relative 6.53% with only a few epochs of training. ","1605":"we present substructure distribution projection (subdp), a technique that projects a distribution over structures in one domain to another, by projecting substructure distributions separately. models for the target domains can be then trained, using the projected distributions as soft silver labels. we evaluate subdp on zero-shot cross-lingual dependency parsing, taking dependency arcs as substructures: we project the predicted dependency arc distributions in the source language(s) to target language(s), and train a target language parser to fit the resulting distributions. when an english treebank is the only annotation that involves human effort, subdp achieves better unlabeled attachment score than all prior work on the universal dependencies v2.2 (nivre et al., 2020) test set across eight diverse target languages, as well as the best labeled attachment score on six out of eight languages. in addition, subdp improves zero-shot cross-lingual dependency parsing with very few (e.g., 50) supervised bitext pairs, across a broader range of target languages. ","1606":"distilling state-of-the-art transformer models into lightweight student models is an effective way to reduce computation cost at inference time. however, the improved inference speed may be still unsatisfactory for certain time-sensitive applications. in this paper, we aim to further push the limit of inference speed by exploring a new area in the design space of the student model. more specifically, we consider distilling a transformer-based text classifier into a billion-parameter, sparsely-activated student model with a embedding-averaging architecture. our experiments show that the student models retain 97% of the roberta-large teacher performance on a collection of six text classification tasks. meanwhile, the student model achieves up to 600x speed-up on both gpus and cpus, compared to the teacher models. further investigation shows that our pipeline is also effective in privacy-preserving and domain generalization settings. ","1607":"pretrained language models (ptlms) are typically learned over a large, static corpus and further fine-tuned for various downstream tasks. however, when deployed in the real world, a ptlm-based model must deal with data from a new domain that deviates from what the ptlm was initially trained on, or newly emerged data that contains out-of-distribution information. in this paper, we study a lifelong language model pretraining challenge where a ptlm is continually updated so as to adapt to emerging data. over a domain-incremental research paper stream and a chronologically ordered tweet stream, we incrementally pretrain a ptlm with different continual learning algorithms, and keep track of the downstream task performance (after fine-tuning) to analyze its ability of acquiring new knowledge and preserving learned knowledge. our experiments show continual learning algorithms improve knowledge preservation, with logit distillation being the most effective approach. we further show that continual pretraining improves generalization when training and testing data of downstream tasks are drawn from different time steps, but do not improve when they are from the same time steps. we believe our problem formulation, methods, and analysis will inspire future studies towards continual pretraining of language models. ","1608":"with ever growing scale of neural models, knowledge distillation (kd) attracts more attention as a prominent tool for neural model compression. however, there are counter intuitive observations in the literature showing some challenging limitations of kd. a case in point is that the best performing checkpoint of the teacher might not necessarily be the best teacher for training the student in kd. therefore, one important question would be how to find the best checkpoint of the teacher for distillation? searching through the checkpoints of the teacher would be a very tedious and computationally expensive process, which we refer to as the \\textit{checkpoint-search problem}. moreover, another observation is that larger teachers might not necessarily be better teachers in kd which is referred to as the \\textit{capacity-gap} problem. to address these challenging problems, in this work, we introduce our progressive knowledge distillation (pro-kd) technique which defines a smoother training path for the student by following the training footprints of the teacher instead of solely relying on distilling from a single mature fully-trained teacher. we demonstrate that our technique is quite effective in mitigating the capacity-gap problem and the checkpoint search problem. we evaluate our technique using a comprehensive set of experiments on different tasks such as image classification (cifar-10 and cifar-100), natural language understanding tasks of the glue benchmark, and question answering (squad 1.1 and 2.0) using bert-based models and consistently got superior results over state-of-the-art techniques. ","1609":"at the foundation of scientific evaluation is the labor-intensive process of peer review. this critical task requires participants to consume and interpret vast amounts of highly technical text. we show that discourse cues from rebuttals can shed light on the quality and interpretation of reviews. further, an understanding of the argumentative strategies employed by the reviewers and authors provides useful signal for area chairs and other decision makers.   this paper presents a new labeled dataset of 20k sentences contained in 506 review-rebuttal pairs in english, annotated by experts. while existing datasets annotate a subset of review sentences using various schemes, ours synthesizes existing label sets and extends them to include fine-grained annotation of the rebuttal sentences, characterizing the authors' stance towards the reviewers' criticisms and their commitment to addressing them. further, we annotate \\textit{every} sentence in both the review and the rebuttal, including a description of the context for each rebuttal sentence. ","1610":"recent researches have demonstrated that bert shows potential in a wide range of natural language processing tasks. it is adopted as an encoder for many state-of-the-art automatic summarizing systems, which achieve excellent performance. however, so far, there is not much work done for vietnamese. in this paper, we showcase how bert can be implemented for extractive text summarization in vietnamese on multi-document. we introduce a novel comparison between different multilingual and monolingual bert models. the experiment results indicate that monolingual models produce promising results compared to other multilingual models and previous text summarizing models for vietnamese. ","1611":"to create models that are robust across a wide range of test inputs, training datasets should include diverse examples that span numerous phenomena. dynamic adversarial data collection (dadc), where annotators craft examples that challenge continually improving models, holds promise as an approach for generating such diverse training sets. prior work has shown that running dadc over 1-3 rounds can help models fix some error types, but it does not necessarily lead to better generalization beyond adversarial test data. we argue that running dadc over many rounds maximizes its training-time benefits, as the different rounds can together cover many of the task-relevant phenomena. we present the first study of longer-term dadc, where we collect 20 rounds of nli examples for a small set of premise paragraphs, with both adversarial and non-adversarial approaches. models trained on dadc examples make 26% fewer errors on our expert-curated test set compared to models trained on non-adversarial data. our analysis shows that dadc yields examples that are more difficult, more lexically and syntactically diverse, and contain fewer annotation artifacts compared to non-adversarial examples. ","1612":"commonsense reasoning (csr) requires the model to be equipped with general world knowledge. while csr is a language-agnostic process, most comprehensive knowledge sources are in few popular languages, especially english. thus, it remains unclear how to effectively conduct multilingual commonsense reasoning (xcsr) for various languages. in this work, we propose to utilize english knowledge sources via a translate-retrieve-translate (trt) strategy. for multilingual commonsense questions and choices, we collect related knowledge via translation and retrieval from the knowledge sources. the retrieved knowledge is then translated into the target language and integrated into a pre-trained multilingual language model via visible knowledge attention. then we utilize a diverse of 4 english knowledge sources to provide more comprehensive coverage of knowledge in different formats. extensive results on the xcsr benchmark demonstrate that trt with external knowledge can significantly improve multilingual commonsense reasoning in both zero-shot and translate-train settings, outperforming 3.3 and 3.6 points over the previous state-of-the-art on xcsr benchmark datasets (x-csqa and x-codah). ","1613":"pre-trained language models (plms) have been successful for a wide range of natural language processing (nlp) tasks. the state-of-the-art of plms, however, are extremely large to be used on edge devices. as a result, the topic of model compression has attracted increasing attention in the nlp community. most of the existing works focus on compressing encoder-based models (tiny-bert, distilbert, distilroberta, etc), however, to the best of our knowledge, the compression of decoder-based models (such as gpt-2) has not been investigated much. our paper aims to fill this gap. specifically, we explore two directions: 1) we employ current state-of-the-art knowledge distillation techniques to improve fine-tuning of distilgpt-2. 2) we pre-train a compressed gpt-2 model using layer truncation and compare it against the distillation-based method (distilgpt2). the training time of our compressed model is significantly less than distilgpt-2, but it can achieve better performance when fine-tuned on downstream tasks. we also demonstrate the impact of data cleaning on model performance. ","1614":"pretrained language models (plm) have established a new paradigm through learning informative contextualized representations on large-scale text corpus. this new paradigm has revolutionized the entire field of natural language processing, and set the new state-of-the-art performance for a wide variety of nlp tasks. however, though plms could store certain knowledge\/facts from training corpus, their knowledge awareness is still far from satisfactory. to address this issue, integrating knowledge into plms have recently become a very active research area and a variety of approaches have been developed. in this paper, we provide a comprehensive survey of the literature on this emerging and fast-growing field - knowledge enhanced pretrained language models (ke-plms). we introduce three taxonomies to categorize existing work. besides, we also survey the various nlu and nlg applications on which ke-plm has demonstrated superior performance over vanilla plms. finally, we discuss challenges that face ke-plms and also promising directions for future research. ","1615":"we translate a closed text that is known in advance into a severely low resource language by leveraging massive source parallelism. in other words, given a text in 124 source languages, we translate it into a severely low resource language using only ~1,000 lines of low resource data without any external help. firstly, we propose a systematic method to rank and choose source languages that are close to the low resource language. we call the linguistic definition of language family family of origin (famo), and we call the empirical definition of higher-ranked languages using our metrics family of choice (famc). secondly, we build an iteratively pretrained multilingual order-preserving lexiconized transformer (ipml) to train on ~1,000 lines (~3.5%) of low resource data. to translate named entities correctly, we build a massive lexicon table for 2,939 bible named entities in 124 source languages, and include many that occur once and covers more than 66 severely low resource languages. moreover, we also build a novel method of combining translations from different source languages into one. using english as a hypothetical low resource language, we get a +23.9 bleu increase over a multilingual baseline, and a +10.3 bleu increase over our asymmetric baseline in the bible dataset. we get a 42.8 bleu score for portuguese-english translation on the medical emea dataset. we also have good results for a real severely low resource mayan language, eastern pokomchi. ","1616":"when writing, a person may need to anticipate questions from their readers, but different types of readers may ask very different types of questions. if someone is writing for advice about a problem, what question will a domain expert ask, and is this different from how a novice might react? in this paper, we address the task of reader-aware question generation. we collect a new data set of questions and posts from social media, augmented with background information about the post readers. based on predictive analysis and descriptive differences, we find that different readers, such as experts and novices, consistently ask different types of questions. we next develop several text generation models that incorporate different types of reader background, including discrete and continuous reader representations based on the readers' prior behavior. we demonstrate that reader-aware models can perform on par or slightly better than the text-only model in some cases, particularly in cases where a post attracts very different questions from readers of different groups. our work has the potential to help writers anticipate the information needs of different readers. ","1617":"language models (lms) have made remarkable progress, but still struggle to generalize beyond the training data to rare linguistic patterns. since rare entities and facts are prevalent in the queries users submit to popular applications such as search and personal assistant systems, improving the ability of lms to reliably capture knowledge over rare entities is a pressing challenge studied in significant prior work. noticing that existing approaches primarily modify the lm architecture or introduce auxiliary objectives to inject useful entity knowledge, we ask to what extent we could match the quality of these architectures using a base lm architecture, and only changing the data? we propose metadata shaping, a method in which readily available metadata, such as entity descriptions and categorical tags, are appended to examples based on information theoretic metrics. intuitively, if metadata corresponding to popular entities overlap with metadata for rare entities, the lm may be able to better reason about the rare entities using patterns learned from similar popular entities. on standard entity-rich tasks (tacred, fewrel, openentity), with no changes to the lm whatsoever, metadata shaping exceeds the bert-baseline by up to 5.3 f1 points, and achieves or competes with state-of-the-art results. we further show the improvements are up to 10x larger on examples containing tail versus popular entities. ","1618":"encoder-decoder transformer architectures have become popular recently with the advent of t5 models. it is also more favorable over architectures like bert for pre-training on language model task when it comes to large scale models which could take months to train given it's generality. while being able to generalize to more tasks, it is not evident if the proposed encoder-decoder architecture is the most efficient for fine-tuning on classification and regression tasks given the pre-trained model. in this work, we study fine-tuning pre-trained encoder-decoder models such as t5. particularly, we propose \\textbf{enct5} as a way to efficiently fine-tune pre-trained encoder-decoder t5 models for classification and regression tasks by using the encoder layers. our experimental results show that \\textbf{enct5} with less than half of the parameters of t5 performs similarly to t5 models on glue benchmark. we believe our proposed approach can be easily applied to any pre-trained encoder-decoder model. ","1619":"estimating the difficulty of a dataset typically involves comparing state-of-the-art models to humans; the bigger the performance gap, the harder the dataset is said to be. not only is this framework informal, but it also provides little understanding of how difficult each instance is, or what attributes make it difficult for a given model. to address these problems, we propose an information-theoretic perspective, framing dataset difficulty as the absence of $\\textit{usable information}$. measuring usable information is as easy as measuring performance, but has certain theoretical advantages. while the latter only allows us to compare different models w.r.t the same dataset, the former also allows us to compare different datasets w.r.t the same model. we then introduce $\\textit{pointwise}$ $\\mathcal{v}-$$\\textit{information}$ (pvi) for measuring the difficulty of individual instances, where instances with higher pvi are easier for model $\\mathcal{v}$. by manipulating the input before measuring usable information, we can understand $\\textit{why}$ a dataset is easy or difficult for a given model, which we use to discover annotation artefacts in widely-used benchmarks. ","1620":"recent works have focused on compressing pre-trained language models (plms) like bert where the major focus has been to improve the compressed model performance for downstream tasks. however, there has been no study in analyzing the impact of compression on the generalizability and robustness of these models. towards this end, we study two popular model compression techniques including knowledge distillation and pruning and show that compressed models are significantly less robust than their plm counterparts on adversarial test sets although they obtain similar performance on in-distribution development sets for a task. further analysis indicates that the compressed models overfit on the easy samples and generalize poorly on the hard ones. we further leverage this observation to develop a regularization strategy for model compression based on sample uncertainty. experimental results on several natural language understanding tasks demonstrate our mitigation framework to improve both the adversarial generalization as well as in-distribution task performance of the compressed models. ","1621":"modern pretrained language models are critical components of nlp pipelines. yet, they suffer from spurious correlations, poor out-of-domain generalization, and biases. inspired by recent progress in causal machine learning, in particular the invariant risk minimization (irm) paradigm, we propose invariant language modeling, a framework for learning invariant representations that generalize better across multiple environments. in particular, we adapt a game-theoretic implementation of irm (irm-games) to language models, where the invariance emerges from a specific training schedule in which all the environments compete to optimize their own environment-specific loss by updating subsets of the model in a round-robin fashion. in a series of controlled experiments, we demonstrate the ability of our method to (i) remove structured noise, (ii) ignore specific spurious correlations without affecting global performance, and (iii) achieve better out-of-domain generalization. these benefits come with a negligible computational overhead compared to standard training, do not require changing the local loss, and can be applied to any language model architecture. we believe this framework is promising to help mitigate spurious correlations and biases in language models. ","1622":"to explain nlp models, many methods inform which inputs tokens are important for a prediction. however, an open question is if these methods accurately reflect the model's logic, a property often called faithfulness. in this work, we adapt and improve a recently proposed faithfulness benchmark from computer vision called roar (remove and retrain), by hooker et al. (2019).   we improve roar by recursively removing dataset redundancies, which otherwise interfere with roar. we adapt and apply roar, to popular nlp importance measures, namely attention, gradient, and integrated gradients. additionally, we use mutual information as an additional baseline. evaluation is done on a suite of classification tasks often used in the faithfulness of attention literature. finally, we propose a scalar faithfulness metric, which makes it easy to compare results across papers.   we find that, importance measures considered to be unfaithful for computer vision tasks perform favorably for nlp tasks, the faithfulness of an importance measure is task-dependent, and the computational overhead of integrated gradient is rarely justified. ","1623":"recent work has shown that self-supervised dialog-specific pretraining on large conversational datasets yields substantial gains over traditional language modeling (lm) pretraining in downstream task-oriented dialog (tod). these approaches, however, exploit general dialogic corpora (e.g., reddit) and thus presumably fail to reliably embed domain-specific knowledge useful for concrete downstream tod domains. in this work, we investigate the effects of domain specialization of pretrained language models (plms) for task-oriented dialog. within our ds-tod framework, we first automatically extract salient domain-specific terms, and then use them to construct domaincc and domainreddit -- resources that we leverage for domain-specific pretraining, based on (i) masked language modeling (mlm) and (ii) response selection (rs) objectives, respectively. we further propose a resource-efficient and modular domain specialization by means of domain adapters -- additional parameter-light layers in which we encode the domain knowledge. our experiments with two prominent tod tasks -- dialog state tracking (dst) and response retrieval (rr) -- encompassing five domains from the multiwoz tod benchmark demonstrate the effectiveness of our domain specialization approach. moreover, we show that the light-weight adapter-based specialization (1) performs comparably to full fine-tuning in single-domain setups and (2) is particularly suitable for multi-domain specialization, in which, besides advantageous computational footprint, it can offer better downstream performance. ","1624":"self-supervised learning (ssl) has proven vital for advancing research in natural language processing (nlp) and computer vision (cv). the paradigm pretrains a shared model on large volumes of unlabeled data and achieves state-of-the-art (sota) for various tasks with minimal adaptation. however, the speech processing community lacks a similar setup to systematically explore the paradigm. to bridge this gap, we introduce speech processing universal performance benchmark (superb). superb is a leaderboard to benchmark the performance of a shared model across a wide range of speech processing tasks with minimal architecture changes and labeled data. among multiple usages of the shared model, we especially focus on extracting the representation learned from ssl due to its preferable re-usability. we present a simple framework to solve superb tasks by learning task-specialized lightweight prediction heads on top of the frozen shared model. our results demonstrate that the framework is promising as ssl representations show competitive generalizability and accessibility across superb tasks. we release superb as a challenge with a leaderboard and a benchmark toolkit to fuel the research in representation learning and general speech processing. ","1625":"rich, open-domain textual data available on the web resulted in great advancements for language processing. however, while that data may be suitable for language processing tasks, they are mostly non-conversational, lacking many phenomena that appear in human interactions and this is one of the reasons why we still have many unsolved challenges in conversational ai. in this work, we attempt to address this by using generative conversational networks to automatically generate data and train social conversational agents. we evaluate our approach on topicalchat with automatic metrics and human evaluators, showing that with 10% of seed data it performs close to the baseline that uses 100% of the data. ","1626":"semantic parsers map natural language utterances into meaning representations (e.g., programs). such models are typically bottlenecked by the paucity of training data due to the required laborious annotation efforts. recent studies have performed zero-shot learning by synthesizing training examples of canonical utterances and programs from a grammar, and further paraphrasing these utterances to improve linguistic diversity. however, such synthetic examples cannot fully capture patterns in real data. in this paper we analyze zero-shot parsers through the lenses of the language and logical gaps (herzig and berant, 2019), which quantify the discrepancy of language and programmatic patterns between the canonical examples and real-world user-issued ones. we propose bridging these gaps using improved grammars, stronger paraphrasers, and efficient learning methods using canonical examples that most likely reflect real user intents. our model achieves strong performance on two semantic parsing benchmarks (scholar, geo) with zero labeled data. ","1627":"in this paper, we propose a novel gender bias detection method by utilizing attention map for transformer-based models. we 1) give an intuitive gender bias judgement method by comparing the different relation degree between the genders and the occupation according to the attention scores, 2) design a gender bias detector by modifying the attention module, 3) insert the gender bias detector into different positions of the model to present the internal gender bias flow, and 4) draw the consistent gender bias conclusion by scanning the entire wikipedia, a bert pretraining dataset. we observe that 1) the attention matrices, wq and wk introduce much more gender bias than other modules (including the embedding layer) and 2) the bias degree changes periodically inside of the model (attention matrix q, k, v, and the remaining part of the attention layer (including the fully-connected layer, the residual connection, and the layer normalization module) enhance the gender bias while the averaged attentions reduces the bias). ","1628":"crowdsourcing platforms are often used to collect datasets for training deep neural networks, despite higher levels of inaccurate labeling compared to expert labeling. there are two common strategies to manage the impact of this noise, the first involves aggregating redundant annotations, but comes at the expense of labeling substantially fewer examples. secondly, prior works have also considered using the entire annotation budget to label as many examples as possible and subsequently apply denoising algorithms to implicitly clean up the dataset. we propose an approach which instead reserves a fraction of annotations to explicitly relabel highly probable labeling errors. in particular, we allocate a large portion of the labeling budget to form an initial dataset used to train a model. this model is then used to identify specific examples that appear most likely to be incorrect, which we spend the remaining budget to relabel. experiments across three model variations and four natural language processing tasks show our approach outperforms both label aggregation and advanced denoising methods designed to handle noisy labels when allocated the same annotation budget. ","1629":"from wearables to powerful smart devices, modern automatic speech recognition (asr) models run on a variety of edge devices with different computational budgets. to navigate the pareto front of model accuracy vs model size, researchers are trapped in a dilemma of optimizing model accuracy by training and fine-tuning models for each individual edge device while keeping the training gpu-hours tractable. in this paper, we propose omni-sparsity dnn, where a single neural network can be pruned to generate optimized model for a large range of model sizes. we develop training strategies for omni-sparsity dnn that allows it to find models along the pareto front of word-error-rate (wer) vs model size while keeping the training gpu-hours to no more than that of training one singular model. we demonstrate the omni-sparsity dnn with streaming e2e asr models. our results show great saving on training time and resources with similar or better accuracy on librispeech compared to individually pruned sparse models: 2%-6.6% better wer on test-other. ","1630":"in this work we introduce kernelized transformer, a generic, scalable, data driven framework for learning the kernel function in transformers. our framework approximates the transformer kernel as a dot product between spectral feature maps and learns the kernel by learning the spectral distribution. this not only helps in learning a generic kernel end-to-end, but also reduces the time and space complexity of transformers from quadratic to linear. we show that kernelized transformers achieve performance comparable to existing efficient transformer architectures, both in terms of accuracy as well as computational efficiency. our study also demonstrates that the choice of the kernel has a substantial impact on performance, and kernel learning variants are competitive alternatives to fixed kernel transformers, both in long as well as short sequence tasks. ","1631":"evaluation for many natural language understanding (nlu) tasks is broken: unreliable and biased systems score so highly on standard benchmarks that there is little room for researchers who develop better systems to demonstrate their improvements. the recent trend to abandon iid benchmarks in favor of adversarially-constructed, out-of-distribution test sets ensures that current models will perform poorly, but ultimately only obscures the abilities that we want our benchmarks to measure. in this position paper, we lay out four criteria that we argue nlu benchmarks should meet. we argue most current benchmarks fail at these criteria, and that adversarial data collection does not meaningfully address the causes of these failures. instead, restoring a healthy evaluation ecosystem will require significant progress in the design of benchmark datasets, the reliability with which they are annotated, their size, and the ways they handle social bias. ","1632":"recent advances in supervised, semi-supervised and self-supervised deep learning algorithms have shown significant improvement in the performance of automatic speech recognition(asr) systems. the state-of-the-art systems have achieved a word error rate (wer) less than 5%. however, in the past, researchers have argued the non-suitability of the wer metric for the evaluation of asr systems for downstream tasks such as spoken language understanding (slu) and information retrieval. the reason is that the wer works at the surface level and does not include any syntactic and semantic knowledge.the current work proposes semantic-wer (swer), a metric to evaluate the asr transcripts for downstream applications in general. the swer can be easily customized for any down-stream task. ","1633":"state-of-the-art machine translation (mt) systems are typically trained to generate the \"standard\" target language; however, many languages have multiple varieties (regional varieties, dialects, sociolects, non-native varieties) that are different from the standard language. such varieties are often low-resource, and hence do not benefit from contemporary nlp solutions, mt included. we propose a general framework to rapidly adapt mt systems to generate language varieties that are close to, but different from, the standard target language, using no parallel (source--variety) data. this also includes adaptation of mt systems to low-resource typologically-related target languages. we experiment with adapting an english--russian mt system to generate ukrainian and belarusian, an english--norwegian bokm{\\aa}l system to generate nynorsk, and an english--arabic system to generate four arabic dialects, obtaining significant improvements over competitive baselines. ","1634":"multi-label text classification is a challenging task because it requires capturing label dependencies. it becomes even more challenging when class distribution is long-tailed. resampling and re-weighting are common approaches used for addressing the class imbalance problem, however, they are not effective when there is label dependency besides class imbalance because they result in oversampling of common labels. here, we introduce the application of balancing loss functions for multi-label text classification. we perform experiments on a general domain dataset with 90 labels (reuters-21578) and a domain-specific dataset from pubmed with 18211 labels. we find that a distribution-balanced loss function, which inherently addresses both the class imbalance and label linkage problems, outperforms commonly used loss functions. distribution balancing methods have been successfully used in the image recognition field. here, we show their effectiveness in natural language processing. source code is available at https:\/\/github.com\/roche\/balancedlossnlp. ","1635":"backdoor attacks are a kind of emergent security threat in deep learning. when a deep neural model is injected with a backdoor, it will behave normally on standard inputs but give adversary-specified predictions once the input contains specific backdoor triggers. current textual backdoor attacks have poor attack performance in some tough situations. in this paper, we find two simple tricks that can make existing textual backdoor attacks much more harmful. the first trick is to add an extra training task to distinguish poisoned and clean data during the training of the victim model, and the second one is to use all the clean training data rather than remove the original clean data corresponding to the poisoned data. these two tricks are universally applicable to different attack models. we conduct experiments in three tough situations including clean data fine-tuning, low poisoning rate, and label-consistent attacks. experimental results show that the two tricks can significantly improve attack performance. this paper exhibits the great potential harmfulness of backdoor attacks. all the code and data will be made public to facilitate further research. ","1636":"multi-task learning with an unbalanced data distribution skews model learning towards high resource tasks, especially when model capacity is fixed and fully shared across all tasks. sparse scaling architectures, such as baselayers, provide flexible mechanisms for different tasks to have a variable number of parameters, which can be useful to counterbalance skewed data distributions. we find that that sparse architectures for multilingual machine translation can perform poorly out of the box, and propose two straightforward techniques to mitigate this - a temperature heating mechanism and dense pre-training. overall, these methods improve performance on two multilingual translation benchmarks compared to standard baselayers and dense scaling baselines, and in combination, more than 2x model convergence speed. ","1637":"building a shopping product collection has been primarily a human job. with the manual efforts of craftsmanship, experts collect related but diverse products with common shopping intent that are effective when displayed together, e.g., backpacks, laptop bags, and messenger bags for freshman bag gifts. automatically constructing a collection requires an ml system to learn a complex relationship between the customer's intent and the product's attributes. however, there have been challenging points, such as 1) long and complicated intent sentences, 2) rich and diverse product attributes, and 3) a huge semantic gap between them, making the problem difficult. in this paper, we use a pretrained language model (plm) that leverages textual attributes of web-scale products to make intent-based product collections. specifically, we train a bert with triplet loss by setting an intent sentence to an anchor and corresponding products to positive examples. also, we improve the performance of the model by search-based negative sampling and category-wise positive pair augmentation. our model significantly outperforms the search-based baseline model for intent-based product matching in offline evaluations. furthermore, online experimental results on our e-commerce platform show that the plm-based method can construct collections of products with increased ctr, cvr, and order-diversity compared to expert-crafted collections. ","1638":"named entity disambiguation (ned), which involves mapping textual mentions to structured entities, is particularly challenging in the medical domain due to the presence of rare entities. existing approaches are limited by the presence of coarse-grained structural resources in biomedical knowledge bases as well as the use of training datasets that provide low coverage over uncommon resources. in this work, we address these issues by proposing a cross-domain data integration method that transfers structural knowledge from a general text knowledge base to the medical domain. we utilize our integration scheme to augment structural resources and generate a large biomedical ned dataset for pretraining. our pretrained model with injected structural knowledge achieves state-of-the-art performance on two benchmark medical ned datasets: medmentions and bc5cdr. furthermore, we improve disambiguation of rare entities by up to 57 accuracy points. ","1639":"dialogue systems are widely used in ai to support timely and interactive communication with users. we propose a general-purpose dialogue system architecture that leverages computational argumentation to perform reasoning and provide consistent and explainable answers. we illustrate the system using a covid-19 vaccine information case study. ","1640":"we present a voice conversion framework that converts normal speech into dysarthric speech while preserving the speaker identity. such a framework is essential for (1) clinical decision making processes and alleviation of patient stress, (2) data augmentation for dysarthric speech recognition. this is an especially challenging task since the converted samples should capture the severity of dysarthric speech while being highly natural and possessing the speaker identity of the normal speaker. to this end, we adopted a two-stage framework, which consists of a sequence-to-sequence model and a nonparallel frame-wise model. objective and subjective evaluations were conducted on the uaspeech dataset, and results showed that the method was able to yield reasonable naturalness and capture severity aspects of the pathological speech. on the other hand, the similarity to the normal source speaker's voice was limited and requires further improvements. ","1641":"recent work has raised concerns about the inherent limitations of text-only pretraining. in this paper, we first demonstrate that reporting bias, the tendency of people to not state the obvious, is one of the causes of this limitation, and then investigate to what extent multimodal training can mitigate this issue. to accomplish this, we 1) generate the color dataset (coda), a dataset of human-perceived color distributions for 521 common objects; 2) use coda to analyze and compare the color distribution found in text, the distribution captured by language models, and a human's perception of color; and 3) investigate the performance differences between text-only and multimodal models on coda. our results show that the distribution of colors that a language model recovers correlates more strongly with the inaccurate distribution found in text than with the ground-truth, supporting the claim that reporting bias negatively impacts and inherently limits text-only training. we then demonstrate that multimodal models can leverage their visual training to mitigate these effects, providing a promising avenue for future research. ","1642":"asking good questions is an essential ability for both human and machine intelligence. however, existing neural question generation approaches mainly focus on the short factoid type of answers. in this paper, we propose a neural question generator, mixqg, to bridge this gap. we combine 9 question answering datasets with diverse answer types, including yes\/no, multiple-choice, extractive, and abstractive answers, to train a single generative model. we show with empirical results that our model outperforms existing work in both seen and unseen domains and can generate questions with different cognitive levels when conditioned on different answer types. our code is released and well-integrated with the huggingface library to facilitate various downstream applications. ","1643":"gpt is an auto-regressive transformer-based pre-trained language model which has attracted a lot of attention in the natural language processing (nlp) domain due to its state-of-the-art performance in several downstream tasks. the success of gpt is mostly attributed to its pre-training on huge amount of data and its large number of parameters (from ~100m to billions of parameters). despite the superior performance of gpt (especially in few-shot or zero-shot setup), this overparameterized nature of gpt can be very prohibitive for deploying this model on devices with limited computational power or memory. this problem can be mitigated using model compression techniques; however, compressing gpt models has not been investigated much in the literature. in this work, we use kronecker decomposition to compress the linear mappings of the gpt-22 model. our kronecker gpt-2 model (kngpt2) is initialized based on the kronecker decomposed version of the gpt-2 model and then is undergone a very light pre-training on only a small portion of the training data with intermediate layer knowledge distillation (ilkd). finally, our kngpt2 is fine-tuned on down-stream tasks using ilkd as well. we evaluate our model on both language modeling and general language understanding evaluation benchmark tasks and show that with more efficient pre-training and similar number of parameters, our kngpt2 outperforms the existing distilgpt2 model significantly. ","1644":"learning to converse using only a few examples is a great challenge in conversational ai. the current best conversational models, which are either good chit-chatters (e.g., blenderbot) or goal-oriented systems (e.g., mintl), are language models (lms) fine-tuned on large conversational datasets. training these models is expensive, both in terms of computational resources and time, and it is hard to keep them up to date with new conversational skills. a simple yet unexplored solution is prompt-based few-shot learning (brown et al. 2020) which does not require gradient-based fine-tuning but instead uses a few examples in the lm context as the only source of learning. in this paper, we explore prompt-based few-shot learning in dialogue tasks. we benchmark lms of different sizes in nine response generation tasks, which include four knowledge-grounded tasks, a task-oriented generations task, three open-chat tasks, and controlled stylistic generation, and five conversational parsing tasks, which include dialogue state tracking, graph path generation, persona information extraction, document retrieval, and internet query generation. the current largest released lm (gpt-j-6b) using prompt-based few-shot learning, and thus requiring no training, achieves competitive performance to fully trained state-of-the-art models. moreover, we propose a novel prompt-based few-shot classifier, that also does not require any fine-tuning, to select the most appropriate prompt given a dialogue history. finally, by combining the power of prompt-based few-shot learning and a skill selector, we create an end-to-end chatbot named the few-shot bot (fsb), which automatically selects the most appropriate conversational skill, queries different knowledge bases or the internet, and uses the retrieved knowledge to generate a human-like response, all using only few dialogue examples per skill. ","1645":"the semantic matching capabilities of neural information retrieval can ameliorate synonymy and polysemy problems of symbolic approaches. however, neural models' dense representations are more suitable for re-ranking, due to their inefficiency. sparse representations, either in symbolic or latent form, are more efficient with an inverted index. taking the merits of the sparse and dense representations, we propose an ultra-high dimensional (uhd) representation scheme equipped with directly controllable sparsity. uhd's large capacity and minimal noise and interference among the dimensions allow for binarized representations, which are highly efficient for storage and search. also proposed is a bucketing method, where the embeddings from multiple layers of bert are selected\/merged to represent diverse linguistic aspects. we test our models with ms marco and trec car, showing that our models outperforms other sparse models ","1646":"the research of adversarial attacks in the text domain attracts many interests in the last few years, and many methods with a high attack success rate have been proposed. however, these attack methods are inefficient as they require lots of queries for the victim model when crafting text adversarial examples. in this paper, a novel attack model is proposed, its attack success rate surpasses the benchmark attack methods, but more importantly, its attack efficiency is much higher than the benchmark attack methods. the novel method is empirically evaluated by attacking wordcnn, lstm, bilstm, and bert on four benchmark datasets. for instance, it achieves a 100\\% attack success rate higher than the state-of-the-art method when attacking bert and bilstm on imdb, but the number of queries for the victim models only is 1\/4 and 1\/6.5 of the state-of-the-art method, respectively. also, further experiments show the novel method has a good transferability on the generated adversarial examples. ","1647":"with the advances in deep learning, tremendous progress has been made with chit-chat dialogue systems and task-oriented dialogue systems. however, these two systems are often tackled separately in current methods. to achieve more natural interaction with humans, a dialogue agent needs to be capable of both chatting and accomplishing tasks. to this end, we propose a unified dialogue system (unids) with the two aforementioned skills. in particular, we design a unified dialogue data schema, compatible for both chit-chat and task-oriented dialogues, and we train unids with mixed dialogue data from a pretrained chit-chat dialogue model. without adding extra parameters to sota baselines, unids can alternatively handle chit-chat and task-oriented dialogues in a unified framework. experimental results demonstrate that the proposed unids works comparably well as the pure chit-chat system, and it outperforms state-of-the-art task-oriented dialogue systems. more importantly, unids achieves better robustness as it is able to smoothly switch between two types of dialogues. these results demonstrate the feasibility and potential of building an one-for-all dialogue system. ","1648":"this paper tackles the problem of processing and combining efficiently arbitrary long data streams, coming from different modalities with different acquisition frequencies. common applications can be, for instance, long-time industrial or real-life systems monitoring from multimodal heterogeneous data (sensor data, monitoring report, images, etc.). to tackle this problem, we propose streamult, a streaming multimodal transformer, relying on cross-modal attention and an augmented memory bank to process arbitrary long input sequences at training time and run in a streaming way at inference. streamult reproduces state-of-the-art results on cmu-mosei dataset, while being able to deal with much longer inputs than other models such as previous multimodal transformer. ","1649":"emotion cause analysis has received considerable attention in recent years. previous studies primarily focused on emotion cause extraction from texts in news articles or microblogs. it is also interesting to discover emotions and their causes in conversations. as conversation in its natural form is multimodal, a large number of studies have been carried out on multimodal emotion recognition in conversations, but there is still a lack of work on multimodal emotion cause analysis. in this work, we introduce a new task named multimodal emotion-cause pair extraction in conversations, aiming to jointly extract emotions and their associated causes from conversations reflected in multiple modalities (text, audio and video). we accordingly construct a multimodal conversational emotion cause dataset, emotion-cause-in-friends, which contains 9,272 multimodal emotion-cause pairs annotated on 13,509 utterances in the sitcom friends. we finally benchmark the task by establishing a baseline system that incorporates multimodal features for emotion-cause pair extraction. preliminary experimental results demonstrate the potential of multimodal information fusion for discovering both emotions and causes in conversations. ","1650":"user-generated content (ugc) on social media can act as a key source of information for emergency responders in crisis situations. however, due to the volume concerned, computational techniques are needed to effectively filter and prioritise this content as it arises during emerging events. in the literature, these techniques are trained using annotated content from previous crises. in this paper, we investigate how this prior knowledge can be best leveraged for new crises by examining the extent to which crisis events of a similar type are more suitable for adaptation to new events (cross-domain adaptation). given the recent successes of transformers in various language processing tasks, we propose cast: an approach for crisis domain adaptation leveraging sequence-to-sequence transformers. we evaluate cast using two major crisis-related message classification datasets. our experiments show that our cast-based best run without using any target data achieves the state of the art performance in both in-domain and cross-domain contexts. moreover, cast is particularly effective in one-to-one cross-domain adaptation when trained with a larger language model. in many-to-one adaptation where multiple crises are jointly used as the source domain, cast further improves its performance. in addition, we find that more similar events are more likely to bring better adaptation performance whereas fine-tuning using dissimilar events does not help for adaptation. to aid reproducibility, we open source our code to the community. ","1651":"we introduce the problem of proficiency modeling: given a user's posts on a social media platform, the task is to identify the subset of posts or topics for which the user has some level of proficiency. this enables the filtering and ranking of social media posts on a given topic as per user proficiency. unlike experts on a given topic, proficient users may not have received formal training and possess years of practical experience, but may be autodidacts, hobbyists, and people with sustained interest, enabling them to make genuine and original contributions to discourse. while predicting whether a user is an expert on a given topic imposes strong constraints on who is a true positive, proficiency modeling implies a graded scoring, relaxing these constraints. put another way, many active social media users can be assumed to possess, or eventually acquire, some level of proficiency on topics relevant to their community. we tackle proficiency modeling in an unsupervised manner by utilizing user embeddings to model engagement with a given topic, as indicated by a user's preference for authoring related content. we investigate five alternative approaches to model proficiency, ranging from basic ones to an advanced, tailored user modeling approach, applied within two real-world benchmarks for evaluation. ","1652":"social media has enabled people to circulate information in a timely fashion, thus motivating people to post messages seeking help during crisis situations. these messages can contribute to the situational awareness of emergency responders, who have a need for them to be categorised according to information types (i.e. the type of aid services the messages are requesting). we introduce a transformer-based multi-task learning (mtl) technique for classifying information types and estimating the priority of these messages. we evaluate the effectiveness of our approach with a variety of metrics by submitting runs to the trec incident streams (is) track: a research initiative specifically designed for disaster tweet classification and prioritisation. the results demonstrate that our approach achieves competitive performance in most metrics as compared to other participating runs. subsequently, we find that an ensemble approach combining disparate transformer encoders within our approach helps to improve the overall effectiveness to a significant extent, achieving state-of-the-art performance in almost every metric. we make the code publicly available so that our work can be reproduced and used as a baseline for the community for future work in this domain. ","1653":"tag recommendation relies on either a ranking function for top-$k$ tags or an autoregressive generation method. however, the previous methods neglect one of two seemingly conflicting yet desirable characteristics of a tag set: orderlessness and inter-dependency. while the ranking approach fails to address the inter-dependency among tags when they are ranked, the autoregressive approach fails to take orderlessness into account because it is designed to utilize sequential relations among tokens. we propose a sequence-oblivious generation method for tag recommendation, in which the next tag to be generated is independent of the order of the generated tags and the order of the ground truth tags occurring in training data. empirical results on two different domains, instagram and stack overflow, show that our method is significantly superior to the previous approaches. ","1654":"recent speech-to-text models often require a large amount of hardware resources and are mostly trained in english. this paper presents speech-to-text models for german, as well as for spanish and french with special features: (a) they are small and run in real-time on microcontrollers like a raspberrypi. (b) using a pretrained english model, they can be trained on consumer-grade hardware with a relatively small dataset. (c) the models are competitive with other solutions and outperform them in german. in this respect, the models combine advantages of other approaches, which only include a subset of the presented features. furthermore, the paper provides a new library for handling datasets, which is focused on easy extension with additional datasets and shows an optimized way for transfer-learning new languages using a pretrained model from another language with a similar alphabet. ","1655":"as deep networks begin to be deployed as autonomous agents, the issue of how they can communicate with each other becomes important. here, we train two deep nets from scratch to perform realistic referent identification through unsupervised emergent communication. we show that the largely interpretable emergent protocol allows the nets to successfully communicate even about object types they did not see at training time. the visual representations induced as a by-product of our training regime, moreover, show comparable quality, when re-used as generic visual features, to a recent self-supervised learning model. our results provide concrete evidence of the viability of (interpretable) emergent deep net communication in a more realistic scenario than previously considered, as well as establishing an intriguing link between this field and self-supervised visual learning. ","1656":"drawing causal conclusions from observational real-world data is a very much desired but challenging task. in this paper we present mixed-method analyses to investigate causal influences of publication trends and behavior on the adoption, persistence, and retirement of certain research foci -- methodologies, materials, and tasks that are of interest to the computational linguistics (cl) community. our key findings highlight evidence of the transition to rapidly emerging methodologies in the research community (e.g., adoption of bidirectional lstms influencing the retirement of lstms), the persistent engagement with trending tasks and techniques (e.g., deep learning, embeddings, generative, and language models), the effect of scientist location from outside the us, e.g., china on propensity of researching languages beyond english, and the potential impact of funding for large-scale research programs. we anticipate this work to provide useful insights about publication trends and behavior and raise the awareness about the potential for causal inference in the computational linguistics and a broader scientific community. ","1657":"there is currently a gap between the natural language expression of scholarly publications and their structured semantic content modeling to enable intelligent content search. with the volume of research growing exponentially every year, a search feature operating over semantically structured content is compelling. the semeval-2021 shared task nlpcontributiongraph (a.k.a. 'the ncg task') tasks participants to develop automated systems that structure contributions from nlp scholarly articles in the english language. being the first-of-its-kind in the semeval series, the task released structured data from nlp scholarly articles at three levels of information granularity, i.e. at sentence-level, phrase-level, and phrases organized as triples toward knowledge graph (kg) building. the sentence-level annotations comprised the few sentences about the article's contribution. the phrase-level annotations were scientific term and predicate phrases from the contribution sentences. finally, the triples constituted the research overview kg. for the shared task, participating systems were then expected to automatically classify contribution sentences, extract scientific terms and relations from the sentences, and organize them as kg triples.   overall, the task drew a strong participation demographic of seven teams and 27 participants. the best end-to-end task system classified contribution sentences at 57.27% f1, phrases at 46.41% f1, and triples at 22.28% f1. while the absolute performance to generate triples remains low, in the conclusion of this article, the difficulty of producing such data and as a consequence of modeling it is highlighted. ","1658":"this article reports ongoing investigations into phonetic change of dialect groups in the northern netherlandic language area, particularly the frisian and low saxon dialect groups, which are known to differ in vitality. to achieve this, we combine existing phonetically transcribed corpora with dialectometric approaches that allow us to quantify change among older male dialect speakers in a real-time framework. a multidimensional variant of the levenshtein distance, combined with methods that induce realistic phonetic distances between transcriptions, is used to estimate how much dialect groups have changed between 1990 and 2010, and whether they changed towards standard dutch or away from it. our analyses indicate that language change is a slow process in this geographical area. moreover, the frisian and groningen dialect groups seem to be most stable, while the other low saxon varieties (excluding the groningen dialect group) were shown to be most prone to change. we offer possible explanations for our findings, while we discuss shortcomings of the data and approach in detail, as well as desiderata for future research. ","1659":"multilingual end-to-end(e2e) models have shown a great potential in the expansion of the language coverage in the realm of automatic speech recognition(asr). in this paper, we aim to enhance the multilingual asr performance in two ways, 1)studying the impact of feeding a one-hot vector identifying the language, 2)formulating the task with a meta-learning objective combined with self-supervised learning (ssl). we associate every language with a distinct task manifold and attempt to improve the performance by transferring knowledge across learning processes itself as compared to transferring through final model parameters. we employ this strategy on a dataset comprising of 6 languages for an in-domain asr task, by minimizing an objective related to expected gradient path length. experimental results reveal the best pre-training strategy resulting in 3.55% relative reduction in overall wer. a combination of leap and ssl yields 3.51% relative reduction in overall wer when using language id. ","1660":"moral psychology is a domain that deals with moral identity, appraisals and emotions. previous work has primarily focused on moral development and the associated role of culture. knowing that language is an inherent element of a culture, we used the social media platform twitter to compare moral behaviors of japanese tweets with english tweets. the five basic moral foundations, i.e., care, fairness, ingroup, authority and purity, along with the associated emotional valence were compared between english and japanese tweets. the tweets from japanese users depicted relatively higher fairness, ingroup, and purity, whereas english tweets expressed more positive emotions for all moral dimensions. considering moral similarities in connecting users on social media, we quantified homophily concerning different moral dimensions using our proposed method. the moral dimensions care, authority and purity for english and ingroup, authority and purity for japanese depicted homophily on twitter. overall, our study uncovers the underlying cultural differences with respect to moral behavior in english- and japanese-speaking users. ","1661":"building on the computer science concept of code smells, we initiate the study of law smells, i.e., patterns in legal texts that pose threats to the comprehensibility and maintainability of the law. with five intuitive law smells as running examples - namely, duplicated phrase, long element, large reference tree, ambiguous syntax, and natural language obsession -, we develop a comprehensive law smell taxonomy. this taxonomy classifies law smells by when they can be detected, which aspects of law they relate to, and how they can be discovered. we introduce text-based and graph-based methods to identify instances of law smells, confirming their utility in practice using the united states code as a test case. our work demonstrates how ideas from software engineering can be leveraged to assess and improve the quality of legal code, thus drawing attention to an understudied area in the intersection of law and computer science and highlighting the potential of computational legal drafting. ","1662":"how can pre-trained language models (plms) learn universal representations and effectively adapt to broad nlp tasks differing a lot superficially? in this work, we empirically find evidences indicating that the adaptations of plms to various tasks can be reparameterized as optimizing only a few free parameters in a common low-dimensional intrinsic task subspace, which may help us understand why plms could easily adapt to various nlp tasks with small-scale data. specifically, to find such a subspace and examine its universality, we resort to the recent success of prompt tuning and decompose the soft prompts of multiple nlp tasks into the same low-dimensional nonlinear subspace, then we learn to adapt the plm to unseen tasks or data by only tuning parameters in the subspace. we dub this pipeline as intrinsic prompt tuning (ipt). in experiments, we study diverse few-shot nlp tasks and surprisingly find that in a 5-dimensional subspace found with 100 random tasks, by only tuning 5 free parameters, we can recover 87% and 65% of the full prompt tuning performance for 100 seen tasks (using different training data) and 20 unseen tasks, respectively, showing great generalization ability of the found intrinsic task subspace. besides being an analysis tool, ipt could further bring practical benefits, such as improving the prompt tuning stability. ","1663":"in this paper, we bring a new way of digesting news content by introducing the task of segmenting a news article into multiple sections and generating the corresponding summary to each section. we make two contributions towards this new task. first, we create and make available a dataset, segnews, consisting of 27k news articles with sections and aligned heading-style section summaries. second, we propose a novel segmentation-based language generation model adapted from pre-trained language models that can jointly segment a document and produce the summary for each section. experimental results on segnews demonstrate that our model can outperform several state-of-the-art sequence-to-sequence generation models for this new task. ","1664":"the current umls (unified medical language system) metathesaurus construction process for integrating over 200 biomedical source vocabularies is expensive and error-prone as it relies on the lexical algorithms and human editors for deciding if the two biomedical terms are synonymous. recent advances in natural language processing such as transformer models like bert and its biomedical variants with contextualized word embeddings have achieved state-of-the-art (sota) performance on downstream tasks. we aim to validate if these approaches using the bert models can actually outperform the existing approaches for predicting synonymy in the umls metathesaurus. in the existing siamese networks with lstm and biowordvec embeddings, we replace the biowordvec embeddings with the biomedical bert embeddings extracted from each bert model using different ways of extraction. in the transformer architecture, we evaluate the use of the different biomedical bert models that have been pre-trained using different datasets and tasks. given the sota performance of these bert models for other downstream tasks, our experiments yield surprisingly interesting results: (1) in both model architectures, the approaches employing these biomedical bert-based models do not outperform the existing approaches using siamese network with biowordvec embeddings for the umls synonymy prediction task, (2) the original biobert large model that has not been pre-trained with the umls outperforms the sapbert models that have been pre-trained with the umls, and (3) using the siamese networks yields better performance for synonymy prediction when compared to using the biomedical bert models. ","1665":"a crucial difference between single- and multi-document summarization is how salient content manifests itself in the document(s). while such content may appear at the beginning of a single document, essential information is frequently reiterated in a set of documents related to a particular topic, resulting in an endorsement effect that increases information salience. in this paper, we model the cross-document endorsement effect and its utilization in multiple document summarization. our method generates a synopsis from each document, which serves as an endorser to identify salient content from other documents. strongly endorsed text segments are used to enrich a neural encoder-decoder model to consolidate them into an abstractive summary. the method has a great potential to learn from fewer examples to identify salient content, which alleviates the need for costly retraining when the set of documents is dynamically adjusted. through extensive experiments on benchmark multi-document summarization datasets, we demonstrate the effectiveness of our proposed method over strong published baselines. finally, we shed light on future research directions and discuss broader challenges of this task using a case study. ","1666":"this paper describes espnet2-tts, an end-to-end text-to-speech (e2e-tts) toolkit. espnet2-tts extends our earlier version, espnet-tts, by adding many new features, including: on-the-fly flexible pre-processing, joint training with neural vocoders, and state-of-the-art tts models with extensions like full-band e2e text-to-waveform modeling, which simplify the training pipeline and further enhance tts performance. the unified design of our recipes enables users to quickly reproduce state-of-the-art e2e-tts results. we also provide many pre-trained models in a unified python interface for inference, offering a quick means for users to generate baseline samples and build demos. experimental evaluations with english and japanese corpora demonstrate that our provided models synthesize utterances comparable to ground-truth ones, achieving state-of-the-art tts performance. the toolkit is available online at https:\/\/github.com\/espnet\/espnet. ","1667":"the growth of cross-lingual pre-trained models has enabled nlp tools to rapidly generalize to new languages. while these models have been applied to tasks involving entities, their ability to explicitly predict typological features of these entities across languages has not been established. in this paper, we present a unified cross-lingual fine-grained entity typing model capable of handling over 100 languages and analyze this model's ability to generalize to languages and entities unseen during training. we train this model on cross-lingual training data collected from wikipedia hyperlinks in multiple languages (training languages). during inference, our model takes an entity mention and context in a particular language (test language, possibly not in the training languages) and predicts fine-grained types for that entity. generalizing to new languages and unseen entities are the fundamental challenges of this entity typing setup, so we focus our evaluation on these settings and compare against simple yet powerful string match baselines. experimental results show that our approach outperforms the baselines on unseen languages such as japanese, tamil, arabic, serbian, and persian. in addition, our approach substantially improves performance on unseen entities (even in unseen languages) over the baselines, and human evaluation shows a strong ability to predict relevant types in these settings. ","1668":"aspect-based sentiment analysis plays an essential role in natural language processing and artificial intelligence. recently, researchers only focused on aspect detection and sentiment classification but ignoring the sub-task of detecting user opinion span, which has enormous potential in practical applications. in this paper, we present a new vietnamese dataset (uit-visd4sa) consisting of 35,396 human-annotated spans on 11,122 feedback comments for evaluating the span detection in aspect-based sentiment analysis. besides, we also propose a novel system using bidirectional long short-term memory (bilstm) with a conditional random field (crf) layer (bilstm-crf) for the span detection task in vietnamese aspect-based sentiment analysis. the best result is a 62.76% f1 score (macro) for span detection using bilstm-crf with embedding fusion of syllable embedding, character embedding, and contextual embedding from xlm-roberta. in future work, span detection will be extended in many nlp tasks such as constructive detection, emotion recognition, complaint analysis, and opinion mining. our dataset is freely available at https:\/\/github.com\/kimkim00\/uit-visd4sa for research purposes. ","1669":"backdoor attacks, which maliciously control a well-trained model's outputs of the instances with specific triggers, are recently shown to be serious threats to the safety of reusing deep neural networks (dnns). in this work, we propose an efficient online defense mechanism based on robustness-aware perturbations. specifically, by analyzing the backdoor training process, we point out that there exists a big gap of robustness between poisoned and clean samples. motivated by this observation, we construct a word-based robustness-aware perturbation to distinguish poisoned samples from clean samples to defend against the backdoor attacks on natural language processing (nlp) models. moreover, we give a theoretical analysis about the feasibility of our robustness-aware perturbation-based defense method. experimental results on sentiment analysis and toxic detection tasks show that our method achieves better defending performance and much lower computational costs than existing online defense methods. our code is available at https:\/\/github.com\/lancopku\/rap. ","1670":"physicians provide expert opinion to legal courts on the medical state of patients, including determining if a patient is likely to have permanent or non-permanent injuries or ailments. an independent medical examination (ime) report summarizes a physicians medical opinion about a patients health status based on the physicians expertise. ime reports contain private and sensitive information (personally identifiable information or pii) that needs to be removed or randomly encoded before further research work can be conducted. in our study the ime is an orthopedic surgeon from a private practice in the united states. the goal of this research is to perform named entity recognition (ner) to identify and subsequently remove\/encode pii information from ime reports prepared by the physician. we apply the ner toolkits of opennlp and spacy, two freely available natural language processing platforms, and compare their precision, recall, and f-measure performance at identifying five categories of pii across trials of randomly selected ime reports using each models common default parameters. we find that both platforms achieve high performance (f-measure > 0.9) at de-identification and that a spacy model trained with a 70-30 train-test data split is most performant. ","1671":"we introduce trankit, a light-weight transformer-based toolkit for multilingual natural language processing (nlp). it provides a trainable pipeline for fundamental nlp tasks over 100 languages, and 90 pretrained pipelines for 56 languages. built on a state-of-the-art pretrained language model, trankit significantly outperforms prior multilingual nlp pipelines over sentence segmentation, part-of-speech tagging, morphological feature tagging, and dependency parsing while maintaining competitive performance for tokenization, multi-word token expansion, and lemmatization over 90 universal dependencies treebanks. despite the use of a large pretrained transformer, our toolkit is still efficient in memory usage and speed. this is achieved by our novel plug-and-play mechanism with adapters where a multilingual pretrained transformer is shared across pipelines for different languages. our toolkit along with pretrained models and code are publicly available at: https:\/\/github.com\/nlp-uoregon\/trankit. a demo website for our toolkit is also available at: http:\/\/nlp.uoregon.edu\/trankit. finally, we create a demo video for trankit at: https:\/\/youtu.be\/q0kgp3zgjgc. ","1672":"quotation extraction and attribution are challenging tasks, aiming at determining the spans containing quotations and attributing each quotation to the original speaker. applying this task to news data is highly related to fact-checking, media monitoring and news tracking. direct quotations are more traceable and informative, and therefore of great significance among different types of quotations. therefore, this paper introduces directquote, a corpus containing 19,760 paragraphs and 10,279 direct quotations manually annotated from online news media. to the best of our knowledge, this is the largest and most complete corpus that focuses on direct quotations in news texts. we ensure that each speaker in the annotation can be linked to a specific named entity on wikidata, benefiting various downstream tasks. in addition, for the first time, we propose several sequence labeling models as baseline methods to extract and attribute quotations simultaneously in an end-to-end manner. ","1673":"to address the performance gap of english asr models on l2 english speakers, we evaluate fine-tuning of pretrained wav2vec 2.0 models (baevski et al., 2020; xu et al., 2021) on l2-arctic, a non-native english speech corpus (zhao et al., 2018) under different training settings. we compare \\textbf{(a)} models trained with a combination of diverse accents to ones trained with only specific accents and \\textbf{(b)} results from different single-accent models. our experiments demonstrate the promise of developing asr models for non-native english speakers, even with small amounts of l2 training data and even without a language model. our models also excel in the zero-shot setting where we train on multiple l2 datasets and test on a blind l2 test set. ","1674":"multilingual neural machine translation (mnmt) trains a single nmt model that supports translation between multiple languages, rather than training separate models for different languages. learning a single model can enhance the low-resource translation by leveraging data from multiple languages. however, the performance of an mnmt model is highly dependent on the type of languages used in training, as transferring knowledge from a diverse set of languages degrades the translation performance due to negative transfer. in this paper, we propose a hierarchical knowledge distillation (hkd) approach for mnmt which capitalises on language groups generated according to typological features and phylogeny of languages to overcome the issue of negative transfer. hkd generates a set of multilingual teacher-assistant models via a selective knowledge distillation mechanism based on the language groups, and then distils the ultimate multilingual model from those assistants in an adaptive way. experimental results derived from the ted dataset with 53 languages demonstrate the effectiveness of our approach in avoiding the negative transfer effect in mnmt, leading to an improved translation performance (about 1 bleu score on average) compared to strong baselines. ","1675":"the goal of natural language semantic code search is to retrieve a semantically relevant code snippet from a fixed set of candidates using a natural language query. existing approaches are neither effective nor efficient enough towards a practical semantic code search system. in this paper, we propose an efficient and accurate semantic code search framework with cascaded fast and slow models, in which a fast transformer encoder model is learned to optimize a scalable index for fast retrieval followed by learning a slow classification-based re-ranking model to improve the performance of the top k results from the fast retrieval. to further reduce the high memory cost of deploying two separate models in practice, we propose to jointly train the fast and slow model based on a single transformer encoder with shared parameters. the proposed cascaded approach is not only efficient and scalable, but also achieves state-of-the-art results with an average mean reciprocal ranking (mrr) score of 0.7795 (across 6 programming languages) as opposed to the previous state-of-the-art result of 0.713 mrr on the codesearchnet benchmark. ","1676":"recent work in multilingual machine translation (mmt) has focused on the potential of positive transfer between languages, particularly cases where higher-resourced languages can benefit lower-resourced ones. while training an mmt model, the supervision signals learned from one language pair can be transferred to the other via the tokens shared by multiple source languages. however, the transfer is inhibited when the token overlap among source languages is small, which manifests naturally when languages use different writing systems. in this paper, we tackle inhibited transfer by augmenting the training data with alternative signals that unify different writing systems, such as phonetic, romanized, and transliterated input. we test these signals on indic and turkic languages, two language families where the writing systems differ but languages still share common features. our results indicate that a straightforward multi-source self-ensemble -- training a model on a mixture of various signals and ensembling the outputs of the same model fed with different signals during inference, outperforms strong ensemble baselines by 1.3 bleu points on both language families. further, we find that incorporating alternative inputs via self-ensemble can be particularly effective when training set is small, leading to +5 bleu when only 5% of the total training data is accessible. finally, our analysis demonstrates that including alternative signals yields more consistency and translates named entities more accurately, which is crucial for increased factuality of automated systems. ","1677":"we present a multilingual bag-of-entities model that effectively boosts the performance of zero-shot cross-lingual text classification by extending a multilingual pre-trained language model (e.g., m-bert). it leverages the multilingual nature of wikidata: entities in multiple languages representing the same concept are defined with a unique identifier. this enables entities described in multiple languages to be represented using shared embeddings. a model trained on entity features in a resource-rich language can thus be directly applied to other languages. our experimental results on cross-lingual topic classification (using the mldoc and ted-cldc datasets) and entity typing (using the shinra2020-ml dataset) show that the proposed model consistently outperforms state-of-the-art models. ","1678":"entity linking is an important problem with many applications. most previous solutions were designed for settings where annotated training data is available, which is, however, not the case in numerous domains. we propose a light-weight and scalable entity linking method, eigenthemes, that relies solely on the availability of entity names and a referent knowledge base. eigenthemes exploits the fact that the entities that are truly mentioned in a document (the \"gold entities\") tend to form a semantically dense subset of the set of all candidate entities in the document. geometrically speaking, when representing entities as vectors via some given embedding, the gold entities tend to lie in a low-rank subspace of the full embedding space. eigenthemes identifies this subspace using the singular value decomposition and scores candidate entities according to their proximity to the subspace. on the empirical front, we introduce multiple strong baselines that compare favorably to (and sometimes even outperform) the existing state of the art. extensive experiments on benchmark datasets from a variety of real-world domains showcase the effectiveness of our approach. ","1679":"crises such as natural disasters, global pandemics, and social unrest continuously threaten our world and emotionally affect millions of people worldwide in distinct ways. understanding emotions that people express during large-scale crises helps inform policy makers and first responders about the emotional states of the population as well as provide emotional support to those who need such support. we present covidemo, ~3k english tweets labeled with emotions and temporally distributed across 18 months. our analyses reveal the emotional toll caused by covid-19, and changes of the social narrative and associated emotions over time. motivated by the time-sensitive nature of crises and the cost of large-scale annotation efforts, we examine how well large pre-trained language models generalize across domains and timeline in the task of perceived emotion prediction in the context of covid-19. our analyses suggest that cross-domain information transfers occur, yet there are still significant gaps. we propose semi-supervised learning as a way to bridge this gap, obtaining significantly better performance using unlabeled data from the target domain. ","1680":"recently, nlp models have achieved remarkable progress across a variety of tasks; however, they have also been criticized for being not robust. many robustness problems can be attributed to models exploiting spurious correlations, or shortcuts between the training data and the task labels. models may fail to generalize to out-of-distribution data or be vulnerable to adversarial attacks if spurious correlations are exploited through the training process. in this paper, we aim to automatically identify such spurious correlations in nlp models at scale. we first leverage existing interpretability methods to extract tokens that significantly affect model's decision process from the input text. we then distinguish \"genuine\" tokens and \"spurious\" tokens by analyzing model predictions across multiple corpora and further verify them through knowledge-aware perturbations. we show that our proposed method can effectively and efficiently identify a scalable set of \"shortcuts\", and mitigating these leads to more robust models in multiple applications. ","1681":"word meaning is notoriously difficult to capture, both synchronically and diachronically. in this paper, we describe the creation of the largest resource of graded contextualized, diachronic word meaning annotation in four different languages, based on 100,000 human semantic proximity judgments. we thoroughly describe the multi-round incremental annotation process, the choice for a clustering algorithm to group usages into senses, and possible - diachronic and synchronic - uses for this dataset. ","1682":"this paper presents a novel open-domain dialogue generation model emphasizing the differentiation of speakers in multi-turn conversations. differing from prior work that solely relies on the content of conversation history to generate a response, we argue that capturing relative social relations among utterances (i.e., generated by either the same speaker or different persons) benefits the machine capturing fine-grained context information from a conversation history to improve context coherence in the generated response. given that, we propose a speaker-aware parallel hierarchical attentive encoder-decoder (phaed) model that aims to model each utterance with the awareness of its speaker and contextual associations with the same speaker's previous messages. specifically, in a conversation involving two speakers, we regard the utterances from one speaker as responses and those from the other as queries. after understanding queries via our encoder with inner-query and inter-query encodings, our decoder reuses the hidden states of previously generated responses, instead of reconstructing these by the encoder, to generate a new response. our empirical results show that phaed outperforms the state-of-the-art in both automatic and human evaluations. furthermore, our ablation study shows that dialogue models with speaker tokens can generally decrease the possibility of generating non-coherent responses regarding the conversation context. ","1683":"deep neural models for low-resource named entity recognition (ner) have shown impressive results by leveraging distant super-vision or other meta-level information (e.g. explanation). however, the costs of acquiring such additional information are generally prohibitive, especially in domains where existing resources (e.g. databases to be used for distant supervision) may not exist. in this paper, we present a novel two-stage framework (autotrigger) to improve ner performance by automatically generating and leveraging \"entity triggers\" which are essentially human-readable clues in the text that can help guide the model to make better decisions. thus, the framework is able to both create and leverage auxiliary supervision by itself. through experiments on three well-studied ner datasets, we show that our automatically extracted triggers are well-matched to human triggers, and autotrigger improves performance over a roberta-crfarchitecture by nearly 0.5 f1 points on average and much more in a low resource setting. ","1684":"cross-topic stance detection is the task to automatically detect stances (pro, against, or neutral) on unseen topics. we successfully reproduce state-of-the-art cross-topic stance detection work (reimers et. al., 2019), and systematically analyze its reproducibility. our attention then turns to the cross-topic aspect of this work, and the specificity of topics in terms of vocabulary and socio-cultural context. we ask: to what extent is stance detection topic-independent and generalizable across topics? we compare the model's performance on various unseen topics, and find topic (e.g. abortion, cloning), class (e.g. pro, con), and their interaction affecting the model's performance. we conclude that investigating performance on different topics, and addressing topic-specific vocabulary and context, is a future avenue for cross-topic stance detection. ","1685":"the covid-19 pandemic poses a great threat to global public health. meanwhile, there is massive misinformation associated with the pandemic which advocates unfounded or unscientific claims. even major social media and news outlets have made an extra effort in debunking covid-19 misinformation, most of the fact-checking information is in english, whereas some unmoderated covid-19 misinformation is still circulating in other languages, threatening the health of less-informed people in immigrant communities and developing countries. in this paper, we make the first attempt to detect covid-19 misinformation in a low-resource language (chinese) only using the fact-checked news in a high-resource language (english). we start by curating a chinese real&fake news dataset according to existing fact-checking information. then, we propose a deep learning framework named crossfake to jointly encode the cross-lingual news body texts and capture the news content as much as possible. empirical results on our dataset demonstrate the effectiveness of crossfake under the cross-lingual setting and it also outperforms several monolingual and cross-lingual fake news detectors. the dataset is available at https:\/\/github.com\/yingtongdou\/crossfake. ","1686":"document-level information extraction is a flexible framework compatible with applications where information is not necessarily localized in a single sentence. for example, key features of a diagnosis in radiology a report may not be explicitly stated, but nevertheless can be inferred from the report's text. however, document-level neural models can easily learn spurious correlations from irrelevant information. this work studies how to ensure that these models make correct inferences from complex text and make those inferences in an auditable way: beyond just being right, are these models \"right for the right reasons?\" we experiment with post-hoc evidence extraction in a predict-select-verify framework using feature attribution techniques. while this basic approach can extract reasonable evidence, it can be regularized with small amounts of evidence supervision during training, which substantially improves the quality of extracted evidence. we evaluate on two domains: a small-scale labeled dataset of brain mri reports and a large-scale modified version of docred (yao et al., 2019) and show that models' plausibility can be improved with no loss in accuracy. ","1687":"machine learning and neural network models in particular have been improving the state of the art performance on many artificial intelligence related tasks. neural network models are typically implemented using frameworks that perform gradient based optimization methods to fit a model to a dataset. these frameworks use a technique of calculating derivatives called automatic differentiation (ad) which removes the burden of performing derivative calculations from the model designer. in this report we describe ad, its motivations, and different implementation approaches. we briefly describe dataflow programming as it relates to ad. lastly, we present example programs that are implemented with tensorflow and pytorch, which are two commonly used ad frameworks. ","1688":"understanding speaker's feelings and producing appropriate responses with emotion connection is a key communicative skill for empathetic dialogue systems. in this paper, we propose a simple technique called affective decoding for empathetic response generation. our method can effectively incorporate emotion signals during each decoding step, and can additionally be augmented with an auxiliary dual emotion encoder, which learns separate embeddings for the speaker and listener given the emotion base of the dialogue. extensive empirical studies show that our models are perceived to be more empathetic by human evaluations, in comparison to several strong mainstream methods for empathetic responding. ","1689":"large-scale language models are rapidly improving, performing well on a wide variety of tasks with little to no customization. in this work we investigate how language models can support science writing, a challenging writing task that is both open-ended and highly constrained. we present a system for generating \"sparks\", sentences related to a scientific concept intended to inspire writers. we find that our sparks are more coherent and diverse than a competitive language model baseline, and approach a human-created gold standard. in a study with 13 phd students writing on topics of their own selection, we find three main use cases of sparks: aiding with crafting detailed sentences, providing interesting angles to engage readers, and demonstrating common reader perspectives. we also report on the various reasons sparks were considered unhelpful, and discuss how we might improve language models as writing support tools. ","1690":"contemporary natural language processing (nlp) revolves around learning from latent document representations, generated either implicitly by neural language models or explicitly by methods such as doc2vec or similar. one of the key properties of the obtained representations is their dimension. whilst the commonly adopted dimensions of 256 and 768 offer sufficient performance on many tasks, it is many times unclear whether the default dimension is the most suitable choice for the subsequent downstream learning tasks. furthermore, representation dimensions are seldom subject to hyperparameter tuning due to computational constraints. the purpose of this paper is to demonstrate that a surprisingly simple and efficient recursive compression procedure can be sufficient to both significantly compress the initial representation, but also potentially improve its performance when considering the task of text classification. having smaller and less noisy representations is the desired property during deployment, as orders of magnitude smaller models can significantly reduce the computational overload and with it the deployment costs. we propose core, a straightforward, representation learner-agnostic framework suitable for representation compression. the core's performance is showcased and studied on a collection of 17 real-life corpora from biomedical, news, social media, and literary domains. we explored core's behavior when considering contextual and non-contextual document representations, different compression levels, and 9 different compression algorithms. current results based on more than 100,000 compression experiments indicate that recursive singular value decomposition offers a very good trade-off between the compression efficiency and performance, making core useful in many existing, representation-dependent nlp pipelines. ","1691":"dense retrieval (dr) methods conduct text retrieval by first encoding texts in the embedding space and then matching them by nearest neighbor search. this requires strong locality properties from the representation space, i.e, the close allocations of each small group of relevant texts, which are hard to generalize to domains without sufficient training data. in this paper, we aim to improve the generalization ability of dr models from source training domains with rich supervision signals to target domains without any relevant labels, in the zero-shot setting. to achieve that, we propose momentum adversarial domain invariant representation learning (modir), which introduces a momentum method in the dr training process to train a domain classifier distinguishing source versus target, and then adversarially updates the dr encoder to learn domain invariant representations. our experiments show that modir robustly outperforms its baselines on 10+ ranking datasets from the beir benchmark in the zero-shot setup, with more than 10% relative gains on datasets with enough sensitivity for dr models' evaluation. source code of this paper will be released. ","1692":"visually-grounded spoken language datasets can enable models to learn cross-modal correspondences with very weak supervision. however, modern audio-visual datasets contain biases that undermine the real-world performance of models trained on that data. we introduce spoken objectnet, which is designed to remove some of these biases and provide a way to better evaluate how effectively models will perform in real-world scenarios. this dataset expands upon objectnet, which is a bias-controlled image dataset that features similar image classes to those present in imagenet. we detail our data collection pipeline, which features several methods to improve caption quality, including automated language model checks. lastly, we show baseline results on image retrieval and audio retrieval tasks. these results show that models trained on other datasets and then evaluated on spoken objectnet tend to perform poorly due to biases in other datasets that the models have learned. we also show evidence that the performance decrease is due to the dataset controls, and not the transfer setting. ","1693":"what would it take to teach a machine to behave ethically? while broad ethical rules may seem straightforward to state (\"thou shalt not kill\"), applying such rules to real-world situations is far more complex. for example, while \"helping a friend\" is generally a good thing to do, \"helping a friend spread fake news\" is not. we identify four underlying challenges towards machine ethics and norms: (1) an understanding of moral precepts and social norms; (2) the ability to perceive real-world situations visually or by reading natural language descriptions; (3) commonsense reasoning to anticipate the outcome of alternative actions in different contexts; (4) most importantly, the ability to make ethical judgments given the interplay between competing values and their grounding in different contexts (e.g., the right to freedom of expression vs. preventing the spread of fake news).   our paper begins to address these questions within the deep learning paradigm. our prototype model, delphi, demonstrates strong promise of language-based commonsense moral reasoning, with up to 92.1% accuracy vetted by humans. this is in stark contrast to the zero-shot performance of gpt-3 of 52.3%, which suggests that massive scale alone does not endow pre-trained neural language models with human values. thus, we present commonsense norm bank, a moral textbook customized for machines, which compiles 1.7m examples of people's ethical judgments on a broad spectrum of everyday situations. in addition to the new resources and baseline performances for future research, our study provides new insights that lead to several important open research questions: differentiating between universal human values and personal values, modeling different moral frameworks, and explainable, consistent approaches to machine ethics. ","1694":"semantic parsing is the task of producing a structured meaning representation for natural language utterances or questions. recent research has pointed out that the commonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to generalize systematically, i.e. to handle examples that require recombining known knowledge in novel settings. in this work, we show that better systematic generalization can be achieved by producing the meaning representation (mr) directly as a graph and not as a sequence. to this end we propose lagr, the labeling aligned graphs algorithm that produces semantic parses by predicting node and edge labels for a complete multi-layer input-aligned graph. the strongly-supervised lagr algorithm requires aligned graphs as inputs, whereas weakly-supervised lagr infers alignments for originally unaligned target graphs using an approximate map inference procedure. on the cogs and cfq compositional generalization benchmarks the strongly- and weakly- supervised lagr algorithms achieve significant improvements upon the baseline seq2seq parsers. ","1695":"in attempts to develop sample-efficient algorithms, researcher have explored myriad mechanisms for collecting and exploiting feature feedback, auxiliary annotations provided for training (but not test) instances that highlight salient evidence. examples include bounding boxes around objects and salient spans in text. despite its intuitive appeal, feature feedback has not delivered significant gains in practical problems as assessed on iid holdout sets. however, recent works on counterfactually augmented data suggest an alternative benefit of supplemental annotations: lessening sensitivity to spurious patterns and consequently delivering gains in out-of-domain evaluations. inspired by these findings, we hypothesize that while the numerous existing methods for incorporating feature feedback have delivered negligible in-sample gains, they may nevertheless generalize better out-of-domain. in experiments addressing sentiment analysis, we show that feature feedback methods perform significantly better on various natural out-of-domain datasets even absent differences on in-domain evaluation. by contrast, on natural language inference tasks, performance remains comparable. finally, we compare those tasks where feature feedback does (and does not) help. ","1696":"fine-tuning all parameters of a pre-trained model has become the mainstream approach for transfer learning. to increase its efficiency and prevent catastrophic forgetting and interference, techniques like adapters and sparse fine-tuning have been developed. adapters are modular, as they can be combined to adapt a model towards different facets of knowledge (e.g., dedicated language and\/or task adapters). sparse fine-tuning is expressive, as it controls the behavior of all model components. in this work, we introduce a new fine-tuning method with both these desirable properties. in particular, we learn sparse, real-valued masks based on a simple variant of the lottery ticket hypothesis. task-specific masks are obtained from annotated data in a source language, and language-specific masks from masked language modeling in a target language. both these masks can then be composed with the pre-trained model. unlike adapter-based fine-tuning, this method neither increases the number of parameters at inference time nor alters the original model architecture. most importantly, it outperforms adapters in zero-shot cross-lingual transfer by a large margin in a series of multilingual benchmarks, including universal dependencies, masakhaner, and americasnli. based on an in-depth analysis, we additionally find that sparsity is crucial to prevent both 1) interference between the fine-tunings to be composed and 2) overfitting. we release the code and models at https:\/\/github.com\/cambridgeltl\/composable-sft. ","1697":"neural rationale models are popular for interpretable predictions of nlp tasks. in these, a selector extracts segments of the input text, called rationales, and passes these segments to a classifier for prediction. since the rationale is the only information accessible to the classifier, it is plausibly defined as the explanation. is such a characterization unconditionally correct? in this paper, we argue to the contrary, with both philosophical perspectives and empirical evidence suggesting that rationale models are, perhaps, less rational and interpretable than expected. we call for more rigorous and comprehensive evaluations of these models to ensure desired properties of interpretability are indeed achieved. the code can be found at https:\/\/github.com\/yimingz89\/neural-rationale-analysis. ","1698":"we present robeczech, a monolingual roberta language representation model trained on czech data. roberta is a robustly optimized transformer-based pretraining approach. we show that robeczech considerably outperforms equally-sized multilingual and czech-trained contextualized language representation models, surpasses current state of the art in all five evaluated nlp tasks and reaches state-of-the-art results in four of them. the robeczech model is released publicly at https:\/\/hdl.handle.net\/11234\/1-3691 and https:\/\/huggingface.co\/ufal\/robeczech-base. ","1699":"how do we perform efficient inference while retaining high translation quality? existing neural machine translation models, such as transformer, achieve high performance, but they decode words one by one, which is inefficient. recent non-autoregressive translation models speed up the inference, but their quality is still inferior. in this work, we propose dslp, a highly efficient and high-performance model for machine translation. the key insight is to train a non-autoregressive transformer with deep supervision and feed additional layer-wise predictions. we conducted extensive experiments on four translation tasks (both directions of wmt'14 en-de and wmt'16 en-ro). results show that our approach consistently improves the bleu scores compared with respective base models. specifically, our best variant outperforms the autoregressive model on three translation tasks, while being 14.8 times more efficient in inference. ","1700":"deep-learning based automatic essay scoring (aes) systems are being actively used by states and language testing agencies alike to evaluate millions of candidates for life-changing decisions ranging from college applications to visa approvals. however, little research has been put to understand and interpret the black-box nature of deep-learning based scoring algorithms. previous studies indicate that scoring models can be easily fooled. in this paper, we explore the reason behind their surprising adversarial brittleness. we utilize recent advances in interpretability to find the extent to which features such as coherence, content, vocabulary, and relevance are important for automated scoring mechanisms. we use this to investigate the oversensitivity i.e., large change in output score with a little change in input essay content) and overstability i.e., little change in output scores with large changes in input essay content) of aes. our results indicate that autoscoring models, despite getting trained as \"end-to-end\" models with rich contextual embeddings such as bert, behave like bag-of-words models. a few words determine the essay score without the requirement of any context making the model largely overstable. this is in stark contrast to recent probing studies on pre-trained representation learning models, which show that rich linguistic features such as parts-of-speech and morphology are encoded by them. further, we also find that the models have learnt dataset biases, making them oversensitive. to deal with these issues, we propose detection-based protection models that can detect oversensitivity and overstability causing samples with high accuracies. we find that our proposed models are able to detect unusual attribution patterns and flag adversarial samples successfully. ","1701":"in this paper, we present a pre-trained language model (plm) based framework called rid for conversational recommender system (crs). rid finetunes the large-scale plms such as dialogpt, together with a pre-trained relational graph convolutional network (rgcn) to encode the node representations of an item-oriented knowledge graph. the former aims to generate fluent and diverse dialogue responses based on the strong language generation ability of plms, while the latter is to facilitate the item recommendation by learning better node embeddings on the structural knowledge base. to unify two modules of dialogue generation and item recommendation into a plms-based framework, we expand the generation vocabulary of plms to include an extra item vocabulary, and introduces a vocabulary pointer to control when to recommend target items in the generation process. extensive experiments on the benchmark dataset redial show rid significantly outperforms the state-of-the-art methods on both evaluations of dialogue and recommendation. ","1702":"knowledgeable faq chatbots are a valuable resource to any organization. while powerful and efficient retrieval-based models exist for english, it is rarely the case for other languages for which the same amount of training data is not available. in this paper, we propose a novel pre-training procedure to adapt convert, an english conversational retriever model, to other languages with less training data available. we apply it for the first time to the task of dutch faq answering related to the covid-19 vaccine. we show it performs better than an open-source alternative in both a low-data regime and a high-data regime. ","1703":"development of speech and language technology for social good (lt4sg), especially those targeted at the welfare of marginalized communities and speakers of low-resource and under-served languages, has been a prominent theme of research within nlp, speech, and the ai communities. researchers have mostly relied on their individual expertise, experiences or ad hoc surveys for prioritization of language technologies that provide social good to the end-users. this has been criticized by several scholars who argue that work on lt4sg must include the target linguistic communities during the design and development process. however, none of the lt4sg work and their critiques suggest principled techniques for prioritization of the technologies and methods for inclusion of the end-user during the development cycle. drawing inspiration from the fields of economics, ethics, psychology, and participatory design, here we chart out a set of methodologies for prioritizing lt4sg that are aligned with the end-user preferences. we then analyze several lt4sg efforts in light of the proposed methodologies and bring out their hidden assumptions and potential pitfalls. while the current study is limited to language technologies, we believe that the principles and prioritization techniques highlighted here are applicable more broadly to ai for social good. ","1704":"the sparsely-activated models have achieved great success in natural language processing through large-scale parameters and relatively low computational cost, and gradually become a feasible technique for training and implementing extremely large models. due to the limit of communication cost, activating multiple experts is hardly affordable during training and inference. therefore, previous work usually activate just one expert at a time to alleviate additional communication cost. such routing mechanism limits the upper bound of model performance. in this paper, we first investigate a phenomenon that increasing the number of activated experts can boost the model performance with higher sparse ratio. to increase the number of activated experts without an increase in computational cost, we propose sam (switch and mixture) routing, an efficient hierarchical routing mechanism that activates multiple experts in a same device (gpu). our methods shed light on the training of extremely large sparse models and experiments prove that our models can achieve significant performance gain with great efficiency improvement. ","1705":"social concepts referring to non-physical objects--such as revolution, violence, or friendship--are powerful tools to describe, index, and query the content of visual data, including ever-growing collections of art images from the cultural heritage (ch) field. while much progress has been made towards complete image understanding in computer vision, automatic detection of social concepts evoked by images is still a challenge. this is partly due to the well-known semantic gap problem, worsened for social concepts given their lack of unique physical features, and reliance on more unspecific features than concrete concepts. in this paper, we propose the translation of recent cognitive theories about social concept representation into a software approach to represent them as multimodal frames, by integrating multisensory data. our method focuses on the extraction, analysis, and integration of multimodal features from visual art material tagged with the concepts of interest. we define a conceptual model and present a novel ontology for formally representing social concepts as multimodal frames. taking the tate gallery's collection as an empirical basis, we experiment our method on a corpus of art images to provide a proof of concept of its potential. we discuss further directions of research, and provide all software, data sources, and results. ","1706":"automated audio captioning (aac) is the task of automatically generating textual descriptions for general audio signals. a captioning system has to identify various information from the input signal and express it with natural language. existing works mainly focus on investigating new methods and try to improve their performance measured on existing datasets. having attracted attention only recently, very few works on aac study the performance of existing pre-trained audio and natural language processing resources. in this paper, we evaluate the performance of off-the-shelf models with a transformer-based captioning approach. we utilize the freely available clotho dataset to compare four different pre-trained machine listening models, four word embedding models, and their combinations in many different settings. our evaluation suggests that yamnet combined with bert embeddings produces the best captions. moreover, in general, fine-tuning pre-trained word embeddings can lead to better performance. finally, we show that sequences of audio embeddings can be processed using a transformer encoder to produce higher-quality captions. ","1707":"deep generative models have been widely used in several areas of nlp, and various techniques have been proposed to augment them or address their training challenges. in this paper, we propose a simple modification to variational autoencoders (vaes) by using an isotropic gaussian posterior (igp) that allows for better utilisation of their latent representation space. this model avoids the sub-optimal behavior of vaes related to inactive dimensions in the representation space. we provide both theoretical analysis, and empirical evidence on various datasets and tasks that show igp leads to consistent improvement on several quantitative and qualitative grounds, from downstream task performance and sample efficiency to robustness. additionally, we give insights about the representational properties encouraged by igp and also show that its gain generalises to image domain as well. ","1708":"we introduce semantic form mid-tuning, an approach for transferring semantic knowledge from semantic meaning representations into transformer-based language encoders. in mid-tuning, we learn to align the text of general sentences -- not tied to any particular inference task -- and structured semantic representations of those sentences. our approach does not require gold annotated semantic representations. instead, it makes use of automatically generated semantic representations, such as from off-the-shelf propbank and framenet semantic parsers. we show that this alignment can be learned implicitly via classification or directly via triplet loss. our method yields language encoders that demonstrate improved predictive performance across inference, reading comprehension, textual similarity, and other semantic tasks drawn from the glue, superglue, and senteval benchmarks. we evaluate our approach on three popular baseline models, where our experimental results and analysis concludes that current pre-trained language models can further benefit from structured semantic frames with the proposed mid-tuning method, as they inject additional task-agnostic knowledge to the encoder, improving the generated embeddings as well as the linguistic properties of the given model, as evident from improvements on a popular sentence embedding toolkit and a variety of probing tasks. ","1709":"in recent years, question answering systems have become more popular and widely used by users. despite the increasing popularity of these systems, the their performance is not even sufficient for textual data and requires further research. these systems consist of several parts that one of them is the answer selection component. this component detects the most relevant answer from a list of candidate answers. the methods presented in previous researches have attempted to provide an independent model to undertake the answer-selection task. an independent model cannot comprehend the syntactic and semantic features of questions and answers with a small training dataset. to fill this gap, language models can be employed in implementing the answer selection part. this action enables the model to have a better understanding of the language in order to understand questions and answers better than previous works. in this research, we will present the \"bas\" (bert answer selection) that uses the bert language model to comprehend language. the empirical results of applying the model on the trecqa raw, trecqa clean, and wikiqa datasets demonstrate that using a robust language model such as bert can enhance the performance. using a more robust classifier also enhances the effect of the language model on the answer selection component. the results demonstrate that language comprehension is an essential requirement in natural language processing tasks such as answer-selection. ","1710":"in various natural language processing tasks, passage retrieval and passage re-ranking are two key procedures in finding and ranking relevant information. since both the two procedures contribute to the final performance, it is important to jointly optimize them in order to achieve mutual improvement. in this paper, we propose a novel joint training approach for dense passage retrieval and passage re-ranking. a major contribution is that we introduce the dynamic listwise distillation, where we design a unified listwise training approach for both the retriever and the re-ranker. during the dynamic distillation, the retriever and the re-ranker can be adaptively improved according to each other's relevance information. we also propose a hybrid data augmentation strategy to construct diverse training instances for listwise training approach. extensive experiments show the effectiveness of our approach on both msmarco and natural questions datasets. our code is available at https:\/\/github.com\/paddlepaddle\/rocketqa. ","1711":"plug-and-play functionality allows deep learning models to adapt well to different tasks without requiring any parameters modified. recently, prefix-tuning was shown to be a plug-and-play method on various text generation tasks by simply inserting corresponding continuous vectors into the inputs. however, sequence labeling tasks invalidate existing plug-and-play methods since different label sets demand changes to the architecture of the model classifier. in this work, we propose the use of label word prediction instead of classification to totally reuse the architecture of pre-trained models for sequence labeling tasks. specifically, for each task, a label word set is first constructed by selecting a high-frequency word for each class respectively, and then, task-specific vectors are inserted into the inputs and optimized to manipulate the model predictions towards the corresponding label words. as a result, by simply switching the plugin vectors on the input, a frozen pre-trained language model is allowed to perform different tasks. experimental results on three sequence labeling tasks show that the performance of the proposed method can achieve comparable performance with standard fine-tuning with only 0.1\\% task-specific parameters. in addition, our method is up to 70 times faster than non-plug-and-play methods while switching different tasks under the resource-constrained scenario. ","1712":"despite the increasing popularity of nlp in the humanities and social sciences, advances in model performance and complexity have been accompanied by concerns about interpretability and explanatory power for sociocultural analysis. one popular model that balances complexity and legibility is word mover's distance (wmd). ostensibly adapted for its interpretability, wmd has nonetheless been used and further developed in ways which frequently discard its most interpretable aspect: namely, the word-level distances required for translating a set of words into another set of words. to address this apparent gap, we introduce wmdecompose: a model and python library that 1) decomposes document-level distances into their constituent word-level distances, and 2) subsequently clusters words to induce thematic elements, such that useful lexical information is retained and summarized for analysis. to illustrate its potential in a social scientific context, we apply it to a longitudinal social media corpus to explore the interrelationship between conspiracy theories and conservative american discourses. finally, because of the full wmd model's high time-complexity, we additionally suggest a method of sampling document pairs from large datasets in a reproducible way, with tight bounds that prevent extrapolation of unreliable results due to poor sampling practices. ","1713":"aspect category sentiment analysis has attracted increasing research attention. the dominant methods make use of pre-trained language models by learning effective aspect category-specific representations, and adding specific output layers to its pre-trained representation. we consider a more direct way of making use of pre-trained language models, by casting the acsa tasks into natural language generation tasks, using natural language sentences to represent the output. our method allows more direct use of pre-trained knowledge in seq2seq language models by directly following the task setting during pre-training. experiments on several benchmarks show that our method gives the best reported results, having large advantages in few-shot and zero-shot settings. ","1714":"during the last fifteen years, automatic text scaling has become one of the key tools of the text as data community in political science. prominent text scaling algorithms, however, rely on the assumption that latent positions can be captured just by leveraging the information about word frequencies in documents under study. we challenge this traditional view and present a new, semantically aware text scaling algorithm, semscale, which combines recent developments in the area of computational linguistics with unsupervised graph-based clustering. we conduct an extensive quantitative analysis over a collection of speeches from the european parliament in five different languages and from two different legislative terms, and show that a scaling approach relying on semantic document representations is often better at capturing known underlying political dimensions than the established frequency-based (i.e., symbolic) scaling method. we further validate our findings through a series of experiments focused on text preprocessing and feature selection, document representation, scaling of party manifestos, and a supervised extension of our algorithm. to catalyze further research on this new branch of text scaling methods, we release a python implementation of semscale with all included data sets and evaluation procedures. ","1715":"the audio segmentation mismatch between training data and those seen at run-time is a major problem in direct speech translation. indeed, while systems are usually trained on manually segmented corpora, in real use cases they are often presented with continuous audio requiring automatic (and sub-optimal) segmentation. after comparing existing techniques (vad-based, fixed-length and hybrid segmentation methods), in this paper we propose enhanced hybrid solutions to produce better results without sacrificing latency. through experiments on different domains and language pairs, we show that our methods outperform all the other techniques, reducing by at least 30% the gap between the traditional vad-based approach and optimal manual segmentation. ","1716":"in this paper, we present an extensive investigation of multi-bridge, many-to-many multilingual nmt models (mb-m2m) ie., models trained on non-english language pairs in addition to english-centric language pairs. in addition to validating previous work which shows that mb-m2m models can overcome zeroshot translation problems, our analysis reveals the following results about multibridge models: (1) it is possible to extract a reasonable amount of parallel corpora between non-english languages for low-resource languages (2) with limited non-english centric data, mb-m2m models are competitive with or outperform pivot models, (3) mb-m2m models can outperform english-any models and perform at par with any-english models, so a single multilingual nmt system can serve all translation directions. ","1717":"aspect sentiment triplet extraction (aste) aims to extract aspect term (aspect), sentiment and opinion term (opinion) triplets from sentences and can tell a complete story, i.e., the discussed aspect, the sentiment toward the aspect, and the cause of the sentiment. aste is a charming task, however, one triplet extracted by aste only includes one opinion of the aspect, but an aspect in a sentence may have multiple corresponding opinions and one opinion only provides part of the reason why the aspect has this sentiment, as a consequence, some triplets extracted by aste are hard to understand, and provide erroneous information for downstream tasks. in this paper, we introduce a new task, named aspect sentiment multiple opinions triplet extraction (asmote). asmote aims to extract aspect, sentiment and multiple opinions triplets. specifically, one triplet extracted by asmote contains all opinions about the aspect and can tell the exact reason that the aspect has the sentiment. we propose an aspect-guided framework (agf) to address this task. agf first extracts aspects, then predicts their opinions and sentiments. moreover, with the help of the proposed sequence labeling attention(sla), agf improves the performance of the sentiment classification using the extracted opinions. experimental results on multiple datasets demonstrate the effectiveness of our approach. ","1718":"coupled with the availability of large scale datasets, deep learning architectures have enabled rapid progress on the question answering task. however, most of those datasets are in english, and the performances of state-of-the-art multilingual models are significantly lower when evaluated on non-english data. due to high data collection costs, it is not realistic to obtain annotated data for each language one desires to support.   we propose a method to improve the cross-lingual question answering performance without requiring additional annotated data, leveraging question generation models to produce synthetic samples in a cross-lingual fashion. we show that the proposed method allows to significantly outperform the baselines trained on english data only. we report a new state-of-the-art on four multilingual datasets: mlqa, xquad, squad-it and piaf (fr). ","1719":"while diverse question answering (qa) datasets have been proposed and contributed significantly to the development of deep learning models for qa tasks, the existing datasets fall short in two aspects. first, we lack qa datasets covering complex questions that involve answers as well as the reasoning processes to get the answers. as a result, the state-of-the-art qa research on numerical reasoning still focuses on simple calculations and does not provide the mathematical expressions or evidences justifying the answers. second, the qa community has contributed much effort to improving the interpretability of qa models. however, these models fail to explicitly show the reasoning process, such as the evidence order for reasoning and the interactions between different pieces of evidence. to address the above shortcomings, we introduce noahqa, a conversational and bilingual qa dataset with questions requiring numerical reasoning with compound mathematical expressions. with noahqa, we develop an interpretable reasoning graph as well as the appropriate evaluation metric to measure the answer quality. we evaluate the state-of-the-art qa models trained using existing qa datasets on noahqa and show that the best among them can only achieve 55.5 exact match scores, while the human performance is 89.7. we also present a new qa model for generating a reasoning graph where the reasoning graph metric still has a large gap compared with that of humans, e.g., 28 scores. ","1720":"recursive processing is considered a hallmark of human linguistic abilities. a recent study evaluated recursive processing in recurrent neural language models (rnn-lms) and showed that such models perform below chance level on embedded dependencies within nested constructions -- a prototypical example of recursion in natural language. here, we study if state-of-the-art transformer lms do any better. we test four different transformer lms on two different types of nested constructions, which differ in whether the embedded (inner) dependency is short or long range. we find that transformers achieve near-perfect performance on short-range embedded dependencies, significantly better than previous results reported for rnn-lms and humans. however, on long-range embedded dependencies, transformers' performance sharply drops below chance level. remarkably, the addition of only three words to the embedded dependency caused transformers to fall from near-perfect to below-chance performance. taken together, our results reveal transformers' shortcoming when it comes to recursive, structure-based, processing. ","1721":"trained on the large corpus, pre-trained language models (plms) can capture different levels of concepts in context and hence generate universal language representations. they can benefit multiple downstream natural language processing (nlp) tasks. although ptms have been widely used in most nlp applications, especially for high-resource languages such as english, it is under-represented in lao nlp research. previous work on lao has been hampered by the lack of annotated datasets and the sparsity of language resources. in this work, we construct a text classification dataset to alleviate the resource-scare situation of the lao language. we additionally present the first transformer-based ptms for lao with four versions: bert-small, bert-base, electra-small and electra-base, and evaluate it over two downstream tasks: part-of-speech tagging and text classification. experiments demonstrate the effectiveness of our lao models. we will release our models and datasets to the community, hoping to facilitate the future development of lao nlp applications. ","1722":"although pre-trained models (plms) have achieved remarkable improvements in a wide range of nlp tasks, they are expensive in terms of time and resources. this calls for the study of training more efficient models with less computation but still ensures impressive performance. instead of pursuing a larger scale, we are committed to developing lightweight yet more powerful models trained with equal or less computation and friendly to rapid deployment. this technical report releases our pre-trained model called mengzi, which stands for a family of discriminative, generative, domain-specific, and multimodal pre-trained model variants, capable of a wide range of language and vision tasks. compared with public chinese plms, mengzi is simple but more powerful. our lightweight model has achieved new state-of-the-art results on the widely-used clue benchmark with our optimized pre-training and fine-tuning techniques. without modifying the model architecture, our model can be easily employed as an alternative to existing plms. our sources are available at https:\/\/github.com\/langboat\/mengzi. ","1723":"recently, sequence-to-sequence (seq-to-seq) models have been successfully applied in text-to-speech (tts) to synthesize speech for single-language text. to synthesize speech for multiple languages usually requires multi-lingual speech from the target speaker. however, it is both laborious and expensive to collect high-quality multi-lingual tts data for the target speakers. in this paper, we proposed to use low-quality code-switched found data from the non-target speakers to achieve cross-lingual voice cloning for the target speakers. experiments show that our proposed method can generate high-quality code-switched speech in the target voices in terms of both naturalness and speaker consistency. more importantly, we find that our method can achieve a comparable result to the state-of-the-art (sota) performance in cross-lingual voice cloning. ","1724":"pun location is to identify the punning word (usually a word or a phrase that makes the text ambiguous) in a given short text, and pun interpretation is to find out two different meanings of the punning word. most previous studies adopt limited word senses obtained by wsd(word sense disambiguation) technique or pronunciation information in isolation to address pun location. for the task of pun interpretation, related work pays attention to various wsd algorithms. in this paper, a model called dann (dual-attentive neural network) is proposed for pun location, effectively integrates word senses and pronunciation with context information to address two kinds of pun at the same time. furthermore, we treat pun interpretation as a classification task and construct pungloss pairs as processing data to solve this task. experiments on the two benchmark datasets show that our proposed methods achieve new state-of-the-art results. our source code is available in the public code repository. ","1725":"recently, semantic communications are envisioned as a key enabler of future 6g networks. back to shannon's information theory, the goal of communication has long been to guarantee the correct reception of transmitted messages irrespective of their meaning. however, in general, whenever communication occurs to convey a meaning, what matters is the receiver's understanding of the transmitted message and not necessarily its correct reconstruction. hence, semantic communications introduce a new paradigm: transmitting only relevant information sufficient for the receiver to capture the meaning intended can save significant communication bandwidth. thus, this work explores the opportunity offered by semantic communications for beyond 5g networks. in particular, we focus on the benefit of semantic compression. we refer to semantic message as a sequence of well-formed symbols learned from the \"meaning\" underlying data, which have to be interpreted at the receiver. this requires a reasoning unit, here artificial, on a knowledge base: a symbolic knowledge representation of the specific application. therefore, we present and detail a novel architecture that enables representation learning of semantic symbols for effective semantic communications. we first discuss theoretical aspects and successfully design objective functions, which help learn effective semantic encoders and decoders. eventually, we show promising numerical results for the scenario of text transmission, especially when the sender and receiver speak different languages. ","1726":"the common practice for training commonsense models has gone from-human-to-corpus-to-machine: humans author commonsense knowledge graphs in order to train commonsense models. in this work, we investigate an alternative, from-machine-to-corpus-to-machine: general language models author these commonsense knowledge graphs to train commonsense models. our study leads to a new framework, symbolic knowledge distillation. as with prior art in knowledge distillation (hinton et al., 2015), our approach uses larger models to teach smaller models. a key difference is that we distill knowledge symbolically-as text-in addition to the neural model. we also distill only one aspect-the commonsense of a general language model teacher, allowing the student to be a different type, a commonsense model. altogether, we show that careful prompt engineering and a separately trained critic model allow us to selectively distill high-quality causal commonsense from gpt-3, a general language model. empirical results demonstrate that, for the first time, a human-authored commonsense knowledge graph is surpassed by our automatically distilled variant in all three criteria: quantity, quality, and diversity. in addition, it results in a neural commonsense model that surpasses the teacher model's commonsense capabilities despite its 100x smaller size. we apply this to the atomic resource, and share our new symbolic knowledge graph and commonsense models. ","1727":"the goal of word sense disambiguation (wsd) is to identify the sense of a polysemous word in a specific context. deep-learning techniques using bert have achieved very promising results in the field and different methods have been proposed to integrate structured knowledge to enhance performance. at the same time, an increasing number of data augmentation techniques have been proven to be useful for nlp tasks. building upon previous works leveraging bert and wordnet knowledge, we explore different data augmentation techniques on context-gloss pairs to improve the performance of wsd. in our experiment, we show that both sentence-level and word-level augmentation methods are effective strategies for wsd. also, we find out that performance can be improved by adding hypernyms' glosses obtained from a lexical knowledge base. we compare and analyze different context-gloss augmentation techniques, and the results show that applying back translation on gloss performs the best. ","1728":"neural abstractive summarization models are susceptible to generating factually inconsistent content, a phenomenon known as hallucination. this limits the usability and adoption of these systems in real-world applications. to reduce the presence of hallucination, we propose the mixture of factual experts (mofe) model, which combines multiple summarization experts that each target a specific type of error. we train our experts using reinforcement learning (rl) to minimize the error defined by two factual consistency metrics: entity overlap and dependency arc entailment. we construct mofe by combining the experts using two ensembling strategies (weights and logits) and evaluate them on two summarization datasets (xsum and cnn\/dm). our experiments on bart models show that the mofe improves performance according to both entity overlap and dependency arc entailment, without a significant performance drop on standard rouge metrics. the performance improvement also transfers to unseen factual consistency metrics, such as question answer-based factuality evaluation metric and bertscore precision with respect to the source document. ","1729":"neural topic models (ntms) apply deep neural networks to topic modelling. despite their success, ntms generally ignore two important aspects: (1) only document-level word count information is utilized for the training, while more fine-grained sentence-level information is ignored, and (2) external semantic knowledge regarding documents, sentences and words are not exploited for the training. to address these issues, we propose a variational autoencoder (vae) ntm model that jointly reconstructs the sentence and document word counts using combinations of bag-of-words (bow) topical embeddings and pre-trained semantic embeddings. the pre-trained embeddings are first transformed into a common latent topical space to align their semantics with the bow embeddings. our model also features hierarchical kl divergence to leverage embeddings of each document to regularize those of their sentences, thereby paying more attention to semantically relevant sentences. both quantitative and qualitative experiments have shown the efficacy of our model in 1) lowering the reconstruction errors at both the sentence and document levels, and 2) discovering more coherent topics from real-world datasets. ","1730":"this paper proposes a transformer over transformer framework, called transformer$^2$, to perform neural text segmentation. it consists of two components: bottom-level sentence encoders using pre-trained transformers, and an upper-level transformer-based segmentation model based on the sentence embeddings. the bottom-level component transfers the pre-trained knowledge learned from large external corpora under both single and pair-wise supervised nlp tasks to model the sentence embeddings for the documents. given the sentence embeddings, the upper-level transformer is trained to recover the segmentation boundaries as well as the topic labels of each sentence. equipped with a multi-task loss and the pre-trained knowledge, transformer$^2$ can better capture the semantic coherence within the same segments. our experiments show that (1) transformer$^2$ manages to surpass state-of-the-art text segmentation models in terms of a commonly-used semantic coherence measure; (2) in most cases, both single and pair-wise pre-trained knowledge contribute to the model performance; (3) bottom-level sentence encoders pre-trained on specific languages yield better performance than those pre-trained on specific domains. ","1731":"open-retrieval generative question answering (genqa) is proven to deliver high-quality, natural-sounding answers in english. in this paper, we present the first generalization of the genqa approach for the multilingual environment. to this end, we present the gentydiqa dataset, which extends the tydiqa evaluation data (clark et al., 2020) with natural-sounding, well-formed answers in arabic, bengali, english, japanese, and russian. for all these languages, we show that a genqa sequence-to-sequence-based model outperforms a state-of-the-art answer sentence selection model. we also show that a multilingually-trained model competes with, and in some cases outperforms, its monolingual counterparts. finally, we show that our system can even compete with strong baselines, even when fed with information from a variety of languages. essentially, our system is able to answer a question in any language of our language set using information from many languages, making it the first language-agnostic genqa system. ","1732":"in recent years, researchers tend to pre-train ever-larger language models to explore the upper limit of deep models. however, large language model pre-training costs intensive computational resources and most of the models are trained from scratch without reusing the existing pre-trained models, which is wasteful. in this paper, we propose bert2bert, which can effectively transfer the knowledge of an existing smaller pre-trained model (e.g., bert_base) to a large model (e.g., bert_large) through parameter initialization and significantly improve the pre-training efficiency of the large model. specifically, we extend the previous function-preserving on transformer-based language model, and further improve it by proposing advanced knowledge for large model's initialization. in addition, a two-stage pre-training method is proposed to further accelerate the training process. we did extensive experiments on representative plms (e.g., bert and gpt) and demonstrate that (1) our method can save a significant amount of training cost compared with baselines including learning from scratch, stackbert and mslt; (2) our method is generic and applicable to different types of pre-trained models. in particular, bert2bert saves about 45% and 47% computational cost of pre-training bert_base and gpt_base by reusing the models of almost their half sizes. the source code will be publicly available upon publication. ","1733":"adversarial attacks and backdoor attacks are two common security threats that hang over deep learning. both of them harness task-irrelevant features of data in their implementation. text style is a feature that is naturally irrelevant to most nlp tasks, and thus suitable for adversarial and backdoor attacks. in this paper, we make the first attempt to conduct adversarial and backdoor attacks based on text style transfer, which is aimed at altering the style of a sentence while preserving its meaning. we design an adversarial attack method and a backdoor attack method, and conduct extensive experiments to evaluate them. experimental results show that popular nlp models are vulnerable to both adversarial and backdoor attacks based on text style transfer -- the attack success rates can exceed 90% without much effort. it reflects the limited ability of nlp models to handle the feature of text style that has not been widely realized. in addition, the style transfer-based adversarial and backdoor attack methods show superiority to baselines in many aspects. all the code and data of this paper can be obtained at https:\/\/github.com\/thunlp\/styleattack. ","1734":"this technical report summarizes our method for the video-and-language understanding evaluation (value) challenge (https:\/\/value-benchmark.github.io\/challenge\\_2021.html). we propose a clip-enhanced method to incorporate the image-text pretrained knowledge into downstream video-text tasks. combined with several other improved designs, our method outperforms the state-of-the-art by $2.4\\%$ ($57.58$ to $60.00$) meta-ave score on value benchmark. ","1735":"we study multilingual amr parsing from the perspective of knowledge distillation, where the aim is to learn and improve a multilingual amr parser by using an existing english parser as its teacher. we constrain our exploration in a strict multilingual setting: there is but one model to parse all different languages including english. we identify that noisy input and precise output are the key to successful distillation. together with extensive pre-training, we obtain an amr parser whose performances surpass all previously published results on four different foreign languages, including german, spanish, italian, and chinese, by large margins (up to 18.8 \\textsc{smatch} points on chinese and on average 11.3 \\textsc{smatch} points). our parser also achieves comparable performance on english to the latest state-of-the-art english-only parser. ","1736":"continual learning (cl), or domain expansion, recently became a popular topic for automatic speech recognition (asr) acoustic modeling because practical systems have to be updated frequently in order to work robustly on types of speech not observed during initial training. while sequential adaptation allows tuning a system to a new domain, it may result in performance degradation on the old domains due to catastrophic forgetting. in this work we explore regularization-based cl for neural network acoustic models trained with the lattice-free maximum mutual information (lf-mmi) criterion. we simulate domain expansion by incrementally adapting the acoustic model on different public datasets that include several accents and speaking styles. we investigate two well-known cl techniques, elastic weight consolidation (ewc) and learning without forgetting (lwf), which aim to reduce forgetting by preserving model weights or network outputs. we additionally introduce a sequence-level lwf regularization, which exploits posteriors from the denominator graph of lf-mmi to further reduce forgetting. empirical results show that the proposed sequence-level lwf can improve the best average word error rate across all domains by up to 9.4% relative compared with using regular lwf. ","1737":"an interactive instruction following task has been proposed as a benchmark for learning to map natural language instructions and first-person vision into sequences of actions to interact with objects in a 3d simulated environment. we find that an existing end-to-end neural model for this task is not robust to variations of objects and language instructions. we assume that this problem is due to the high sensitiveness of neural feature extraction to small changes in vision and language inputs. to mitigate this problem, we propose a neuro-symbolic approach that performs reasoning over high-level symbolic representations that are robust to small changes in raw inputs. our experiments on the alfred dataset show that our approach significantly outperforms the existing model by 18, 52, and 73 points in the success rate on the toggleobject, pickupobject, and sliceobject subtasks in unseen environments respectively. ","1738":"the covid-19 pandemic is a global crisis that has been testing every society and exposing the critical role of local politics in crisis response. in the united states, there has been a strong partisan divide between the democratic and republican party's narratives about the pandemic which resulted in polarization of individual behaviors and divergent policy adoption across regions. as shown in this case, as well as in most major social issues, strongly polarized narrative frameworks facilitate such narratives. to understand polarization and other social chasms, it is critical to dissect these diverging narratives. here, taking the democratic and republican political social media posts about the pandemic as a case study, we demonstrate that a combination of computational methods can provide useful insights into the different contexts, framing, and characters and relationships that construct their narrative frameworks which individual posts source from. leveraging a dataset of tweets from elite politicians in the u.s., we found that the democrats' narrative tends to be more concerned with the pandemic as well as financial and social support, while the republicans discuss more about other political entities such as china. we then perform an automatic framing analysis to characterize the ways in which they frame their narratives, where we found that the democrats emphasize the government's role in responding to the pandemic, and the republicans emphasize the roles of individuals and support for small businesses. finally, we present a semantic role analysis that uncovers the important characters and relationships in their narratives as well as how they facilitate a membership categorization process. our findings concretely expose the gaps in the \"elusive consensus\" between the two parties. our methodologies may be applied to computationally study narratives in various domains. ","1739":"this work concentrates on reducing the rtf and word error rate of a hybrid hmm-dnn. our baseline system uses an architecture with tdnn and lstm layers. we find this architecture particularly useful for lightly reverberated environments. however, these models tend to demand more computation than is desirable. in this work, we explore alternate architectures employing singular value decomposition (svd) is applied to the tdnn layers to reduce the rtf, as well as to the affine transforms of every lstm cell. we compare this approach with specifying bottleneck layers similar to those introduced by svd before training. additionally, we reduced the search space of the decoding graph to make it a better fit to operate in real-time applications. we report -61.57% relative reduction in rtf and almost 1% relative decrease in wer for our architecture trained on fisher data along with reverberated versions of this dataset in order to match one of our target test distributions. ","1740":"phrase representations derived from bert often do not exhibit complex phrasal compositionality, as the model relies instead on lexical similarity to determine semantic relatedness. in this paper, we propose a contrastive fine-tuning objective that enables bert to produce more powerful phrase embeddings. our approach (phrase-bert) relies on a dataset of diverse phrasal paraphrases, which is automatically generated using a paraphrase generation model, as well as a large-scale dataset of phrases in context mined from the books3 corpus. phrase-bert outperforms baselines across a variety of phrase-level similarity tasks, while also demonstrating increased lexical diversity between nearest neighbors in the vector space. finally, as a case study, we show that phrase-bert embeddings can be easily integrated with a simple autoencoder to build a phrase-based neural topic model that interprets topics as mixtures of words and phrases by performing a nearest neighbor search in the embedding space. crowdsourced evaluations demonstrate that this phrase-based topic model produces more coherent and meaningful topics than baseline word and phrase-level topic models, further validating the utility of phrase-bert. ","1741":"deep neural networks are becoming more and more popular due to their revolutionary success in diverse areas, such as computer vision, natural language processing, and speech recognition. however, the decision-making processes of these models are generally not interpretable to users. in various domains, such as healthcare, finance, or law, it is critical to know the reasons behind a decision made by an artificial intelligence system. therefore, several directions for explaining neural models have recently been explored. in this thesis, i investigate two major directions for explaining deep neural networks. the first direction consists of feature-based post-hoc explanatory methods, that is, methods that aim to explain an already trained and fixed model (post-hoc), and that provide explanations in terms of input features, such as tokens for text and superpixels for images (feature-based). the second direction consists of self-explanatory neural models that generate natural language explanations, that is, models that have a built-in module that generates explanations for the predictions of the model. ","1742":"text autoencoders are often used for unsupervised conditional text generation by applying mappings in the latent space to change attributes to the desired values. recently, mai et al. (2020) proposed emb2emb, a method to learn these mappings in the embedding space of an autoencoder. however, their method is restricted to autoencoders with a single-vector embedding, which limits how much information can be retained. we address this issue by extending their method to bag-of-vectors autoencoders (bov-aes), which encode the text into a variable-size bag of vectors that grows with the size of the text, as in attention-based models. this allows to encode and reconstruct much longer texts than standard autoencoders. analogous to conventional autoencoders, we propose regularization techniques that facilitate learning meaningful operations in the latent space. finally, we adapt for a training scheme that learns to map an input bag to an output bag, including a novel loss function and neural architecture. our experimental evaluations on unsupervised sentiment transfer and sentence summarization show that our method performs substantially better than a standard autoencoder. ","1743":"despite considerable advancements with deep neural language models (lms), neural text generation still suffers from degeneration: the generated text is repetitive, generic, self-contradictory, and often lacks commonsense. our analyses on sentence-level attention patterns in lms reveal that neural degeneration may be associated with insufficient learning of task-specific characteristics by the attention mechanism. this finding motivates on-the-fly attention modulation -- a simple but effective method that enables the injection of priors into attention computation during inference. automatic and human evaluation results on three text generation benchmarks demonstrate that attention modulation helps lms generate text with enhanced fluency, creativity, and commonsense reasoning, in addition to significantly reduce sentence-level repetition. ","1744":"training data for machine translation (mt) is often sourced from a multitude of large corpora that are multi-faceted in nature, e.g. containing contents from multiple domains or different levels of quality or complexity. naturally, these facets do not occur with equal frequency, nor are they equally important for the test scenario at hand. in this work, we propose to optimize this balance jointly with mt model parameters to relieve system developers from manual schedule design. a multi-armed bandit is trained to dynamically choose between facets in a way that is most beneficial for the mt system. we evaluate it on three different multi-facet applications: balancing translationese and natural training data, or data from multiple domains or multiple language pairs. we find that bandit learning leads to competitive mt systems across tasks, and our analysis provides insights into its learned strategies and the underlying data sets. ","1745":"since late 2019, covid-19 has quickly emerged as the newest biomedical domain, resulting in a surge of new information. as with other emergent domains, the discussion surrounding the topic has been rapidly changing, leading to the spread of misinformation. this has created the need for a public space for users to ask questions and receive credible, scientific answers. to fulfill this need, we turn to the task of open-domain question-answering, which we can use to efficiently find answers to free-text questions from a large set of documents. in this work, we present such a system for the emergent domain of covid-19. despite the small data size available, we are able to successfully train the system to retrieve answers from a large-scale corpus of published covid-19 scientific papers. furthermore, we incorporate effective re-ranking and question-answering techniques, such as document diversity and multiple answer spans. our open-domain question-answering system can further act as a model for the quick development of similar systems that can be adapted and modified for other developing emergent domains. ","1746":"the integration of syntactic structures into transformer machine translation has shown positive results, but to our knowledge, no work has attempted to do so with semantic structures. in this work we propose two novel parameter-free methods for injecting semantic information into transformers, both rely on semantics-aware masking of (some of) the attention heads. one such method operates on the encoder, through a scene-aware self-attention (sasa) head. another on the decoder, through a scene-aware cross-attention (sacra) head. we show a consistent improvement over the vanilla transformer and syntax-aware models for four language pairs. we further show an additional gain when using both semantic and syntactic structures in some language pairs. ","1747":"the winograd schema (ws) has been proposed as a test for measuring commonsense capabilities of models. recently, pre-trained language model-based approaches have boosted performance on some ws benchmarks but the source of improvement is still not clear. this paper suggests that the apparent progress on ws may not necessarily reflect progress in commonsense reasoning. to support this claim, we first show that the current evaluation method of ws is sub-optimal and propose a modification that uses twin sentences for evaluation. we also propose two new baselines that indicate the existence of artifacts in ws benchmarks. we then develop a method for evaluating ws-like sentences in a zero-shot setting to account for the commonsense reasoning abilities acquired during the pretraining and observe that popular language models perform randomly in this setting when using our more strict evaluation. we conclude that the observed progress is mostly due to the use of supervision in training ws models, which is not likely to successfully support all the required commonsense reasoning skills and knowledge. ","1748":"we demonstrate that large language models are able to simulate task oriented dialogues in novel domains, provided only with an api implementation and a list of goals. we show these simulations can formulate online, automatic metrics that correlate well with human evaluations. furthermore, by checking for whether the user's goals are met, we can use simulation to repeatedly generate training data and improve the quality of simulations themselves. with no human intervention or domain-specific training data, our simulations bootstrap end-to-end models which achieve a 37\\% error reduction in previously unseen domains. by including as few as 32 domain-specific conversations, bootstrapped models can match the performance of a fully-supervised model with $10\\times$ more data. to our knowledge, this is the first time simulations have been shown to be effective at bootstrapping models without explicitly requiring any domain-specific training data, rule-engineering, or humans-in-the-loop. ","1749":"in previous work, we have proposed the audio-visual scene-aware dialog (avsd) task, collected an avsd dataset, developed avsd technologies, and hosted an avsd challenge track at both the 7th and 8th dialog system technology challenges (dstc7, dstc8). in these challenges, the best-performing systems relied heavily on human-generated descriptions of the video content, which were available in the datasets but would be unavailable in real-world applications. to promote further advancements for real-world applications, we proposed a third avsd challenge, at dstc10, with two modifications: 1) the human-created description is unavailable at inference time, and 2) systems must demonstrate temporal reasoning by finding evidence from the video to support each answer. this paper introduces the new task that includes temporal reasoning and our new extension of the avsd dataset for dstc10, for which we collected human-generated temporal reasoning data. we also introduce a baseline system built using an av-transformer, which we released along with the new dataset. finally, this paper introduces a new system that extends our baseline system with attentional multimodal fusion, joint student-teacher learning (jstl), and model combination techniques, achieving state-of-the-art performances on the avsd datasets for dstc7, dstc8, and dstc10. we also propose two temporal reasoning methods for avsd: one attention-based, and one based on a time-domain region proposal network. ","1750":"we describe a question answering (qa) dataset that contains complex questions with conditional answers, i.e. the answers are only applicable when certain conditions apply. we call this dataset conditionalqa. in addition to conditional answers, the dataset also features: (1) long context documents with information that is related in logically complex ways; (2) multi-hop questions that require compositional logical reasoning; (3) a combination of extractive questions, yes\/no questions, questions with multiple answers, and not-answerable questions; (4) questions asked without knowing the answers. we show that conditionalqa is challenging for many of the existing qa models, especially in selecting answer conditions. we believe that this dataset will motivate further research in answering complex questions over long documents. data and leaderboard are publicly available at \\url{https:\/\/github.com\/haitian-sun\/conditionalqa}. ","1751":"automated essay scoring (aes) is gaining increasing attention in the education sector as it significantly reduces the burden of manual scoring and allows ad hoc feedback for learners. natural language processing based on machine learning has been shown to be particularly suitable for text classification and aes. while many machine-learning approaches for aes still rely on a bag-of-words (bow) approach, we consider a transformer-based approach in this paper, compare its performance to a logistic regression model based on the bow approach and discuss their differences. the analysis is based on 2,088 email responses to a problem-solving task, that were manually labeled in terms of politeness. both transformer models considered in that analysis outperformed without any hyper-parameter tuning the regression-based model. we argue that for aes tasks such as politeness classification, the transformer-based approach has significant advantages, while a bow approach suffers from not taking word order into account and reducing the words to their stem. further, we show how such models can help increase the accuracy of human raters, and we provide a detailed instruction on how to implement transformer-based models for one's own purpose. ","1752":"semantic role labeling is a fundamental yet challenging task in the nlp community. recent works of srl mainly fall into two lines:1) bio-based and 2) span-based. despite effectiveness, they share some intrinsic drawbacks of not explicitly considering internal argument structures, which may potentially hinder the model's expressiveness. to remedy this, we propose to reduce srl to a dependency parsing task and regard the flat argument spans as latent subtrees. in particular, we equip our formulation with a novel span-constrained treecrf model to make tree structures span-aware, and further extend it to the second-order case. experiments on conll05 and conll12 benchmarks reveal that the results of our methods outperform all previous works and achieve the state-of-the-art. ","1753":"modern mathematics is built on the idea that proofs should be translatable into formal proofs, whose validity is an objective question, decidable by a computer. yet, in practice, proofs are informal and may omit many details. an agent considers a proof valid if they trust that it could be expanded into a machine-verifiable proof. a proof's validity can thus become a subjective matter and lead to a debate, which may be difficult to settle. hence, while the concept of valid proof is well-defined, the process to establish validity is itself a complex multi-agent problem.   we introduce the sprig protocol. sprig allows agents to propose and verify succinct and informative proofs in a decentralized fashion; the trust is established by agents being able to request more details in the proof steps; debates, if they arise, must isolate details of proofs and, if they persist, go down to machine-level details, where they are automatically settled. a structure of bounties and stakes is set to incentivize agents to act in good faith.   we propose a game-theoretic discussion of sprig, showing how agents with various types of information interact, leading to a proof tree with an appropriate level of detail and to the invalidation of wrong proofs, and we discuss resilience against various attacks. we then analyze a simplified model, characterize its equilibria and compute the agents' level of trust.   sprig is designed to run as a smart contract on a blockchain platform. this allows anonymous agents to participate in the verification debate, and to contribute with their information. the smart contract mediates the interactions, settles debates, and guarantees that bounties and stakes are paid as specified.   sprig enables new applications, such as the issuance of bounties for open problems, and the creation of derivatives markets, allowing agents to inject more information pertaining to proofs. ","1754":"we define `ousiometrics' to be the study of essential meaning in whatever context that meaningful signals are communicated, and `telegnomics' as the study of remotely sensed knowledge. from work emerging through the middle of the 20th century, the essence of meaning has become generally accepted as being well captured by the three orthogonal dimensions of evaluation, potency, and activation (epa). by re-examining first types and then tokens for the english language, and through the use of automatically annotated histograms -- `ousiograms' -- we find here that: 1. the essence of meaning conveyed by words is instead best described by a compass-like power-danger (pd) framework, and 2. analysis of a disparate collection of large-scale english language corpora -- literature, news, wikipedia, talk radio, and social media -- shows that natural language exhibits a systematic bias toward safe, low danger words -- a reinterpretation of the pollyanna principle's positivity bias for written expression. to help justify our choice of dimension names and to help address the problems with representing observed ousiometric dimensions by bipolar adjective pairs, we introduce and explore `synousionyms' and `antousionyms' -- ousiometric counterparts of synonyms and antonyms. we further show that the pd framework revises the circumplex model of affect as a more general model of state of mind. finally, we use our findings to construct and test a prototype `ousiometer', a telegnomic instrument that measures ousiometric time series for temporal corpora. we contend that our power-danger ousiometric framework provides a complement for entropy-based measurements, and may be of value for the study of a wide variety of communication across biological and artificial life. ","1755":"pairwise dot product-based attention allows transformers to exchange information between tokens in an input-dependent way, and is key to their success across diverse applications in language and vision. however, a typical transformer model computes such pairwise attention scores repeatedly for the same sequence, in multiple heads in multiple layers. we systematically analyze the empirical similarity of these scores across heads and layers and find them to be considerably redundant, especially adjacent layers showing high similarity. motivated by these findings, we propose a novel architecture that reuses attention scores computed in one layer in multiple subsequent layers. experiments on a number of standard benchmarks show that reusing attention delivers performance equivalent to or better than standard transformers, while reducing both compute and memory usage. ","1756":"the nlp pipeline has evolved dramatically in the last few years. the first step in the pipeline is to find suitable annotated datasets to evaluate the tasks we are trying to solve. unfortunately, most of the published datasets lack metadata annotations that describe their attributes. not to mention, the absence of a public catalogue that indexes all the publicly available datasets related to specific regions or languages. when we consider low-resource dialectical languages, for example, this issue becomes more prominent. in this paper we create \\textit{masader}, the largest public catalogue for arabic nlp datasets, which consists of 200 datasets annotated with 25 attributes. furthermore, we develop a metadata annotation strategy that could be extended to other languages. we also make remarks and highlight some issues about the current status of arabic nlp datasets and suggest recommendations to address them. ","1757":"natural language processing (nlp) systems have become a central technology in communication, education, medicine, artificial intelligence, and many other domains of research and development. while the performance of nlp methods has grown enormously over the last decade, this progress has been restricted to a minuscule subset of the world's 6,500 languages. we introduce a framework for estimating the global utility of language technologies as revealed in a comprehensive snapshot of recent publications in nlp. our analyses involve the field at large, but also more in-depth studies on both user-facing technologies (machine translation, language understanding, question answering, text-to-speech synthesis) as well as more linguistic nlp tasks (dependency parsing, morphological inflection). in the process, we (1) quantify disparities in the current state of nlp research, (2) explore some of its associated societal and academic factors, and (3) produce tailored recommendations for evidence-based policy making aimed at promoting more global and equitable language technologies. ","1758":"in many contexts, lying -- the use of verbal falsehoods to deceive -- is harmful. while lying has traditionally been a human affair, ai systems that make sophisticated verbal statements are becoming increasingly prevalent. this raises the question of how we should limit the harm caused by ai \"lies\" (i.e. falsehoods that are actively selected for). human truthfulness is governed by social norms and by laws (against defamation, perjury, and fraud). differences between ai and humans present an opportunity to have more precise standards of truthfulness for ai, and to have these standards rise over time. this could provide significant benefits to public epistemics and the economy, and mitigate risks of worst-case ai futures.   establishing norms or laws of ai truthfulness will require significant work to: (1) identify clear truthfulness standards; (2) create institutions that can judge adherence to those standards; and (3) develop ai systems that are robustly truthful.   our initial proposals for these areas include: (1) a standard of avoiding \"negligent falsehoods\" (a generalisation of lies that is easier to assess); (2) institutions to evaluate ai systems before and after real-world deployment; and (3) explicitly training ai systems to be truthful via curated datasets and human interaction.   a concerning possibility is that evaluation mechanisms for eventual truthfulness standards could be captured by political interests, leading to harmful censorship and propaganda. avoiding this might take careful attention. and since the scale of ai speech acts might grow dramatically over the coming decades, early truthfulness standards might be particularly important because of the precedents they set. ","1759":"question generation is a conditioned language generation task that consists in generating a context-aware question given a context and the targeted answer. train language modelling with a mere likelihood maximization has been widely used while suffering from exposure bias and the discordance between the training and the test metrics. in the way of addressing this issue, the presented work portrays a fully transformer-based reinforcement learning generator-evaluation architecture for neural question generation. to edge the flexibility of the generation, a semantic-based reward score was externally infused during the training to drive the training of the language model. the global architecture is laid out in a generator-evaluator fashion optimized directly to n-gram and semantic-based metrics. evaluation metrics for language modelling only based on n-gram overlapping do not consider semantic relations between reference and candidate sequences. to improve the evaluation step, a two-fold evaluation was carried out. on the one side, an n-gram overlapping evaluation using the bleu score. on the other side, a semantic-based assessment using bertscore and nubia. the results were corroborated by a binary human evaluation of the semantic relatedness of the generated question and the ground truth. the results obtained showed that use a semantic-based reinforce algorithm for the question generation syntactically reshapes the generated questions while preserving their underlying semantic meaning. many downstream applications can be drawn from a successful question generation including the enlargement of question answering datasets, the improvement of conversational systems, the enhancement of autonomous educational assessment systems, and so forth. ","1760":"pre-trained language models in the past years have shown exponential growth in model parameters and compute time. electra is a novel approach for improving the compute efficiency of pre-trained language models (e.g. bert) based on masked language modeling (mlm) by addressing the sample inefficiency problem with the replaced token detection (rtd) task. our work proposes adaptive early exit strategy to maximize the efficiency of the pre-training process by relieving the model's subsequent layers of the need to process latent features by leveraging earlier layer representations. moreover, we evaluate an initial approach to the problem that has not succeeded in maintaining the accuracy of the model while showing a promising compute efficiency by thoroughly investigating the necessity of the generator module of electra. ","1761":"e-commerce marketplaces support millions of daily transactions, and some disagreements between buyers and sellers are unavoidable. resolving disputes in an accurate, fast, and fair manner is of great importance for maintaining a trustworthy platform. simple cases can be automated, but intricate cases are not sufficiently addressed by hard-coded rules, and therefore most disputes are currently resolved by people. in this work we take a first step towards automatically assisting human agents in dispute resolution at scale. we construct a large dataset of disputes from the ebay online marketplace, and identify several interesting behavioral and linguistic patterns. we then train classifiers to predict dispute outcomes with high accuracy. we explore the model and the dataset, reporting interesting correlations, important features, and insights. ","1762":"keyphrases, that concisely summarize the high-level topics discussed in a document, can be categorized into present keyphrase which explicitly appears in the source text, and absent keyphrase which does not match any contiguous subsequence but is highly semantically related to the source. most existing keyphrase generation approaches synchronously generate present and absent keyphrases without explicitly distinguishing these two categories. in this paper, a select-guide-generate (sgg) approach is proposed to deal with present and absent keyphrase generation separately with different mechanisms. specifically, sgg is a hierarchical neural network which consists of a pointing-based selector at low layer concentrated on present keyphrase generation, a selection-guided generator at high layer dedicated to absent keyphrase generation, and a guider in the middle to transfer information from selector to generator. experimental results on four keyphrase generation benchmarks demonstrate the effectiveness of our model, which significantly outperforms the strong baselines for both present and absent keyphrases generation. furthermore, we extend sgg to a title generation task which indicates its extensibility in natural language generation tasks. ","1763":"simultaneous speech-to-text translation (simulst) systems translate source speech in tandem with the speaker using partial input. recent works have tried to leverage the text translation task to improve the performance of speech translation (st) in the offline domain. motivated by these improvements, we propose to add decision attentive regularization (dar) to monotonic multihead attention (mma) based simulst systems. dar improves the read\/write decisions for speech using the simultaneous text translation (simulmt) task. we also extend several techniques from the offline domain to the simulst task. our proposed system achieves significant performance improvements for the must-c english-german (ende) simulst task, where we provide an average blue score improvement of around 4.57 points or 34.17% across different latencies. further, the latency-quality tradeoffs establish that the proposed model achieves better results compared to the baseline. ","1764":"the ability to generate natural-language questions with controlled complexity levels is highly desirable as it further expands the applicability of question generation. in this paper, we propose an end-to-end neural complexity-controllable question generation model, which incorporates a mixture of experts (moe) as the selector of soft templates to improve the accuracy of complexity control and the quality of generated questions. the soft templates capture question similarity while avoiding the expensive construction of actual templates. our method introduces a novel, cross-domain complexity estimator to assess the complexity of a question, taking into account the passage, the question, the answer and their interactions. the experimental results on two benchmark qa datasets demonstrate that our qg model is superior to state-of-the-art methods in both automatic and manual evaluation. moreover, our complexity estimator is significantly more accurate than the baselines in both in-domain and out-domain settings. ","1765":"standard few-shot relation classification (rc) is designed to learn a robust classifier with only few labeled data for each class. however, previous works rarely investigate the effects of a different number of classes (i.e., $n$-way) and number of labeled data per class (i.e., $k$-shot) during training vs. testing. in this work, we define a new task, \\textit{inconsistent few-shot rc}, where the model needs to handle the inconsistency of $n$ and $k$ between training and testing. to address this new task, we propose prototype network-based cross-attention contrastive learning (protocacl) to capture the rich mutual interactions between the support set and query set. experimental results demonstrate that our protocacl can outperform the state-of-the-art baseline model under both inconsistent $k$ and inconsistent $n$ settings, owing to its more robust and discriminate representations. moreover, we identify that in the inconsistent few-shot learning setting, models can achieve better performance with \\textit{less data} than the standard few-shot setting with carefully-selected $n$ and $k$. in the end of the paper, we provide further analyses and suggestions to systematically guide the selection of $n$ and $k$ under different scenarios. ","1766":"natural language inference (nli) requires models to learn and apply commonsense knowledge. these reasoning abilities are particularly important for explainable nli systems that generate a natural language explanation in addition to their label prediction. the integration of external knowledge has been shown to improve nli systems, here we investigate whether it can also improve their explanation capabilities. for this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. we find that different sources of knowledge have a different effect on reasoning abilities, for example, implicit knowledge stored in language models can hinder reasoning on numbers and negations. finally, we conduct the largest and most fine-grained explainable nli crowdsourcing study to date. it reveals that even large differences in automatic performance scores do neither reflect in human ratings of label, explanation, commonsense nor grammar correctness. ","1767":"negation is both an operation in formal logic and in natural language by which a proposition is replaced by one stating the opposite, as by the addition of \"not\" or another negation cue. treating negation in an adequate way is required for cognitive reasoning, which aims at modeling the human ability to draw meaningful conclusions despite incomplete and inconsistent knowledge. one task of cognitive reasoning is answering questions given by sentences in natural language. there are tools based on discourse representation theory to convert sentences automatically into a formal logic representation, and additional knowledge can be added using the predicate names in the formula and knowledge databases. however, the knowledge in logic databases in practice always is incomplete. hence, forward reasoning of automated reasoning systems alone does not suffice to derive answers to questions because, instead of complete proofs, often only partial positive knowledge can be derived, while negative knowledge is used only during the reasoning process. in consequence, we aim at eliminating syntactic negation, strictly speaking, the negated event or property. in this paper, we describe an effective procedure to determine the negated event or property in order to replace it by its inverse. this lays the basis of cognitive reasoning, employing both logic and machine learning for general question answering. we evaluate our procedure by several benchmarks and demonstrate its practical usefulness in our cognitive reasoning system. ","1768":"event correlation reasoning infers whether a natural language paragraph containing multiple events conforms to human common sense. for example, \"andrew was very drowsy, so he took a long nap, and now he is very alert\" is sound and reasonable. in contrast, \"andrew was very drowsy, so he stayed up a long time, now he is very alert\" does not comply with human common sense. such reasoning capability is essential for many downstream tasks, such as script reasoning, abductive reasoning, narrative incoherence, story cloze test, etc. however, conducting event correlation reasoning is challenging due to a lack of large amounts of diverse event-based knowledge and difficulty in capturing correlation among multiple events. in this paper, we propose eventbert, a pre-trained model to encapsulate eventuality knowledge from unlabeled text. specifically, we collect a large volume of training examples by identifying natural language paragraphs that describe multiple correlated events and further extracting event spans in an unsupervised manner. we then propose three novel event- and correlation-based learning objectives to pre-train an event correlation model on our created training corpus. empirical results show eventbert outperforms strong baselines on four downstream tasks, and achieves sota results on most of them. besides, it outperforms existing pre-trained models by a large margin, e.g., 6.5~23%, in zero-shot learning of these tasks. ","1769":"we introduce deeppsl a variant of probabilistic soft logic (psl) to produce an end-to-end trainable system that integrates reasoning and perception. psl represents first-order logic in terms of a convex graphical model -- hinge loss markov random fields (hl-mrfs). psl stands out among probabilistic logic frameworks due to its tractability having been applied to systems of more than 1 billion ground rules. the key to our approach is to represent predicates in first-order logic using deep neural networks and then to approximately back-propagate through the hl-mrf and thus train every aspect of the first-order system being represented. we believe that this approach represents an interesting direction for the integration of deep learning and reasoning techniques with applications to knowledge base learning, multi-task learning, and explainability. we evaluate deeppsl on a zero shot learning problem in image classification. state of the art results demonstrate the utility and flexibility of our approach. ","1770":"in this paper, we discuss the initial attempts at boosting understanding human language based on deep-learning models with quantum computing. we successfully train a quantum-enhanced long short-term memory network to perform the parts-of-speech tagging task via numerical simulations. moreover, a quantum-enhanced transformer is proposed to perform the sentiment analysis based on the existing dataset. ","1771":"recent studies in speech perception have been closely linked to fields of cognitive psychology, phonology, and phonetics in linguistics. during perceptual attunement, a critical and sensitive developmental trajectory has been examined in bilingual and monolingual infants where they can best discriminate common phonemes. in this paper, we compare and identify these cognitive aspects on deep neural-based visual lip-reading models. we conduct experiments on the two most extensive public visual speech recognition datasets for english and mandarin. through our experimental results, we observe a strong correlation between these theories in cognitive psychology and our unique modeling. we inspect how these computational models develop similar phases in speech perception and acquisitions. ","1772":"we give simpler, sparser, and faster algorithms for differentially private fine-tuning of large-scale pre-trained language models, which achieve the state-of-the-art privacy versus utility tradeoffs on many standard nlp tasks. we propose a meta-framework for this problem, inspired by the recent success of highly parameter-efficient methods for fine-tuning. our experiments show that differentially private adaptations of these approaches outperform previous private algorithms in three important dimensions: utility, privacy, and the computational and memory cost of private training. on many commonly studied datasets, the utility of private models approaches that of non-private models. for example, on the mnli dataset we achieve an accuracy of $87.8\\%$ using roberta-large and $83.5\\%$ using roberta-base with a privacy budget of $\\epsilon = 6.7$. in comparison, absent privacy constraints, roberta-large achieves an accuracy of $90.2\\%$. our findings are similar for natural language generation tasks. privately fine-tuning with dart, gpt-2-small, gpt-2-medium, gpt-2-large, and gpt-2-xl achieve bleu scores of 38.5, 42.0, 43.1, and 43.8 respectively (privacy budget of $\\epsilon = 6.8,\\delta=$ 1e-5) whereas the non-private baseline is $48.1$. all our experiments suggest that larger models are better suited for private fine-tuning: while they are well known to achieve superior accuracy non-privately, we find that they also better maintain their accuracy when privacy is introduced. ","1773":"chatbots are intelligent software built to be used as a replacement for human interaction. existing studies typically do not provide enough support for low-resource languages like bangla. due to the increasing popularity of social media, we can also see the rise of interactions in bangla transliteration (mostly in english) among the native bangla speakers. in this paper, we propose a novel approach to build a bangla chatbot aimed to be used as a business assistant which can communicate in low-resource languages like bangla and bangla transliteration in english with high confidence consistently. since annotated data was not available for this purpose, we had to work on the whole machine learning life cycle (data preparation, machine learning modeling, and model deployment) using rasa open source framework, fasttext embeddings, polyglot embeddings, flask, and other systems as building blocks. while working with the skewed annotated dataset, we try out different components and pipelines to evaluate which works best and provide possible reasoning behind the observed results. finally, we present a pipeline for intent classification and entity extraction which achieves reasonable performance (accuracy: 83.02%, precision: 80.82%, recall: 83.02%, f1-score: 80%). ","1774":"computational modeling of the emotions evoked by art in humans is a challenging problem because of the subjective and nuanced nature of art and affective signals. in this paper, we consider the above-mentioned problem of understanding emotions evoked in viewers by artwork using both text and visual modalities. specifically, we analyze images and the accompanying text captions from the viewers expressing emotions as a multimodal classification task. our results show that single-stream multimodal transformer-based models like mmbt and visualbert perform better compared to both image-only models and dual-stream multimodal models having separate pathways for text and image modalities. we also observe improvements in performance for extreme positive and negative emotion classes, when a single-stream model like mmbt is compared with a text-only transformer model like bert. ","1775":"entity alignment (ea) aims to match equivalent entities across different knowledge graphs (kgs) and is an essential step of kg fusion. current mainstream methods -- neural ea models -- rely on training with seed alignment, i.e., a set of pre-aligned entity pairs which are very costly to annotate. in this paper, we devise a novel active learning (al) framework for neural ea, aiming to create highly informative seed alignment to obtain more effective ea models with less annotation cost. our framework tackles two main challenges encountered when applying al to ea: (1) how to exploit dependencies between entities within the al strategy. most al strategies assume that the data instances to sample are independent and identically distributed. however, entities in kgs are related. to address this challenge, we propose a structure-aware uncertainty sampling strategy that can measure the uncertainty of each entity as well as its impact on its neighbour entities in the kg. (2) how to recognise entities that appear in one kg but not in the other kg (i.e., bachelors). identifying bachelors would likely save annotation budget. to address this challenge, we devise a bachelor recognizer paying attention to alleviate the effect of sampling bias. empirical results show that our proposed al strategy can significantly improve sampling quality with good generality across different datasets, ea models and amount of bachelors. ","1776":"this paper addresses the problem of fake news detection in spanish using machine learning techniques. it is fundamentally the same problem tackled for the english language; however, there is not a significant amount of publicly available and adequately labeled fake news in spanish to effectively train a machine learning model, similarly to those proposed for the english language. therefore, this work explores different training strategies and architectures to establish a baseline for further research in this area. four datasets were used, two in english and two in spanish, and four experimental schemes were tested, including a baseline with classical machine learning models, trained and validated using a small dataset in spanish. the remaining schemes include state-of-the-art deep learning models trained (or fine-tuned) and validated in english, trained and validated in spanish, and fitted in english and validated with automatic translated spanish sentences. the deep learning architectures were built on top of different pre-trained word embedding representations, including glove, elmo, bert, and beto (a bert version trained on a large corpus in spanish). according to the results, the best strategy was a combination of a pre-trained beto model and a recurrent neural network based on lstm layers, yielding an accuracy of up to 80%; nonetheless, a baseline model using a random forest estimator obtained similar outcomes. additionally, the translation strategy did not yield acceptable results because of the propagation error; there was also observed a significant difference in models performance when trained in english or spanish, mainly attributable to the number of samples available for each language. ","1777":"dominant sentence ordering models can be classified into pairwise ordering models and set-to-sequence models. however, there is little attempt to combine these two types of models, which inituitively possess complementary advantages. in this paper, we propose a novel sentence ordering framework which introduces two classifiers to make better use of pairwise orderings for graph-based sentence ordering. specially, given an initial sentence-entity graph, we first introduce a graph-based classifier to predict pairwise orderings between linked sentences. then, in an iterative manner, based on the graph updated by previously predicted high-confident pairwise orderings, another classifier is used to predict the remaining uncertain pairwise orderings. at last, we adapt a grn-based sentence ordering model on the basis of final graph. experiments on five commonly-used datasets demonstrate the effectiveness and generality of our model. particularly, when equipped with bert and fhdecoder, our model achieves state-of-the-art performance. ","1778":"there are two cases describing how a classifier processes input text, namely, misclassification and correct classification. in terms of misclassified texts, a classifier handles the texts with both incorrect predictions and adversarial texts, which are generated to fool the classifier, which is called a victim. both types are misunderstood by the victim, but they can still be recognized by other classifiers. this induces large gaps in predicted probabilities between the victim and the other classifiers. in contrast, text correctly classified by the victim is often successfully predicted by the others and induces small gaps. in this paper, we propose an ensemble model based on similarity estimation of predicted probabilities (sepp) to exploit the large gaps in the misclassified predictions in contrast to small gaps in the correct classification. sepp then corrects the incorrect predictions of the misclassified texts. we demonstrate the resilience of sepp in defending and detecting adversarial texts through different types of victim classifiers, classification tasks, and adversarial attacks. ","1779":"neural conversational models have long suffered from the problem of inconsistency and lacking coherent personality. to address the issue, persona-based models capturing individual characteristics have been proposed, but they still face the dilemma of model adaption and data privacy. to break this dilemma, we propose a novel federated natural language generation (fednlg) framework, which learns personalized representations from various dataset on distributed devices, and thus implements the personalized dialogue system efficiently and safely. fednlg first pre-trains parameters of standard neural conversational model over a large dialogue corpus, and then fine-tune the model parameters and persona embeddings on specific datasets, in a federated manner. thus, the model could simultaneously learn the persona embeddings in local clients and learn shared model parameters by federated aggregation, which achieves accuracyprivacy balance. by conducting extensive experiments, we demonstrate the effectiveness of our model by pre-training model over cornell movie-dialogs corpus and fine-tuning the model over two tv series dataset. ","1780":"existing generative pre-trained language models (e.g., gpt) focus on modeling the language structure and semantics of general texts. however, those models do not consider the numerical properties of numbers and cannot perform robustly on numerical reasoning tasks (e.g., math word problems and measurement estimation). in this paper, we propose numgpt, a generative pre-trained model that explicitly models the numerical properties of numbers in texts. specifically, it leverages a prototype-based numeral embedding to encode the mantissa of the number and an individual embedding to encode the exponent of the number. a numeral-aware loss function is designed to integrate numerals into the pre-training objective of numgpt. we conduct extensive experiments on four different datasets to evaluate the numeracy ability of numgpt. the experiment results show that numgpt outperforms baseline models (e.g., gpt and gpt with dice) on a range of numerical reasoning tasks such as measurement estimation, number comparison, math word problems, and magnitude classification. ablation studies are also conducted to evaluate the impact of pre-training and model hyperparameters on the performance. ","1781":"the outbreak of the sars-cov-2 pandemic of the new covid-19 disease (covid-19 for short) demands empowering existing medical, economic, and social emergency backend systems with data analytics capabilities. an impediment in taking advantages of data analytics in these systems is the lack of a unified framework or reference model. ontologies are highlighted as a promising solution to bridge this gap by providing a formal representation of covid-19 concepts such as symptoms, infections rate, contact tracing, and drug modelling. ontology-based solutions enable the integration of diverse data sources that leads to a better understanding of pandemic data, management of smart lockdowns by identifying pandemic hotspots, and knowledge-driven inference, reasoning, and recommendations to tackle surrounding issues. ","1782":"we propose a novel method for applying transformer models to extractive question answering (qa) tasks. recently, pretrained generative sequence-to-sequence (seq2seq) models have achieved great success in question answering. contributing to the success of these models are internal attention mechanisms such as cross-attention. we propose a simple strategy to obtain an extractive answer span from the generative model by leveraging the decoder cross-attention patterns. viewing cross-attention as an architectural prior, we apply joint training to further improve qa performance. empirical results show that on open-domain question answering datasets like naturalquestions and triviaqa, our method approaches state-of-the-art performance on both generative and extractive inference, all while using much fewer parameters. furthermore, this strategy allows us to perform hallucination-free inference while conferring significant improvements to the model's ability to rerank relevant passages. ","1783":"improving the quality of natural language understanding (nlu) models, and more specifically, task-oriented semantic parsing models, in production is a cumbersome task. in this work, we present a system called autonlu, which we designed to scale the nlu quality improvement process. it adds automation to three key steps: detection, attribution, and correction of model errors, i.e., bugs. we detected four times more failed tasks than with random sampling, finding that even a simple active learning sampling method on an uncalibrated model is surprisingly effective for this purpose. the autonlu tool empowered linguists to fix ten times more semantic parsing bugs than with prior manual processes, auto-correcting 65% of all identified bugs. ","1784":"large scale language models encode rich commonsense knowledge acquired through exposure to massive data during pre-training, but their understanding of entities and their semantic properties is unclear. we probe bert (devlin et al., 2019) for the properties of english nouns as expressed by adjectives that do not restrict the reference scope of the noun they modify (as in \"red car\"), but instead emphasise some inherent aspect (\"red strawberry\"). we base our study on psycholinguistics datasets that capture the association strength between nouns and their semantic features. we probe bert using cloze tasks and in a classification setting, and show that the model has marginal knowledge of these features and their prevalence as expressed in these datasets. we discuss factors that make evaluation challenging and impede drawing general conclusions about the models' knowledge of noun properties. finally, we show that when tested in a fine-tuning setting addressing entailment, bert successfully leverages the information needed for reasoning about the meaning of adjective-noun constructions outperforming previous methods. ","1785":"recent developments in machine translation and multilingual text generation have led researchers to adopt trained metrics such as comet or bleurt, which treat evaluation as a regression problem and use representations from multilingual pre-trained models such as xlm-roberta or mbert. yet studies on related tasks suggest that these models are most efficient when they are large, which is costly and impractical for evaluation. we investigate the trade-off between multilinguality and model capacity with rembert, a state-of-the-art multilingual language model, using data from the wmt metrics shared task. we present a series of experiments which show that model size is indeed a bottleneck for cross-lingual transfer, then demonstrate how distillation can help addressing this bottleneck, by leveraging synthetic data generation and transferring knowledge from one teacher to multiple students trained on related languages. our method yields up to 10.5% improvement over vanilla fine-tuning and reaches 92.6% of rembert's performance using only a third of its parameters. ","1786":"dialogue agents that interact with humans in situated environments need to manage referential ambiguity across multiple modalities and ask for help as needed. however, it is not clear what kinds of questions such agents should ask nor how the answers to such questions can be used to resolve ambiguity. to address this, we analyzed dialogue data from an interactive study in which participants controlled a virtual robot tasked with organizing a set of tools while engaging in dialogue with a live, remote experimenter. we discovered a number of novel results, including the distribution of question types used to resolve ambiguity and the influence of dialogue-level factors on the reference resolution process. based on these empirical findings we: (1) developed a computational model for clarification requests using a decision network with an entropy-based utility assignment method that operates across modalities, (2) evaluated the model, showing that it outperforms a slot-filling baseline in environments of varying ambiguity, and (3) interpreted the results to offer insight into the ways that agents can ask questions to facilitate situated reference resolution. ","1787":"this paper introduces s3prl-vc, an open-source voice conversion (vc) framework based on the s3prl toolkit. in the context of recognition-synthesis vc, self-supervised speech representation (s3r) is valuable in its potential to replace the expensive supervised representation adopted by state-of-the-art vc systems. moreover, we claim that vc is a good probing task for s3r analysis. in this work, we provide a series of in-depth analyses by benchmarking on the two tasks in vcc2020, namely intra-\/cross-lingual any-to-one (a2o) vc, as well as an any-to-any (a2a) setting. we also provide comparisons between not only different s3rs but also top systems in vcc2020 with supervised representations. systematic objective and subjective evaluation were conducted, and we show that s3r is comparable with vcc2020 top systems in the a2o setting in terms of similarity, and achieves state-of-the-art in s3r-based a2a vc. we believe the extensive analysis, as well as the toolkit itself, contribute to not only the s3r community but also the vc community. the codebase is now open-sourced. ","1788":"we present a new method list for efficient fine-tuning of large pre-trained language models (plms) in few-shot learning settings. list significantly improves over recent methods that adopt prompt fine-tuning using two key techniques. the first one is the use of self-training to leverage large amounts of unlabeled data for prompt-tuning to significantly boost the model performance in few-shot settings. we use self-training in conjunction with meta-learning for re-weighting noisy pseudo-prompt labels. however, traditional self-training is expensive as it requires updating all the model parameters repetitively. therefore, we use a second technique for light-weight fine-tuning where we introduce a small number of task-specific adapter parameters that are fine-tuned during self-training while keeping the plm encoder frozen. this also significantly reduces the overall model footprint across several tasks that can now share a common plm encoder as backbone for inference. combining the above techniques, list not only improves the model performance for few-shot learning on target domains but also reduces the model memory footprint. we present a comprehensive study on six nlu tasks to validate the effectiveness of list. the results show that list improves by 35% over classic fine-tuning methods and 6% over prompt-tuning with 96% reduction in number of trainable parameters when fine-tuned with no more than 30 labeled examples from each target domain. ","1789":"although neural models have shown strong performance in datasets such as snli, they lack the ability to generalize out-of-distribution (ood). in this work, we formulate a few-shot learning setup and examine the effects of natural language explanations on ood generalization. we leverage the templates in the hans dataset and construct templated natural language explanations for each template. although generated explanations show competitive bleu scores against groundtruth explanations, they fail to improve prediction performance. we further show that generated explanations often hallucinate information and miss key elements that indicate the label. ","1790":"many legal professionals think that the explosion of information about local, regional, national, and international legislation makes their practice more costly, time-consuming, and even error-prone. the two main reasons for this are that most legislation is usually unstructured, and the tremendous amount and pace with which laws are released causes information overload in their daily tasks. in the case of the legal domain, the research community agrees that a system allowing to generate automatic responses to legal questions could substantially impact many practical implications in daily activities. the degree of usefulness is such that even a semi-automatic solution could significantly help to reduce the workload to be faced. this is mainly because a question answering system could be able to automatically process a massive amount of legal resources to answer a question or doubt in seconds, which means that it could save resources in the form of effort, money, and time to many professionals in the legal sector. in this work, we quantitatively and qualitatively survey the solutions that currently exist to meet this challenge. ","1791":"in 2020, covid-19 became the chief concern of the world and is still reflected widely in all social networks. each day, users post millions of tweets and comments on this subject, which contain significant implicit information about the public opinion. in this regard, a dataset of covid-related tweets in english language is collected, which consists of more than two million tweets from march 23 to june 23 of 2020 to extract the feelings of the people in various countries in the early stages of this outbreak. to this end, first, we use a lexicon-based approach in conjunction with the geonames geographic database to label the tweets with their locations. next, a method based on the recently introduced and widely cited roberta model is proposed to analyze their sentimental content. after that, the trend graphs of the frequency of tweets as well as sentiments are produced for the world and the nations that were more engaged with covid-19. graph analysis shows that the frequency graphs of the tweets for the majority of nations are significantly correlated with the official statistics of the daily afflicted in them. moreover, several implicit knowledge is extracted and discussed. ","1792":"a popular approach to decompose the neural bases of language consists in correlating, across individuals, the brain responses to different stimuli (e.g. regular speech versus scrambled words, sentences, or paragraphs). although successful, this `model-free' approach necessitates the acquisition of a large and costly set of neuroimaging data. here, we show that a model-based approach can reach equivalent results within subjects exposed to natural stimuli. we capitalize on the recently-discovered similarities between deep language models and the human brain to compute the mapping between i) the brain responses to regular speech and ii) the activations of deep language models elicited by modified stimuli (e.g. scrambled words, sentences, or paragraphs). our model-based approach successfully replicates the seminal study of lerner et al. (2011), which revealed the hierarchy of language areas by comparing the functional-magnetic resonance imaging (fmri) of seven subjects listening to 7min of both regular and scrambled narratives. we further extend and precise these results to the brain signals of 305 individuals listening to 4.1 hours of narrated stories. overall, this study paves the way for efficient and flexible analyses of the brain bases of language. ","1793":"neural models for the various flavours of morphological inflection tasks have proven to be extremely accurate given ample labeled data -- data that may be slow and costly to obtain. in this work we aim to overcome this annotation bottleneck by bootstrapping labeled data from a seed as little as {\\em five} labeled paradigms, accompanied by a large bulk of unlabeled text. our approach exploits different kinds of regularities in morphological systems in a two-phased setup, where word tagging based on {\\em analogies} is followed by word pairing based on {\\em distances}. we experiment with the paradigm cell filling problem over eight typologically different languages, and find that, in languages with relatively simple morphology, orthographic regularities on their own allow inflection models to achieve respectable accuracy. combined orthographic and semantic regularities alleviate difficulties with particularly complex morpho-phonological systems. our results suggest that hand-crafting many tagged examples might be an unnecessary effort. however, more work is needed in order to address rarely used forms. ","1794":"to create a more inclusive workplace, enterprises are actively investing in identifying and eliminating unconscious bias (e.g., gender, race, age, disability, elitism and religion) across their various functions. we propose a deep learning model with a transfer learning based language model to learn from manually tagged documents for automatically identifying bias in enterprise content. we first pretrain a deep learning-based language-model using wikipedia, then fine tune the model with a large unlabelled data set related with various types of enterprise content. finally, a linear layer followed by softmax layer is added at the end of the language model and the model is trained on a labelled bias dataset consisting of enterprise content. the trained model is thoroughly evaluated on independent datasets to ensure a general application. we present the proposed method and its deployment detail in a real-world application. ","1795":"despite the recent advances in applying pre-trained language models to generate high-quality texts, generating long passages that maintain long-range coherence is yet challenging for these models. in this paper, we propose discodvt, a discourse-aware discrete variational transformer to tackle the incoherence issue. discodvt learns a discrete variable sequence that summarizes the global structure of the text and then applies it to guide the generation process at each decoding step. to further embed discourse-aware information into the discrete latent representations, we introduce an auxiliary objective to model the discourse relations within the text. we conduct extensive experiments on two open story generation datasets and demonstrate that the latent codes learn meaningful correspondence to the discourse structures that guide the model to generate long texts with better long-range coherence. ","1796":"current benchmark tasks for natural language processing contain text that is qualitatively different from the text used in informal day to day digital communication. this discrepancy has led to severe performance degradation of state-of-the-art nlp models when fine-tuned on real-world data. one way to resolve this issue is through lexical normalization, which is the process of transforming non-standard text, usually from social media, into a more standardized form. in this work, we propose a sentence-level sequence-to-sequence model based on mbart, which frames the problem as a machine translation problem. as the noisy text is a pervasive problem across languages, not just english, we leverage the multi-lingual pre-training of mbart to fine-tune it to our data. while current approaches mainly operate at the word or subword level, we argue that this approach is straightforward from a technical standpoint and builds upon existing pre-trained transformer networks. our results show that while word-level, intrinsic, performance evaluation is behind other methods, our model improves performance on extrinsic, downstream tasks through normalization compared to models operating on raw, unprocessed, social media text. ","1797":"data processing is an important step in various natural language processing tasks. as the commonly used datasets in named entity recognition contain only a limited number of samples, it is important to obtain additional labeled data in an efficient and reliable manner. a common practice is to utilize large monolingual unlabeled corpora. another popular technique is to create synthetic data from the original labeled data (data augmentation). in this work, we investigate the impact of these two methods on the performance of three different named entity recognition tasks. ","1798":"ai technologies for natural languages have made tremendous progress recently. however, commensurate progress has not been made on sign languages, in particular, in recognizing signs as individual words or as complete sentences. we introduce openhands, a library where we take four key ideas from the nlp community for low-resource languages and apply them to sign languages for word-level recognition. first, we propose using pose extracted through pretrained models as the standard modality of data to reduce training time and enable efficient inference, and we release standardized pose datasets for 6 different sign languages - american, argentinian, chinese, greek, indian, and turkish. second, we train and release checkpoints of 4 pose-based isolated sign language recognition models across all 6 languages, providing baselines and ready checkpoints for deployment. third, to address the lack of labelled data, we propose self-supervised pretraining on unlabelled data. we curate and release the largest pose-based pretraining dataset on indian sign language (indian-sl). fourth, we compare different pretraining strategies and for the first time establish that pretraining is effective for sign language recognition by demonstrating (a) improved fine-tuning performance especially in low-resource settings, and (b) high crosslingual transfer from indian-sl to few other sign languages. we open-source all models and datasets in openhands with a hope that it makes research in sign languages more accessible, available here at https:\/\/github.com\/ai4bharat\/openhands . ","1799":"video-text retrieval has many real-world applications such as media analytics, surveillance, and robotics. this paper presents the 1st place solution to the video retrieval track of the iccv value challenge 2021. we present a simple yet effective approach to jointly tackle two video-text retrieval tasks (video retrieval and video corpus moment retrieval) by leveraging the model trained only on the video retrieval task. in addition, we create an ensemble model that achieves the new state-of-the-art performance on all four datasets (tvr, how2r, youcook2r, and vatexr) presented in the value challenge. ","1800":"most of the deep learning-based speech enhancement models are learned in a supervised manner, which implies that pairs of noisy and clean speech are required during training. consequently, several noisy speeches recorded in daily life cannot be used to train the model. although certain unsupervised learning frameworks have also been proposed to solve the pair constraint, they still require clean speech or noise for training. therefore, in this paper, we propose metricgan-u, which stands for metricgan-unsupervised, to further release the constraint from conventional unsupervised learning. in metricgan-u, only noisy speech is required to train the model by optimizing non-intrusive speech quality metrics. the experimental results verified that metricgan-u outperforms baselines in both objective and subjective metrics. ","1801":"fact verification has attracted a lot of attention in the machine learning and natural language processing communities, as it is one of the key methods for detecting misinformation. existing large-scale benchmarks for this task have focused mostly on textual sources, i.e. unstructured information, and thus ignored the wealth of information available in structured formats, such as tables. in this paper we introduce a novel dataset and benchmark, fact extraction and verification over unstructured and structured information (feverous), which consists of 87,026 verified claims. each claim is annotated with evidence in the form of sentences and\/or cells from tables in wikipedia, as well as a label indicating whether this evidence supports, refutes, or does not provide enough information to reach a verdict. furthermore, we detail our efforts to track and minimize the biases present in the dataset and could be exploited by models, e.g. being able to predict the label without using evidence. finally, we develop a baseline for verifying claims against text and tables which predicts both the correct evidence and verdict for 18% of the claims. ","1802":"pre-trained language models (plms) have been the de facto paradigm for most natural language processing (nlp) tasks. this also benefits biomedical domain: researchers from informatics, medicine, and computer science (cs) communities propose various plms trained on biomedical datasets, e.g., biomedical text, electronic health records, protein, and dna sequences for various biomedical tasks. however, the cross-discipline characteristics of biomedical plms hinder their spreading among communities; some existing works are isolated from each other without comprehensive comparison and discussions. it expects a survey that not only systematically reviews recent advances of biomedical plms and their applications but also standardizes terminology and benchmarks. in this paper, we summarize the recent progress of pre-trained language models in the biomedical domain and their applications in biomedical downstream tasks. particularly, we discuss the motivations and propose a taxonomy of existing biomedical plms. their applications in biomedical downstream tasks are exhaustively discussed. at last, we illustrate various limitations and future trends, which we hope can provide inspiration for the future research of the research community. ","1803":"we present work on summarising deliberative processes for non-english languages. unlike commonly studied datasets, such as news articles, this deliberation dataset reflects difficulties of combining multiple narratives, mostly of poor grammatical quality, in a single text. we report an extensive evaluation of a wide range of abstractive summarisation models in combination with an off-the-shelf machine translation model. texts are translated into english, summarised, and translated back to the original language. we obtain promising results regarding the fluency, consistency and relevance of the summaries produced. our approach is easy to implement for many languages for production purposes by simply changing the translation model. ","1804":"when training and evaluating machine learning models on a large number of tasks, it is important to not only look at average task accuracy -- which may be biased by easy or redundant tasks -- but also worst-case accuracy (i.e. the performance on the task with the lowest accuracy). in this work, we show how to use techniques from the distributionally robust optimization (dro) literature to improve worst-case performance in multitask learning. we highlight several failure cases of dro when applied off-the-shelf and present an improved method, lookahead-dro (l-dro), which mitigates these issues. the core idea of l-dro is to anticipate the interaction between tasks during training in order to choose a dynamic re-weighting of the various task losses, which will (i) lead to minimal worst-case loss and (ii) train on as many tasks as possible. after demonstrating the efficacy of l-dro on a small controlled synthetic setting, we evaluate it on two realistic benchmarks: a multitask version of the cifar-100 image classification dataset and a large-scale multilingual language modeling experiment. our empirical results show that l-dro achieves a better trade-off between average and worst-case accuracy with little computational overhead compared to several strong baselines. ","1805":"parsing spoken dialogue poses unique difficulties, including disfluencies and unmarked boundaries between sentence-like units. previous work has shown that prosody can help with parsing disfluent speech (tran et al. 2018), but has assumed that the input to the parser is already segmented into sentence-like units (sus), which isn't true in existing speech applications. we investigate how prosody affects a parser that receives an entire dialogue turn as input (a turn-based model), instead of gold standard pre-segmented sus (an su-based model). in experiments on the english switchboard corpus, we find that when using transcripts alone, the turn-based model has trouble segmenting sus, leading to worse parse performance than the su-based model. however, prosody can effectively replace gold standard su boundaries: with prosody, the turn-based model performs as well as the su-based model (90.79 vs. 90.65 f1 score, respectively), despite performing two tasks (su segmentation and parsing) rather than one (parsing alone). analysis shows that pitch and intensity features are the most important for this corpus, since they allow the model to correctly distinguish an su boundary from a speech disfluency -- a distinction that the model otherwise struggles to make. ","1806":"this work demonstrates that using the objective with independence assumption for modelling the span probability $p(a_s,a_e) = p(a_s)p(a_e)$ of span starting at position $a_s$ and ending at position $a_e$ has adverse effects. therefore we propose multiple approaches to modelling joint probability $p(a_s,a_e)$ directly. among those, we propose a compound objective, composed from the joint probability while still keeping the objective with independence assumption as an auxiliary objective. we find that the compound objective is consistently superior or equal to other assumptions in exact match. additionally, we identified common errors caused by the assumption of independence and manually checked the counterpart predictions, demonstrating the impact of the compound objective on the real examples. our findings are supported via experiments with three extractive qa models (bidaf, bert, albert) over six datasets and our code, individual results and manual analysis are available online. ","1807":"dialog is a core building block of human natural language interactions. it contains multi-party utterances used to convey information from one party to another in a dynamic and evolving manner. the ability to compare dialogs is beneficial in many real world use cases, such as conversation analytics for contact center calls and virtual agent design.   we propose a novel adaptation of the edit distance metric to the scenario of dialog similarity. our approach takes into account various conversation aspects such as utterance semantics, conversation flow, and the participants. we evaluate this new approach and compare it to existing document similarity measures on two publicly available datasets. the results demonstrate that our method outperforms the other approaches in capturing dialog flow, and is better aligned with the human perception of conversation similarity. ","1808":"we adopt an evolutionary view on language change in which cognitive factors (in addition to social ones) affect the fitness of words and their success in the linguistic ecosystem. specifically, we propose a variety of psycholinguistic factors -- semantic, distributional, and phonological -- that we hypothesize are predictive of lexical decline, in which words greatly decrease in frequency over time. using historical data across three languages (english, french, and german), we find that most of our proposed factors show a significant difference in the expected direction between each curated set of declining words and their matched stable words. moreover, logistic regression analyses show that semantic and distributional factors are significant in predicting declining words. further diachronic analysis reveals that declining words tend to decrease in the diversity of their lexical contexts over time, gradually narrowing their 'ecological niches'. ","1809":"training machines to understand natural language and interact with humans is an elusive and essential task of artificial intelligence. a diversity of dialogue systems has been designed with the rapid development of deep learning techniques, especially the recent pre-trained language models (prlms). among these studies, the fundamental yet challenging type of task is dialogue comprehension whose role is to teach the machines to read and comprehend the dialogue context before responding. in this paper, we review the previous methods from the technical perspective of dialogue modeling for the dialogue comprehension task. we summarize the characteristics and challenges of dialogue comprehension in contrast to plain-text reading comprehension. then, we discuss three typical patterns of dialogue modeling. in addition, we categorize dialogue-related pre-training techniques which are employed to enhance prlms in dialogue scenarios. finally, we highlight the technical advances in recent years and point out the lessons from the empirical analysis and the prospects towards a new frontier of researches. ","1810":"training machines to understand natural language and interact with humans is an elusive and essential task of artificial intelligence. a diversity of dialogue systems has been designed with the rapid development of deep learning techniques, especially the recent pre-trained language models (prlms). among these studies, the fundamental yet challenging type of task is dialogue comprehension whose role is to teach the machines to read and comprehend the dialogue context before responding. in this paper, we review the previous methods from the technical perspective of dialogue modeling for the dialogue comprehension task. we summarize the characteristics and challenges of dialogue comprehension in contrast to plain-text reading comprehension. then, we discuss three typical patterns of dialogue modeling. in addition, we categorize dialogue-related pre-training techniques which are employed to enhance prlms in dialogue scenarios. finally, we highlight the technical advances in recent years and point out the lessons from the empirical analysis and the prospects towards a new frontier of researches. ","1811":"self-supervised learning (ssl) is a long-standing goal for speech processing, since it utilizes large-scale unlabeled data and avoids extensive human labeling. recent years witness great successes in applying self-supervised learning in speech recognition, while limited exploration was attempted in applying ssl for modeling speaker characteristics. in this paper, we aim to improve the existing ssl framework for speaker representation learning. two methods are introduced for enhancing the unsupervised speaker information extraction. first, we apply the multi-task learning to the current ssl framework, where we integrate the utterance-wise contrastive loss with the ssl objective function. second, for better speaker discrimination, we propose an utterance mixing strategy for data augmentation, where additional overlapped utterances are created unsupervisely and incorporate during training. we integrate the proposed methods into the hubert framework. experiment results on superb benchmark show that the proposed system achieves state-of-the-art performance in universal representation learning, especially for speaker identification oriented tasks. an ablation study is performed verifying the efficacy of each proposed method. finally, we scale up training dataset to 94 thousand hours public audio data and achieve further performance improvement in all superb tasks. ","1812":"sports game summarization aims to generate news articles from live text commentaries. a recent state-of-the-art work, sportssum, not only constructs a large benchmark dataset, but also proposes a two-step framework. despite its great contributions, the work has three main drawbacks: 1) the noise existed in sportssum dataset degrades the summarization performance; 2) the neglect of lexical overlap between news and commentaries results in low-quality pseudo-labeling algorithm; 3) the usage of directly concatenating rewritten sentences to form news limits its practicability. in this paper, we publish a new benchmark dataset sportssum2.0, together with a modified summarization framework. in particular, to obtain a clean dataset, we employ crowd workers to manually clean the original dataset. moreover, the degree of lexical overlap is incorporated into the generation of pseudo labels. further, we introduce a reranker-enhanced summarizer to take into account the fluency and expressiveness of the summarized news. extensive experiments show that our model outperforms the state-of-the-art baseline. ","1813":"sota coreference resolution produces increasingly impressive scores on the ontonotes benchmark. however lack of comparable data following the same scheme for more genres makes it difficult to evaluate generalizability to open domain data. zhu et al. (2021) introduced the creation of the ontogum corpus for evaluating geralizability of the latest neural lm-based end-to-end systems. this paper covers details of the mapping process which is a set of deterministic rules applied to the rich syntactic and discourse annotations manually annotated in the gum corpus. out-of-domain evaluation across 12 genres shows nearly 15-20% degradation for both deterministic and deep learning systems, indicating a lack of generalizability or covert overfitting in existing coreference resolution models. ","1814":"this work presents a supervised method for generating a classifier model of the stances held by chinese-speaking politicians and other twitter users. many previous works of political tweets prediction exist on english tweets, but to the best of our knowledge, this is the first work that builds prediction model on chinese political tweets. it firstly collects data by scraping tweets of famous political figure and their related users. it secondly defines the political spectrum in two groups: the group that shows approvals to the chinese communist party and the group that does not. since there are not space between words in chinese to identify the independent words, it then completes segmentation and vectorization by jieba, a chinese segmentation tool. finally, it trains the data collected from political tweets and produce a classification model with high accuracy for understanding users' political stances from their tweets on twitter. ","1815":"majority voting and averaging are common approaches employed to resolve annotator disagreements and derive single ground truth labels from multiple annotations. however, annotators may systematically disagree with one another, often reflecting their individual biases and values, especially in the case of subjective tasks such as detecting affect, aggression, and hate speech. annotator disagreements may capture important nuances in such tasks that are often ignored while aggregating annotations to a single ground truth. in order to address this, we investigate the efficacy of multi-annotator models. in particular, our multi-task based approach treats predicting each annotators' judgements as separate subtasks, while sharing a common learned representation of the task. we show that this approach yields same or better performance than aggregating labels in the data prior to training across seven different binary classification tasks. our approach also provides a way to estimate uncertainty in predictions, which we demonstrate better correlate with annotation disagreements than traditional methods. being able to model uncertainty is especially useful in deployment scenarios where knowing when not to make a prediction is important. ","1816":"the task of learning from only a few examples (called a few-shot setting) is of key importance and relevance to a real-world setting. for question answering (qa), the current state-of-the-art pre-trained models typically need fine-tuning on tens of thousands of examples to obtain good results. their performance degrades significantly in a few-shot setting (< 100 examples). to address this, we propose a simple fine-tuning framework that leverages pre-trained text-to-text models and is directly aligned with their pre-training framework. specifically, we construct the input as a concatenation of the question, a mask token representing the answer span and a context. given this input, the model is fine-tuned using the same objective as that of its pre-training objective. through experimental studies on various few-shot configurations, we show that this formulation leads to significant gains on multiple qa benchmarks (an absolute gain of 34.2 f1 points on average when there are only 16 training examples). the gains extend further when used with larger models (eg:- 72.3 f1 on squad using bart-large with only 32 examples) and translate well to a multilingual setting . on the multilingual tydiqa benchmark, our model outperforms the xlm-roberta-large by an absolute margin of upto 40 f1 points and an average of 33 f1 points in a few-shot setting (<= 64 training examples). we conduct detailed ablation studies to analyze factors contributing to these gains. ","1817":"a common practice in building nlp datasets, especially using crowd-sourced annotations, involves obtaining multiple annotator judgements on the same data instances, which are then flattened to produce a single \"ground truth\" label or score, through majority voting, averaging, or adjudication. while these approaches may be appropriate in certain annotation tasks, such aggregations overlook the socially constructed nature of human perceptions that annotations for relatively more subjective tasks are meant to capture. in particular, systematic disagreements between annotators owing to their socio-cultural backgrounds and\/or lived experiences are often obfuscated through such aggregations. in this paper, we empirically demonstrate that label aggregation may introduce representational biases of individual and group perspectives. based on this finding, we propose a set of recommendations for increased utility and transparency of datasets for downstream use cases. ","1818":"recent work like gpt-3 has demonstrated excellent performance of zero-shot and few-shot learning on many natural language processing (nlp) tasks by scaling up model size, dataset size and the amount of computation. however, training a model like gpt-3 requires huge amount of computational resources which makes it challengeable to researchers. in this work, we propose a method that incorporates large-scale distributed training performance into model architecture design. with this method, yuan 1.0, the current largest singleton language model with 245b parameters, achieves excellent performance on thousands gpus during training, and the state-of-the-art results on nlp tasks. a data processing method is designed to efficiently filter massive amount of raw data. the current largest high-quality chinese corpus with 5tb high quality texts is built based on this method. in addition, a calibration and label expansion method is proposed to improve the zero-shot and few-shot performance, and steady improvement is observed on the accuracy of various tasks. yuan 1.0 presents strong capacity of natural language generation, and the generated articles are difficult to distinguish from the human-written ones. ","1819":"neural machine translation (nmt) models are known to suffer from noisy inputs. to make models robust, we generate adversarial augmentation samples that attack the model and preserve the source-side semantic meaning at the same time. to generate such samples, we propose a doubly-trained architecture that pairs two nmt models of opposite translation directions with a joint loss function, which combines the target-side attack and the source-side semantic similarity constraint. the results from our experiments across three different language pairs and two evaluation metrics show that these adversarial samples improve the model robustness. ","1820":"differentially private (dp) learning has seen limited success for building large deep learning models of text, and attempts at straightforwardly applying differentially private stochastic gradient descent (dp-sgd) to nlp tasks have resulted in large performance drops and high computational overhead. we show that this performance drop can be mitigated with (1) the use of large pretrained models; (2) hyperparameters that suit dp optimization; and (3) fine-tuning objectives aligned with the pretraining procedure. with these factors set right, we obtain private nlp models that outperform state-of-the-art private training approaches and strong non-private baselines -- by directly fine-tuning pretrained models with dp optimization on moderately-sized corpora. to address the computational challenge of running dp-sgd with large transformers, we propose a memory saving technique that allows clipping in dp-sgd to run without instantiating per-example gradients for any layer in the model. the technique enables privately training transformers with almost the same memory cost as non-private training at a modest run-time overhead. contrary to conventional wisdom that dp optimization fails at learning high-dimensional models (due to noise that scales with dimension) empirical results reveal that private learning with pretrained models tends to not suffer from dimension-dependent performance degradation. ","1821":"alfred is a recently proposed benchmark that requires a model to complete tasks in simulated house environments specified by instructions in natural language. we hypothesize that key to success is accurately aligning the text modality with visual inputs. motivated by this, we inspect how well existing models can align these modalities using our proposed intrinsic metric, boundary adherence score (bas). the results show the previous models are indeed failing to perform proper alignment. to address this issue, we introduce approaches aimed at improving model alignment and demonstrate how improved alignment, improves end task performance. ","1822":"multi-modal reasoning systems rely on a pre-trained object detector to extract regions of interest from the image. however, this crucial module is typically used as a black box, trained independently of the downstream task and on a fixed vocabulary of objects and attributes. this makes it challenging for such systems to capture the long tail of visual concepts expressed in free form text. in this paper we propose mdetr, an end-to-end modulated detector that detects objects in an image conditioned on a raw text query, like a caption or a question. we use a transformer-based architecture to reason jointly over text and image by fusing the two modalities at an early stage of the model. we pre-train the network on 1.3m text-image pairs, mined from pre-existing multi-modal datasets having explicit alignment between phrases in text and objects in the image. we then fine-tune on several downstream tasks such as phrase grounding, referring expression comprehension and segmentation, achieving state-of-the-art results on popular benchmarks. we also investigate the utility of our model as an object detector on a given label set when fine-tuned in a few-shot setting. we show that our pre-training approach provides a way to handle the long tail of object categories which have very few labelled instances. our approach can be easily extended for visual question answering, achieving competitive performance on gqa and clevr. the code and models are available at https:\/\/github.com\/ashkamath\/mdetr. ","1823":"this paper measures the impact of increased exposure on whether learned construction grammars converge onto shared representations when trained on data from different registers. register influences the frequency of constructions, with some structures common in formal but not informal usage. we expect that a grammar induction algorithm exposed to different registers will acquire different constructions. to what degree does increased exposure lead to the convergence of register-specific grammars? the experiments in this paper simulate language learning in 12 languages (half germanic and half romance) with corpora representing three registers (twitter, wikipedia, web). these simulations are repeated with increasing amounts of exposure, from 100k to 2 million words, to measure the impact of exposure on the convergence of grammars. the results show that increased exposure does lead to converging grammars across all languages. in addition, a shared core of register-universal constructions remains constant across increasing amounts of exposure. ","1824":"the task of generating rich and fluent narratives that aptly describe the characteristics, trends, and anomalies of time-series data is invaluable to the sciences (geology, meteorology, epidemiology) or finance (trades, stocks, or sales and inventory). the efforts for time-series narration hitherto are domain-specific and use predefined templates that offer consistency but lead to mechanical narratives. we present tcube (time-series-to-text), a domain-agnostic neural framework for time-series narration, that couples the representation of essential time-series elements in the form of a dense knowledge graph and the translation of said knowledge graph into rich and fluent narratives through the transfer-learning capabilities of plms (pre-trained language models). tcube's design primarily addresses the challenge that lies in building a neural framework in the complete paucity of annotated training data for time-series. the design incorporates knowledge graphs as an intermediary for the representation of essential time-series elements which can be linearized for textual translation. to the best of our knowledge, tcube is the first investigation of the use of neural strategies for time-series narration. through extensive evaluations, we show that tcube can improve the lexical diversity of the generated narratives by up to 65.38% while still maintaining grammatical integrity. the practicality and deployability of tcube is further validated through an expert review (n=21) where 76.2% of participating experts wary of auto-generated narratives favored tcube as a deployable system for time-series narration due to its richer narratives. our code-base, models, and datasets, with detailed instructions for reproducibility is publicly hosted at https:\/\/github.com\/mandar-sharma\/tcube. ","1825":"public transport agencies use social media as an essential tool for communicating mobility incidents to passengers. however, while the short term, day-to-day information about transport phenomena is usually posted in social media with low latency, its availability is short term as the content is rarely made an aggregated form. social media communication of transport phenomena usually lacks gis annotations as most social media platforms do not allow attaching non-poi gps coordinates to posts. as a result, the analysis of transport phenomena information is minimal. we collected three years of social media posts of a polish public transport company with user comments. through exploration, we infer a six-class transport information typology. we successfully build an information type classifier for social media posts, detect stop names in posts, and relate them to gps coordinates, obtaining a spatial understanding of long-term aggregated phenomena. we show that our approach enables citizen science and use it to analyze the impact of three years of infrastructure incidents on passenger mobility, and the sentiment and reaction scale towards each of the events. all these results are achieved for polish, an under-resourced language when it comes to spatial language understanding, especially in social media contexts. to improve the situation, we released two of our annotated data sets: social media posts with incident type labels and matched stop names and social media comments with the annotated sentiment. we also opensource the experimental codebase. ","1826":"the transformer architecture has been well adopted as a dominant architecture in most sequence transduction tasks including automatic speech recognition (asr), since its attention mechanism excels in capturing long-range dependencies. while models built solely upon attention can be better parallelized than regular rnn, a novel network architecture, sru++, was recently proposed. by combining the fast recurrence and attention mechanism, sru++ exhibits strong capability in sequence modeling and achieves near-state-of-the-art results in various language modeling and machine translation tasks with improved compute efficiency. in this work, we present the advantages of applying sru++ in asr tasks by comparing with conformer across multiple asr benchmarks and study how the benefits can be generalized to long-form speech inputs. on the popular librispeech benchmark, our sru++ model achieves 2.0% \/ 4.7% wer on test-clean \/ test-other, showing competitive performances compared with the state-of-the-art conformer encoder under the same set-up. specifically, sru++ can surpass conformer on long-form speech input with a large margin, based on our analysis. ","1827":"in this paper, we identify the state of data as being an important reason for failure in applied natural language processing (nlp) projects. we argue that there is a gap between academic research in nlp and its application to problems outside academia, and that this gap is rooted in poor mutual understanding between academic researchers and their non-academic peers who seek to apply research results to their operations. to foster transfer of research results from academia to non-academic settings, and the corresponding influx of requirements back to academia, we propose a method for improving the communication between researchers and external stakeholders regarding the accessibility, validity, and utility of data based on data readiness levels \\cite{lawrence2017data}. while still in its infancy, the method has been iterated on and applied in multiple innovation and research projects carried out with stakeholders in both the private and public sectors. finally, we invite researchers and practitioners to share their experiences, and thus contributing to a body of work aimed at raising awareness of the importance of data readiness for nlp. ","1828":"recently neural response generation models have leveraged large pre-trained transformer models and knowledge snippets to generate relevant and informative responses. however, this does not guarantee that generated responses are factually correct. in this paper, we examine factual correctness in knowledge-grounded neural response generation models. we present a human annotation setup to identify three different response types: responses that are factually consistent with respect to the input knowledge, responses that contain hallucinated knowledge, and non-verifiable chitchat style responses. we use this setup to annotate responses generated using different stateof-the-art models, knowledge snippets, and decoding strategies. in addition, to facilitate the development of a factual consistency detector, we automatically create a new corpus called conv-fever that is adapted from the wizard of wikipedia dataset and includes factually consistent and inconsistent responses. we demonstrate the benefit of our conv-fever dataset by showing that the models trained on this data perform reasonably well to detect factually inconsistent responses with respect to the provided knowledge through evaluation on our human annotated data. we will release the conv-fever dataset and the human annotated responses. ","1829":"we show how to derive state-of-the-art unsupervised neural machine translation systems from generatively pre-trained language models. our method consists of three steps: few-shot amplification, distillation, and backtranslation. we first use the zero-shot translation ability of large pre-trained language models to generate translations for a small set of unlabeled sentences. we then amplify these zero-shot translations by using them as few-shot demonstrations for sampling a larger synthetic dataset. this dataset is distilled by discarding the few-shot demonstrations and then fine-tuning. during backtranslation, we repeatedly generate translations for a set of inputs and then fine-tune a single language model on both directions of the translation task at once, ensuring cycle-consistency by swapping the roles of gold monotext and generated translations when fine-tuning. by using our method to leverage gpt-3's zero-shot translation capability, we achieve a new state-of-the-art in unsupervised translation on the wmt14 english-french benchmark, attaining a bleu score of 42.1. ","1830":"translating source code from one programming language to another is a critical, time-consuming task in modernizing legacy applications and codebases. recent work in this space has drawn inspiration from the software naturalness hypothesis by applying natural language processing techniques towards automating the code translation task. however, due to the paucity of parallel data in this domain, supervised techniques have only been applied to a limited set of popular programming languages. to bypass this limitation, unsupervised neural machine translation techniques have been proposed to learn code translation using only monolingual corpora. in this work, we propose to use document similarity methods to create noisy parallel datasets of code, thus enabling supervised techniques to be applied for automated code translation without having to rely on the availability or expensive curation of parallel code datasets. we explore the noise tolerance of models trained on such automatically-created datasets and show that these models perform comparably to models trained on ground truth for reasonable levels of noise. finally, we exhibit the practical utility of the proposed method by creating parallel datasets for languages beyond the ones explored in prior work, thus expanding the set of programming languages for automated code translation. ","1831":"to be good conversational partners, natural language processing (nlp) systems should be trained to produce contextually useful utterances. prior work has investigated training nlp systems with communication-based objectives, where a neural listener stands in as a communication partner. however, these systems commonly suffer from semantic drift where the learned language diverges radically from natural language. we propose a method that uses a population of neural listeners to regularize speaker training. we first show that language drift originates from the poor uncertainty calibration of a neural listener, which makes high-certainty predictions on novel sentences. we explore ensemble- and dropout-based populations of listeners and find that the former results in better uncertainty quantification. we evaluate both population-based objectives on reference games, and show that the ensemble method with better calibration enables the speaker to generate pragmatic utterances while scaling to a large vocabulary and generalizing to new games and listeners. ","1832":"in this paper, a bert based neural network model is applied to the jigsaw data set in order to create a model identifying hateful and toxic comments (strictly seperated from offensive language) in online social platforms (english language), in this case twitter. three other neural network architectures and a gpt-2 model are also applied on the provided data set in order to compare these different models. the trained bert model is then applied on two different data sets to evaluate its generalisation power, namely on another twitter data set and the data set hasoc 2019 which includes twitter and also facebook comments; we focus on the english hasoc 2019 data. in addition, it can be shown that by fine-tuning the trained bert model on these two data sets by applying different transfer learning scenarios via retraining partial or all layers the predictive scores improve compared to simply applying the model pre-trained on the jigsaw data set. with our results, we get precisions from 64% to around 90% while still achieving acceptable recall values of at least lower 60s%, proving that bert is suitable for real use cases in social platforms. ","1833":"measuring automatic speech recognition (asr) system quality is critical for creating user-satisfying voice-driven applications. word error rate (wer) has been traditionally used to evaluate asr system quality; however, it sometimes correlates poorly with user perception of transcription quality. this is because wer weighs every word equally and does not consider semantic correctness which has a higher impact on user perception. in this work, we propose evaluating asr output hypotheses quality with semdist that can measure semantic correctness by using the distance between the semantic vectors of the reference and hypothesis extracted from a pre-trained language model. our experimental results of 71k and 36k user annotated asr output quality show that semdist achieves higher correlation with user perception than wer. we also show that semdist has higher correlation with downstream nlu tasks than wer. ","1834":"misleading or false information has been creating chaos in some places around the world. to mitigate this issue, many researchers have proposed automated fact-checking methods to fight the spread of fake news. however, most methods cannot explain the reasoning behind their decisions, failing to build trust between machines and humans using such technology. trust is essential for fact-checking to be applied in the real world. here, we address fact-checking explainability through question answering. in particular, we propose generating questions and answers from claims and answering the same questions from evidence. we also propose an answer comparison model with an attention mechanism attached to each question. leveraging question answering as a proxy, we break down automated fact-checking into several steps -- this separation aids models' explainability as it allows for more detailed analysis of their decision-making processes. experimental results show that the proposed model can achieve state-of-the-art performance while providing reasonable explainable capabilities. ","1835":"although pre-trained language models, such as bert, achieve state-of-art performance in many language understanding tasks, they have been demonstrated to inherit strong gender bias from its training data. existing studies addressing the gender bias issue of pre-trained models, usually recollect and build gender-neutral data on their own and conduct a second phase pre-training on the released pre-trained model with such data. however, given the limited size of the gender-neutral data and its potential distributional mismatch with the original pre-training data, catastrophic forgetting would occur during the second-phase pre-training. forgetting on the original training data may damage the model's downstream performance to a large margin. in this work, we first empirically show that even if the gender-neutral data for second-phase pre-training comes from the original training data, catastrophic forgetting still occurs if the size of gender-neutral data is smaller than that of original training data. then, we propose a new method, gender equality prompt (geep), to improve gender fairness of pre-trained models without forgetting. geep learns gender-related prompts to reduce gender bias, conditioned on frozen language models. since all pre-trained parameters are frozen, forgetting on information from the original training data can be alleviated to the most extent. then geep trains new embeddings of profession names as gender equality prompts conditioned on the frozen model. empirical results show that geep not only achieves state-of-the-art performances on gender debiasing in various applications such as pronoun predicting and coreference resolution, but also achieves comparable results on general downstream tasks such as glue with original pre-trained models without much forgetting. ","1836":"performing event and entity coreference resolution across documents vastly increases the number of candidate mentions, making it intractable to do the full $n^2$ pairwise comparisons. existing approaches simplify by considering coreference only within document clusters, but this fails to handle inter-cluster coreference, common in many applications. as a result cross-document coreference algorithms are rarely applied to downstream tasks. we draw on an insight from discourse coherence theory: potential coreferences are constrained by the reader's discourse focus. we model the entities\/events in a reader's focus as a neighborhood within a learned latent embedding space which minimizes the distance between mentions and the centroids of their gold coreference clusters. we then use these neighborhoods to sample only hard negatives to train a fine-grained classifier on mention pairs and their local discourse features. our approach achieves state-of-the-art results for both events and entities on the ecb+, gun violence, football coreference, and cross-domain cross-document coreference corpora. furthermore, training on multiple corpora improves average performance across all datasets by 17.2 f1 points, leading to a robust coreference resolution model for use in downstream tasks where link distribution is unknown. ","1837":"language is an interface to the outside world. in order for embodied agents to use it, language must be grounded in other, sensorimotor modalities. while there is an extended literature studying how machines can learn grounded language, the topic of how to learn spatio-temporal linguistic concepts is still largely uncharted. to make progress in this direction, we here introduce a novel spatio-temporal language grounding task where the goal is to learn the meaning of spatio-temporal descriptions of behavioral traces of an embodied agent. this is achieved by training a truth function that predicts if a description matches a given history of observations. the descriptions involve time-extended predicates in past and present tense as well as spatio-temporal references to objects in the scene. to study the role of architectural biases in this task, we train several models including multimodal transformer architectures; the latter implement different attention computations between words and objects across space and time. we test models on two classes of generalization: 1) generalization to randomly held-out sentences; 2) generalization to grammar primitives. we observe that maintaining object identity in the attention computation of our transformers is instrumental to achieving good performance on generalization overall, and that summarizing object traces in a single token has little influence on performance. we then discuss how this opens new perspectives for language-guided autonomous embodied agents. we also release our code under open-source license as well as pretrained models and datasets to encourage the wider community to build upon and extend our work in the future. ","1838":"despite the success of pretrained masked language models (mlm), why mlm pretraining is useful is still a qeustion not fully answered. in this work we theoretically and empirically show that mlm pretraining makes models robust to lexicon-level spurious features, partly answer the question. we theoretically show that, when we can model the distribution of a spurious feature $\\pi$ conditioned on the context, then (1) $\\pi$ is at least as informative as the spurious feature, and (2) learning from $\\pi$ is at least as simple as learning from the spurious feature. therefore, mlm pretraining rescues the model from the simplicity bias caused by the spurious feature. we also explore the efficacy of mlm pretraing in causal settings. finally we close the gap between our theories and the real world practices by conducting experiments on the hate speech detection and the name entity recognition tasks. ","1839":"the complete freedom of expression in social media has its costs especially in spreading harmful and abusive content that may induce people to act accordingly. therefore, the need of detecting automatically such a content becomes an urgent task that will help and enhance the efficiency in limiting this toxic spread. compared to other arabic dialects which are mostly based on msa, the tunisian dialect is a combination of many other languages like msa, tamazight, italian and french. because of its rich language, dealing with nlp problems can be challenging due to the lack of large annotated datasets. in this paper we are introducing a new annotated dataset composed of approximately 10k of comments. we provide an in-depth exploration of its vocabulary through feature engineering approaches as well as the results of the classification performance of machine learning classifiers like nb and svm and deep learning models such as arbert, marbert and xlm-r. ","1840":"non-autoregressive (nar) models simultaneously generate multiple outputs in a sequence, which significantly reduces the inference speed at the cost of accuracy drop compared to autoregressive baselines. showing great potential for real-time applications, an increasing number of nar models have been explored in different fields to mitigate the performance gap against ar models. in this work, we conduct a comparative study of various nar modeling methods for end-to-end automatic speech recognition (asr). experiments are performed in the state-of-the-art setting using espnet. the results on various tasks provide interesting findings for developing an understanding of nar asr, such as the accuracy-speed trade-off and robustness against long-form utterances. we also show that the techniques can be combined for further improvement and applied to nar end-to-end speech translation. all the implementations are publicly available to encourage further research in nar speech processing. ","1841":"task-oriented dialogue systems have been a promising area in the nlp field. previous work showed the effectiveness of using a single gpt-2 based model to predict belief states and responses via causal language modeling. in this paper, we leverage multi-task learning techniques to train a gpt-2 based model on a more challenging dataset with multiple domains, multiple modalities, and more diversity in output formats.   using only a single model, our method achieves better performance on all sub-tasks, across domains, compared to task and domain-specific models. furthermore, we evaluated several proposed strategies for gpt-2 based dialogue systems with comprehensive ablation studies, showing that all techniques can further improve the performance. ","1842":"most existing simultaneous machine translation (simt) systems are trained and evaluated on offline translation corpora. we argue that simt systems should be trained and tested on real interpretation data. to illustrate this argument, we propose an interpretation test set and conduct a realistic evaluation of simt trained on offline translations. our results, on our test set along with 3 existing smaller scale language pairs, highlight the difference of up-to 13.83 bleu score when simt models are evaluated on translation vs interpretation data. in the absence of interpretation training data, we propose a translation-to-interpretation (t2i) style transfer method which allows converting existing offline translations into interpretation-style data, leading to up-to 2.8 bleu improvement. however, the evaluation gap remains notable, calling for constructing large-scale interpretation corpora better suited for evaluating and developing simt systems. ","1843":"wav2vec 2.0 is an end-to-end framework of self-supervised learning for speech representation that is successful in automatic speech recognition (asr), but most of the work on the topic has been developed with a single language: english. therefore, it is unclear whether the self-supervised framework is effective in recognizing other languages with different writing systems, such as korean which uses the hangul having a unique writing system. in this paper, we present k-wav2vec 2.0, which is a modified version of wav2vec 2.0 designed for korean automatic speech recognition by exploring and optimizing various factors of the original wav2vec 2.0. in fine-tuning, we propose a multi-task hierarchical architecture to reflect the korean writing structure. moreover, a joint decoder is applied to alleviate the problem of words existing outside of the vocabulary. in pre-training, we attempted the cross-lingual transfer of the pre-trained model by further pre-training the english wav2vec 2.0 on a korean dataset, considering limited resources. our experimental results demonstrate that the proposed method yields the best performance on both korean asr datasets: ksponspeech (a large-scale korean speech corpus) and clovacall (a call-based dialog corpus). further pre-training is also effective in language adaptation, leading to large improvements without additional data. ","1844":"recent weak supervision (ws) approaches have had widespread success in easing the bottleneck of labeling training data for machine learning by synthesizing labels from multiple potentially noisy supervision sources. however, proper measurement and analysis of these approaches remain a challenge. first, datasets used in existing works are often private and\/or custom, limiting standardization. second, ws datasets with the same name and base data often vary in terms of the labels and weak supervision sources used, a significant \"hidden\" source of evaluation variance. finally, ws studies often diverge in terms of the evaluation protocol and ablations used. to address these problems, we introduce a benchmark platform, wrench, for thorough and standardized evaluation of ws approaches. it consists of 22 varied real-world datasets for classification and sequence tagging; a range of real, synthetic, and procedurally-generated weak supervision sources; and a modular, extensible framework for ws evaluation, including implementations for popular ws methods. we use wrench to conduct extensive comparisons over more than 120 method variants to demonstrate its efficacy as a benchmark platform. the code is available at https:\/\/github.com\/jieyuz2\/wrench. ","1845":"research in sociology and linguistics shows that people use language not only to express their own identity but to understand the identity of others. recent work established a connection between expression of identity and emoji usage on social media, through use of emoji skin tone modifiers. motivated by that finding, this work asks if, as with language, readers are sensitive to such acts of self-expression and use them to understand the identity of authors. in behavioral experiments (n=488), where text and emoji content of social media posts were carefully controlled before being presented to participants, we find in the affirmative -- emoji are a salient signal of author identity. that signal is distinct from, and complementary to, the one encoded in language. participant groups (based on self-identified ethnicity) showed no differences in how they perceive this signal, except in the case of the default yellow emoji. while both groups associate this with a white identity, the effect was stronger in white participants. our finding that emoji can index social variables will have experimental applications for researchers but also implications for designers: supposedly ``neutral`` defaults may be more representative of some users than others. ","1846":"vaccine hesitancy and other covid-19-related concerns and complaints in the philippines are evident on social media. it is important to identify these different topics and sentiments in order to gauge public opinion, use the insights to develop policies, and make necessary adjustments or actions to improve public image and reputation of the administering agency and the covid-19 vaccines themselves. this paper proposes a semi-supervised machine learning pipeline to perform topic modeling, sentiment analysis, and an analysis of vaccine brand reputation to obtain an in-depth understanding of national public opinion of filipinos on facebook. the methodology makes use of a multilingual version of bidirectional encoder representations from transformers or bert for topic modeling, hierarchical clustering, five different classifiers for sentiment analysis, and cosine similarity of bert topic embeddings for vaccine brand reputation analysis. results suggest that any type of covid-19 misinformation is an emergent property of covid-19 public opinion, and that the detection of covid-19 misinformation can be an unsupervised task. sentiment analysis aided by hierarchical clustering reveal that 21 of the 25 topics extrapolated by topic modeling are negative topics. such negative comments spike in count whenever the department of health in the philippines posts about the covid-19 situation in other countries. additionally, the high numbers of laugh reactions on the facebook posts by the same agency -- without any humorous content -- suggest that the reactors of these posts tend to react the way they do, not because of what the posts are about but because of who posted them. ","1847":"attention is an increasingly popular mechanism used in a wide range of neural architectures. the mechanism itself has been realized in a variety of formats. however, because of the fast-paced advances in this domain, a systematic overview of attention is still missing. in this article, we define a unified model for attention architectures in natural language processing, with a focus on those designed to work with vector representations of the textual data. we propose a taxonomy of attention models according to four dimensions: the representation of the input, the compatibility function, the distribution function, and the multiplicity of the input and\/or output. we present the examples of how prior information can be exploited in attention models and discuss ongoing research efforts and open challenges in the area, providing the first extensive categorization of the vast body of literature in this exciting domain. ","1848":"this paper describes a novel study on using `attention mask' input in transformers and using this approach for detecting offensive content in both english and persian languages. the paper's principal focus is to suggest a methodology to enhance the performance of the bert-based models on the `offensive language detection' task. therefore, we customize attention probabilities by changing the `attention mask' input to create more efficacious word embeddings. to do this, we firstly tokenize the training set of the exploited datasets (by bert tokenizer). then, we apply multinomial naive bayes to map these tokens to two probabilities. these probabilities indicate the likelihood of making a text non-offensive or offensive, provided that it contains that token. afterwards, we use these probabilities to define a new term, namely offensive score. next, we create two separate (because of the differences in the types of the employed datasets) equations based on offensive scores for each language to re-distribute the `attention mask' input for paying more attention to more offensive phrases. eventually, we put the f1-macro score as our evaluation metric and fine-tune several combinations of bert with anns, cnns and rnns to examine the effect of using this methodology on various combinations. the results indicate that all models will enhance with this methodology. the most improvement was 2% and 10% for english and persian languages, respectively. ","1849":"certainty and uncertainty are fundamental to science communication. hedges have widely been used as proxies for uncertainty. however, certainty is a complex construct, with authors expressing not only the degree but the type and aspects of uncertainty in order to give the reader a certain impression of what is known. here, we introduce a new study of certainty that models both the level and the aspects of certainty in scientific findings. using a new dataset of 2167 annotated scientific findings, we demonstrate that hedges alone account for only a partial explanation of certainty. we show that both the overall certainty and individual aspects can be predicted with pre-trained language models, providing a more complete picture of the author's intended communication. downstream analyses on 431k scientific findings from news and scientific abstracts demonstrate that modeling sentence-level and aspect-level certainty is meaningful for areas like science communication. both the model and datasets used in this paper are released at https:\/\/blablablab.si.umich.edu\/projects\/certainty\/. ","1850":"coreference resolution is an important nlp task and most state-of-the-art methods rely on word embeddings for word representation. however, one issue that has been largely overlooked in literature is that of comparing the performance of different embeddings across and within families in this task. therefore, we frame our study in the context of event and entity coreference resolution (evcr & encr), and address two questions : 1) is there a trade-off between performance (predictive & run-time) and embedding size? 2) how do the embeddings' performance compare within and across families? our experiments reveal several interesting findings. first, we observe diminishing returns in performance with respect to embedding size. e.g. a model using solely a character embedding achieves 86% of the performance of the largest model (elmo, glove, character) while being 1.2% of its size. second, the larger model using multiple embeddings learns faster overall despite being slower per epoch. however, it is still slower at test time. finally, elmo performs best on both evcr and encr, while glove and fasttext perform best in evcr and encr respectively. ","1851":"online conversations can sometimes take a turn for the worse, either due to systematic cultural differences, accidental misunderstandings, or mere malice. automatically forecasting derailment in public online conversations provides an opportunity to take early action to moderate it. previous work in this space is limited, and we extend it in several ways. we apply a pretrained language encoder to the task, which outperforms earlier approaches. we further experiment with shifting the training paradigm for the task from a static to a dynamic one to increase the forecast horizon. this approach shows mixed results: in a high-quality data setting, a longer average forecast horizon can be achieved at the cost of a small drop in f1; in a low-quality data setting, however, dynamic training propagates the noise and is highly detrimental to performance. ","1852":"we present mlqe-pe, a new dataset for machine translation (mt) quality estimation (qe) and automatic post-editing (ape). the dataset contains eleven language pairs, with human labels for up to 10,000 translations per language pair in the following formats: sentence-level direct assessments and post-editing effort, and word-level good\/bad labels. it also contains the post-edited sentences, as well as titles of the articles where the sentences were extracted from, and the neural mt models used to translate the text. ","1853":"we introduce dense relational captioning, a novel image captioning task which aims to generate multiple captions with respect to relational information between objects in a visual scene. relational captioning provides explicit descriptions for each relationship between object combinations. this framework is advantageous in both diversity and amount of information, leading to a comprehensive image understanding based on relationships, e.g., relational proposal generation. for relational understanding between objects, the part-of-speech (pos; i.e., subject-object-predicate categories) can be a valuable prior information to guide the causal sequence of words in a caption. we enforce our framework to learn not only to generate captions but also to understand the pos of each word. to this end, we propose the multi-task triple-stream network (mttsnet) which consists of three recurrent units responsible for each pos which is trained by jointly predicting the correct captions and pos for each word. in addition, we found that the performance of mttsnet can be improved by modulating the object embeddings with an explicit relational module. we demonstrate that our proposed model can generate more diverse and richer captions, via extensive experimental analysis on large scale datasets and several metrics. then, we present applications of our framework to holistic image captioning, scene graph generation, and retrieval tasks. ","1854":"text simplification is a valuable technique. however, current research is limited to sentence simplification. in this paper, we define and investigate a new task of document-level text simplification, which aims to simplify a document consisting of multiple sentences. based on wikipedia dumps, we first construct a large-scale dataset named d-wikipedia and perform analysis and human evaluation on it to show that the dataset is reliable. then, we propose a new automatic evaluation metric called d-sari that is more suitable for the document-level simplification task. finally, we select several representative models as baseline models for this task and perform automatic evaluation and human evaluation. we analyze the results and point out the shortcomings of the baseline models. ","1855":"reputed by their low-cost, easy-access, real-time and valuable information, social media also wildly spread unverified or fake news. rumors can notably cause severe damage on individuals and the society. therefore, rumor detection on social media has recently attracted tremendous attention. most rumor detection approaches focus on rumor feature analysis and social features, i.e., metadata in social media. unfortunately, these features are data-specific and may not always be available, e.g., when the rumor has just popped up and not yet propagated. in contrast, post contents (including images or videos) play an important role and can indicate the diffusion purpose of a rumor. furthermore, rumor classification is also closely related to opinion mining and sentiment analysis. yet, to the best of our knowledge, exploiting images and sentiments is little investigated.considering the available multimodal features from microblogs, notably, we propose in this paper an end-to-end model called deepmonitor that is based on deep neural networks and allows quite accurate automated rumor verification, by utilizing all three characteristics: post textual and image contents, as well as sentiment. deepmonitor concatenates image features with the joint text and sentiment features to produce a reliable, fused classification. we conduct extensive experiments on two large-scale, real-world datasets. the results show that deepmonitor achieves a higher accuracy than state-of-the-art methods. ","1856":"societal ideas and trends dictate media narratives and cinematic depictions which in turn influences people's beliefs and perceptions of the real world. media portrayal of culture, education, government, religion, and family affect their function and evolution over time as people interpret and perceive these representations and incorporate them into their beliefs and actions. it is important to study media depictions of these social structures so that they do not propagate or reinforce negative stereotypes, or discriminate against any demographic section. in this work, we examine media representation of professions and provide computational insights into their incidence, and sentiment expressed, in entertainment media content. we create a searchable taxonomy of professional groups and titles to facilitate their retrieval from speaker-agnostic text passages like movie and television (tv) show subtitles. we leverage this taxonomy and relevant natural language processing (nlp) models to create a corpus of professional mentions in media content, spanning more than 136,000 imdb titles over seven decades (1950-2017). we analyze the frequency and sentiment trends of different occupations, study the effect of media attributes like genre, country of production, and title type on these trends, and investigate if the incidence of professions in media subtitles correlate with their real-world employment statistics. we observe increased media mentions of stem, arts, sports, and entertainment occupations in the analyzed subtitles, and a decreased frequency of manual labor jobs and military occupations. the sentiment expressed toward lawyers, police, and doctors is becoming negative over time, whereas astronauts, musicians, singers, and engineers are mentioned favorably. professions that employ more people have increased media frequency, supporting our hypothesis that media acts as a mirror to society. ","1857":"emotion recognition from text is a challenging task due to diverse emotion taxonomies, lack of reliable labeled data in different domains, and highly subjective annotation standards. few-shot and zero-shot techniques can generalize across unseen emotions by projecting the documents and emotion labels onto a shared embedding space. in this work, we explore the task of few-shot emotion recognition by transferring the knowledge gained from supervision on the goemotions reddit dataset to the semeval tweets corpus, using different emotion representation methods. the results show that knowledge transfer using external knowledge bases and fine-tuned encoders perform comparably as supervised baselines, requiring minimal supervision from the task dataset. ","1858":"developing an automatic part-of-speech (pos) tagging for any new language is considered a necessary step for further computational linguistics methodology beyond tagging, like chunking and parsing, to be fully applied to the language. many pos disambiguation technologies have been developed for this type of research and there are factors that influence the choice of choosing one. this could be either corpus-based or non-corpus-based. in this paper, we present a review of pos tagging technologies. ","1859":"the construction and application of knowledge graphs have seen a rapid increase across many disciplines in recent years. additionally, the problem of uncovering relationships between developments in the covid-19 pandemic and social media behavior is of great interest to researchers hoping to curb the spread of the disease. in this paper we present a knowledge graph constructed from covid-19 related tweets in the los angeles area, supplemented with federal and state policy announcements and disease spread statistics. by incorporating dates, topics, and events as entities, we construct a knowledge graph that describes the connections between these useful information. we use natural language processing and change point analysis to extract tweet-topic, tweet-date, and event-date relations. further analysis on the constructed knowledge graph provides insight into how tweets reflect public sentiments towards covid-19 related topics and how changes in these sentiments correlate with real-world events. ","1860":"open-domain question answering answers a question based on evidence retrieved from a large corpus. state-of-the-art neural approaches require intermediate evidence annotations for training. however, such intermediate annotations are expensive, and methods that rely on them cannot transfer to the more common setting, where only question-answer pairs are available. this paper investigates whether models can learn to find evidence from a large corpus, with only distant supervision from answer labels for model training, thereby generating no additional annotation cost. we introduce a novel approach (distdr) that iteratively improves over a weak retriever by alternately finding evidence from the up-to-date model and encouraging the model to learn the most likely evidence. without using any evidence labels, distdr is on par with fully-supervised state-of-the-art methods on both multi-hop and single-hop qa benchmarks. our analysis confirms that distdr finds more accurate evidence over iterations, which leads to model improvements. ","1861":"pre-trained language models (lms) have recently gained attention for their potential as an alternative to (or proxy for) explicit knowledge bases (kbs). in this position paper, we examine this hypothesis, identify strengths and limitations of both lms and kbs, and discuss the complementary nature of the two paradigms. in particular, we offer qualitative arguments that latent lms are not suitable as a substitute for explicit kbs, but could play a major role for augmenting and curating kbs. ","1862":"this paper provides a new approach for offensive language and hate speech detection on social media. our approach incorporates an offensive lexicon composed of implicit and explicit offensive and swearing expressions annotated with binary classes: context-dependent and context-independent offensive. due to the severity of the hate speech and offensive comments in brazil, and the lack of research in portuguese, brazilian portuguese is the language used to validate the proposed method. nevertheless, our proposal may be applied to any other language or domain. based on the obtained results, the proposed approach showed high-performance overcoming the current baselines for european and brazilian portuguese. ","1863":"classic information extraction techniques consist in building questions and answers about the facts. indeed, it is still a challenge to subjective information extraction systems to identify opinions and feelings in context. in sentiment-based nlp tasks, there are few resources to information extraction, above all offensive or hateful opinions in context. to fill this important gap, this short paper provides a new cross-lingual and contextual offensive lexicon, which consists of explicit and implicit offensive and swearing expressions of opinion, which were annotated in two different classes: context dependent and context-independent offensive. in addition, we provide markers to identify hate speech. annotation approach was evaluated at the expression-level and achieves high human inter-annotator agreement. the provided offensive lexicon is available in portuguese and english languages. ","1864":"typically, information extraction (ie) requires a pipeline approach: first, a sequence labeling model is trained on manually annotated documents to extract relevant spans; then, when a new document arrives, a model predicts spans which are then post-processed and standardized to convert the information into a database entry. we replace this labor-intensive workflow with a transformer language model trained on existing database records to directly generate structured json. our solution removes the workload associated with producing token-level annotations and takes advantage of a data source which is generally quite plentiful (e.g. database records). as long documents are common in information extraction tasks, we use gradient checkpointing and chunked encoding to apply our method to sequences of up to 32,000 tokens on a single gpu. our doc2dict approach is competitive with more complex, hand-engineered pipelines and offers a simple but effective baseline for document-level information extraction. we release our doc2dict model and code to reproduce our experiments and facilitate future work. ","1865":"the united nations identified gender equality as a sustainable development goal in 2015, recognizing the underrepresentation of women in politics as a specific barrier to achieving gender equality. political systems around the world experience gender inequality across all levels of elected government as fewer women run for office than men. this is due in part to online abuse, particularly on social media platforms like twitter, where women seeking or in power tend to be targeted with more toxic maltreatment than their male counterparts. in this paper, we present reflections on paritybot - the first natural language processing-based intervention designed to affect online discourse for women in politics for the better, at scale. deployed across elections in canada, the united states and new zealand, paritybot was used to analyse and classify more than 12 million tweets directed at women candidates and counter toxic tweets with supportive ones. from these elections we present three case studies highlighting the current limitations of, and future research and application opportunities for, using a natural language processing-based system to detect online toxicity, specifically with regards to contextually important microaggressions. we examine the rate of false negatives, where paritybot failed to pick up on insults directed at specific high profile women, which would be obvious to human users. we examine the unaddressed harms of microaggressions and the potential of yet unseen damage they cause for women in these communities, and for progress towards gender equality overall, in light of these technological blindspots. this work concludes with a discussion on the benefits of partnerships between nonprofit social groups and technology experts to develop responsible, socially impactful approaches to addressing online hate. ","1866":"representing text as graph to solve the summarization task has been discussed for more than 10 years. however, with the development of attention or transformer, the connection between attention and graph remains poorly understood. we demonstrate that the text structure can be analyzed through the attention matrix, which represents the relation between sentences by the attention weights. in this work, we show that the attention matrix produced in pre-training language model can be used as the adjacent matrix of graph convolutional network model. our model performs a competitive result on 2 different datasets based on the rouge index. also, with fewer parameters, the model reduces the computation resource when training and inferring. ","1867":"self-supervised model pre-training has recently garnered significant interest, but relatively few efforts have explored using additional resources in fine-tuning these models. we demonstrate how universal phoneset acoustic models can leverage cross-lingual supervision to improve transfer of pretrained self-supervised representations to new languages. we also show how target-language text can be used to enable and improve fine-tuning with the lattice-free maximum mutual information (lf-mmi) objective. in three low-resource languages these techniques greatly improved few-shot learning performance. ","1868":"the rise of internet has made it a major source of information. unfortunately, not all information online is true, and thus a number of fact-checking initiatives have been launched, both manual and automatic, to deal with the problem. here, we present our contribution in this regard: \\emph{whatthewikifact}, a system for automatic claim verification using wikipedia. the system can predict the veracity of an input claim, and it further shows the evidence it has retrieved as part of the verification process. it shows confidence scores and a list of relevant wikipedia articles, together with detailed information about each article, including the phrase used to retrieve it, the most relevant sentences extracted from it and their stance with respect to the input claim, as well as the associated probabilities. the system supports several languages: bulgarian, english, and russian. ","1869":"the use of contrastive loss for representation learning has become prominent in computer vision, and it is now getting attention in natural language processing (nlp). here, we explore the idea of using a batch-softmax contrastive loss when fine-tuning large-scale pre-trained transformer models to learn better task-specific sentence embeddings for pairwise sentence scoring tasks. we introduce and study a number of variations in the calculation of the loss as well as in the overall training procedure; in particular, we find that data shuffling can be quite important. our experimental results show sizable improvements on a number of datasets and pairwise sentence scoring tasks including classification, ranking, and regression. finally, we offer detailed analysis and discussion, which should be useful for researchers aiming to explore the utility of contrastive loss in nlp. ","1870":"the degree of semantic relatedness (or, closeness in meaning) of two units of language has long been considered fundamental to understanding meaning. automatically determining relatedness has many applications such as question answering and summarization. however, prior nlp work has largely focused on semantic similarity (a subset of relatedness), because of a lack of relatedness datasets. here for the first time, we introduce a dataset of semantic relatedness for sentence pairs. this dataset, str-2021, has 5,500 english sentence pairs manually annotated for semantic relatedness using a comparative annotation framework. we show that the resulting scores have high reliability (repeat annotation correlation of 0.84). we use the dataset to explore a number of questions on what makes two sentences more semantically related. we also evaluate a suite of sentence representation methods on their ability to place pairs that are more related closer to each other in vector space. ","1871":"multimodal abstractive summarization (mas) models that summarize videos (vision modality) and their corresponding transcripts (text modality) are able to extract the essential information from massive multimodal data on the internet. recently, large-scale generative pre-trained language models (gplms) have been shown to be effective in text generation tasks. however, existing mas models cannot leverage gplms' powerful generation ability. to fill this research gap, we aim to study two research questions: 1) how to inject visual information into gplms without hurting their generation ability; and 2) where is the optimal place in gplms to inject the visual information? in this paper, we present a simple yet effective method to construct vision guided (vg) gplms for the mas task using attention-based add-on layers to incorporate visual information while maintaining their original text generation ability. results show that our best model significantly surpasses the prior state-of-the-art model by 5.7 rouge-1, 5.3 rouge-2, and 5.1 rouge-l scores on the how2 dataset, and our visual guidance method contributes 83.6% of the overall improvement. furthermore, we conduct thorough ablation studies to analyze the effectiveness of various modality fusion methods and fusion locations. ","1872":"for each goal-oriented dialog task of interest, large amounts of data need to be collected for end-to-end learning of a neural dialog system. collecting that data is a costly and time-consuming process. instead, we show that we can use only a small amount of data, supplemented with data from a related dialog task. naively learning from related data fails to improve performance as the related data can be inconsistent with the target task. we describe a meta-learning based method that selectively learns from the related dialog task data. our approach leads to significant accuracy improvements in an example dialog task. ","1873":"in this paper, we propose dynamic compressive transformer (dct), a transformer-based framework for modeling the unbounded sequence. in contrast to the previous baselines which append every sentence representation to memory, conditionally selecting and appending them is a more reasonable solution to deal with unlimited long sequences. our model uses a policy that determines whether the sequence should be kept in memory with a compressed state or discarded during the training process. with the benefits of retaining semantically meaningful sentence information in the memory system, our experiment results on enwik8 benchmark show that dct outperforms the previous state-of-the-art (sota) model. ","1874":"automatic text generation has garnered growing attention in recent years as an essential step towards computer creativity. generative pretraining transformer 2 (gpt2) is one of the state of the art approaches that have excellent successes. in this paper, we took the first step to investigate the power of gpt2 in traditional vietnamese poetry generation. in the earlier time, our experiment with base gpt2 was quite good at generating the poem in the proper template. though it can learn the patterns, including rhyme and tone rules, from the training data, like almost all other text generation approaches, the poems generated still has a topic drift and semantic inconsistency. to improve the cohesion within the poems, we proposed a new model sp-gpt2 (semantic poem gpt2) which was built on the top gpt2 model and an additional loss to constrain context throughout the entire poem. for better evaluation, we examined the methods by both automatic quantitative evaluation and human evaluation. both automatic and human evaluation demonstrated that our approach can generate poems that have better cohesion without losing the quality due to additional loss. at the same time, we are the pioneers of this topic. we released the first computational scoring module for poems generated in the template containing the style rule dictionary. additionally, we are the first to publish a luc-bat dataset, including 87609 luc bat poems, which is equivalent to about 2.6 million sentences, combined with about 83579 poems in other styles was also published for further exploration. the code is available at https:\/\/github.com\/fsoft-ailab\/poem-generator ","1875":"aspect sentiment triplet extraction (aste) deals with extracting opinion triplets, consisting of an opinion target or aspect, its associated sentiment, and the corresponding opinion term\/span explaining the rationale behind the sentiment. existing research efforts are majorly tagging-based. among the methods taking a sequence tagging approach, some fail to capture the strong interdependence between the three opinion factors, whereas others fall short of identifying triplets with overlapping aspect\/opinion spans. a recent grid tagging approach on the other hand fails to capture the span-level semantics while predicting the sentiment between an aspect-opinion pair. different from these, we present a tagging-free solution for the task, while addressing the limitations of the existing works. we adapt an encoder-decoder architecture with a pointer network-based decoding framework that generates an entire opinion triplet at each time step thereby making our solution end-to-end. interactions between the aspects and opinions are effectively captured by the decoder by considering their entire detected spans while predicting their connecting sentiment. extensive experiments on several benchmark datasets establish the better efficacy of our proposed approach, especially in the recall, and in predicting multiple and aspect\/opinion-overlapped triplets from the same review sentence. we report our results both with and without bert and also demonstrate the utility of domain-specific bert post-training for the task. ","1876":"multi-hop question answering (qa) is a challenging task because it requires precise reasoning with entity relations at every step towards the answer. the relations can be represented in terms of labels in knowledge graph (e.g., \\textit{spouse}) or text in text corpus (e.g., \\textit{they have been married for 26 years}). existing models usually infer the answer by predicting the sequential relation path or aggregating the hidden graph features. the former is hard to optimize, and the latter lacks interpretability. in this paper, we propose transfernet, an effective and transparent model for multi-hop qa, which supports both label and text relations in a unified framework. transfernet jumps across entities at multiple steps. at each step, it attends to different parts of the question, computes activated scores for relations, and then transfer the previous entity scores along activated relations in a differentiable way. we carry out extensive experiments on three datasets and demonstrate that transfernet surpasses the state-of-the-art models by a large margin. in particular, on metaqa, it achieves 100\\% accuracy in 2-hop and 3-hop questions. by qualitative analysis, we show that transfernet has transparent and interpretable intermediate results. ","1877":"this study investigates whether phonological features can be applied in text-to-speech systems to generate native and non-native speech in english and mandarin. we present a mapping of arpabet\/pinyin to sampa\/sampa-sc and then to phonological features. we tested whether this mapping could lead to the successful generation of native, non-native, and code-switched speech in the two languages. we ran two experiments, one with a small dataset and one with a larger dataset. the results proved that phonological features could be used as a feasible input system, although further investigation is needed to improve model performance. the accented output generated by the tts models also helps with understanding human second language acquisition processes. ","1878":"recently, phonetic posteriorgrams (ppgs) based methods have been quite popular in non-parallel singing voice conversion systems. however, due to the lack of acoustic information in ppgs, style and naturalness of the converted singing voices are still limited. to solve these problems, in this paper, we utilize an acoustic reference encoder to implicitly model singing characteristics. we experiment with different auxiliary features, including mel spectrograms, hubert, and the middle hidden feature (ppg-mid) of pretrained automatic speech recognition (asr) model, as the input of the reference encoder, and finally find the hubert feature is the best choice. in addition, we use contrastive predictive coding (cpc) module to further smooth the voices by predicting future observations in latent space. experiments show that, compared with the baseline models, our proposed model can significantly improve the naturalness of converted singing voices and the similarity with the target singer. moreover, our proposed model can also make the speakers with just speech data sing. ","1879":"long text understanding is important yet challenging in natural language processing. a long article or essay usually contains many redundant words that are not pertinent to its gist and sometimes can be regarded as noise. in this paper, we consider the problem of how to disentangle the gist-relevant and irrelevant information for long text understanding. with distillation mechanism, we transfer the knowledge about how to focus the salient parts from the abstractive summarization model and further integrate the distilled model, named \\emph{gist detector}, into existing models as a supplementary component to augment the long text understanding. experiments on document classification, distantly supervised open-domain question answering (ds-qa) and non-parallel text style transfer show that our method can significantly improve the performance of the baseline models, and achieves state-of-the-art overall results for document classification. ","1880":"task-agnostic pre-training followed by task-specific fine-tuning is a default approach to train nlu models. such models need to be deployed on devices across the cloud and the edge with varying resource and accuracy constraints. for a given task, repeating pre-training and fine-tuning across tens of devices is prohibitively expensive. we propose supershaper, a task agnostic pre-training approach which simultaneously pre-trains a large number of transformer models by varying shapes, i.e., by varying the hidden dimensions across layers. this is enabled by a backbone network with linear bottleneck matrices around each transformer layer which are sliced to generate differently shaped sub-networks. in spite of its simple design space and efficient implementation, supershaper discovers networks that effectively trade-off accuracy and model size: discovered networks are more accurate than a range of hand-crafted and automatically searched networks on glue benchmarks. further, we find two critical advantages of shape as a design variable for neural architecture search (nas): (a) heuristics of good shapes can be derived and networks found with these heuristics match and even improve on carefully searched networks across a range of parameter counts, and (b) the latency of networks across multiple cpus and gpus are insensitive to the shape and thus enable device-agnostic search. in summary, supershaper radically simplifies nas for language models and discovers networks that generalize across tasks, parameter constraints, and devices. ","1881":"the ability to continuously expand knowledge over time and utilize it to rapidly generalize to new tasks is a key feature of human linguistic intelligence. existing models that pursue rapid generalization to new tasks (e.g., few-shot learning methods), however, are mostly trained in a single shot on fixed datasets, unable to dynamically expand their knowledge; while continual learning algorithms are not specifically designed for rapid generalization. we present a new learning setup, continual learning of few-shot learners (clif), to address the challenges of both learning settings in a unified setup. clif assumes a model learns from a sequence of diverse nlp tasks arriving sequentially, accumulating knowledge for improved generalization to new tasks, while also retaining performance on the tasks learned earlier. we examine how the generalization ability is affected in the continual learning setup, evaluate a number of continual learning algorithms, and propose a novel regularized adapter generation approach. we find that catastrophic forgetting affects generalization ability to a less degree than performance on seen tasks; while continual learning algorithms can still bring considerable benefit to the generalization ability. ","1882":"we propose a framework that learns to execute natural language instructions in an environment consisting of goal-reaching tasks that share components of their task descriptions. our approach leverages the compositionality of both value functions and language, with the aim of reducing the sample complexity of learning novel tasks. first, we train a reinforcement learning agent to learn value functions that can be subsequently composed through a boolean algebra to solve novel tasks. second, we fine-tune a seq2seq model pretrained on web-scale corpora to map language to logical expressions that specify the required value function compositions. evaluating our agent in the babyai domain, we observe a decrease of 86% in the number of training steps needed to learn a second task after mastering a single task. results from ablation studies further indicate that it is the combination of compositional value functions and language representations that allows the agent to quickly generalize to new tasks. ","1883":"we explore the link between the extent to which syntactic relations are preserved in translation and the ease of correctly constructing a parse tree in a zero-shot setting. while previous work suggests such a relation, it tends to focus on the macro level and not on the level of individual edges-a gap we aim to address. as a test case, we take the transfer of universal dependencies (ud) parsing from english to a diverse set of languages and conduct two sets of experiments. in one, we analyze zero-shot performance based on the extent to which english source edges are preserved in translation. in another, we apply three linguistically motivated transformations to ud, creating more cross-lingually stable versions of it, and assess their zero-shot parsability. in order to compare parsing performance across different schemes, we perform extrinsic evaluation on the downstream task of cross-lingual relation extraction (re) using a subset of a popular english re benchmark translated to russian and korean. in both sets of experiments, our results suggest a strong relation between cross-lingual stability and zero-shot parsing performance. ","1884":"as neural-network-based qa models become deeper and more complex, there is a demand for robust frameworks which can access a model's rationale for its prediction. current techniques that provide insights on a model's working are either dependent on adversarial datasets or are proposing models with explicit explanation generation components. these techniques are time-consuming and challenging to extend to existing models and new datasets. in this work, we use `integrated gradients' to extract rationale for existing state-of-the-art models in the task of reading comprehension based question answering (rcqa). on detailed analysis and comparison with collected human rationales, we find that though ~40-80% words of extracted rationale coincide with the human rationale (precision), only 6-19% of human rationale is present in the extracted rationale (recall). ","1885":"empathetic response generation aims to comprehend the user emotion and then respond to it appropriately. most existing works merely focus on what the emotion is and ignore how the emotion is evoked, thus weakening the capacity of the model to understand the emotional experience of the user for generating empathetic responses. to tackle this problem, we consider the emotional causality, namely, what feelings the user expresses (i.e., emotion) and why the user has such feelings (i.e., cause). then, we propose a novel graph-based model with multi-hop reasoning to model the emotional causality of the empathetic conversation. finally, we demonstrate the effectiveness of our model on empatheticdialogues in comparison with several competitive models. ","1886":"this study investigates the performance of personalized automatic speech recognition (asr) for recognizing disordered speech using small amounts of per-speaker adaptation data. we trained personalized models for 195 individuals with different types and severities of speech impairment with training sets ranging in size from <1 minute to 18-20 minutes of speech data. word error rate (wer) thresholds were selected to determine success percentage (the percentage of personalized models reaching the target wer) in different application scenarios. for the home automation scenario, 79% of speakers reached the target wer with 18-20 minutes of speech; but even with only 3-4 minutes of speech, 63% of speakers reached the target wer. further evaluation found similar improvement on test sets with conversational and out-of-domain, unprompted phrases. our results demonstrate that with only a few minutes of recordings, individuals with disordered speech could benefit from personalized asr. ","1887":"natural language generation (nlg) benchmarks provide an important avenue to measure progress and develop better nlg systems. unfortunately, the lack of publicly available nlg benchmarks for low-resource languages poses a challenging barrier for building nlg systems that work well for languages with limited amounts of data. here we introduce indonlg, the first benchmark to measure natural language generation (nlg) progress in three low-resource -- yet widely spoken -- languages of indonesia: indonesian, javanese, and sundanese. altogether, these languages are spoken by more than 100 million native speakers, and hence constitute an important use case of nlg systems today. concretely, indonlg covers six tasks: summarization, question answering, chit-chat, and three different pairs of machine translation (mt) tasks. we collate a clean pretraining corpus of indonesian, sundanese, and javanese datasets, indo4b-plus, which is used to pretrain our models: indobart and indogpt. we show that indobart and indogpt achieve competitive performance on all tasks -- despite using only one-fifth the parameters of a larger multilingual model, mbart-large (liu et al., 2020). this finding emphasizes the importance of pretraining on closely related, local languages to achieve more efficient learning and faster inference for very low-resource languages like javanese and sundanese. ","1888":"self-supervised pretraining on speech data has achieved a lot of progress. high-fidelity representation of the speech signal is learned from a lot of untranscribed data and shows promising performance. recently, there are several works focusing on evaluating the quality of self-supervised pretrained representations on various tasks without domain restriction, e.g. superb. however, such evaluations do not provide a comprehensive comparison among many asr benchmark corpora. in this paper, we focus on the general applications of pretrained speech representations, on advanced end-to-end automatic speech recognition (e2e-asr) models. we select several pretrained speech representations and present the experimental results on various open-source and publicly available corpora for e2e-asr. without any modification of the back-end model architectures or training strategy, some of the experiments with pretrained representations, e.g., wsj, wsj0-2mix with hubert, reach or outperform current state-of-the-art (sota) recognition performance. moreover, we further explore more scenarios for whether the pretraining representations are effective, such as the cross-language or overlapped speech. the scripts, configuratons and the trained models have been released in espnet to let the community reproduce our experiments and improve them. ","1889":"unifying acoustic and linguistic representation learning has become increasingly crucial to transfer the knowledge learned on the abundance of high-resource language data for low-resource speech recognition. existing approaches simply cascade pre-trained acoustic and language models to learn the transfer from speech to text. however, how to solve the representation discrepancy of speech and text is unexplored, which hinders the utilization of acoustic and linguistic information. moreover, previous works simply replace the embedding layer of the pre-trained language model with the acoustic features, which may cause the catastrophic forgetting problem. in this work, we introduce wav-bert, a cooperative acoustic and linguistic representation learning method to fuse and utilize the contextual information of speech and text. specifically, we unify a pre-trained acoustic model (wav2vec 2.0) and a language model (bert) into an end-to-end trainable framework. a representation aggregation module is designed to aggregate acoustic and linguistic representation, and an embedding attention module is introduced to incorporate acoustic information into bert, which can effectively facilitate the cooperation of two pre-trained models and thus boost the representation learning. extensive experiments show that our wav-bert significantly outperforms the existing approaches and achieves state-of-the-art performance on low-resource speech recognition. ","1890":"large-scale contrastive vision-language pre-training has shown significant progress in visual representation learning. unlike traditional visual systems trained by a fixed set of discrete labels, a new paradigm was introduced in \\cite{radford2021learning} to directly learn to align images with raw texts in an open-vocabulary setting. on downstream tasks, a carefully chosen text prompt is employed to make zero-shot predictions.~to avoid non-trivial prompt engineering, context optimization \\cite{zhou2021coop} has been proposed to learn continuous vectors as task-specific prompts with few-shot training examples.~in this paper, we show that there is an alternative path to achieve better vision-language models other than prompt tuning.~while prompt tuning is for the textual inputs, we propose clip-adapter to conduct fine-tuning with feature adapters on either visual or language branch. specifically, clip-adapter adopts an additional bottleneck layer to learn new features and performs residual-style feature blending with the original pre-trained features.~as a consequence, clip-adapter is able to outperform context optimization while maintains a simple design. experiments and extensive ablation studies on various visual classification tasks demonstrate the effectiveness of our approach. ","1891":"while multi-party conversations are often less structured than monologues and documents, they are implicitly organized by semantic level correlations across the interactive turns, and dialogue discourse analysis can be applied to predict the dependency structure and relations between the elementary discourse units, and provide feature-rich structural information for downstream tasks. however, the existing corpora with dialogue discourse annotation are collected from specific domains with limited sample sizes, rendering the performance of data-driven approaches poor on incoming dialogues without any domain adaptation. in this paper, we first introduce a transformer-based parser, and assess its cross-domain performance. we next adopt three methods to gain domain integration from both data and language modeling perspectives to improve the generalization capability. empirical results show that the neural parser can benefit from our proposed methods, and performs better on cross-domain dialogue samples. ","1892":"machine translation has wide applications in daily life. in mission-critical applications such as translating official documents, incorrect translation can have unpleasant or sometimes catastrophic consequences. this motivates recent research on testing methodologies for machine translation systems. existing methodologies mostly rely on metamorphic relations designed at the textual level (e.g., levenshtein distance) or syntactic level (e.g., the distance between grammar structures) to determine the correctness of translation results. however, these metamorphic relations do not consider whether the original and translated sentences have the same meaning (i.e., semantic similarity). therefore, in this paper, we propose semmt, an automatic testing approach for machine translation systems based on semantic similarity checking. semmt applies round-trip translation and measures the semantic similarity between the original and translated sentences. our insight is that the semantics expressed by the logic and numeric constraint in sentences can be captured using regular expressions (or deterministic finite automata) where efficient equivalence\/similarity checking algorithms are available. leveraging the insight, we propose three semantic similarity metrics and implement them in semmt. the experiment result reveals semmt can achieve higher effectiveness compared with state-of-the-art works, achieving an increase of 21% and 23% on accuracy and f-score, respectively. we also explore potential improvements that can be achieved when proper combinations of metrics are adopted. finally, we discuss a solution to locate the suspicious trip in round-trip translation, which may shed lights on further exploration. ","1893":"text discourse parsing weighs importantly in understanding information flow and argumentative structure in natural language, making it beneficial for downstream tasks. while previous work significantly improves the performance of rst discourse parsing, they are not readily applicable to practical use cases: (1) edu segmentation is not integrated into most existing tree parsing frameworks, thus it is not straightforward to apply such models on newly-coming data. (2) most parsers cannot be used in multilingual scenarios, because they are developed only in english. (3) parsers trained from single-domain treebanks do not generalize well on out-of-domain inputs. in this work, we propose a document-level multilingual rst discourse parsing framework, which conducts edu segmentation and discourse tree parsing jointly. moreover, we propose a cross-translation augmentation strategy to enable the framework to support multilingual parsing and improve its domain generality. experimental results show that our model achieves state-of-the-art performance on document-level multilingual rst parsing in all sub-tasks. ","1894":"nlp models that compare or consolidate information across multiple documents often struggle when challenged with recognizing substantial information redundancies across the texts. for example, in multi-document summarization it is crucial to identify salient information across texts and then generate a non-redundant summary, while facing repeated and usually differently-phrased salient content. to facilitate researching such challenges, the sentence-level task of \\textit{sentence fusion} was proposed, yet previous datasets for this task were very limited in their size and scope. in this paper, we revisit and substantially extend previous dataset creation efforts. with careful modifications, relabeling and employing complementing data sources, we were able to triple the size of a notable earlier dataset. moreover, we show that our extended version uses more representative texts for multi-document tasks and provides a larger and more diverse training set, which substantially improves model training. ","1895":"self-supervised pre-training has dramatically improved the performance of automatic speech recognition (asr). however, most existing self-supervised pre-training approaches are task-agnostic, i.e., could be applied to various downstream tasks. and there is a gap between the task-agnostic pre-training and the task-specific downstream fine-tuning, which may degrade the downstream performance. in this work, we propose a novel pre-training paradigm called wav2vec-s, where we use task-specific semi-supervised pre-training to bridge this gap. specifically, the semi-supervised pre-training is conducted on the basis of self-supervised pre-training such as wav2vec 2.0. experiments on asr show that compared to wav2vec 2.0, wav2vec-s only requires marginal increment of pre-training time but could significantly improve asr performance on in-domain, cross-domain and cross-lingual datasets. the average relative wer reductions are 26.3% and 6.3% for 1h and 10h fine-tuning, respectively. ","1896":"this work presents a lifelong learning approach to train a multilingual text-to-speech (tts) system, where each language was seen as an individual task and was learned sequentially and continually. it does not require pooled data from all languages altogether, and thus alleviates the storage and computation burden. one of the challenges of lifelong learning methods is \"catastrophic forgetting\": in tts scenario it means that model performance quickly degrades on previous languages when adapted to a new language. we approach this problem via a data-replay-based lifelong learning method. we formulate the replay process as a supervised learning problem, and propose a simple yet effective dual-sampler framework to tackle the heavily language-imbalanced training samples. through objective and subjective evaluations, we show that this supervised learning formulation outperforms other gradient-based and regularization-based lifelong learning methods, achieving 43% mel-cepstral distortion reduction compared to a fine-tuning baseline. ","1897":"bayesian active learning has had significant impact to various nlp problems, but nevertheless it's application to text summarization has been explored very little. we introduce bayesian active summarization (bas), as a method of combining active learning methods with state-of-the-art summarization models. our findings suggest that bas achieves better and more robust performance, compared to random selection, particularly for small and very small data annotation budgets. using bas we showcase it is possible to leverage large summarization models to effectively solve real-world problems with very limited annotated data. ","1898":"cognitively inspired natural language pro-cessing uses human-derived behavioral datalike eye-tracking data, which reflect the seman-tic representations of language in the humanbrain to augment the neural nets to solve arange of tasks spanning syntax and semanticswith the aim of teaching machines about lan-guage processing mechanisms. in this paper,we use the zuco 1.0 and zuco 2.0 dataset con-taining the eye-gaze features to explore differ-ent linguistic models to directly predict thesegaze features for each word with respect to itssentence. we tried different neural networkmodels with the words as inputs to predict thetargets. and after lots of experimentation andfeature engineering finally devised a novel ar-chitecture consisting of roberta token clas-sifier with a dense layer on top for languagemodeling and a stand-alone model consistingof dense layers followed by a transformer layerfor the extra features we engineered. finally,we took the mean of the outputs of both thesemodels to make the final predictions. we eval-uated the models using mean absolute error(mae) and the r2 score for each target. ","1899":"transcripts generated by automatic speech recognition (asr) systems for spoken documents lack structural annotations such as paragraphs, significantly reducing their readability. automatically predicting paragraph segmentation for spoken documents may both improve readability and downstream nlp performance such as summarization and machine reading comprehension. we propose a sequence model with self-adaptive sliding window for accurate and efficient paragraph segmentation. we also propose an approach to exploit phonetic information, which significantly improves robustness of spoken document segmentation to asr errors. evaluations are conducted on the english wiki-727k document segmentation benchmark, a chinese wikipedia-based document segmentation dataset we created, and an in-house chinese spoken document dataset. our proposed model outperforms the state-of-the-art (sota) model based on the same bert-base, increasing segmentation f1 on the english benchmark by 4.2 points and on chinese datasets by 4.3-10.1 points, while reducing inference time to less than 1\/6 of inference time of the current sota. ","1900":"position encoding in transformer architecture provides supervision for dependency modeling between elements at different positions in the sequence. we investigate various methods to encode positional information in transformer-based language models and propose a novel implementation named rotary position embedding(rope). the proposed rope encodes absolute positional information with rotation matrix and naturally incorporates explicit relative position dependency in self-attention formulation. notably, rope comes with valuable properties such as flexibility of being expand to any sequence lengths, decaying inter-token dependency with increasing relative distances, and capability of equipping the linear self-attention with relative position encoding. as a result, the enhanced transformer with rotary position embedding, or roformer, achieves superior performance in tasks with long texts. we release the theoretical analysis along with some preliminary experiment results on chinese data. the undergoing experiment for english benchmark will soon be updated. ","1901":"to enable robots to instruct humans in collaborations, we identify several aspects of language processing that are not commonly studied in this context. these include location, planning, and generation. we suggest evaluations for each task, offer baselines for simple methods, and close by discussing challenges and opportunities in studying language for collaboration. ","1902":"referring image segmentation (ris) aims at segmenting the target object from an image referred by one given natural language expression. the diverse and flexible expressions as well as complex visual contents in the images raise the ris model with higher demands for investigating fine-grained matching behaviors between words in expressions and objects presented in images. however, such matching behaviors are hard to be learned and captured when the visual cues of referents (i.e. referred objects) are insufficient, as the referents with weak visual cues tend to be easily confused by cluttered background at boundary or even overwhelmed by salient objects in the image. and the insufficient visual cues issue can not be handled by the cross-modal fusion mechanisms as done in previous work. in this paper, we tackle this problem from a novel perspective of enhancing the visual information for the referents by devising a two-stage visual cues enhancement network (tv-net), where a novel retrieval and enrichment scheme (res) and an adaptive multi-resolution feature fusion (amf) module are proposed. through the two-stage enhancement, our proposed tv-net enjoys better performances in learning fine-grained matching behaviors between the natural language expression and image, especially when the visual information of the referent is inadequate, thus produces better segmentation results. extensive experiments are conducted to validate the effectiveness of the proposed method on the ris task, with our proposed tv-net surpassing the state-of-the-art approaches on four benchmark datasets. ","1903":"recently proposed self-supervised learning approaches have been successful for pre-training speech representation models. the utility of these learned representations has been observed empirically, but not much has been studied about the type or extent of information encoded in the pre-trained representations themselves. developing such insights can help understand the capabilities and limits of these models and enable the research community to more efficiently develop their usage for downstream applications. in this work, we begin to fill this gap by examining one recent and successful pre-trained model (wav2vec 2.0), via its intermediate representation vectors, using a suite of analysis tools. we use the metrics of canonical correlation, mutual information, and performance on simple downstream tasks with non-parametric probes, in order to (i) query for acoustic and linguistic information content, (ii) characterize the evolution of information across model layers, and (iii) understand how fine-tuning the model for automatic speech recognition (asr) affects these observations. our findings motivate modifying the fine-tuning protocol for asr, which produces improved word error rates in a low-resource setting. ","1904":"distantly supervised named entity recognition (ds-ner) efficiently reduces labor costs but meanwhile intrinsically suffers from the label noise due to the strong assumption of distant supervision. typically, the wrongly labeled instances comprise numbers of incomplete and inaccurate annotation noise, while most prior denoising works are only concerned with one kind of noise and fail to fully explore useful information in the whole training set. to address this issue, we propose a robust learning paradigm named self-collaborative denoising learning (scdl), which jointly trains two teacher-student networks in a mutually-beneficial manner to iteratively perform noisy label refinery. each network is designed to exploit reliable labels via self denoising, and two networks communicate with each other to explore unreliable annotations by collaborative denoising. extensive experimental results on five real-world datasets demonstrate that scdl is superior to state-of-the-art ds-ner denoising methods. ","1905":"online platforms and communities establish their own norms that govern what behavior is acceptable within the community. substantial effort in nlp has focused on identifying unacceptable behaviors and, recently, on forecasting them before they occur. however, these efforts have largely focused on toxicity as the sole form of community norm violation. such focus has overlooked the much larger set of rules that moderators enforce. here, we introduce a new dataset focusing on a more complete spectrum of community norms and their violations in the local conversational and global community contexts. we introduce a series of models that use this data to develop context- and community-sensitive norm violation detection, showing that these changes give high performance. ","1906":"the field of conversational agents is growing fast and there is an increasing need for algorithms that enhance natural interaction. in this work we show how we achieved state of the art results in the keyword spotting field by adapting and tweaking the xception algorithm, which achieved outstanding results in several computer vision tasks. we obtained about 96\\% accuracy when classifying audio clips belonging to 35 different categories, beating human annotation at the most complex tasks proposed. ","1907":"natural language descriptions sometimes accompany visualizations to better communicate and contextualize their insights, and to improve their accessibility for readers with disabilities. however, it is difficult to evaluate the usefulness of these descriptions, and how effectively they improve access to meaningful information, because we have little understanding of the semantic content they convey, and how different readers receive this content. in response, we introduce a conceptual model for the semantic content conveyed by natural language descriptions of visualizations. developed through a grounded theory analysis of 2,147 sentences, our model spans four levels of semantic content: enumerating visualization construction properties (e.g., marks and encodings); reporting statistical concepts and relations (e.g., extrema and correlations); identifying perceptual and cognitive phenomena (e.g., complex trends and patterns); and elucidating domain-specific insights (e.g., social and political context). to demonstrate how our model can be applied to evaluate the effectiveness of visualization descriptions, we conduct a mixed-methods evaluation with 30 blind and 90 sighted readers, and find that these reader groups differ significantly on which semantic content they rank as most useful. together, our model and findings suggest that access to meaningful information is strongly reader-specific, and that research in automatic visualization captioning should orient toward descriptions that more richly communicate overall trends and statistics, sensitive to reader preferences. our work further opens a space of research on natural language as a data interface coequal with visualization. ","1908":"the outbreak of the novel coronavirus disease 2019 (covid-19) has lasted for nearly two years and caused unprecedented impacts on people's daily life around the world. even worse, the emergence of the covid-19 delta variant once again puts the world in danger. fortunately, many countries and companies have started to develop coronavirus vaccines since the beginning of this disaster. till now, more than 20 vaccines have been approved by the world health organization (who), bringing light to people besieged by the pandemic. the promotion of covid-19 vaccination around the world also brings a lot of discussions on social media about different aspects of vaccines, such as efficacy and security. however, there does not exist much research work to systematically analyze public opinion towards covid-19 vaccines. in this study, we conduct an in-depth analysis of tweets related to the coronavirus vaccine on twitter to understand the trending topics and their corresponding sentimental polarities regarding the country and vaccine levels. the results show that a majority of people are confident in the effectiveness of vaccines and are willing to get vaccinated. in contrast, the negative tweets are often associated with the complaints of vaccine shortages, side effects after injections and possible death after being vaccinated. overall, this study exploits popular nlp and topic modeling methods to mine people's opinions on the covid-19 vaccines on social media and to analyse and visualise them objectively. our findings can improve the readability of the noisy information on social media and provide effective data support for the government and policy makers. ","1909":"in this paper, we introduce the eval4nlp-2021shared task on explainable quality estimation. given a source-translation pair, this shared task requires not only to provide a sentence-level score indicating the overall quality of the translation, but also to explain this score by identifying the words that negatively impact translation quality. we present the data, annotation guidelines and evaluation setup of the shared task, describe the six participating systems, and analyze the results. to the best of our knowledge, this is the first shared task on explainable nlp evaluation metrics. datasets and results are available at https:\/\/github.com\/eval4nlp\/sharedtask2021. ","1910":"summarization systems are ultimately evaluated by human annotators and raters. usually, annotators and raters do not reflect the demographics of end users, but are recruited through student populations or crowdsourcing platforms with skewed demographics. for two different evaluation scenarios -- evaluation against gold summaries and system output ratings -- we show that summary evaluation is sensitive to protected attributes. this can severely bias system development and evaluation, leading us to build models that cater for some groups rather than others. ","1911":"we investigate the dynamics of increasing the number of model parameters versus the number of labeled examples across a wide variety of tasks. our exploration reveals that while scaling parameters consistently yields performance improvements, the contribution of additional examples highly depends on the task's format. specifically, in open question answering tasks, enlarging the training set does not improve performance. in contrast, classification, extractive question answering, and multiple choice tasks benefit so much from additional examples that collecting a few hundred examples is often \"worth\" billions of parameters. we hypothesize that unlike open question answering, which involves recalling specific information, solving strategies for tasks with a more restricted output space transfer across examples, and can therefore be learned with small amounts of labeled data. ","1912":"we present howsumm, a novel large-scale dataset for the task of query-focused multi-document summarization (qmds), which targets the use-case of generating actionable instructions from a set of sources. this use-case is different from the use-cases covered in existing multi-document summarization (mds) datasets and is applicable to educational and industrial scenarios. we employed automatic methods, and leveraged statistics from existing human-crafted qmds datasets, to create howsumm from wikihow website articles and the sources they cite. we describe the creation of the dataset and discuss the unique features that distinguish it from other summarization corpora. automatic and human evaluations of both extractive and abstractive summarization models on the dataset reveal that there is room for improvement. ","1913":"current open-domain question answering (odqa) model paradigm often contains a retrieving module and a reading module. given an input question, the reading module predicts the answer from the relevant passages which are retrieved by the retriever. the recent proposed fusion-in-decoder (fid), which is built on top of the pretrained generative model t5, achieves the state-of-the-art performance in the reading module. although being effective, it remains constrained by inefficient attention on all retrieved passages which contain a lot of noise. in this work, we propose a novel method kg-fid, which filters noisy passages by leveraging the structural relationship among the retrieved passages with a knowledge graph. we initiate the passage node embedding from the fid encoder and then use graph neural network (gnn) to update the representation for reranking. to improve the efficiency, we build the gnn on top of the intermediate layer output of the fid encoder and only pass a few top reranked passages into the higher layers of encoder and decoder for answer generation. we also apply the proposed gnn based reranking method to enhance the passage retrieval results in the retrieving module. extensive experiments on common odqa benchmark datasets (natural question and triviaqa) demonstrate that kg-fid can improve vanilla fid by up to 1.5% on answer exact match score and achieve comparable performance with fid with only 40% of computation cost. ","1914":"we have a fpga design, we make it fast, efficient, and tested for a few important examples. now we must infer a general solution to deploy in the data center. here, we describe the fpga dpuv3int8 design and our compiler effort. the hand-tuned sw-hw solution for resnet50\\_v1 has (close to) 2 times better images per second (throughput) than our best fpga implementation; the compiler generalizes the hand written techniques achieving about 1.5 times better performance for the same example, the compiler generalizes the optimizations to a model zoo of networks, and it achieves 80+\\% hw efficiency. ","1915":"affective computing is the study of how computers can recognize, interpret and simulate human affects. sentiment analysis is a common task innlp related to this topic, but it focuses only on emotion valence (positive, negative, neutral). an emerging approach in nlp is emotion recognition, which relies on fined-grained classification. this research describes an approach to create a lexical-based weakly supervised corpus for fine-grained emotion in portuguese. we evaluated our dataset by fine-tuning a transformer-based language model (bert) and validating it on a gold standard annotated validation set. our results (f1-score=.64) suggest lexical-based weak supervision as an appropriate strategy for initial work in low resourced environment. ","1916":"sentence ordering refers to the task of rearranging a set of sentences into the appropriate coherent order. for this task, most previous approaches have explored global context-based end-to-end methods using sequence generation techniques. in this paper, we put forward a set of robust local and global context-based pairwise ordering strategies, leveraging which our prediction strategies outperform all previous works in this domain. our proposed encoding method utilizes the paragraph's rich global contextual information to predict the pairwise order using novel transformer architectures. analysis of the two proposed decoding strategies helps better explain error propagation in pairwise models. this approach is the most accurate pure pairwise model and our encoding strategy also significantly improves the performance of other recent approaches that use pairwise models, including the previous state-of-the-art, demonstrating the research novelty and generalizability of this work. additionally, we show how the pre-training task for albert helps it to significantly outperform bert, despite having considerably lesser parameters. the extensive experimental results, architectural analysis and ablation studies demonstrate the effectiveness and superiority of the proposed models compared to the previous state-of-the-art, besides providing a much better understanding of the functioning of pairwise models. ","1917":"text summarization is a challenging task within natural language processing that involves text generation from lengthy input sequences. while this task has been widely studied in english, there is very limited research on summarization for vietnamese text. in this paper, we investigate the robustness of transformer-based encoder-decoder architectures for vietnamese abstractive summarization. leveraging transfer learning and self-supervised learning, we validate the performance of the methods on two vietnamese datasets. ","1918":"we present lambeq, the first high-level python library for quantum natural language processing (qnlp). the open-source toolkit offers a detailed hierarchy of modules and classes implementing all stages of a pipeline for converting sentences to string diagrams, tensor networks, and quantum circuits ready to be used on a quantum computer. lambeq supports syntactic parsing, rewriting and simplification of string diagrams, ansatz creation and manipulation, as well as a number of compositional models for preparing quantum-friendly representations of sentences, employing various degrees of syntax sensitivity. we present the generic architecture and describe the most important modules in detail, demonstrating the usage with illustrative examples. further, we test the toolkit in practice by using it to perform a number of experiments on simple nlp tasks, implementing both classical and quantum pipelines. ","1919":"the formulation of good academic paper titles in english is challenging for intermediate english authors (particularly students). this is because such authors are not aware of the type of titles that are generally in use. we aim to realize a support system for formulating more effective english titles for intermediate english and beginner authors. this study develops an extractive title generation system that formulates titles from keywords extracted from an abstract. moreover, we realize a title evaluation model that can evaluate the appropriateness of paper titles. we train the model with titles of top-conference papers by using bert. this paper describes the training data, implementation, and experimental results. the results show that our evaluation model can identify top-conference titles more effectively than intermediate english and beginner students. ","1920":"humans can systematically generalize to novel compositions of existing concepts. there have been extensive conjectures into the extent to which neural networks can do the same. recent arguments supported by evidence on the scan dataset claim that neural networks are inherently ineffective in such cognitive capacity. in this paper, we revisit systematic generalization from the perspective of meaningful learning, an exceptional capability of humans to learn new concepts by connecting them with other previously known knowledge. we propose to augment a training dataset in either an inductive or deductive manner to build semantic links between new and old concepts. our observations on scan suggest that, following the meaningful learning principle, modern sequence-to-sequence models, including rnns, cnns, and transformers, can successfully generalize to compositions of new concepts. we further validate our findings on two real-world datasets on semantic parsing and consistent compositional generalization is also observed. moreover, our experiments demonstrate that both prior knowledge and semantic linking play a key role to achieve systematic generalization. meanwhile, inductive learning generally works better than deductive learning in our experiments. finally, we provide an explanation for data augmentation techniques by concluding them into either inductive-based or deductive-based meaningful learning. we hope our findings will encourage excavating existing neural networks' potential in systematic generalization through more advanced learning schemes. ","1921":"much information available to applied researchers is contained within written language or spoken text. deep language models such as bert have achieved unprecedented success in many applications of computational linguistics. however, much less is known about how these models can be used to analyze existing text. we propose a novel method that combines transformer models with network analysis to form a self-referential representation of language use within a corpus of interest. our approach produces linguistic relations strongly consistent with the underlying model as well as mathematically well-defined operations on them, while reducing the amount of discretionary choices of representation and distance measures. it represents, to the best of our knowledge, the first unsupervised method to extract semantic networks directly from deep language models. we illustrate our approach in a semantic analysis of the term \"founder\". using the entire corpus of harvard business review from 1980 to 2020, we find that ties in our network track the semantics of discourse over time, and across contexts, identifying and relating clusters of semantic and syntactic relations. finally, we discuss how this method can also complement and inform analyses of the behavior of deep learning models. ","1922":"most learners fail to develop deep text comprehension when reading textbooks passively. posing questions about what learners have read is a well-established way of fostering their text comprehension. however, many textbooks lack self-assessment questions because authoring them is timeconsuming and expensive. automatic question generators may alleviate this scarcity by generating sound pedagogical questions. however, generating questions automatically poses linguistic and pedagogical challenges. what should we ask? and, how do we phrase the question automatically? we address those challenges with an automatic question generator grounded in learning theory. the paper introduces a novel pedagogically meaningful content selection mechanism to find question-worthy sentences and answers in arbitrary textbook contents. we conducted an empirical evaluation study with educational experts, annotating 150 generated questions in six different domains. results indicate a high linguistic quality of the generated questions. furthermore, the evaluation results imply that the majority of the generated questions inquire central information related to the given text and may foster text comprehension in specific learning scenarios. ","1923":"in this paper, we take the advantage of previous pre-trained models (ptms) and propose a novel chinese pre-trained unbalanced transformer (cpt). different from previous chinese ptms, cpt is designed for both natural language understanding (nlu) and natural language generation (nlg) tasks. cpt consists of three parts: a shared encoder, an understanding decoder, and a generation decoder. two specific decoders with a shared encoder are pre-trained with masked language modeling (mlm) and denoising auto-encoding (dae) tasks, respectively. with the partially shared architecture and multi-task pre-training, cpt can (1) learn specific knowledge of both nlu or nlg tasks with two decoders and (2) be fine-tuned flexibly that fully exploits the potential of the model. moreover, the unbalanced transformer saves the computational and storage cost, which makes cpt competitive and greatly accelerates the inference of text generation. experimental results on a wide range of chinese nlu and nlg tasks show the effectiveness of cpt. ","1924":"emoji have become a significant part of our informal textual communication. previous work addressing the societal and linguistic functions of emoji overlook the evolving meaning of the symbol. this evolution could be addressed through the framework of semantic drifts. in this paper we model and analyze the semantic drift of emoji and discuss the features that may be contributing to the drift, some are unique to emoji and some are more general. ","1925":"in this paper, we investigate mathematical content representations suitable for the automated classification of and the similarity search in stem documents using standard machine learning algorithms: the latent dirichlet allocation (lda) and the latent semantic indexing (lsi). the methods are evaluated on a subset of arxiv.org papers with the mathematics subject classification (msc) as a reference classification and using the standard precision\/recall\/f1-measure metrics. the results give insight into how different math representations may influence the performance of the classification and similarity search tasks in stem repositories. non-surprisingly, machine learning methods are able to grab distributional semantics from textual tokens. a proper selection of weighted tokens representing math may improve the quality of the results slightly. a structured math representation that imitates successful text-processing techniques with math is shown to yield better results than flat tex tokens. ","1926":"in this paper, we present foodchem, a new relation extraction (re) model for identifying chemicals present in the composition of food entities, based on textual information provided in biomedical peer-reviewed scientific literature. the re task is treated as a binary classification problem, aimed at identifying whether the contains relation exists between a food-chemical entity pair. this is accomplished by fine-tuning bert, biobert and roberta transformer models. for evaluation purposes, a novel dataset with annotated contains relations in food-chemical entity pairs is generated, in a golden and silver version. the models are integrated into a voting scheme in order to produce the silver version of the dataset which we use for augmenting the individual models, while the manually annotated golden version is used for their evaluation. out of the three evaluated models, the biobert model achieves the best results, with a macro averaged f1 score of 0.902 in the unbalanced augmentation setting. ","1927":"we present a literature survey on non-interactive computational story generation. the article starts with the presentation of requirements for creative systems, three types of models of creativity (computational, socio-cultural, and individual), and models of human creative writing. then it reviews each class of story generation approach depending on the used technology: story-schemas, analogy, rules, planning, evolutionary algorithms, implicit knowledge learning, and explicit knowledge learning. before the concluding section, the article analyses the contributions of the reviewed work to improve the quality of the generated stories. this analysis addresses the description of the story characters, the use of narrative knowledge including about character believability, and the possible lack of more comprehensive or more detailed knowledge or creativity models. finally, the article presents concluding remarks in the form of suggestions of research topics that might have a significant impact on the advancement of the state of the art on autonomous non-interactive story generation systems. the article concludes that the autonomous generation and adoption of the main idea to be conveyed and the autonomous design of the creativity ensuring criteria are possibly two of most important topics for future research. ","1928":"this paper proposes a method to relax the conditional independence assumption of connectionist temporal classification (ctc)-based automatic speech recognition (asr) models. we train a ctc-based asr model with auxiliary ctc losses in intermediate layers in addition to the original ctc loss in the last layer. during both training and inference, each generated prediction in the intermediate layers is summed to the input of the next layer to condition the prediction of the last layer on those intermediate predictions. our method is easy to implement and retains the merits of ctc-based asr: a simple model architecture and fast decoding speed. we conduct experiments on three different asr corpora. our proposed method improves a standard ctc model significantly (e.g., more than 20 % relative word error rate reduction on the wsj corpus) with a little computational overhead. moreover, for the tedlium2 corpus and the aishell-1 corpus, it achieves a comparable performance to a strong autoregressive model with beam search, but the decoding speed is at least 30 times faster. ","1929":"existing sarcasm detection systems focus on exploiting linguistic markers, context, or user-level priors. however, social studies suggest that the relationship between the author and the audience can be equally relevant for the sarcasm usage and interpretation. in this work, we propose a framework jointly leveraging (1) a user context from their historical tweets together with (2) the social information from a user's conversational neighborhood in an interaction graph, to contextualize the interpretation of the post. we use graph attention networks (gat) over users and tweets in a conversation thread, combined with dense user history representations. apart from achieving state-of-the-art results on the recently published dataset of 19k twitter users with 30k labeled tweets, adding 10m unlabeled tweets as context, our results indicate that the model contributes to interpreting the sarcastic intentions of an author more than to predicting the sarcasm perception by others. ","1930":"this paper surveys 60 english machine reading comprehension datasets, with a view to providing a convenient resource for other researchers interested in this problem. we categorize the datasets according to their question and answer form and compare them across various dimensions including size, vocabulary, data source, method of creation, human performance level, and first question word. our analysis reveals that wikipedia is by far the most common data source and that there is a relative lack of why, when, and where questions across datasets. ","1931":"pre-trained vision-language models (vl-ptms) have shown promising capabilities in grounding natural language in image data, facilitating a broad variety of cross-modal tasks. however, we note that there exists a significant gap between the objective forms of model pre-training and fine-tuning, resulting in a need for large amounts of labeled data to stimulate the visual grounding capability of vl-ptms for downstream tasks. to address the challenge, we present cross-modal prompt tuning (cpt, alternatively, colorful prompt tuning), a novel paradigm for tuning vl-ptms, which reformulates visual grounding into a fill-in-the-blank problem with color-based co-referential markers in image and text, maximally mitigating the gap. in this way, cpt enables strong few-shot and even zero-shot visual grounding capabilities of vl-ptms. comprehensive experimental results show that the prompt-tuned vl-ptms outperform their fine-tuned counterparts by a large margin (e.g., 17.3% absolute accuracy improvement, and 73.8% relative standard deviation reduction on average with one shot in refcoco evaluation). all the data and codes will be available to facilitate future research. ","1932":"apart from the coherence and fluency of responses, an empathetic chatbot emphasizes more on people's feelings. by considering altruistic behaviors between human interaction, empathetic chatbots enable people to get a better interactive and supportive experience. this study presents a framework whereby several empathetic chatbots are based on understanding users' implied feelings and replying empathetically for multiple dialogue turns. we call these chatbots cheerbots. cheerbots can be retrieval-based or generative-based and were finetuned by deep reinforcement learning. to respond in an empathetic way, we develop a simulating agent, a conceptual human model, as aids for cheerbots in training with considerations on changes in user's emotional states in the future to arouse sympathy. finally, automatic metrics and human rating results demonstrate that cheerbots outperform other baseline chatbots and achieves reciprocal altruism. the code and the pre-trained models will be made available. ","1933":"self-attention (sa), which encodes vector sequences according to their pairwise similarity, is widely used in speech recognition due to its strong context modeling ability. however, when applied to long sequence data, its accuracy is reduced. this is caused by the fact that its weighted average operator may lead to the dispersion of the attention distribution, which results in the relationship between adjacent signals ignored. to address this issue, in this paper, we introduce relative-position-awareness self-attention (rpsa). it not only maintains the global-range dependency modeling ability of self-attention, but also improves the localness modeling ability. because the local window length of the original rpsa is fixed and sensitive to different test data, here we propose gaussian-based self-attention (gsa) whose window length is learnable and adaptive to the test data automatically. we further generalize gsa to a new residual gaussian self-attention (resgsa) for the performance improvement. we apply rpsa, gsa, and resgsa to transformer-based speech recognition respectively. experimental results on the aishell-1 mandarin speech recognition corpus demonstrate the effectiveness of the proposed methods. for example, the resgsa-transformer achieves a character error rate (cer) of 5.86% on the test set, which is relative 7.8% lower than that of the sa-transformer. although the performance of the proposed resgsa-transformer is only slightly better than that of the rpsa-transformer, it does not have to tune the window length manually. ","1934":"peer assessment has been widely applied across diverse academic fields over the last few decades and has demonstrated its effectiveness. however, the advantages of peer assessment can only be achieved with high-quality peer reviews. previous studies have found that high-quality review comments usually comprise several features (e.g., contain suggestions, mention problems, use a positive tone). thus, researchers have attempted to evaluate peer-review comments by detecting different features using various machine learning and deep learning models. however, there is no single study that investigates using a multi-task learning (mtl) model to detect multiple features simultaneously. this paper presents two mtl models for evaluating peer-review comments by leveraging the state-of-the-art pre-trained language representation models bert and distilbert. our results demonstrate that bert-based models significantly outperform previous glove-based methods by around 6% in f1-score on tasks of detecting a single feature, and mtl further improves performance while reducing model size. ","1935":"the attention mechanism has largely improved the performance of end-to-end speech recognition systems. however, the underlying behaviours of attention is not yet clearer. in this study, we use decision trees to explain how the attention mechanism impact itself in speech recognition. the results indicate that attention levels are largely impacted by their previous states rather than the encoder and decoder patterns. additionally, the default attention mechanism seems to put more weights on closer states, but behaves poorly on modelling long-term dependencies of attention states. ","1936":"providing technologies to communities or domains where training data is scarce or protected e.g., for privacy reasons, is becoming increasingly important. to that end, we generalise methods for unsupervised transfer from multiple input models for structured prediction. we show that the means of aggregating over the input models is critical, and that multiplying marginal probabilities of substructures to obtain high-probability structures for distant supervision is substantially better than taking the union of such structures over the input models, as done in prior work. testing on 18 languages, we demonstrate that the method works in a cross-lingual setting, considering both dependency parsing and part-of-speech structured prediction problems. our analyses show that the proposed method produces less noisy labels for the distant supervision. ","1937":"in the development of neural text-to-speech systems, model pre-training with a large amount of non-target speakers' data is a common approach. however, in terms of ultimately achieved system performance for target speaker(s), the actual benefits of model pre-training are uncertain and unstable, depending very much on the quantity and text content of training data. this study aims to understand better why and how model pre-training can positively contribute to tts system performance. it is postulated that the pre-training process plays a critical role in learning text-related variation in speech, while further training with the target speaker's data aims to capture the speaker-related variation. different test sets are created with varying degrees of similarity to target speaker data in terms of text content. experiments show that leveraging a speaker-independent tts trained on speech data with diverse text content can improve the target speaker tts on domain-mismatched text. we also attempt to reduce the amount of pre-training data for a new text domain and improve the data and computational efficiency. it is found that the tts system could achieve comparable performance when the pre-training data is reduced to 1\/8 of its original size. ","1938":"we propose a simple and efficient approach for training the bert model. our approach exploits the special structure of bert that contains a stack of repeated modules (i.e., transformer encoders). our proposed approach first trains bert with the weights shared across all the repeated modules till some point. this is for learning the commonly shared component of weights across all repeated layers. we then stop weight sharing and continue training until convergence. we present theoretic insights for training by sharing weights then unsharing with analysis for simplified models. empirical experiments on the bert model show that our method yields better performance of trained models, and significantly reduces the number of training iterations. ","1939":"automatic dubbing aims at seamlessly replacing the speech in a video document with synthetic speech in a different language. the task implies many challenges, one of which is generating translations that not only convey the original content, but also match the duration of the corresponding utterances. in this paper, we focus on the problem of controlling the verbosity of machine translation output, so that subsequent steps of our automatic dubbing pipeline can generate dubs of better quality. we propose new methods to control the verbosity of mt output and compare them against the state of the art with both intrinsic and extrinsic evaluations. for our experiments we use a public data set to dub english speeches into french, italian, german and spanish. finally, we report extensive subjective tests that measure the impact of mt verbosity control on the final quality of dubbed video clips. ","1940":"training a model for grammatical error correction (gec) requires a set of labeled ungrammatical \/ grammatical sentence pairs, but manually annotating such pairs can be expensive. recently, the break-it-fix-it (bifi) framework has demonstrated strong results on learning to repair a broken program without any labeled examples, but this relies on a perfect critic (e.g., a compiler) that returns whether an example is valid or not, which does not exist for the gec task. in this work, we show how to leverage a pretrained language model (lm) in defining an lm-critic, which judges a sentence to be grammatical if the lm assigns it a higher probability than its local perturbations. we apply this lm-critic and bifi along with a large set of unlabeled sentences to bootstrap realistic ungrammatical \/ grammatical pairs for training a corrector. we evaluate our approach on gec datasets across multiple domains (conll-2014, bea-2019, gmeg-wiki and gmeg-yahoo) and show that it outperforms existing methods in both the unsupervised setting (+7.7 f0.5) and the supervised setting (+0.5 f0.5). ","1941":"current approaches to incorporating terminology constraints in machine translation (mt) typically assume that the constraint terms are provided in their correct morphological forms. this limits their application to real-world scenarios where constraint terms are provided as lemmas. in this paper, we introduce a modular framework for incorporating lemma constraints in neural mt (nmt) in which linguistic knowledge and diverse types of nmt models can be flexibly applied. it is based on a novel cross-lingual inflection module that inflects the target lemma constraints based on the source context. we explore linguistically motivated rule-based and data-driven neural-based inflection modules and design english-german health and english-lithuanian news test suites to evaluate them in domain adaptation and low-resource mt settings. results show that our rule-based inflection module helps nmt models incorporate lemma constraints more accurately than a neural module and outperforms the existing end-to-end approach with lower training costs. ","1942":"this paper improves the streaming transformer transducer for speech recognition by using non-causal convolution. many works apply the causal convolution to improve streaming transformer ignoring the lookahead context. we propose to use non-causal convolution to process the center block and lookahead context separately. this method leverages the lookahead context in convolution and maintains similar training and decoding efficiency. given the similar latency, using the non-causal convolution with lookahead context gives better accuracy than causal convolution, especially for open-domain dictation scenarios. besides, this paper applies talking-head attention and a novel history context compression scheme to further improve the performance. the talking-head attention improves the multi-head self-attention by transferring information among different heads. the history context compression method introduces more extended history context compactly. on our in-house data, the proposed methods improve a small emformer baseline with lookahead context by relative werr 5.1\\%, 14.5\\%, 8.4\\% on open-domain dictation, assistant general scenarios, and assistant calling scenarios, respectively. ","1943":"aspect-based sentiment analysis (absa) is an nlp task that entails processing user-generated reviews to determine (i) the target being evaluated, (ii) the aspect category to which it belongs, and (iii) the sentiment expressed towards the target and aspect pair. in this article, we propose transforming absa into an abstract summary-like conditional text generation task that uses targets, aspects, and polarities to generate auxiliary statements. to demonstrate the efficacy of our task formulation and a proposed system, we fine-tune a pre-trained model for conditional text generation tasks to get new state-of-the-art results on a few restaurant domains and urban neighborhoods domain benchmark datasets. ","1944":"the aim of this study is to determine the effect of language varieties on the spectral distribution of stressed and unstressed sonorants (nasals \/m, n\/, lateral approximants \/l\/, and rhotics \/r\/) and on their coarticulatory effects on adjacent sounds. to quantify the shape of the spectral distribution, we calculated the spectral moments from the sonorant spectra of nasals \/m, n\/, lateral approximants \/l\/, and rhotics \/r\/ produced by athenian greek and cypriot greek speakers. to estimate the co-articulatory effects of sonorants on the adjacent vowels' f1 - f4 formant frequencies, we developed polynomial models of the adjacent vowel's formant contours. we found significant effects of language variety (sociolinguistic information) on the spectral moments of each sonorant \/m\/, \/n\/, \/l\/, \/r\/ (except between \/m\/ and \/n\/) and on the formant contours of the adjacent vowel. all sonorants (including \/m\/ and \/n\/) had distinct effects on adjacent vowel's formant contours, especially for f3 and f4. the study highlights that the combination of spectral moments and coarticulatory effects of sonorants determines linguistic (stress and phonemic category) and sociolinguistic (language variety) characteristics of sonorants. it also provides the first comparative acoustic analysis of athenian greek and cypriot greek sonorants. ","1945":"toxicity is pervasive in social media and poses a major threat to the health of online communities. the recent introduction of pre-trained language models, which have achieved state-of-the-art results in many nlp tasks, has transformed the way in which we approach natural language processing. however, the inherent nature of pre-training means that they are unlikely to capture task-specific statistical information or learn domain-specific knowledge. additionally, most implementations of these models typically do not employ conditional random fields, a method for simultaneous token classification. we show that these modifications can improve model performance on the toxic spans detection task at semeval-2021 to achieve a score within 4 percentage points of the top performing team. ","1946":"although pretrained language models (ptlms) have been shown to contain significant amounts of world knowledge, they can still produce inconsistent answers to questions when probed, even after using specialized training techniques to reduce inconsistency. as a result, it can be hard to identify what the model actually \"believes\" about the world. our goal is to reduce this problem, so systems are more globally consistent and accurate in their answers. our approach is to add a memory component -- a beliefbank -- that records a model's answers, and two mechanisms that use it to improve consistency among beliefs. first, a reasoning component -- a weighted sat solver -- improves consistency by flipping answers that significantly clash with others. second, a feedback component re-queries the model but using known beliefs as context. we show that, in a controlled experimental setting, these two mechanisms improve both accuracy and consistency. this is significant as it is a first step towards endowing models with an evolving memory, allowing them to construct a more coherent picture of the world. ","1947":"zero-shot cross-domain slot filling alleviates the data dependence in the case of data scarcity in the target domain, which has aroused extensive research. however, as most of the existing methods do not achieve effective knowledge transfer to the target domain, they just fit the distribution of the seen slot and show poor performance on unseen slot in the target domain. to solve this, we propose a novel approach based on prototypical contrastive learning with a dynamic label confusion strategy for zero-shot slot filling. the prototypical contrastive learning aims to reconstruct the semantic constraints of labels, and we introduce the label confusion strategy to establish the label dependence between the source domains and the target domain on-the-fly. experimental results show that our model achieves significant improvement on the unseen slots, while also set new state-of-the-arts on slot filling task. ","1948":"we present gesera, an open-source improved version of sera for evaluating automatic extractive and abstractive summaries from the general domain. sera is based on a search engine that compares candidate and reference summaries (called queries) against an information retrieval document base (called index). sera was originally designed for the biomedical domain only, where it showed a better correlation with manual methods than the widely used lexical-based rouge method. in this paper, we take out sera from the biomedical domain to the general one by adapting its content-based method to successfully evaluate summaries from the general domain. first, we improve the query reformulation strategy with pos tags analysis of general-domain corpora. second, we replace the biomedical index used in sera with two article collections from aquaint-2 and wikipedia. we conduct experiments with tac2008, tac2009, and cnndm datasets. results show that, in most cases, gesera achieves higher correlations with manual evaluation methods than sera, while it reduces its gap with rouge for general-domain summary evaluation. gesera even surpasses rouge in two cases of tac2009. finally, we conduct extensive experiments and provide a comprehensive study of the impact of human annotators and the index size on summary evaluation with sera and gesera. ","1949":"we propose a simple and effective cross-lingual transfer learning method to adapt monolingual wav2vec-2.0 models for automatic speech recognition (asr) in resource-scarce languages. we show that a monolingual wav2vec-2.0 is a good few-shot asr learner in several languages. we improve its performance further via several iterations of dropout uncertainty-driven self-training (dust) by using a moderate-sized unlabeled speech dataset in the target language. a key finding of this work is that the adapted monolingual wav2vec-2.0 achieves similar performance as the topline multilingual xlsr model, which is trained on fifty-three languages, on the target language asr task. ","1950":"code-switching (cs) is common in daily conversations where more than one language is used within a sentence. the difficulties of cs speech recognition lie in alternating languages and the lack of transcribed data. therefore, this paper uses the recently successful self-supervised learning (ssl) methods to leverage many unlabeled speech data without cs. we show that hidden representations of ssl models offer frame-level language identity even if the models are trained with english speech only. jointly training ctc and language identification modules with self-supervised speech representations improves cs speech recognition performance. furthermore, using multilingual speech data for pre-training obtains the best cs speech recognition. ","1951":"sequence-to-sequence neural networks have been widely used in language-based applications as they have flexible capabilities to learn various language models. however, when seeking for the optimal language response through trained neural networks, current existing approaches such as beam-search decoder strategies are still not able reaching to promising performances. instead of developing various decoder strategies based on a \"regular sentence order\" neural network (a trained model by outputting sentences from left-to-right order), we leveraged \"reverse\" order as additional language model (a trained model by outputting sentences from right-to-left order) which can provide different perspectives for the path finding problems. in this paper, we propose bidirectional strategies in searching paths by combining two networks (left-to-right and right-to-left language models) making a bidirectional beam search possible. besides, our solution allows us using any similarity measure in our sentence selection criterion. our approaches demonstrate better performance compared to the unidirectional beam search strategy. ","1952":"most existing document-level neural machine translation (nmt) models leverage a fixed number of the previous or all global source sentences to handle the context-independent problem in standard nmt. however, the translating of each source sentence benefits from various sizes of context, and inappropriate context may harm the translation performance. in this work, we introduce a data-adaptive method that enables the model to adopt the necessary and useful context. specifically, we introduce a light predictor into two document-level translation models to select the explicit context. experiments demonstrate the proposed approach can significantly improve the performance over the previous methods with a gain up to 1.99 bleu points. ","1953":"in the last few years, the ml community has created a number of new nlp models based on transformer architecture. these models have shown great performance for various nlp tasks on benchmark datasets, often surpassing sota results. buoyed with this success, one often finds industry practitioners actively experimenting with fine-tuning these models to build nlp applications for industry use cases. however, for most datasets that are used by practitioners to build industrial nlp applications, it is hard to guarantee the presence of any noise in the data. while most transformer based nlp models have performed exceedingly well in transferring the learnings from one dataset to another, it remains unclear how these models perform when fine-tuned on noisy text. we address the open question by kumar et al. (2020) to explore the sensitivity of popular transformer based nlp models to noise in the text data. we continue working with the noise as defined by them -- spelling mistakes & typos (which are the most commonly occurring noise). we show (via experimental results) that these models perform badly on most common nlp tasks namely text classification, textual similarity, ner, question answering, text summarization on benchmark datasets. we further show that as the noise in data increases, the performance degrades. our findings suggest that one must be vary of the presence of noise in their datasets while fine-tuning popular transformer based nlp models. ","1954":"in this paper, we propose a simple but effective method to decode the output of connectionist temporal classifier (ctc) model using a bi-directional neural language model. the bidirectional language model uses the future as well as the past information in order to predict the next output in the sequence. the proposed method based on bi-directional beam search takes advantage of the ctc greedy decoding output to represent the noisy future information. experiments on the librispeechdataset demonstrate the superiority of our proposed method compared to baselines using unidirectional decoding. in particular, the boost inaccuracy is most apparent at the start of a sequence which is the most erroneous part for existing systems based on unidirectional decoding. ","1955":"in this paper, we provide the first focused study on the discontinuities (aka. holes) in the latent space of variational auto-encoders (vaes), a phenomenon which has been shown to have a detrimental effect on model capacity. when investigating latent holes, existing works are exclusively centred around the encoder network and they merely explore the existence of holes. we tackle these limitations by proposing a highly efficient tree-based decoder-centric (tdc) algorithm for latent hole identification, with a focal point on the text domain. in contrast to past studies, our approach pays attention to the decoder network, as a decoder has a direct impact on the model's output quality. furthermore, we provide, for the first time, in-depth empirical analysis of the latent hole phenomenon, investigating several important aspects such as how the holes impact vae algorithms' performance on text generation, and how the holes are distributed in the latent space. ","1956":"machine learning has brought striking advances in multilingual natural language processing capabilities over the past year. for example, the latest techniques have improved the state-of-the-art performance on the xtreme multilingual benchmark by more than 13 points. while a sizeable gap to human-level performance remains, improvements have been easier to achieve in some tasks than in others. this paper analyzes the current state of cross-lingual transfer learning and summarizes some lessons learned. in order to catalyze meaningful progress, we extend xtreme to xtreme-r, which consists of an improved set of ten natural language understanding tasks, including challenging language-agnostic retrieval tasks, and covers 50 typologically diverse languages. in addition, we provide a massively multilingual diagnostic suite (multichecklist) and fine-grained multi-dataset evaluation capabilities through an interactive public leaderboard to gain a better understanding of such models. the leaderboard and code for xtreme-r will be made available at https:\/\/sites.research.google\/xtreme and https:\/\/github.com\/google-research\/xtreme respectively. ","1957":"with the advancement of deep models, research work on image captioning has led to a remarkable gain in raw performance over the last decade, along with increasing model complexity and computational cost. however, surprisingly works on compression of deep networks for image captioning task has received little to no attention. for the first time in image captioning research, we provide an extensive comparison of various unstructured weight pruning methods on three different popular image captioning architectures, namely soft-attention, up-down and object relation transformer. following this, we propose a novel end-to-end weight pruning method that performs gradual sparsification based on weight sensitivity to the training loss. the pruning schemes are then extended with encoder pruning, where we show that conducting both decoder pruning and training simultaneously prior to the encoder pruning provides good overall performance. empirically, we show that an 80% to 95% sparse network (up to 75% reduction in model size) can either match or outperform its dense counterpart. the code and pre-trained models for up-down and object relation transformer that are capable of achieving cider scores >120 on the ms-coco dataset but with only 8.7 mb and 14.5 mb in model size (size reduction of 96% and 94% respectively against dense versions) are publicly available at https:\/\/github.com\/jiahuei\/sparse-image-captioning. ","1958":"autism spectrum disorder (asd) can be defined as a neurodevelopmental disorder that affects how children interact, communicate and socialize with others. this disorder can occur in a broad spectrum of symptoms, with varying effects and severity. while there is no permanent cure for asd, early detection and proactive treatment can substantially improve the lives of many children. current methods to accurately diagnose asd are invasive, time-consuming, and tedious. they can also be subjective perspectives of a number of clinicians involved, including pediatricians, speech pathologists, psychologists, and psychiatrists. new technologies are rapidly emerging that include machine learning models using speech, computer vision from facial, retinal, and brain mri images of patients to accurately and timely detect this disorder. our research focuses on computational linguistics and machine learning using speech data from talkbank, the world's largest spoken language database. we used data of both asd and typical development (td) in children from talkbank to develop machine learning models to accurately predict asd. more than 50 features were used from specifically two datasets in talkbank to run our experiments using five different classifiers. logistic regression and random forest models were found to be the most effective for each of these two main datasets, with an accuracy of 0.75. these experiments confirm that while significant opportunities exist for improving the accuracy, machine learning models can reliably predict asd status in children for effective diagnosis. ","1959":"multi-party dialogue machine reading comprehension (mrc) raises an even more challenging understanding goal on dialogue with more than two involved speakers, compared with the traditional plain passage style mrc. to accurately perform the question-answering (qa) task according to such multi-party dialogue, models have to handle fundamentally different discourse relationships from common non-dialogue plain text, where discourse relations are supposed to connect two far apart utterances in a linguistics-motivated way.to further explore the role of such unusual discourse structure on the correlated qa task in terms of mrc, we propose the first multi-task model for jointly performing qa and discourse parsing (dp) on the multi-party dialogue mrc task. our proposed model is evaluated on the latest benchmark molweni, whose results indicate that training with complementary tasks indeed benefits not only qa task, but also dp task itself. we further find that the joint model is distinctly stronger when handling longer dialogues which again verifies the necessity of dp in the related mrc. ","1960":"while transformer-based models have shown impressive language modeling performance, the large computation cost is often prohibitive for practical use. attention head pruning, which removes unnecessary attention heads in the multihead attention, is a promising technique to solve this problem. however, it does not evenly reduce the overall load because the heavy feedforward module is not affected by head pruning. in this paper, we apply layer-wise attention head pruning on all-attention transformer so that the entire computation and the number of parameters can be reduced proportionally to the number of pruned heads. while the architecture has the potential to fully utilize head pruning, we propose three training methods that are especially helpful to minimize performance degradation and stabilize the pruning process. our pruned model shows consistently lower perplexity within a comparable parameter size than transformer-xl on wikitext-103 language modeling benchmark. ","1961":"among the most critical limitations of deep learning nlp models are their lack of interpretability, and their reliance on spurious correlations. prior work proposed various approaches to interpreting the black-box models to unveil the spurious correlations, but the research was primarily used in human-computer interaction scenarios. it still remains underexplored whether or how such model interpretations can be used to automatically \"unlearn\" confounding features. in this work, we propose influence tuning--a procedure that leverages model interpretations to update the model parameters towards a plausible interpretation (rather than an interpretation that relies on spurious patterns in the data) in addition to learning to predict the task labels. we show that in a controlled setup, influence tuning can help deconfounding the model from spurious patterns in data, significantly outperforming baseline methods that use adversarial training. ","1962":"question answering (qa) has been a long-standing research topic in ai and nlp fields, and a wealth of studies have been conducted to attempt to equip qa systems with human-level reasoning capability. to approximate the complicated human reasoning process, state-of-the-art qa systems commonly use pre-trained language models (lms) to access knowledge encoded in lms together with elaborately designed modules based on graph neural networks (gnns) to perform reasoning over knowledge graphs (kgs). however, many problems remain open regarding the reasoning functionality of these gnn-based modules. can these gnn-based modules really perform a complex reasoning process? are they under- or over-complicated for qa? to open the black box of gnn and investigate these problems, we dissect state-of-the-art gnn modules for qa and analyze their reasoning capability. we discover that even a very simple graph neural counter can outperform all the existing gnn modules on commonsenseqa and openbookqa, two popular qa benchmark datasets which heavily rely on knowledge-aware reasoning. our work reveals that existing knowledge-aware gnn modules may only carry out some simple reasoning such as counting. it remains a challenging open problem to build comprehensive reasoning modules for knowledge-powered qa. ","1963":"documents are central to many business systems, and include forms, reports, contracts, invoices or purchase orders. the information in documents is typically in natural language, but can be organized in various layouts and formats. there have been recent spurt of interest in understanding document content with novel deep learning architectures. however, document understanding tasks need dense information annotations, which are costly to scale and generalize. several active learning techniques have been proposed to reduce the overall budget of annotation while maintaining the performance of the underlying deep learning model. however, most of these techniques work only for classification problems. but content detection is a more complex task, and has been scarcely explored in active learning literature. in this paper, we propose \\textit{opad}, a novel framework using reinforcement policy for active learning in content detection tasks for documents. the proposed framework learns the acquisition function to decide the samples to be selected while optimizing performance metrics that the tasks typically have. furthermore, we extend to weak labelling scenarios to further reduce the cost of annotation significantly. we propose novel rewards to account for class imbalance and user feedback in the annotation interface, to improve the active learning method. we show superior performance of the proposed \\textit{opad} framework for active learning for various tasks related to document understanding like layout parsing, object detection and named entity recognition. ablation studies for human feedback and class imbalance rewards are presented, along with a comparison of annotation times for different approaches. ","1964":"question answering (qa) is a task in natural language processing that has seen considerable growth after the advent of transformers. there has been a surge in qa datasets that have been proposed to challenge natural language processing models to improve human and existing model performance. many pre-trained language models have proven to be incredibly effective at the task of extractive question answering. however, generalizability remains as a challenge for the majority of these models. that is, some datasets require models to reason more than others. in this paper, we train various pre-trained language models and fine-tune them on multiple question answering datasets of varying levels of difficulty to determine which of the models are capable of generalizing the most comprehensively across different datasets. further, we propose a new architecture, bert-bilstm, and compare it with other language models to determine if adding more bidirectionality can improve model performance. using the f1-score as our metric, we find that the roberta and bart pre-trained models perform the best across all datasets and that our bert-bilstm model outperforms the baseline bert model. ","1965":"fast contextual adaptation has shown to be effective in improving automatic speech recognition (asr) of rare words and when combined with an on-device personalized training, it can yield an even better recognition result. however, the traditional re-scoring approaches based on an external language model is prone to diverge during the personalized training. in this work, we introduce a model-based end-to-end contextual adaptation approach that is decoder-agnostic and amenable to on-device personalization. our on-device simulation experiments demonstrate that the proposed approach outperforms the traditional re-scoring technique by 12% relative wer and 15.7% entity mention specific f1-score in a continues personalization scenario. ","1966":"we investigate transfer learning based on pre-trained neural machine translation models to translate between (low-resource) similar languages. this work is part of our contribution to the wmt 2021 similar languages translation shared task where we submitted models for different language pairs, including french-bambara, spanish-catalan, and spanish-portuguese in both directions. our models for catalan-spanish ($82.79$ bleu) and portuguese-spanish ($87.11$ bleu) rank top 1 in the official shared task evaluation, and we are the only team to submit models for the french-bambara pairs. ","1967":"aspect-based sentiment analysis (absa) accomplishes a fine-grained analysis that defines the aspects of a given document or sentence and the sentiments conveyed regarding each aspect. this level of analysis is the most detailed version that is capable of exploring the nuanced viewpoints of the reviews. the bulk of study in absa focuses on english with very little work available in arabic. most previous work in arabic has been based on regular methods of machine learning that mainly depends on a group of rare resources and tools for analyzing and processing arabic content such as lexicons, but the lack of those resources presents another challenge. in order to address these challenges, deep learning (dl)-based methods are proposed using two models based on gated recurrent units (gru) neural networks for absa. the first is a dl model that takes advantage of word and character representations by combining bidirectional gru, convolutional neural network (cnn), and conditional random field (crf) making up the (bgru-cnn-crf) model to extract the main opinionated aspects (ote). the second is an interactive attention network based on bidirectional gru (ian-bgru) to identify sentiment polarity toward extracted aspects. we evaluated our models using the benchmarked arabic hotel reviews dataset. the results indicate that the proposed methods are better than baseline research on both tasks having 39.7% enhancement in f1-score for opinion target extraction (t2) and 7.58% in accuracy for aspect-based sentiment polarity classification (t3). achieving f1 score of 70.67% for t2, and accuracy of 83.98% for t3. ","1968":"while conventional wisdom suggests that more aggressively filtering data from low-quality sources like common crawl always monotonically improves the quality of training data, we find that aggressive filtering can in fact lead to a decrease in model quality on a wide array of downstream tasks for a gpt-like language model. we speculate that this is because optimizing sufficiently strongly for a proxy metric harms performance on the true objective, suggesting a need for more robust filtering objectives when attempting to filter more aggressively. we hope this work leads to detailed analysis of the effects of dataset filtering design choices on downstream model performance in future work. ","1969":"block-based environments are visual programming environments, which are becoming more and more popular because of their ease of use. the ease of use comes thanks to their intuitive graphical representation and structural metaphors (jigsaw-like puzzles) to display valid combinations of language constructs to the users. part of the current popularity of block-based environments is thanks to scratch. as a result they are often associated with tools for children or young learners. however, it is unclear how these types of programming environments are developed and used in general. so we conducted a systematic literature review on block-based environments by studying 152 papers published between 2014 and 2020, and a non-systematic tool review of 32 block-based environments. in particular, we provide a helpful inventory of block-based editors for end-users on different topics and domains. likewise, we focused on identifying the main components of block-based environments, how they are engineered, and how they are used. this survey should be equally helpful for language engineering researchers and language engineers alike. ","1970":"recent progress in pre-trained neural language models has significantly improved the performance of many natural language processing (nlp) tasks. in this paper we propose a new model architecture deberta (decoding-enhanced bert with disentangled attention) that improves the bert and roberta models using two novel techniques. the first is the disentangled attention mechanism, where each word is represented using two vectors that encode its content and position, respectively, and the attention weights among words are computed using disentangled matrices on their contents and relative positions, respectively. second, an enhanced mask decoder is used to incorporate absolute positions in the decoding layer to predict the masked tokens in model pre-training. in addition, a new virtual adversarial training method is used for fine-tuning to improve models' generalization. we show that these techniques significantly improve the efficiency of model pre-training and the performance of both natural language understanding (nlu) and natural langauge generation (nlg) downstream tasks. compared to roberta-large, a deberta model trained on half of the training data performs consistently better on a wide range of nlp tasks, achieving improvements on mnli by +0.9% (90.2% vs. 91.1%), on squad v2.0 by +2.3% (88.4% vs. 90.7%) and race by +3.6% (83.2% vs. 86.8%). notably, we scale up deberta by training a larger version that consists of 48 transform layers with 1.5 billion parameters. the significant performance boost makes the single deberta model surpass the human performance on the superglue benchmark (wang et al., 2019a) for the first time in terms of macro-average score (89.9 versus 89.8), and the ensemble deberta model sits atop the superglue leaderboard as of january 6, 2021, out performing the human baseline by a decent margin (90.3 versus 89.8). ","1971":"all-neural, end-to-end asr systems gained rapid interest from the speech recognition community. such systems convert speech input to text units using a single trainable neural network model. e2e models require large amounts of paired speech text data that is expensive to obtain. the amount of data available varies across different languages and dialects. it is critical to make use of all these data so that both low resource languages and high resource languages can be improved. when we want to deploy an asr system for a new application domain, the amount of domain specific training data is very limited. to be able to leverage data from existing domains is important for asr accuracy in the new domain. in this paper, we treat all these aspects as categorical information in an asr system, and propose a simple yet effective way to integrate categorical features into e2e model. we perform detailed analysis on various training strategies, and find that building a joint model that includes categorical features can be more accurate than multiple independently trained models. ","1972":"a \"bigger is better\" explosion in the number of parameters in deep neural networks has made it increasingly challenging to make state-of-the-art networks accessible in compute-restricted environments. compression techniques have taken on renewed importance as a way to bridge the gap. however, evaluation of the trade-offs incurred by popular compression techniques has been centered on high-resource datasets. in this work, we instead consider the impact of compression in a data-limited regime. we introduce the term low-resource double bind to refer to the co-occurrence of data limitations and compute resource constraints. this is a common setting for nlp for low-resource languages, yet the trade-offs in performance are poorly studied. our work offers surprising insights into the relationship between capacity and generalization in data-limited regimes for the task of machine translation. our experiments on magnitude pruning for translations from english into yoruba, hausa, igbo and german show that in low-resource regimes, sparsity preserves performance on frequent sentences but has a disparate impact on infrequent ones. however, it improves robustness to out-of-distribution shifts, especially for datasets that are very distinct from the training distribution. our findings suggest that sparsity can play a beneficial role at curbing memorization of low frequency attributes, and therefore offers a promising solution to the low-resource double bind. ","1973":"intent detection is a crucial task in any natural language understanding (nlu) system and forms the foundation of a task-oriented dialogue system. to build high-quality real-world conversational solutions for edge devices, there is a need for deploying intent detection model on device. this necessitates a light-weight, fast, and accurate model that can perform efficiently in a resource-constrained environment. to this end, we propose lidsnet, a novel lightweight on-device intent detection model, which accurately predicts the message intent by utilizing a deep siamese network for learning better sentence representations. we use character-level features to enrich the sentence-level representations and empirically demonstrate the advantage of transfer learning by utilizing pre-trained embeddings. furthermore, to investigate the efficacy of the modules in our architecture, we conduct an ablation study and arrive at our optimal model. experimental results prove that lidsnet achieves state-of-the-art competitive accuracy of 98.00% and 95.97% on snips and atis public datasets respectively, with under 0.59m parameters. we further benchmark lidsnet against fine-tuned berts and show that our model is at least 41x lighter and 30x faster during inference than mobilebert on samsung galaxy s20 device, justifying its efficiency on resource-constrained edge devices. ","1974":"automatic identification of cause-effect spans in financial documents is important for causality modelling and understanding reasons that lead to financial events. to exploit the observation that words are more connected to other words with the same cause-effect type in a dependency tree, we construct useful graph embeddings by incorporating dependency relation features through a graph neural network. our model builds on a baseline bert token classifier with viterbi decoding, and outperforms this baseline in cross-validation and during the competition. in the official run of fincausal 2021, we obtained precision, recall, and f1 scores of 95.56%, 95.56% and 95.57% that all ranked 1st place, and an exact match score of 86.05% which ranked 3rd place. ","1975":"maximum likelihood estimation (mle) is the predominant algorithm for training text generation models. this paradigm relies on direct supervision examples, which is not applicable to many emerging applications, such as generating adversarial attacks or generating prompts to control language models. reinforcement learning (rl) on the other hand offers a more flexible solution by allowing users to plug in arbitrary task metrics as reward. yet previous rl algorithms for text generation, such as policy gradient (on-policy rl) and q-learning (off-policy rl), are often notoriously inefficient or unstable to train due to the large sequence space and the sparse reward received only at the end of sequences. in this paper, we introduce a new rl formulation for text generation from the soft q-learning (sql) perspective. it enables us to draw from the latest rl advances, such as path consistency learning, to combine the best of on-\/off-policy updates, and learn effectively from sparse reward. we apply the approach to a wide range of text generation tasks, including learning from noisy\/negative examples, adversarial attacks, and prompt generation. experiments show our approach consistently outperforms both task-specialized algorithms and the previous rl methods. ","1976":"recent studies have proposed different methods to improve multilingual word representations in contextualized settings including techniques that align between source and target embedding spaces. for contextualized embeddings, alignment becomes more complex as we additionally take context into consideration. in this work, we propose using optimal transport (ot) as an alignment objective during fine-tuning to further improve multilingual contextualized representations for downstream cross-lingual transfer. this approach does not require word-alignment pairs prior to fine-tuning that may lead to sub-optimal matching and instead learns the word alignments within context in an unsupervised manner. it also allows different types of mappings due to soft matching between source and target sentences. we benchmark our proposed method on two tasks (xnli and xquad) and achieve improvements over baselines as well as competitive results compared to similar recent works. ","1977":"word embeddings are a fixed, distributional representation of the context of words in a corpus learned from word co-occurrences. despite their proven utility in machine learning tasks, word embedding models may capture uneven semantic and syntactic representations, and can inadvertently reflect various kinds of bias present within corpora upon which they were trained. it has been demonstrated that post-processing of word embeddings to apply information found in lexical dictionaries can improve the semantic associations, thus improving their quality. building on this idea, we propose a system that incorporates an adaptation of word embedding post-processing, which we call \"interactive refitting\", to address some of the most daunting qualitative problems found in word embeddings. our approach allows a human to identify and address potential quality issues with word embeddings interactively. this has the advantage of negating the question of who decides what constitutes bias or what other quality issues may affect downstream tasks. it allows each organization or entity to address concerns they may have at a fine grained level and to do so in an iterative and interactive fashion. it also allows for better insight into what effect word embeddings, and refinements to word embeddings, have on machine learning pipelines. ","1978":"finite-state transducers (fsts) are frequently used in speech recognition. transducer composition is an essential operation for combining different sources of information at different granularities. however, composition is also one of the more computationally expensive operations. due to the heterogeneous structure of fsts, parallel algorithms for composition are suboptimal in efficiency, generality, or both. we propose an algorithm for parallel composition and implement it on graphics processing units. we benchmark our parallel algorithm on the composition of random graphs and the composition of graphs commonly used in speech recognition. the parallel composition scales better with the size of the input graphs and for large graphs can be as much as 10 to 30 times faster than a sequential cpu algorithm. ","1979":"learning good representations on multi-relational graphs is essential to knowledge base completion (kbc). in this paper, we propose a new self-supervised training objective for multi-relational graph representation learning, via simply incorporating relation prediction into the commonly used 1vsall objective. the new training objective contains not only terms for predicting the subject and object of a given triple, but also a term for predicting the relation type. we analyse how this new objective impacts multi-relational learning in kbc: experiments on a variety of datasets and models show that relation prediction can significantly improve entity ranking, the most widely used evaluation task for kbc, yielding a 6.1% increase in mrr and 9.9% increase in hits@1 on fb15k-237 as well as a 3.1% increase in mrr and 3.4% in hits@1 on aristo-v4. moreover, we observe that the proposed objective is especially effective on highly multi-relational datasets, i.e. datasets with a large number of predicates, and generates better representations when larger embedding sizes are used. ","1980":"recognition of uncommon words such as names and technical terminology is important to understanding conversations in context. however, the ability to recognise such words remains a challenge in modern automatic speech recognition (asr) systems.   in this paper, we propose a simple but powerful asr decoding method that can better recognise these uncommon keywords, which in turn enables better readability of the results. the method boosts the probabilities of given keywords in a beam search based on acoustic model predictions. the method does not require any training in advance.   we demonstrate the effectiveness of our method on the librispeeech test sets and also internal data of real-world conversations. our method significantly boosts keyword accuracy on the test sets, while maintaining the accuracy of the other words, and as well as providing significant qualitative improvements. this method is applicable to other tasks such as machine translation, or wherever unseen and difficult keywords need to be recognised in beam search. ","1981":"recently, it has been argued that encoder-decoder models can be made more interpretable by replacing the softmax function in the attention with its sparse variants. in this work, we introduce a novel, simple method for achieving sparsity in attention: we replace the softmax activation with a relu, and show that sparsity naturally emerges from such a formulation. training stability is achieved with layer normalization with either a specialized initialization or an additional gating function. our model, which we call rectified linear attention (rela), is easy to implement and more efficient than previously proposed sparse attention mechanisms. we apply rela to the transformer and conduct experiments on five machine translation tasks. rela achieves translation performance comparable to several strong baselines, with training and decoding speed similar to that of the vanilla attention. our analysis shows that rela delivers high sparsity rate and head diversity, and the induced cross attention achieves better accuracy with respect to source-target word alignment than recent sparsified softmax-based models. intriguingly, rela heads also learn to attend to nothing (i.e. 'switch off') for some queries, which is not possible with sparsified softmax alternatives. ","1982":"this survey provides an overview of the evolution of visually grounded models of spoken language over the last 20 years. such models are inspired by the observation that when children pick up a language, they rely on a wide range of indirect and noisy clues, crucially including signals from the visual modality co-occurring with spoken utterances. several fields have made important contributions to this approach to modeling or mimicking the process of learning language: machine learning, natural language and speech processing, computer vision and cognitive science. the current paper brings together these contributions in order to provide a useful introduction and overview for practitioners in all these areas. we discuss the central research questions addressed, the timeline of developments, and the datasets which enabled much of this work. we then summarize the main modeling architectures and offer an exhaustive overview of the evaluation metrics and analysis techniques. ","1983":"it is presented here a machine learning-based (ml) natural language processing (nlp) approach capable to automatically recognize and extract categorical and numerical parameters from a corpus of articles. the approach (named a.rix) operates with a concomitant\/interchangeable use of ml models such as neuron networks (nns), latent semantic analysis (lsa), naive-bayes classifiers (nbc), and a pattern recognition model using regular expression (regex). a corpus of 7,873 scientific articles dealing with natural products (nps) was used to demonstrate the efficiency of the a.rix engine. the engine automatically extracts categorical and numerical parameters such as (i) the plant species from which active molecules are extracted, (ii) the microorganisms species for which active molecules can act against, and (iii) the values of minimum inhibitory concentration (mic) against these microorganisms. the parameters are extracted without part-of-speech tagging (pos) and named entity recognition (ner) approaches (i.e. without the need of text annotation), and the models training is performed with unsupervised approaches. in this way, a.rix can be essentially used on articles from any scientific field. finally, it can potentially make obsolete the current article reviewing process in some areas, especially those in which machine learning models capture texts structure, text semantics, and latent knowledge. ","1984":"this article introduces to the interactive leipzig corpus miner (ilcm) - a newly released, open-source software to perform automatic content analysis. since the ilcm is based on the r-programming language, its generic text mining procedures provided via a user-friendly graphical user interface (gui) can easily be extended using the integrated ide rstudio-server or numerous other interfaces in the tool. furthermore, the ilcm offers various possibilities to use quantitative and qualitative research approaches in combination. some of these possibilities will be presented in more detail in the following. ","1985":"contextualised word embeddings generated from neural language models (nlms), such as bert, represent a word with a vector that considers the semantics of the target word as well its context. on the other hand, static word embeddings such as glove represent words by relatively low-dimensional, memory- and compute-efficient vectors but are not sensitive to the different senses of the word. we propose context derived embeddings of senses (cdes), a method that extracts sense related information from contextualised embeddings and injects it into static embeddings to create sense-specific static embeddings. experimental results on multiple benchmarks for word sense disambiguation and sense discrimination tasks show that cdes can accurately learn sense-specific static embeddings reporting comparable performance to the current state-of-the-art sense embeddings. ","1986":"weakly-supervised text classification has received much attention in recent years for it can alleviate the heavy burden of annotating massive data. among them, keyword-driven methods are the mainstream where user-provided keywords are exploited to generate pseudo-labels for unlabeled texts. however, existing methods treat keywords independently, thus ignore the correlation among them, which should be useful if properly exploited. in this paper, we propose a novel framework called classkg to explore keyword-keyword correlation on keyword graph by gnn. our framework is an iterative process. in each iteration, we first construct a keyword graph, so the task of assigning pseudo labels is transformed to annotating keyword subgraphs. to improve the annotation quality, we introduce a self-supervised task to pretrain a subgraph annotator, and then finetune it. with the pseudo labels generated by the subgraph annotator, we then train a text classifier to classify the unlabeled texts. finally, we re-extract keywords from the classified texts. extensive experiments on both long-text and short-text datasets show that our method substantially outperforms the existing ones ","1987":"multi-modal word semantics aims to enhance embeddings with perceptual input, assuming that human meaning representation is grounded in sensory experience. most research focuses on evaluation involving direct visual input, however, visual grounding can contribute to linguistic applications as well. another motivation for this paper is the growing need for more interpretable models and for evaluating model efficiency regarding size and performance. this work explores the impact of visual information for semantics when the evaluation involves no direct visual input, specifically semantic similarity and relatedness. we investigate a new embedding type in-between linguistic and visual modalities, based on the structured annotations of visual genome. we compare uni- and multi-modal models including structured, linguistic and image based representations. we measure the efficiency of each model with regard to data and model size, modality \/ data distribution and information gain. the analysis includes an interpretation of embedding structures. we found that this new embedding conveys complementary information for text based embeddings. it achieves comparable performance in an economic way, using orders of magnitude less resources than visual models. ","1988":"recent studies have shown that deep neural networks are vulnerable to intentionally crafted adversarial examples, and various methods have been proposed to defend against adversarial word-substitution attacks for neural nlp models. however, there is a lack of systematic study on comparing different defense approaches under the same attacking setting. in this paper, we seek to fill the gap of systematic studies through comprehensive researches on understanding the behavior of neural text classifiers trained by various defense methods under representative adversarial attacks. in addition, we propose an effective method to further improve the robustness of neural text classifiers against such attacks and achieved the highest accuracy on both clean and adversarial examples on agnews and imdb datasets by a significant margin. ","1989":"pre-trained models are widely used in fine-tuning downstream tasks with linear classifiers optimized by the cross-entropy loss, which might face robustness and stability problems. these problems can be improved by learning representations that focus on similarities in the same class and contradictions in different classes when making predictions. in this paper, we utilize the k-nearest neighbors classifier in pre-trained model fine-tuning. for this knn classifier, we introduce a supervised momentum contrastive learning framework to learn the clustered representations of the supervised downstream tasks. extensive experiments on text classification tasks and robustness tests show that by incorporating knns with the traditional fine-tuning process, we can obtain significant improvements on the clean accuracy in both rich-source and few-shot settings and can improve the robustness against adversarial attacks. \\footnote{all codes is available at https:\/\/github.com\/linyanglee\/knn-bert} ","1990":"this paper examines the challenging problem of learning representations of entities and relations in a complex multi-relational knowledge graph. we propose hitter, a hierarchical transformer model to jointly learn entity-relation composition and relational contextualization based on a source entity's neighborhood. our proposed model consists of two different transformer blocks: the bottom block extracts features of each entity-relation pair in the local neighborhood of the source entity and the top block aggregates the relational information from outputs of the bottom block. we further design a masked entity prediction task to balance information from the relational context and the source entity itself. experimental results show that hitter achieves new state-of-the-art results on multiple link prediction datasets. we additionally propose a simple approach to integrate hitter into bert and demonstrate its effectiveness on two freebase factoid question answering datasets. ","1991":"transformer architectures have achieved state-of-the-art results on a variety of sequence modeling tasks. however, their attention mechanism comes with a quadratic complexity in sequence lengths, making the computational overhead prohibitive, especially for long sequences. attention context can be seen as a random-access memory with each token taking a slot. under this perspective, the memory size grows linearly with the sequence length, and so does the overhead of reading from it. one way to improve the efficiency is to bound the memory size. we show that disparate approaches can be subsumed into one abstraction, attention with bounded-memory control (abc), and they vary in their organization of the memory. abc reveals new, unexplored possibilities. first, it connects several efficient attention variants that would otherwise seem apart. second, this abstraction gives new insights--an established approach (wang et al., 2020b) previously thought to be not applicable in causal attention, actually is. last, we present a new instance of abc, which draws inspiration from existing abc approaches, but replaces their heuristic memory-organizing functions with a learned, contextualized one. our experiments on language modeling, machine translation, and masked language model finetuning show that our approach outperforms previous efficient attention models; compared to the strong transformer baselines, it significantly improves the inference time and space efficiency with no or negligible accuracy loss. ","1992":"modern medical diagnosis relies on precise pain assessment tools in translating clinical information from patient to physician. the mcgill pain questionnaire (mpq) is a clinical pain assessment technique that utilizes 78 adjectives of different intensities in 20 different categories to quantity a patient's pain. the questionnaire's efficacy depends on a predictable pattern of adjective use by patients experiencing pain. in this study, i recreate the mpq's adjective intensity orderings using data gathered from patient forums and modern nlp techniques. i extract adjective intensity relationships by searching for key linguistic contexts, and then combine the relationship information to form robust adjective scales. of 17 adjective relationships predicted by this research, only 4 diverge from the mpq's orderings, which is statistically significant at the 0.1 alpha level. the results suggest predictable patterns of adjective use by people experiencing pain, but call into question the mpq's categories for grouping adjectives. ","1993":"pre-trained natural language processing (nlp) models can be easily adapted to a variety of downstream language tasks. this significantly accelerates the development of language models. however, nlp models have been shown to be vulnerable to backdoor attacks, where a pre-defined trigger word in the input text causes model misprediction. previous nlp backdoor attacks mainly focus on some specific tasks. this makes those attacks less general and applicable to other kinds of nlp models and tasks. in this work, we propose \\name, the first task-agnostic backdoor attack against the pre-trained nlp models. the key feature of our attack is that the adversary does not need prior information about the downstream tasks when implanting the backdoor to the pre-trained model. when this malicious model is released, any downstream models transferred from it will also inherit the backdoor, even after the extensive transfer learning process. we further design a simple yet effective strategy to bypass a state-of-the-art defense. experimental results indicate that our approach can compromise a wide range of downstream nlp tasks in an effective and stealthy way. ","1994":"one important challenge of applying deep learning to electronic health records (ehr) is the complexity of their multimodal structure. ehr usually contains a mixture of structured (codes) and unstructured (free-text) data with sparse and irregular longitudinal features -- all of which doctors utilize when making decisions. in the deep learning regime, determining how different modality representations should be fused together is a difficult problem, which is often addressed by handcrafted modeling and intuition. in this work, we extend state-of-the-art neural architecture search (nas) methods and propose multimodal fusion architecture search (mufasa) to simultaneously search across multimodal fusion strategies and modality-specific architectures for the first time. we demonstrate empirically that our mufasa method outperforms established unimodal nas on public ehr data with comparable computation costs. in addition, mufasa produces architectures that outperform transformer and evolved transformer. compared with these baselines on ccs diagnosis code prediction, our discovered models improve top-5 recall from 0.88 to 0.91 and demonstrate the ability to generalize to other ehr tasks. studying our top architecture in depth, we provide empirical evidence that mufasa's improvements are derived from its ability to both customize modeling for each data modality and find effective fusion strategies. ","1995":"multilabel conditional image generation is a challenging problem in computer vision. in this work we propose multi-ingredient pizza generator (mpg), a conditional generative neural network (gan) framework for synthesizing multilabel images. we design mpg based on a state-of-the-art gan structure called stylegan2, in which we develop a new conditioning technique by enforcing intermediate feature maps to learn scalewise label information. because of the complex nature of the multilabel image generation problem, we also regularize synthetic image by predicting the corresponding ingredients as well as encourage the discriminator to distinguish between matched image and mismatched image. to verify the efficacy of mpg, we test it on pizza10, which is a carefully annotated multi-ingredient pizza image dataset. mpg can successfully generate photo-realist pizza images with desired ingredients. the framework can be easily extend to other multilabel image generation scenarios. ","1996":"enhancing the user experience is an essential task for application service providers. for instance, two users living wide apart may have different tastes of food. a food recommender mobile application installed on an edge device might want to learn from user feedback (reviews) to satisfy the client's needs pertaining to distinct domains. retrieving user data comes at the cost of privacy while asking for model parameters trained on a user device becomes space inefficient at a large scale. in this work, we propose an approach to learn a central (global) model from the federation of (local) models which are trained on user-devices, without disclosing the local data or model parameters to the server. we propose a federation mechanism for the problems with natural similarity metric between the labels which commonly appear in natural language understanding (nlu) tasks. to learn the global model, the objective is to minimize the optimal transport cost of the global model's predictions from the confident sum of soft-targets assigned by local models. the confidence (a model weighting scheme) score of a model is defined as the l2 distance of a model's prediction from its probability bias. the method improves the global model's performance over the baseline designed on three nlu tasks with intrinsic label space semantics, i.e., fine-grained sentiment analysis, emotion recognition in conversation, and natural language inference. we make our codes public at https:\/\/github.com\/declare-lab\/sinkhorn-loss. ","1997":"face aging techniques have used generative adversarial networks (gans) and style transfer learning to transform one's appearance to look younger\/older. identity is maintained by conditioning these generative networks on a learned vector representation of the source content. in this work, we apply a similar approach to age a speaker's voice, referred to as voice aging. we first analyze the classification of a speaker's age by training a convolutional neural network (cnn) on the speaker's voice and face data from common voice and voxceleb datasets. we generate aged voices from style transfer to transform an input spectrogram to various ages and demonstrate our method on a mobile app. ","1998":"we investigate how neural language models acquire individual words during training, extracting learning curves and ages of acquisition for over 600 words on the macarthur-bates communicative development inventory (fenson et al., 2007). drawing on studies of word acquisition in children, we evaluate multiple predictors for words' ages of acquisition in lstms, bert, and gpt-2. we find that the effects of concreteness, word length, and lexical class are pointedly different in children and language models, reinforcing the importance of interaction and sensorimotor experience in child language acquisition. language models rely far more on word frequency than children, but like children, they exhibit slower learning of words in longer utterances. interestingly, models follow consistent patterns during training for both unidirectional and bidirectional models, and for both lstm and transformer architectures. models predict based on unigram token frequencies early in training, before transitioning loosely to bigram probabilities, eventually converging on more nuanced predictions. these results shed light on the role of distributional learning mechanisms in children, while also providing insights for more human-like language acquisition in language models. ","1999":"recent studies have demonstrated that the performance of transformers on the task of language modeling obeys a power-law relationship with model size over six orders of magnitude. while transformers exhibit impressive scaling, their performance hinges on processing large amounts of data, and their computational and memory requirements grow quadratically with sequence length. motivated by these considerations, we construct a legendre memory unit based model that introduces a general prior for sequence processing and exhibits an $o(n)$ and $o(n \\ln n)$ (or better) dependency for memory and computation respectively. over three orders of magnitude, we show that our new architecture attains the same accuracy as transformers with 10x fewer tokens. we also show that for the same amount of training our model improves the loss over transformers about as much as transformers improve over lstms. additionally, we demonstrate that adding global self-attention complements our architecture and the augmented model improves performance even further. ","2000":"parallel corpus is a critical resource in machine learning-based translation. the task of collecting, extracting, and aligning texts in order to build an acceptable corpus for doing the translation is very tedious most especially for low-resource languages. in this paper, we present the efforts made to build a parallel corpus for cebuano and filipino from two different domains: biblical texts and the web. for the biblical resource, subword unit translation for verbs and copy-able approach for nouns were applied to correct inconsistencies in the translation. this correction mechanism was applied as a preprocessing technique. on the other hand, for wikipedia being the main web resource, commonly occurring topic segments were extracted from both the source and the target languages. these observed topic segments are unique in 4 different categories. the identification of these topic segments may be used for the automatic extraction of sentences. a recurrent neural network was used to implement the translation using opennmt sequence modeling tool in tensorflow. the two different corpora were then evaluated by using them as two separate inputs in the neural network. results have shown a difference in bleu scores in both corpora. ","2001":"multilingual language models achieve impressive zero-shot accuracies in many languages in complex tasks such as natural language inference (nli). examples in nli (and equivalent complex tasks) often pertain to various types of sub-tasks, requiring different kinds of reasoning. certain types of reasoning have proven to be more difficult to learn in a monolingual context, and in the crosslingual context, similar observations may shed light on zero-shot transfer efficiency and few-shot sample selection. hence, to investigate the effects of types of reasoning on transfer performance, we propose a category-annotated multilingual nli dataset and discuss the challenges to scale monolingual annotations to multiple languages. we statistically observe interesting effects that the confluence of reasoning types and language similarities have on transfer performance. ","2002":"tokenization is a fundamental preprocessing step for almost all nlp tasks. in this paper, we propose efficient algorithms for the wordpiece tokenization used in bert, from single-word tokenization to general text (e.g., sentence) tokenization. when tokenizing a single word, wordpiece uses a longest-match-first strategy, known as maximum matching. the best known algorithms so far are o(n^2) (where n is the input length) or o(nm) (where m is the maximum vocabulary token length). we propose a novel algorithm whose tokenization complexity is strictly o(n). our method is inspired by the aho-corasick algorithm. we introduce additional linkages on top of the trie built from the vocabulary, allowing smart transitions when the trie matching cannot continue. for general text, we further propose an algorithm that combines pre-tokenization (splitting the text into words) and our linear-time wordpiece method into a single pass. experimental results show that our method is 8.2x faster than huggingface tokenizers and 5.1x faster than tensorflow text on average for general text tokenization. ","2003":"large natural language models (such as gpt-3 or t5) demonstrate impressive abilities across a range of general nlp tasks. here, we show that the knowledge embedded in such models provides a useful inductive bias, not just on traditional nlp tasks, but also in the nontraditional task of training a symbolic reasoning engine. we observe that these engines learn quickly and generalize in a natural way that reflects human intuition. for example, training such a system to model block-stacking might naturally generalize to stacking other types of objects because of structure in the real world that has been partially captured by the language describing it. we study several abstract textual reasoning tasks, such as object manipulation and navigation, and demonstrate multiple types of generalization to novel scenarios and the symbols that comprise them. we also demonstrate the surprising utility of \\textit{compositional learning}, where a learner dedicated to mastering a complicated task gains an advantage by training on relevant simpler tasks instead of jumping straight to the complicated task. ","2004":"this work introduces itihasa, a large-scale translation dataset containing 93,000 pairs of sanskrit shlokas and their english translations. the shlokas are extracted from two indian epics viz., the ramayana and the mahabharata. we first describe the motivation behind the curation of such a dataset and follow up with empirical analysis to bring out its nuances. we then benchmark the performance of standard translation models on this corpus and show that even state-of-the-art transformer architectures perform poorly, emphasizing the complexity of the dataset. ","2005":"massively pre-trained transformer models are computationally expensive to fine-tune, slow for inference, and have large storage requirements. recent approaches tackle these shortcomings by training smaller models, dynamically reducing the model size, and by training light-weight adapters. in this paper, we propose adapterdrop, removing adapters from lower transformer layers during training and inference, which incorporates concepts from all three directions. we show that adapterdrop can dynamically reduce the computational overhead when performing inference over multiple tasks simultaneously, with minimal decrease in task performances. we further prune adapters from adapterfusion, which improves the inference efficiency while maintaining the task performances entirely. ","2006":"little inquiry has explicitly addressed the role of action spaces in language-guided visual navigation -- either in terms of its effect on navigation success or the efficiency with which a robotic agent could execute the resulting trajectory. building on the recently released vln-ce setting for instruction following in continuous environments, we develop a class of language-conditioned waypoint prediction networks to examine this question. we vary the expressivity of these models to explore a spectrum between low-level actions and continuous waypoint prediction. we measure task performance and estimated execution time on a profiled locobot robot. we find more expressive models result in simpler, faster to execute trajectories, but lower-level actions can achieve better navigation metrics by approximating shortest paths better. further, our models outperform prior work in vln-ce and set a new state-of-the-art on the public leaderboard -- increasing success rate by 4% with our best model on this challenging task. ","2007":"the problem statement addressed in this work is : for a public sentiment classification api, how can we set up a classifier that works well on different types of data, having limited ability to annotate data from across domains. we show that given a large amount of unannotated data from across different domains and pseudolabels on this dataset generated by a classifier trained on a small annotated dataset from one domain, we can train a sentiment classifier that generalizes better across different datasets. ","2008":"large-scale pretraining instills large amounts of knowledge in deep neural networks. this, in turn, improves the generalization behavior of these models in downstream tasks. what exactly are the limits to the generalization benefits of large-scale pretraining? here, we report observations from some simple experiments aimed at addressing this question in the context of two semantic parsing tasks involving natural language, scan and cogs. we show that language models pretrained exclusively with non-english corpora, or even with programming language corpora, significantly improve out-of-distribution generalization in these benchmarks, compared with models trained from scratch, even though both benchmarks are english-based. this demonstrates the surprisingly broad transferability of pretrained representations and knowledge. pretraining with a large-scale protein sequence prediction task, on the other hand, mostly deteriorates the generalization performance in scan and cogs, suggesting that pretrained representations do not transfer universally and that there are constraints on the similarity between the pretraining and downstream domains for successful transfer. finally, we show that larger models are harder to train from scratch and their generalization accuracy is lower when trained up to convergence on the relatively small scan and cogs datasets, but the benefits of large-scale pretraining become much clearer with larger models. ","2009":"one of the most important incidents in the world in 2020 is the outbreak of the coronavirus. users on social networks publish a large number of comments about this event. these comments contain important hidden information of public opinion regarding this pandemic. in this research, a large number of coronavirus-related tweets are considered and analyzed using natural language processing and information retrieval science. initially, the location of the tweets is determined using a dictionary prepared through the geo-names geographic database, which contains detailed and complete information of places such as city names, streets, and postal codes. then, using a large dictionary prepared from the terms of economics, related tweets are extracted and sentiments corresponded to tweets are analyzed with the help of the roberta language-based model, which has high accuracy and good performance. finally, the frequency chart of tweets related to the economy and their sentiment scores (positive and negative tweets) is plotted over time for the entire world and the top 10 economies. from the analysis of the charts, we learn that the reason for publishing economic tweets is not only the increase in the number of people infected with the coronavirus but also imposed restrictions and lockdowns in countries. the consequences of these restrictions include the loss of millions of jobs and the economic downturn. ","2010":"recent models in developing summarization systems consist of millions of parameters and the model performance is highly dependent on the abundance of training data. while most existing summarization corpora contain data in the order of thousands to one million, generation of large-scale summarization datasets in order of couple of millions is yet to be explored. practically, more data is better at generalizing the training patterns to unseen data. in this paper, we introduce tldr9+ -- a large-scale summarization dataset -- containing over 9 million training instances extracted from reddit discussion forum (https:\/\/github.com\/sajastu\/reddit_collector). this dataset is specifically gathered to perform extreme summarization (i.e., generating one-sentence summary in high compression and abstraction) and is more than twice larger than the previously proposed dataset. we go one step further and with the help of human annotations, we distill a more fine-grained dataset by sampling high-quality instances from tldr9+ and call it tldrhq dataset. we further pinpoint different state-of-the-art summarization models on our proposed datasets. ","2011":"we propose a 'legal approach' to hate speech detection by operationalization of the decision as to whether a post is subject to criminal law into an nlp task. comparing existing regulatory regimes for hate speech, we base our investigation on the european union's framework as it provides a widely applicable legal minimum standard. accurately judging whether a post is punishable or not usually requires legal training. we show that, by breaking the legal assessment down into a series of simpler sub-decisions, even laypersons can annotate consistently. based on a newly annotated dataset, our experiments show that directly learning an automated model of punishable content is challenging. however, learning the two sub-tasks of `target group' and `targeting conduct' instead of an end-to-end approach to punishability yields better results. overall, our method also provides decisions that are more transparent than those of end-to-end models, which is a crucial point in legal decision-making. ","2012":"language identification (lid), a recommended initial step to automatic speech recognition (asr), is used to detect a spoken language from audio specimens. in state-of-the-art systems capable of multilingual speech processing, however, users have to explicitly set one or more languages before using them. lid, therefore, plays a very important role in situations where asr based systems cannot parse the uttered language in multilingual contexts causing failure in speech recognition. we propose an attention based convolutional recurrent neural network (crnn with attention) that works on mel-frequency cepstral coefficient (mfcc) features of audio specimens. additionally, we reproduce some state-of-the-art approaches, namely convolutional neural network (cnn) and convolutional recurrent neural network (crnn), and compare them to our proposed method. we performed extensive evaluation on thirteen different indian languages and our model achieves classification accuracy over 98%. our lid model is robust to noise and provides 91.2% accuracy in a noisy scenario. the proposed model is easily extensible to new languages. ","2013":"predicting the potential success of a book in advance is vital in many applications. this could help both publishers and readers in their decision-making process whether or not a book is worth publishing and reading, respectively. in this paper, we propose a model that leverages pretrained sentence embeddings along with various readability scores for book success prediction. unlike previous methods, the proposed method requires no count-based, lexical, or syntactic features. instead, we use a convolutional neural network over pretrained sentence embeddings and leverage different readability scores through a simple concatenation operation. our proposed model outperforms strong baselines for this task by as large as 6.4\\% f1-score points. moreover, our experiments show that according to our model, only the first 1k sentences are good enough to predict the potential success of books. ","2014":"current research in dialogue systems is focused on conversational assistants working on short conversations in either task-oriented or open domain settings. in this paper, we focus on improving task-based conversational assistants online, primarily those working on document-type conversations (e.g., emails) whose contents may or may not be completely related to the assistant's task. we propose \"narle\" a deep reinforcement learning (rl) framework for improving the natural language understanding (nlu) component of dialogue systems online without the need to collect human labels for customer data. the proposed solution associates user emotion with the assistant's action and uses that to improve nlu models using policy gradients. for two intent classification problems, we empirically show that using reinforcement learning to fine tune the pre-trained supervised learning models improves performance up to 43%. furthermore, we demonstrate the robustness of the method to partial and noisy implicit feedback. ","2015":"detecting the user's intent and finding the corresponding slots among the utterance's words are important tasks in natural language understanding. their interconnected nature makes their joint modeling a standard part of training such models. moreover, data scarceness and specialized vocabularies pose additional challenges. recently, the advances in pre-trained language models, namely contextualized models such as elmo and bert have revolutionized the field by tapping the potential of training very large models with just a few steps of fine-tuning on a task-specific dataset. here, we leverage such models, namely bert and roberta, and we design a novel architecture on top of them. moreover, we propose an intent pooling attention mechanism, and we reinforce the slot filling task by fusing intent distributions, word features, and token representations. the experimental results on standard datasets show that our model outperforms both the current non-bert state of the art as well as some stronger bert-based baselines. ","2016":"with the success of neural network based modeling in automatic speech recognition (asr), many studies investigated acoustic modeling and learning of feature extractors directly based on the raw waveform. recently, one line of research has focused on unsupervised pre-training of feature extractors on audio-only data to improve downstream asr performance. in this work, we investigate the usefulness of one of these front-end frameworks, namely wav2vec, in a setting without additional untranscribed data for hybrid asr systems. we compare this framework both to the manually defined standard gammatone feature set, as well as to features extracted as part of the acoustic model of an asr system trained supervised. we study the benefits of using the pre-trained feature extractor and explore how to additionally exploit an existing acoustic model trained with different features. finally, we systematically examine combinations of the described features in order to further advance the performance. ","2017":"in this paper, we present the first multilingual faq dataset publicly available. we collected around 6m faq pairs from the web, in 21 different languages. although this is significantly larger than existing faq retrieval datasets, it comes with its own challenges: duplication of content and uneven distribution of topics. we adopt a similar setup as dense passage retrieval (dpr) and test various bi-encoders on this dataset. our experiments reveal that a multilingual model based on xlm-roberta achieves the best results, except for english. lower resources languages seem to learn from one another as a multilingual model achieves a higher mrr than language-specific ones. our qualitative analysis reveals the brittleness of the model on simple word changes. we publicly release our dataset, model and training script. ","2018":"knowledge grounded conversation models (kgcm) are usually based on a selection\/retrieval module and a generation module, trained separately or simultaneously, with or without having access to a gold knowledge option. with the introduction of large pre-trained generative models, the selection and generation part have become more and more entangled, shifting the focus towards enhancing knowledge incorporation (from multiple sources) instead of trying to pick the best knowledge option. these approaches however depend on knowledge labels and\/or a separate dense retriever for their best performance. in this work we study the unsupervised selection abilities of pre-trained generative models (e.g. bart) and show that by adding a score-and-aggregate module between encoder and decoder, they are capable of learning to pick the proper knowledge through minimising the language modelling loss (i.e. without having access to knowledge labels). trained as such, our model - k-mine - shows competitive selection and generation performance against models that benefit from knowledge labels and\/or separate dense retriever. ","2019":"text classification is a primary task in natural language processing (nlp). recently, graph neural networks (gnns) have developed rapidly and been applied to text classification tasks. although more complex models tend to achieve better performance, research highly depends on the computing power of the device used. in this article, we propose tent (https:\/\/github.com\/daisean\/tent) to obtain better text classification performance and reduce the reliance on computing power. specifically, we first establish a dependency analysis graph for each text and then convert each graph into its corresponding encoding tree. the representation of the entire graph is obtained by updating the representation of the non-leaf nodes in the encoding tree. experimental results show that our method outperforms other baselines on several datasets while having a simple structure and few parameters. ","2020":"this paper describes our approach (ur-iw-hnt) for the shared task of germeval2021 to identify toxic, engaging, and fact-claiming comments. we submitted three runs using an ensembling strategy by majority (hard) voting with multiple different bert models of three different types: german-based, twitter-based, and multilingual models. all ensemble models outperform single models, while bertweet is the winner of all individual models in every subtask. twitter-based models perform better than germanbert models, and multilingual models perform worse but by a small margin. ","2021":"in this paper we introduce the food drinks and groceries images multi lingual (foodi-ml) dataset. this dataset contains over 1.5m unique images and over 9.5m store names, product names descriptions, and collection sections gathered from the glovo application. the data made available corresponds to food, drinks and groceries products from 37 countries in europe, the middle east, africa and latin america. the dataset comprehends 33 languages, including 870k samples of languages of countries from eastern europe and western asia such as ukrainian and kazakh, which have been so far underrepresented in publicly available visio-linguistic datasets. the dataset also includes widely spoken languages such as spanish and english. to assist further research, we include a benchmark over the text-image retrieval task using adapt, a sota existing technique. ","2022":"automatic text summarization has been studied in a variety of domains and languages. however, this does not hold for the russian language. to overcome this issue, we present gazeta, the first dataset for summarization of russian news. we describe the properties of this dataset and benchmark several extractive and abstractive models. we demonstrate that the dataset is a valid task for methods of text summarization for russian. additionally, we prove the pretrained mbart model to be useful for russian text summarization. ","2023":"semantic sentence embeddings are usually supervisedly built minimizing distances between pairs of embeddings of sentences labelled as semantically similar by annotators. since big labelled datasets are rare, in particular for non-english languages, and expensive, recent studies focus on unsupervised approaches that require not-paired input sentences. we instead propose a language-independent approach to build large datasets of pairs of informal texts weakly similar, without manual human effort, exploiting twitter's intrinsic powerful signals of relatedness: replies and quotes of tweets. we use the collected pairs to train a transformer model with triplet-like structures, and we test the generated embeddings on twitter nlp similarity tasks (pit and turl) and stsb. we also introduce four new sentence ranking evaluation benchmarks of informal texts, carefully extracted from the initial collections of tweets, proving not only that our best model learns classical semantic textual similarity, but also excels on tasks where pairs of sentences are not exact paraphrases. ablation studies reveal how increasing the corpus size influences positively the results, even at 2m samples, suggesting that bigger collections of tweets still do not contain redundant information about semantic similarities. ","2024":"in this paper, we propose a general framework for mitigating the disparities of the predicted classes with respect to secondary attributes within the data (e.g., race, gender etc.). our proposed method involves learning a multi-objective function that in addition to learning the primary objective of predicting the primary class labels from the data, also employs a clustering-based heuristic to minimize the disparities of the class label distribution with respect to the cluster memberships, with the assumption that each cluster should ideally map to a distinct combination of attribute values. experiments demonstrate effective mitigation of cognitive biases on a benchmark dataset without the use of annotations of secondary attribute values (the zero-shot case) or with the use of a small number of attribute value annotations (the few-shot case). ","2025":"coronavirus disease (covid-19) is an infectious respiratory disease that was first discovered in late december 2019, in wuhan, china, and then spread worldwide causing a lot of panic and death. users of social networking sites such as facebook and twitter have been focused on reading, publishing, and sharing novelties, tweets, and articles regarding the newly emerging pandemic. a lot of these users often employ sarcasm to convey their intended meaning in a humorous, funny, and indirect way making it hard for computer-based applications to automatically understand and identify their goal and the harm level that they can inflect. motivated by the emerging need for annotated datasets that tackle these kinds of problems in the context of covid-19, this paper builds and releases aracovid19-ssd a manually annotated arabic covid-19 sarcasm and sentiment detection dataset containing 5,162 tweets. to confirm the practical utility of the built dataset, it has been carefully analyzed and tested using several classification models. ","2026":"with 17,000 pairs of sicilian-english translated sentences, arba sicula developed the first neural machine translator for the sicilian language. using small subword vocabularies, we trained small transformer models with high dropout parameters and achieved bleu scores in the upper 20s. then we supplemented our dataset with backtranslation and multilingual translation and pushed our scores into the mid 30s. we also attribute our success to incorporating theoretical information in our dataset. prior to training, we biased the subword vocabulary towards the desinences one finds in a textbook. and we included textbook exercises in our dataset. ","2027":"in automatic speech recognition (asr) rescoring, the hypothesis with the fewest errors should be selected from the n-best list using a language model (lm). however, lms are usually trained to maximize the likelihood of correct word sequences, not to detect asr errors. we propose an asr rescoring method for directly detecting errors with electra, which is originally a pre-training method for nlp tasks. electra is pre-trained to predict whether each word is replaced by bert or not, which can simulate asr error detection on large text corpora. to make this pre-training closer to asr error detection, we further propose an extended version of electra called phone-attentive electra (p-electra). in the pre-training of p-electra, each word is replaced by a phone-to-word conversion model, which leverages phone information to generate acoustically similar words. since our rescoring method is optimized for detecting errors, it can also be used for word-level confidence estimation. experimental evaluations on the librispeech and ted-lium2 corpora show that our rescoring method with electra is competitive with conventional rescoring methods with faster inference. electra also performs better in confidence estimation than bert because it can learn to detect inappropriate words not only in fine-tuning but also in pre-training. ","2028":"during this pandemic situation, extracting any relevant information related to covid-19 will be immensely beneficial to the community at large. in this paper, we present a very important resource, covidread, a stanford question answering dataset (squad) like dataset over more than 100k question-answer pairs. the dataset consists of context-answer-question triples. primarily the questions from the context are constructed in an automated way. after that, the system-generated questions are manually checked by hu-mans annotators. this is a precious resource that could serve many purposes, ranging from common people queries regarding this very uncommon disease to managing articles by editors\/associate editors of a journal. we establish several end-to-end neural network based baseline models that attain the lowest f1 of 32.03% and the highest f1 of 37.19%. to the best of our knowledge, we are the first to provide this kind of qa dataset in such a large volume on covid-19. this dataset creates a new avenue of carrying out research on covid-19 by providing a benchmark dataset and a baseline model. ","2029":"in this paper, we explore the task of automatically generating natural language descriptions of salient patterns in a time series, such as stock prices of a company over a week. a model for this task should be able to extract high-level patterns such as presence of a peak or a dip. while typical contemporary neural models with attention mechanisms can generate fluent output descriptions for this task, they often generate factually incorrect descriptions. we propose a computational model with a truth-conditional architecture which first runs small learned programs on the input time series, then identifies the programs\/patterns which hold true for the given input, and finally conditions on only the chosen valid program (rather than the input time series) to generate the output text description. a program in our model is constructed from modules, which are small neural networks that are designed to capture numerical patterns and temporal information. the modules are shared across multiple programs, enabling compositionality as well as efficient learning of module parameters. the modules, as well as the composition of the modules, are unobserved in data, and we learn them in an end-to-end fashion with the only training signal coming from the accompanying natural language text descriptions. we find that the proposed model is able to generate high-precision captions even though we consider a small and simple space of module types. ","2030":"in translating text where sentiment is the main message, human translators give particular attention to sentiment-carrying words. the reason is that an incorrect translation of such words would miss the fundamental aspect of the source text, i.e. the author's sentiment. in the online world, mt systems are extensively used to translate user-generated content (ugc) such as reviews, tweets, and social media posts, where the main message is often the author's positive or negative attitude towards the topic of the text. it is important in such scenarios to accurately measure how far an mt system can be a reliable real-life utility in transferring the correct affect message. this paper tackles an under-recognised problem in the field of machine translation evaluation which is judging to what extent automatic metrics concur with the gold standard of human evaluation for a correct translation of sentiment. we evaluate the efficacy of conventional quality metrics in spotting a mistranslation of sentiment, especially when it is the sole error in the mt output. we propose a numerical `sentiment-closeness' measure appropriate for assessing the accuracy of a translated affect message in ugc text by an mt system. we will show that incorporating this sentiment-aware measure can significantly enhance the correlation of some available quality metrics with the human judgement of an accurate translation of sentiment. ","2031":"we present and make available pre-trained language models (phraser, word2vec, doc2vec, fasttext, and bert) for the brazilian legal language, a python package with functions to facilitate their use, and a set of demonstrations\/tutorials containing some applications involving them. given that our material is built upon legal texts coming from several brazilian courts, this initiative is extremely helpful for the brazilian legal field, which lacks other open and specific tools and language models. our main objective is to catalyze the use of natural language processing tools for legal texts analysis by the brazilian industry, government, and academia, providing the necessary tools and accessible material. ","2032":"pre-training (pt) and back-translation (bt) are two simple and powerful methods to utilize monolingual data for improving the model performance of neural machine translation (nmt). this paper takes the first step to investigate the complementarity between pt and bt. we introduce two probing tasks for pt and bt respectively and find that pt mainly contributes to the encoder module while bt brings more benefits to the decoder. experimental results show that pt and bt are nicely complementary to each other, establishing state-of-the-art performances on the wmt16 english-romanian and english-russian benchmarks. through extensive analyses on sentence originality and word frequency, we also demonstrate that combining tagged bt with pt is more helpful to their complementarity, leading to better translation quality. source code is freely available at https:\/\/github.com\/sunbowliu\/ptvsbt. ","2033":"understanding human language has been a sub-challenge on the way of intelligent machines. the study of meaning in natural language processing (nlp) relies on the distributional hypothesis where language elements get meaning from the words that co-occur within contexts. the revolutionary idea of distributed representation for a concept is close to the working of a human mind in that the meaning of a word is spread across several neurons, and a loss of activation will only slightly affect the memory retrieval process.   neural word embeddings transformed the whole field of nlp by introducing substantial improvements in all nlp tasks. in this survey, we provide a comprehensive literature review on neural word embeddings. we give theoretical foundations and describe existing work by an interplay between word embeddings and language modelling. we provide broad coverage on neural word embeddings, including early word embeddings, embeddings targeting specific semantic relations, sense embeddings, morpheme embeddings, and finally, contextual representations. finally, we describe benchmark datasets in word embeddings' performance evaluation and downstream tasks along with the performance results of\/due to word embeddings. ","2034":"reviewing contracts is a time-consuming procedure that incurs large expenses to companies and social inequality to those who cannot afford it. in this work, we propose \"document-level natural language inference (nli) for contracts\", a novel, real-world application of nli that addresses such problems. in this task, a system is given a set of hypotheses (such as \"some obligations of agreement may survive termination.\") and a contract, and it is asked to classify whether each hypothesis is \"entailed by\", \"contradicting to\" or \"not mentioned by\" (neutral to) the contract as well as identifying \"evidence\" for the decision as spans in the contract. we annotated and release the largest corpus to date consisting of 607 annotated contracts. we then show that existing models fail badly on our task and introduce a strong baseline, which (1) models evidence identification as multi-label classification over spans instead of trying to predict start and end tokens, and (2) employs more sophisticated context segmentation for dealing with long documents. we also show that linguistic characteristics of contracts, such as negations by exceptions, are contributing to the difficulty of this task and that there is much room for improvement. ","2035":"during a psychotherapy session, the counselor typically adopts techniques which are codified along specific dimensions (e.g., 'displays warmth and confidence', or 'attempts to set up collaboration') to facilitate the evaluation of the session. those constructs, traditionally scored by trained human raters, reflect the complex nature of psychotherapy and highly depend on the context of the interaction. recent advances in deep contextualized language models offer an avenue for accurate in-domain linguistic representations which can lead to robust recognition and scoring of such psychotherapy-relevant behavioral constructs, and support quality assurance and supervision. in this work, we propose a bert-based model for automatic behavioral scoring of a specific type of psychotherapy, called cognitive behavioral therapy (cbt), where prior work is limited to frequency-based language features and\/or short text excerpts which do not capture the unique elements involved in a spontaneous long conversational interaction. the model focuses on the classification of therapy sessions with respect to the overall score achieved on the widely-used cognitive therapy rating scale (ctrs), but is trained in a multi-task manner in order to achieve higher interpretability. bert-based representations are further augmented with available therapy metadata, providing relevant non-linguistic context and leading to consistent performance improvements. we train and evaluate our models on a set of 1,118 real-world therapy sessions, recorded and automatically transcribed. our best model achieves an f1 score equal to 72.61% on the binary classification task of low vs. high total ctrs. ","2036":"we consider the hierarchical representation of documents as graphs and use geometric deep learning to classify them into different categories. while graph neural networks can efficiently handle the variable structure of hierarchical documents using the permutation invariant message passing operations, we show that we can gain extra performance improvements using our proposed selective graph pooling operation that arises from the fact that some parts of the hierarchy are invariable across different documents. we applied our model to classify clinical trial (ct) protocols into completed and terminated categories. we use bag-of-words based, as well as pre-trained transformer-based embeddings to featurize the graph nodes, achieving f1-scores around 0.85 on a publicly available large scale ct registry of around 360k protocols. we further demonstrate how the selective pooling can add insights into the ct termination status prediction. we make the source code and dataset splits accessible. ","2037":"empathetic dialog generation aims at generating coherent responses following previous dialog turns and, more importantly, showing a sense of caring and a desire to help. existing models either rely on pre-defined emotion labels to guide the response generation, or use deterministic rules to decide the emotion of the response. with the advent of advanced language models, it is possible to learn subtle interactions directly from the dataset, providing that the emotion categories offer sufficient nuances and other non-emotional but emotional regulating intents are included. in this paper, we describe how to incorporate a taxonomy of 32 emotion categories and 8 additional emotion regulating intents to succeed the task of empathetic response generation. to facilitate the training, we also curated a large-scale emotional dialog dataset from movie subtitles. through a carefully designed crowdsourcing experiment, we evaluated and demonstrated how our model produces more empathetic dialogs compared with its baselines. ","2038":"it is often stated that human languages, as other biological systems, are shaped by cost-cutting pressures but, to what extent? attempts to quantify the degree of optimality of languages by means of an optimality score have been scarce and focused mostly on english. here we recast the problem of the optimality of the word order of a sentence as an optimization problem on a spatial network where the vertices are words, arcs indicate syntactic dependencies and the space is defined by the linear order of the words in the sentence. we introduce a new score to quantify the cognitive pressure to reduce the distance between linked words in a sentence. the analysis of sentences from 93 languages representing 19 linguistic families reveals that half of languages are optimized to a 70% or more. the score indicates that distances are not significantly reduced in a few languages and confirms two theoretical predictions, i.e. that longer sentences are more optimized and that distances are more likely to be longer than expected by chance in short sentences. we present a new hierarchical ranking of languages by their degree of optimization. the new score has implications for various fields of language research (dependency linguistics, typology, historical linguistics, clinical linguistics and cognitive science). finally, the principles behind the design of the score have implications for network science. ","2039":"privacy is important considering the financial domain as such data is highly confidential and sensitive. natural language processing (nlp) techniques can be applied for text classification and entity detection purposes in financial domains such as customer feedback sentiment analysis, invoice entity detection, categorisation of financial documents by type etc. due to the sensitive nature of such data, privacy measures need to be taken for handling and training large models with such data. in this work, we propose a contextualized transformer (bert and roberta) based text classification model integrated with privacy features such as differential privacy (dp) and federated learning (fl). we present how to privately train nlp models and desirable privacy-utility tradeoffs and evaluate them on the financial phrase bank dataset. ","2040":"one key feature of dense passage retrievers (dpr) is the use of separate question and passage encoder in a bi-encoder design. previous work on generalization of dpr mainly focus on testing both encoders in tandem on out-of-distribution (ood) question-answering (qa) tasks, which is also known as domain adaptation. however, it is still unknown how dpr's individual question\/passage encoder affects generalization. specifically, in this paper, we want to know how an in-distribution (ind) question\/passage encoder would generalize if paired with an ood passage\/question encoder from another domain. we refer to this challenge as \\textit{encoder adaptation}. to answer this question, we inspect different combinations of dpr's question and passage encoder learned from five benchmark qa datasets on both in-domain and out-of-domain questions. we find that the passage encoder has more influence on the lower bound of generalization while the question encoder seems to affect the upper bound in general. for example, applying an ood passage encoder usually hurts the retrieval accuracy while an ood question encoder sometimes even improves the accuracy. ","2041":"electroencephalography (eeg) is a powerful non-invasive brain imaging technique with a high temporal resolution that has seen extensive use across multiple areas of cognitive science research. this thesis adapts representational similarity analysis (rsa) to single-trial eeg datasets and introduces its principles to eeg researchers unfamiliar with multivariate analyses. we have two separate aims: 1. we want to explore the effectiveness of single-trial rsa on eeg datasets; 2. we want to utilize single-trial rsa and computational semantic models to investigate the role of semantic meaning in emotional word processing. we report two primary findings: 1. single-trial rsa on eeg datasets can produce meaningful and interpretable results given a high number of trials and subjects; 2. single-trial rsa reveals that emotional processing in the 500-800ms time window is associated with additional semantic analysis. ","2042":"our goal is to deliver a new task and leaderboard to stimulate research on question answering and pre-trained language models (ptlms) to understand a significant instructional document, e.g., an introductory college textbook or a manual. ptlms have shown great success in many question-answering tasks, given significant supervised training, but much less so in zero-shot settings. we propose a new task that includes two college-level introductory texts in the social sciences (american government 2e) and humanities (u.s. history), hundreds of true\/false statements based on review questions written by the textbook authors, validation\/development tests based on the first eight chapters of the textbooks, blind tests based on the remaining textbook chapters, and baseline results given state-of-the-art ptlms. since the questions are balanced, random performance should be ~50%. t5, fine-tuned with boolq achieves the same performance, suggesting that the textbook's content is not pre-represented in the ptlm. taking the exam closed book, but having read the textbook (i.e., adding the textbook to t5's pre-training), yields at best minor improvement (56%), suggesting that the ptlm may not have \"understood\" the textbook (or perhaps misunderstood the questions). performance is better (~60%) when the exam is taken open-book (i.e., allowing the machine to automatically retrieve a paragraph and use it to answer the question). ","2043":"banking call centers receive millions of calls annually, with much of the information in these calls unavailable to analysts interested in tracking new and emerging call center trends. in this study we present an approach to call center theme detection that captures the occurrence of multiple themes in a question, using a publicly available corpus of stackexchange personal finance questions, labeled by users with topic tags, as a testbed. to capture the occurrence of multiple themes in a single question, the approach encodes and clusters at the sentence- rather than question-level. we also present a comparison of state-of-the-art sentence encoding models, including the sbert family of sentence encoders. we frame our evaluation as a multiclass classification task and show that a simple combination of the original sentence text, universal sentence encoder, and kmeans outperforms more sophisticated techniques that involve semantic parsing, sbert-family models, and hdbscan. our highest performing approach achieves a micro-f1 of 0.46 for this task and we show that the resulting clusters, even when slightly noisy, contain sentences that are topically consistent with the label associated with the cluster. ","2044":"much of recent progress in nlu was shown to be due to models' learning dataset-specific heuristics. we conduct a case study of generalization in nli (from mnli to the adversarially constructed hans dataset) in a range of bert-based architectures (adapters, siamese transformers, hex debiasing), as well as with subsampling the data and increasing the model size. we report 2 successful and 3 unsuccessful strategies, all providing insights into how transformer-based models learn to generalize. ","2045":"to obtain high-quality sentence embeddings from pretrained language models (plms), they must either be augmented with additional pretraining objectives or finetuned on a large set of labeled text pairs. while the latter approach typically outperforms the former, it requires great human effort to generate suitable datasets of sufficient size. in this paper, we show how plms can be leveraged to obtain high-quality sentence embeddings without the need for labeled data, finetuning or modifications to the pretraining objective: we utilize the generative abilities of large and high-performing plms to generate entire datasets of labeled text pairs from scratch, which we then use for finetuning much smaller and more efficient models. our fully unsupervised approach outperforms strong baselines on several semantic textual similarity datasets. ","2046":"providing pretrained language models with simple task descriptions in natural language enables them to solve some tasks in a fully unsupervised fashion. moreover, when combined with regular learning from examples, this idea yields impressive few-shot results for a wide range of text classification tasks. it is also a promising direction to improve data efficiency in generative settings, but there are several challenges to using a combination of task descriptions and example-based learning for text generation. in particular, it is crucial to find task descriptions that are easy to understand for the pretrained model and to ensure that it actually makes good use of them; furthermore, effective measures against overfitting have to be implemented. in this paper, we show how these challenges can be tackled: we introduce genpet, a method for text generation that is based on pattern-exploiting training, a recent approach for combining textual instructions with supervised learning that only works for classification tasks. on several summarization and headline generation datasets, genpet gives consistent improvements over strong baselines in few-shot settings. ","2047":"automatic speech recognition systems are part of people's daily lives, embedded in personal assistants and mobile phones, helping as a facilitator for human-machine interaction while allowing access to information in a practically intuitive way. such systems are usually implemented using machine learning techniques, especially with deep neural networks. even with its high performance in the task of transcribing text from speech, few works address the issue of its recognition in noisy environments and, usually, the datasets used do not contain noisy audio examples, while only mitigating this issue using data augmentation techniques. this work aims to present the process of building a dataset of noisy audios, in a specific case of degenerated audios due to interference, commonly present in radio transmissions. additionally, we present initial results of a classifier that uses such data for evaluation, indicating the benefits of using this dataset in the recognizer's training process. such recognizer achieves an average result of 0.4116 in terms of character error rate in the noisy set (snr = 30). ","2048":"privacy preservation is a crucial component of any real-world application. but, in applications relying on machine learning backends, privacy is challenging because models often capture more than what the model was initially trained for, resulting in the potential leakage of sensitive information. in this paper, we propose an automatic and quantifiable metric that allows us to evaluate humans' perception of a model's ability to preserve privacy with respect to sensitive variables. in this paper, we focus on saliency-based explanations, explanations that highlight regions of the input text, to infer internal workings of a black box model. we use the degree with which differences in interpretation of general vs privacy preserving models correlate with sociolinguistic biases to inform metric design. we show how certain commonly-used methods that seek to preserve privacy do not align with human perception of privacy preservation leading to distrust about model's claims. we demonstrate the versatility of our proposed metric by validating its utility for measuring cross corpus generalization for both privacy and emotion. finally, we conduct crowdsourcing experiments to evaluate the inclination of the evaluators to choose a particular model for a given purpose when model explanations are provided, and show a positive relationship with the proposed metric. to the best of our knowledge, we take the first step in proposing automatic and quantifiable metrics that best align with human perception of model's ability for privacy preservation, allowing for cost-effective model development. ","2049":"amid lockdown period more people express their feelings over social media platforms due to closed third-place and academic researchers have witnessed strong associations between the mental healthcare and social media posts. the stress for a brief period may lead to clinical depressions and the long-lasting traits of prevailing depressions can be life threatening with suicidal ideation as the possible outcome. the increasing concern towards the rise in number of suicide cases is because it is one of the leading cause of premature but preventable death. recent studies have shown that mining social media data has helped in quantifying the suicidal tendency of users at risk. this potential manuscript elucidates the taxonomy of mental healthcare and highlights some recent attempts in examining the potential of quantifying suicidal tendency on social media data. this manuscript presents the classification of heterogeneous features from social media data and handling feature vector representation. aiming to identify the new research directions and advances in the development of machine learning (ml) and deep learning (dl) based models, a quantitative synthesis and a qualitative review was carried out with corpus of over 77 potential research articles related to stress, depression and suicide risk from 2013 to 2021. ","2050":"we present a method for exploring regions around individual points in a contextualized vector space (particularly, bert space), as a way to investigate how these regions correspond to word senses. by inducing a contextualized \"pseudoword\" as a stand-in for a static embedding in the input layer, and then performing masked prediction of a word in the sentence, we are able to investigate the geometry of the bert-space in a controlled manner around individual instances. using our method on a set of carefully constructed sentences targeting ambiguous english words, we find substantial regularity in the contextualized space, with regions that correspond to distinct word senses; but between these regions there are occasionally \"sense voids\" -- regions that do not correspond to any intelligible sense. ","2051":"we present several neural networks to address the task of named entity recognition for morphologically complex languages (mcl). kazakh is a morphologically complex language in which each root\/stem can produce hundreds or thousands of variant word forms. this nature of the language could lead to a serious data sparsity problem, which may prevent the deep learning models from being well trained for under-resourced mcls. in order to model the mcls' words effectively, we introduce root and entity tag embedding plus tensor layer to the neural networks. the effects of those are significant for improving ner model performance of mcls. the proposed models outperform state-of-the-art including character-based approaches, and can be potentially applied to other morphologically complex languages. ","2052":"semantic annotation of long texts, such as novels, remains an open challenge in natural language processing (nlp). this research investigates the problem of detecting person entities and assigning them unique identities, i.e., recognizing people (especially main characters) in novels. we prepared a method for person entity linkage (named entity recognition and disambiguation) and new testing datasets. the datasets comprise 1,300 sentences from 13 classic novels of different genres that a novel reader had manually annotated. our process of identifying literary characters in a text, implemented in protagonisttagger, comprises two stages: (1) named entity recognition (ner) of persons, (2) named entity disambiguation (ned) - matching each recognized person with the literary character's full name, based on approximate text matching. the protagonisttagger achieves both precision and recall of above 83% on the prepared testing sets. finally, we gathered a corpus of 13 full-text novels tagged with protagonisttagger that comprises more than 35,000 mentions of literary characters. ","2053":"bug reports are a popular target for natural language processing (nlp). however, bug reports often contain artifacts such as code snippets, log outputs and stack traces. these artifacts not only inflate the bug reports with noise, but often constitute a real problem for the nlp approach at hand and have to be removed. in this paper, we present a machine learning based approach to classify content into natural language and artifacts at line level implemented in python. we show how data from github issue trackers can be used for automated training set generation, and present a custom preprocessing approach for bug reports. our model scores at 0.95 roc-auc and 0.93 f1 against our manually annotated validation set, and classifies 10k lines in 0.72 seconds. we cross evaluated our model against a foreign dataset and a foreign r model for the same task. the python implementation of our model and our datasets are made publicly available under an open source license. ","2054":"recent studies on compression of pretrained language models (e.g., bert) usually use preserved accuracy as the metric for evaluation. in this paper, we propose two new metrics, label loyalty and probability loyalty that measure how closely a compressed model (i.e., student) mimics the original model (i.e., teacher). we also explore the effect of compression with regard to robustness under adversarial attacks. we benchmark quantization, pruning, knowledge distillation and progressive module replacing with loyalty and robustness. by combining multiple compression techniques, we provide a practical strategy to achieve better accuracy, loyalty and robustness. ","2055":"recently more attention has been given to adversarial attacks on neural networks for natural language processing (nlp). a central research topic has been the investigation of search algorithms and search constraints, accompanied by benchmark algorithms and tasks. we implement an algorithm inspired by zeroth order optimization-based attacks and compare with the benchmark results in the textattack framework. surprisingly, we find that optimization-based methods do not yield any improvement in a constrained setup and slightly benefit from approximate gradient information only in unconstrained setups where search spaces are larger. in contrast, simple heuristics exploiting nearest neighbors without querying the target function yield substantial success rates in constrained setups, and nearly full success rate in unconstrained setups, at an order of magnitude fewer queries. we conclude from these results that current textattack benchmark tasks are too easy and constraints are too strict, preventing meaningful research on black-box adversarial text attacks. ","2056":"automated compliance checking (acc) systems aim to semantically parse building regulations to a set of rules. however, semantic parsing is known to be hard and requires large amounts of training data. the complexity of creating such training data has led to research that focuses on small sub-tasks, such as shallow parsing or the extraction of a limited subset of rules. this study introduces a shallow parsing task for which training data is relatively cheap to create, with the aim of learning a lexicon for acc. we annotate a small domain-specific dataset of 200 sentences, spar.txt, and train a sequence tagger that achieves 79,93 f1-score on the test set. we then show through manual evaluation that the model identifies most (89,84%) defined terms in a set of building regulation documents, and that both contiguous and discontiguous multi-word expressions (mwe) are discovered with reasonable accuracy (70,3%). ","2057":"this paper presents an unsupervised extractive approach to summarize scientific long documents based on the information bottleneck principle. inspired by previous work which uses the information bottleneck principle for sentence compression, we extend it to document level summarization with two separate steps. in the first step, we use signal(s) as queries to retrieve the key content from the source document. then, a pre-trained language model conducts further sentence search and edit to return the final extracted summaries. importantly, our work can be flexibly extended to a multi-view framework by different signals. automatic evaluation on three scientific document datasets verifies the effectiveness of the proposed framework. the further human evaluation suggests that the extracted summaries cover more content aspects than previous systems. ","2058":"tibetan is a low-resource language. in order to alleviate the shortage of parallel corpus between tibetan and chinese, this paper uses two monolingual corpora and a small number of seed dictionaries to learn the semi-supervised method with seed dictionaries and self-supervised adversarial training method through the similarity calculation of word clusters in different embedded spaces and puts forward an improved self-supervised adversarial learning method of tibetan and chinese monolingual data alignment only. the experimental results are as follows. first, the experimental results of tibetan syllables chinese characters are not good, which reflects the weak semantic correlation between tibetan syllables and chinese characters; second, the seed dictionary of semi-supervised method made before 10 predicted word accuracy of 66.5 (tibetan - chinese) and 74.8 (chinese - tibetan) results, to improve the self-supervision methods in both language directions have reached 53.5 accuracy. ","2059":"as unlabeled data carry rich task-relevant information, they are proven useful for few-shot learning of language model. the question is how to effectively make use of such data. in this work, we revisit the self-training technique for language model fine-tuning and present a state-of-the-art prompt-based few-shot learner, sflm. given two views of a text sample via weak and strong augmentation techniques, sflm generates a pseudo label on the weakly augmented version. then, the model predicts the same pseudo label when fine-tuned with the strongly augmented version. this simple approach is shown to outperform other state-of-the-art supervised and semi-supervised counterparts on six sentence classification and six sentence-pair classification benchmarking tasks. in addition, sflm only relies on a few in-domain unlabeled data. we conduct a comprehensive analysis to demonstrate the robustness of our proposed approach under various settings, including augmentation techniques, model scale, and few-shot knowledge transfer across tasks. ","2060":"the widespread usage of social networks during mass convergence events, such as health emergencies and disease outbreaks, provides instant access to citizen-generated data that carry rich information about public opinions, sentiments, urgent needs, and situational reports. such information can help authorities understand the emergent situation and react accordingly. moreover, social media plays a vital role in tackling misinformation and disinformation. this work presents tbcov, a large-scale twitter dataset comprising more than two billion multilingual tweets related to the covid-19 pandemic collected worldwide over a continuous period of more than one year. more importantly, several state-of-the-art deep learning models are used to enrich the data with important attributes, including sentiment labels, named-entities (e.g., mentions of persons, organizations, locations), user types, and gender information. last but not least, a geotagging method is proposed to assign country, state, county, and city information to tweets, enabling a myriad of data analysis tasks to understand real-world issues. our sentiment and trend analyses reveal interesting insights and confirm tbcov's broad coverage of important topics. ","2061":"personality detection is an old topic in psychology and automatic personality prediction (or perception) (app) is the automated (computationally) forecasting of the personality on different types of human generated\/exchanged contents (such as text, speech, image, video). the principal objective of this study is to offer a shallow (overall) review of natural language processing approaches on app since 2010. with the advent of deep learning and following it transfer-learning and pre-trained model in nlp, app research area has been a hot topic, so in this review, methods are categorized into three; pre-trained independent, pre-trained model based, multimodal approaches. also, to achieve a comprehensive comparison, reported results are informed by datasets. ","2062":"in this paper, we leverage pre-trained language models (plms) to precisely evaluate the semantics preservation of edition process on sentences. our metric, neighbor distribution divergence (ndd), evaluates the disturbance on predicted distribution of neighboring words from mask language model (mlm). ndd is capable of detecting precise changes in semantics which are easily ignored by text similarity. by exploiting the property of ndd, we implement a unsupervised and even training-free algorithm for extractive sentence compression. we show that our ndd-based algorithm outperforms previous perplexity-based unsupervised algorithm by a large margin. for further exploration on interpretability, we evaluate ndd by pruning on syntactic dependency treebanks and apply ndd for predicate detection as well. ","2063":"a meaningful understanding of clinical protocols and patient pathways helps improve healthcare outcomes. electronic health records (ehr) reflect real-world treatment behaviours that are used to enhance healthcare management but present challenges; protocols and pathways are often loosely defined and with elements frequently not recorded in ehrs, complicating the enhancement. to solve this challenge, healthcare objectives associated with healthcare management activities can be indirectly observed in ehrs as latent topics. topic models, such as latent dirichlet allocation (lda), are used to identify latent patterns in ehr data. however, they do not examine the ordered nature of ehr sequences, nor do they appraise individual events in isolation. our novel approach, the categorical sequence encoder (case) addresses these shortcomings. the sequential nature of ehrs is captured by case's event-level representations, revealing latent healthcare objectives. in synthetic ehr sequences, case outperforms lda by up to 37% at identifying healthcare objectives. in the real-world mimic-iii dataset, case identifies meaningful representations that could critically enhance protocol and pathway development. ","2064":"ad hoc abbreviations are commonly found in informal communication channels that favor shorter messages. we consider the task of reversing these abbreviations in context to recover normalized, expanded versions of abbreviated messages. the problem is related to, but distinct from, spelling correction, in that ad hoc abbreviations are intentional and may involve substantial differences from the original words. ad hoc abbreviations are productively generated on-the-fly, so they cannot be resolved solely by dictionary lookup. we generate a large, open-source data set of ad hoc abbreviations. this data is used to study abbreviation strategies and to develop two strong baselines for abbreviation expansion ","2065":"we present three natural language inference (nli) challenge sets that can evaluate nli models on their understanding of temporal expressions. more specifically, we probe these models for three temporal properties: (a) the order between points in time, (b) the duration between two points in time, (c) the relation between the magnitude of times specified in different units. we find that although large language models fine-tuned on mnli have some basic perception of the order between points in time, at large, these models do not have a thorough understanding of the relation between temporal expressions. ","2066":"over the last few years, contextualized pre-trained neural language models, such as bert, gpt, have shown significant gains in various nlp tasks. to enhance the robustness of existing pre-trained models, one way is adversarial examples generation and evaluation for conducting data augmentation or adversarial learning. in the meanwhile, gender bias embedded in the models seems to be a serious problem in practical applications. many researches have covered the gender bias produced by word-level information(e.g. gender-stereotypical occupations), while few researchers have investigated the sentence-level cases and implicit cases.   in this paper, we proposed a method to automatically generate implicit gender bias samples at sentence-level and a metric to measure gender bias. samples generated by our method will be evaluated in terms of accuracy. the metric will be used to guide the generation of examples from pre-trained models. therefore, those examples could be used to impose attacks on pre-trained models. finally, we discussed the evaluation efficacy of our generated examples on reducing gender bias for future research. ","2067":"in this paper, we introduce the task of predicting severity of age-restricted aspects of movie content based solely on the dialogue script. we first investigate categorizing the ordinal severity of movies on 5 aspects: sex, violence, profanity, substance consumption, and frightening scenes. the problem is handled using a siamese network-based multitask framework which concurrently improves the interpretability of the predictions. the experimental results show that our method outperforms the previous state-of-the-art model and provides useful information to interpret model predictions. the proposed dataset and source code are publicly available at our github repository. ","2068":"opinion formation and persuasion in argumentation are affected by three major factors: the argument itself, the source of the argument, and the properties of the audience. understanding the role of each and the interplay between them is crucial for obtaining insights regarding argument interpretation and generation. it is particularly important for building effective argument generation systems that can take both the discourse and the audience characteristics into account. having such personalized argument generation systems would be helpful to expose individuals to different viewpoints and help them make a more fair and informed decision on an issue. even though studies in social sciences and psychology have shown that source and audience effects are essential components of the persuasion process, most research in computational persuasion has focused solely on understanding the characteristics of persuasive language. in this thesis, we make several contributions to understand the relative effect of the source, audience, and language in computational persuasion. we first introduce a large-scale dataset with extensive user information to study these factors' effects simultaneously. then, we propose models to understand the role of the audience's prior beliefs on their perception of arguments. we also investigate the role of social interactions and engagement in understanding users' success in online debating over time. we find that the users' prior beliefs and social interactions play an essential role in predicting their success in persuasion. finally, we explore the importance of incorporating contextual information to predict argument impact and show improvements compared to encoding only the text of the arguments. ","2069":"keyphrase extraction has been comprehensively researched within the single-document setting, with an abundance of methods and a wealth of datasets. in contrast, multi-document keyphrase extraction has been infrequently studied, despite its utility for describing sets of documents, and its use in summarization. moreover, no dataset existed for multi-document keyphrase extraction, hindering the progress of the task. recent advances in multi-text processing make the task an even more appealing challenge to pursue. to initiate this pursuit, we present here the first literature review and the first dataset for the task, mk-duc-01, which can serve as a new benchmark. we test several keyphrase extraction baselines on our data and show their results. "},"authors":{"0":["Vivek Subramanian","Dhanasekar Sundararaman"],"1":["Afia Fairoose Abedin","Amirul Islam Al Mamun","Rownak Jahan Nowrin","Amitabha Chakrabarty","Moin Mostakim","Sudip Kumar Naskar"],"2":["Aditya Mogadala","Marimuthu Kalimuthu","Dietrich Klakow"],"3":["Huihan Yao","Ying Chen","Qinyuan Ye","Xisen Jin","Xiang Ren"],"4":["Kazuki Irie","J\u00fcrgen Schmidhuber"],"5":["Shivani Kumar","Anubhav Shrimal","Md Shad Akhtar","Tanmoy Chakraborty"],"6":["Gaochen Wu","Bin Xu","Yuxin Qin","Yang Liu","Lingyu Liu","Ziwei Wang"],"7":["Maya Raifer","Guy Rotman","Reut Apel","Moshe Tennenholtz","Roi Reichart"],"8":["Jianqiang Huang","Yu Qin","Jiaxin Qi","Qianru Sun","Hanwang Zhang"],"9":["Dongbo Xi","Fuzhen Zhuang","Ganbin Zhou","Xiaohu Cheng","Fen Lin","Qing He"],"10":["Han Zhang","Weichong Yin","Yewei Fang","Lanxin Li","Boqiang Duan","Zhihua Wu","Yu Sun","Hao Tian","Hua Wu","Haifeng Wang"],"11":["Saiping Guan","Xueqi Cheng","Long Bai","Fujun Zhang","Zixuan Li","Yutao Zeng","Xiaolong Jin","Jiafeng Guo"],"12":["Minghan Wang","Jiaxin Guo","Yuxia Wang","Daimeng Wei","Hengchao Shang","Chang Su","Yimeng Chen","Yinglu Li","Min Zhang","Shimin Tao","Hao Yang"],"13":["Sergey Slavnov"],"14":["Diptesh Kanojia","Kevin Patel","Pushpak Bhattacharyya","Malhar Kulkarni","Gholamreza Haffari"],"15":["Teresa Paccosi","Alessio Palmero Aprosio"],"16":["Jiayuan Chen","Boyu Zhang","Yinfei Xu","Meng Wang"],"17":["Shiwei Zhang","Xiuzhen Zhang"],"18":["Yingying Wang","Cunliang Kong","Liner Yang","Yijun Wang","Xiaorong Lu","Renfen Hu","Shan He","Zhenghao Liu","Yun Chen","Erhong Yang","Maosong Sun"],"19":["Shuxin Yang","Xian Wu","Shen Ge","Xingwang Wu","S. Kevin Zhou","Li Xiao"],"20":["Shuxin Yang","Xian Wu","Shen Ge","Shaohua Kevin Zhou","Li Xiao"],"21":["Changsheng Zhao","Ting Hua","Yilin Shen","Qian Lou","Hongxia Jin"],"22":["Saurav Ghosh","Philippe Loustaunau"],"23":["Jinchuan Tian","Jianwei Yu","Chao Weng","Shi-Xiong Zhang","Dan Su","Dong Yu","Yuexian Zou"],"24":["Zhengxin Yang"],"25":["Jiayi Wang","Ke Wang","Boxing Chen","Yu Zhao","Weihua Luo","Yuqi Zhang"],"26":["Di Wu","Binbin Zhang","Chao Yang","Zhendong Peng","Wenjing Xia","Xiaoyu Chen","Xin Lei"],"27":["Deven Shah","Pinak Ghate","Manali Paranjape","Amit Kumar"],"28":["Shaoshi Ling","Julian Salazar","Yuzong Liu","Katrin Kirchhoff"],"29":["Ashish Salunkhe"],"30":["Shounak Paul","Pawan Goyal","Saptarshi Ghosh"],"31":["Haw-Shiuan Chang","Amol Agrawal","Andrew McCallum"],"32":["Nobel Dhar","Gaurob Saha","Prithwiraj Bhattacharjee","Avi Mallick","Md Saiful Islam"],"33":["Ibrahim Faruk Ceylan","Necmettin Bera Calik","Mert Yapucuoglu","Ahmet Yavuz Uluslu"],"34":["Igor Samenko","Alexey Tikhonov","Borislav Kozlovskii","Ivan P. Yamshchikov"],"35":["Qintong Li","Piji Li","Zhaochun Ren","Pengjie Ren","Zhumin Chen"],"36":["Binbin Zhang","Di Wu","Zhuoyuan Yao","Xiong Wang","Fan Yu","Chao Yang","Liyong Guo","Yaguang Hu","Lei Xie","Xin Lei"],"37":["Zhuoyuan Yao","Di Wu","Xiong Wang","Binbin Zhang","Fan Yu","Chao Yang","Zhendong Peng","Xiaoyu Chen","Lei Xie","Xin Lei"],"38":["Tong Zhang","Wei Ye","Baosong Yang","Long Zhang","Xingzhang Ren","Dayiheng Liu","Jinan Sun","Shikun Zhang","Haibo Zhang","Wen Zhao"],"39":["Mayank Sethi","Ambika Sadhu","Khushbu Pahwa","Sargun Nagpal","Tavpritesh Sethi"],"40":["Guoliang Dong","Jingyi Wang","Jun Sun","Sudipta Chattopadhyay","Xinyu Wang","Ting Dai","Jie Shi","Jin Song Dong"],"41":["Yongfa Ling","Wenbo Guan","Qiang Ruan","Heping Song","Yuping Lai"],"42":["Aishwarya Padmakumar","Jesse Thomason","Ayush Shrivastava","Patrick Lange","Anjali Narayan-Chen","Spandana Gella","Robinson Piramuthu","Gokhan Tur","Dilek Hakkani-Tur"],"43":["Rami Mohawesh","Shuxiang Xu","Matthew Springer","Muna Al-Hawawreh","Sumbal Maqsood"],"44":["Hila Gonen","Ganesh Jawahar","Djam\u00e9 Seddah","Yoav Goldberg"],"45":["Grace E. Lee","Aixin Sun"],"46":["Denis Paperno"],"47":["Matt Gardner","William Merrill","Jesse Dodge","Matthew E. Peters","Alexis Ross","Sameer Singh","Noah A. Smith"],"48":["Chandrakant Bothe"],"49":["Jimmy Lin"],"50":["Leonard Adolphs","Benjamin Boerschinger","Christian Buck","Michelle Chen Huebscher","Massimiliano Ciaramita","Lasse Espeholt","Thomas Hofmann","Yannic Kilcher","Sascha Rothe","Pier Giuseppe Sessa","Lierni Sestorain Saralegui"],"51":["Xudong Li","Ye Fan","Rugui Yao","Peng Wang","Nan Qi","Xiaoya Zuo"],"52":["Karolina Stanczak","Isabelle Augenstein"],"53":["Niko Partanen","Jack Rueter","Mika H\u00e4m\u00e4l\u00e4inen","Khalid Alnajjar"],"54":["Abbas Raza Ali"],"55":["Kostia Chardonnet","Louis Lemonnier","Beno\u00eet Valiron"],"56":["Jamin Shin","Juneyoung Park"],"57":["Jamin Shin","Peng Xu","Andrea Madotto","Pascale Fung"],"58":["Yekyung Kim","Seohyeong Jeong","Kyunghyun Cho"],"59":["Mohaddeseh Bastan","Shahram Khadivi"],"60":["Maxwell Weinzierl","Sanda M. Harabagiu"],"61":["Sedigheh Eslami","Gerard de Melo","Christoph Meinel"],"62":["Ahmed Izzidien"],"63":["Abhilasha Sancheti","Rachel Rudinger"],"64":["Serge Gladkoff","Lifeng Han"],"65":["Kumar Saurav","Kumar Saunack","Diptesh Kanojia","Pushpak Bhattacharyya"],"66":["Karen Leung","Nikos Ar\u00e9chiga","Marco Pavone"],"67":["Elvys Linhares Pontes","Mohamed Benjannet"],"68":["Jiahuan Pei","Cheng Wang","Gy\u00f6rgy Szarvas"],"69":["Gaoussou Youssouf Kebe","Luke E. Richards","Edward Raff","Francis Ferraro","Cynthia Matuszek"],"70":["Markus Kreuzthaler","Stefan Schulz"],"71":["Vahid Zarrabi","Salar Mohtaj","Habibollah Asghari"],"72":["Alon Kipnis"],"73":["Andreas Chandra","Affandy Fahrizain"," Ibrahim","Simon Willyanto Laufried"],"74":["Qian Wang","Jiajun Zhang"],"75":["Yuan Yao","Qingxiu Dong","Jian Guan","Boxi Cao","Zhengyan Zhang","Chaojun Xiao","Xiaozhi Wang","Fanchao Qi","Junwei Bao","Jinran Nie","Zheni Zeng","Yuxian Gu","Kun Zhou","Xuancheng Huang","Wenhao Li","Shuhuai Ren","Jinliang Lu","Chengqiang Xu","Huadong Wang","Guoyang Zeng","Zile Zhou","Jiajun Zhang","Juanzi Li","Minlie Huang","Rui Yan","Xiaodong He","Xiaojun Wan","Xin Zhao","Xu Sun","Yang Liu","Zhiyuan Liu","Xianpei Han","Erhong Yang","Zhifang Sui","Maosong Sun"],"76":["Paul Egr\u00e9","Benjamin Spector","Ad\u00e8le Mortier","Steven Verheyen"],"77":["Shen Gao","Yuchi Zhang","Yongliang Wang","Yang Dong","Xiuying Chen","Dongyan Zhao","Rui Yan"],"78":["Yang Deng","Yaliang Li","Wenxuan Zhang","Bolin Ding","Wai Lam"],"79":["Wilson Lau","Kevin Lybarger","Martin L. Gunn","Meliha Yetisgen"],"80":["Suchismit Mahapatra","Vladimir Blagojevic","Pablo Bertorello","Prasanna Kumar"],"81":["Jiawei Wang","Hai Zhao"],"82":["D. Emre Ta\u015far","\u015e\u00fckr\u00fc Ozan","M. Fatih Akca","O\u011fuzhan \u00d6lmez","Semih G\u00fcl\u00fcm","Se\u00e7ilay Kutal","Ceren Belhan"],"83":["Chen Chen","Xuanli He","Lingjuan Lyu","Fangzhao Wu"],"84":["Marc Tanti","Lonneke van der Plas","Claudia Borg","Albert Gatt"],"85":["Wei Liu","Xiyan Fu","Yue Zhang","Wenming Xiao"],"86":["Hanh Hong-Phuc Vo","Hieu Trung Tran","Son T. Luu"],"87":["Ankush Chopra","Mahima Arora","Shubham Pandey"],"88":["Timo Spinde"],"89":["Jen-Chieh Yang","Jia-Yan Wu","Sung-Ping Chang","Ya-Chieh Huang"],"90":["Akshay Parekh","Ashish Anand","Amit Awekar"],"91":["Kamil Khadiev","Carlos Manuel Bosch Machado"],"92":["Dai Quoc Nguyen","Vinh Tong","Dinh Phung","Dat Quoc Nguyen"],"93":["Nathan Schneider","Amir Zeldes"],"94":["Dilek K\u00fc\u00e7\u00fck"],"95":["Hasham Ul Haq","Veysel Kocaman","David Talby"],"96":["Luis-Gil Moreno-Jim\u00e9nez","Juan-Manuel Torres-Moreno","Roseli S. Wedemann"],"97":["Naghme Jamali","Yadollah Yaghoobzadeh","Hesham Faili"],"98":["Nithish Kannen","Divyanshu Sheth","Abhranil Chandra","Shubhraneel Pal"],"99":["Luoqiu Li","Xiang Chen","Hongbin Ye","Zhen Bi","Shumin Deng","Ningyu Zhang","Huajun Chen"],"100":["Defeng Xie","Jianmin Ji","Jiafei Xu","Ran Ji"],"101":["Peter West","Ximing Lu","Ari Holtzman","Chandra Bhagavatula","Jena Hwang","Yejin Choi"],"102":["Liner Yang","Chencheng Wang","Yun Chen","Yongping Du","Erhong Yang"],"103":["Xuanyu Shi","Jian Du"],"104":["Trisha Singhal","Junhua Liu","Lucienne T. M. Blessing","Kwan Hui Lim"],"105":["Chiyuan Zhang","Daphne Ippolito","Katherine Lee","Matthew Jagielski","Florian Tram\u00e8r","Nicholas Carlini"],"106":["Anna Wr\u00f3blewska","Pawe\u0142 Rzepi\u0144ski","Sylwia Sysko-Roma\u0144czuk"],"107":["Chen Zhang","Jo\u00e3o Sedoc","Luis Fernando D'Haro","Rafael Banchs","Alexander Rudnicky"],"108":["Hannah Rashkin","Vitaly Nikolaev","Matthew Lamm","Michael Collins","Dipanjan Das","Slav Petrov","Gaurav Singh Tomar","Iulia Turc","David Reitter"],"109":["Maunika Tamire","Srinivas Anumasa","P. K. Srijith"],"110":["Shuohuan Wang","Yu Sun","Yang Xiang","Zhihua Wu","Siyu Ding","Weibao Gong","Shikun Feng","Junyuan Shang","Yanbin Zhao","Chao Pang","Jiaxiang Liu","Xuyi Chen","Yuxiang Lu","Weixin Liu","Xi Wang","Yangfan Bai","Qiuliang Chen","Li Zhao","Shiyong Li","Peng Sun","Dianhai Yu","Yanjun Ma","Hao Tian","Hua Wu","Tian Wu","Wei Zeng","Ge Li","Wen Gao","Haifeng Wang"],"111":["Francesco Moramarco","Damir Juric","Aleksandar Savkov","Jack Flann","Maria Lehl","Kristian Boda","Tessa Grafen","Vitalii Zhelezniak","Sunir Gohil","Alex Papadopoulos Korfiatis","Nils Hammerla"],"112":["Quan Duong","Mika H\u00e4m\u00e4l\u00e4inen","Khalid Alnajjar"],"113":["Muhammad Bilal Zafar","Philipp Schmidt","Michele Donini","C\u00e9dric Archambeau","Felix Biessmann","Sanjiv Ranjan Das","Krishnaram Kenthapadi"],"114":["Xin Tian","Xinxian Huang","Dongfeng He","Yingzhan Lin","Siqi Bao","Huang He","Liankai Huang","Qiang Ju","Xiyuan Zhang","Jian Xie","Shuqi Sun","Fan Wang","Hua Wu","Haifeng Wang"],"115":["Shaoshi Sun","Zhenyuan Zhang","BoCheng Huang","Pengbin Lei","Jianlin Su","Shengfeng Pan","Jiarun Cao"],"116":["Sumanth Doddapaneni","Gowtham Ramesh","Mitesh M. Khapra","Anoop Kunchukuttan","Pratyush Kumar"],"117":["Ishika Singh","Gargi Singh","Ashutosh Modi"],"118":["Chen Liang","Chong Yang","Jing Xu","Juyang Huang","Yongliang Wang","Yang Dong"],"119":["Yasaswi Sri Chandra Gandhi Kilaru","Indrajit Ghosh"],"120":["Junxiang Wang","Xuchao Zhang","Bo Zong","Yanchi Liu","Wei Cheng","Jingchao Ni","Haifeng Chen","Liang Zhao"],"121":["Michael Sun","Kaili Huang","Mehrad Moradshahi"],"122":["Chenglei Si","Zhengyan Zhang","Yingfa Chen","Fanchao Qi","Xiaozhi Wang","Zhiyuan Liu","Yasheng Wang","Qun Liu","Maosong Sun"],"123":["Erich Round","Rikker Dockum","Robin J. Ryder"],"124":["Sumit Kumar","Harichandana B S S","Himanshu Arora"],"125":["Harichandana B S S","Sumit Kumar"],"126":["Sara Marjanovic","Karolina Sta\u0144czak","Isabelle Augenstein"],"127":["Lucas Rafael Stefanel Gris","Edresson Casanova","Frederico Santos de Oliveira","Anderson da Silva Soares","Arnaldo Candido Junior"],"128":["Ilia Kulikov","Maksim Eremeev","Kyunghyun Cho"],"129":["Mike Hardy"],"130":["J\u00f6rg Frohberg","Frank Binder"],"131":["Nayan Varma Alluri","Neeli Dheeraj Krishna"],"132":["Qian Li","Hao Peng","Jianxin Li","Congying Xia","Renyu Yang","Lichao Sun","Philip S. Yu","Lifang He"],"133":["Qian Li","Hao Peng","Jianxin Li","Jia Wu","Yuanxing Ning","Lihong Wang","Philip S. Yu","Zheng Wang"],"134":["Lukas Gienapp","Wolfgang Kircheis","Bjarne Sievers","Benno Stein","Martin Potthast"],"135":["Christian Oliva","Luis F. Lago-Fern\u00e1ndez"],"136":["Ji-Ung Lee","Jan-Christoph Klie","Iryna Gurevych"],"137":["Mohamed Ghanem","Dauod Siniora"],"138":["Qian Li","Jianxin Li","Jiawei Sheng","Shiyao Cui","Jia Wu","Yiming Hei","Hao Peng","Shu Guo","Lihong Wang","Amin Beheshti","Philip S. Yu"],"139":["Changxing Wu","Liuwen Cao","Yubin Ge","Yang Liu","Min Zhang","Jinsong Su"],"140":["Chenhe Dong","Yinghui Li","Haifan Gong","Miaoxin Chen","Junxin Li","Ying Shen","Min Yang"],"141":["Zhanqiu Zhang","Jie Wang","Jiajun Chen","Shuiwang Ji","Feng Wu"],"142":["Zaijing Li","Fengxiao Tang","Tieyu Sun","Yusen Zhu","Ming Zhao"],"143":["Tahir Javed","Sumanth Doddapaneni","Abhigyan Raman","Kaushal Santosh Bhogale","Gowtham Ramesh","Anoop Kunchukuttan","Pratyush Kumar","Mitesh M. Khapra"],"144":["Md Tahmid Rahman Laskar","Enamul Hoque","Jimmy Xiangji Huang"],"145":["Xinhsuai Dong","Luu Anh Tuan","Min Lin","Shuicheng Yan","Hanwang Zhang"],"146":["Zhengzhe Yu","Jiaxin Guo","Minghan Wang","Daimeng Wei","Hengchao Shang","Zongyao Li","Zhanglin Wu","Yuxia Wang","Yimeng Chen","Chang Su","Min Zhang","Lizhi Lei","shimin tao","Hao Yang"],"147":["Jiaxin Guo","Minghan Wang","Daimeng Wei","Hengchao Shang","Yuxia Wang","Zongyao Li","Zhengzhe Yu","Zhanglin Wu","Yimeng Chen","Chang Su","Min Zhang","Lizhi Lei","shimin tao","Hao Yang"],"148":["John X. Morris","Eli Lifland","Jack Lanchantin","Yangfeng Ji","Yanjun Qi"],"149":["Matthew R. Walter","Siddharth Patki","Andrea F. Daniele","Ethan Fahnestock","Felix Duvallet","Sachithra Hemachandra","Jean Oh","Anthony Stentz","Nicholas Roy","Thomas M. Howard"],"150":["Hannes Westermann","Jaromir Savelka","Vern R. Walker","Kevin D. Ashley","Karim Benyekhlef"],"151":["Vivian Lai","Chacha Chen","Q. Vera Liao","Alison Smith-Renner","Chenhao Tan"],"152":["Guillermo C\u00e1mbara","Jordi Luque","Mireia Farr\u00fas"],"153":["Samujjwal Ghosh","Subhadeep Maji","Maunendra Sankar Desarkar"],"154":["\u00c9. O. Rodrigues","A. Conci","P. Liatsis"],"155":["Boyan Wan","Mishal Sohail"],"156":["Hao Peng","Hang Li","Lei Hou","Juanzi Li","Chao Qiao"],"157":["Urchade Zaratiana"],"158":["Dhruva Pendharkar","Kinjal Basu","Farhad Shakerin","Gopal Gupta"],"159":["Ryan Fellows","Hisham Ihshaish","Steve Battle","Ciaran Haines","Peter Mayhew","J. Ignacio Deza"],"160":["Aayushee Gupta","K. M. Annervaz","Ambedkar Dukkipati","Shubhashis Sengupta"],"161":["Momchil Hardalov","Arnav Arora","Preslav Nakov","Isabelle Augenstein"],"162":["Robert Litschko","Ivan Vuli\u0107","Simone Paolo Ponzetto","Goran Glava\u0161"],"163":["Yichao Du","Zhirui Zhang","Weizhi Wang","Boxing Chen","Jun Xie","Tong Xu"],"164":["Diederik Aerts","Lester Beltran"],"165":["Thanh-Dung Le","Rita Noumeir","Jerome Rambaud","Guillaume Sans","Philippe Jouvet"],"166":["Shruti Agarwal","Liwen Hu","Evonne Ng","Trevor Darrell","Hao Li","Anna Rohrbach"],"167":["Ashwin Kalyan","Abhinav Kumar","Arjun Chandrasekaran","Ashish Sabharwal","Peter Clark"],"168":["Immanuel Trummer"],"169":["Abulhair Saparov","Tom M. Mitchell"],"170":["Tamara Katic","Martin Pavlovski","Danijela Sekulic","Slobodan Vucetic"],"171":["Mikel Artetxe","Shruti Bhosale","Naman Goyal","Todor Mihaylov","Myle Ott","Sam Shleifer","Xi Victoria Lin","Jingfei Du","Srinivasan Iyer","Ramakanth Pasunuru","Giri Anantharaman","Xian Li","Shuohui Chen","Halil Akin","Mandeep Baines","Louis Martin","Xing Zhou","Punit Singh Koura","Brian O'Horo","Jeff Wang","Luke Zettlemoyer","Mona Diab","Zornitsa Kozareva","Ves Stoyanov"],"172":["Xi Victoria Lin","Todor Mihaylov","Mikel Artetxe","Tianlu Wang","Shuohui Chen","Daniel Simig","Myle Ott","Naman Goyal","Shruti Bhosale","Jingfei Du","Ramakanth Pasunuru","Sam Shleifer","Punit Singh Koura","Vishrav Chaudhary","Brian O'Horo","Jeff Wang","Luke Zettlemoyer","Zornitsa Kozareva","Mona Diab","Veselin Stoyanov","Xian Li"],"173":["Ron Korenblum Pick","Vladyslav Kozhukhov","Dan Vilenchik","Oren Tsur"],"174":["Petar Milin","Benjamin V. Tucker","Dagmar Divjak"],"175":["Khaled Hechmi","Trung Ngo Trong","Ville Hautamaki","Tomi Kinnunen"],"176":["Matej Ul\u010dar","Marko Robnik-\u0160ikonja"],"177":["Yong Cao","Yukun Feng","Shaohui Kuang","Gu Xu"],"178":["Sabrina J. Mielke","Zaid Alyafeai","Elizabeth Salesky","Colin Raffel","Manan Dey","Matthias Gall\u00e9","Arun Raja","Chenglei Si","Wilson Y. Lee","Beno\u00eet Sagot","Samson Tan"],"179":["Yiwei Chen","Yu Pan","Daoyi Dong"],"180":["Dongfang Li","Baotian Hu","Qingcai Chen","Tujie Xu","Jingcong Tao","Yunan Zhang"],"181":["Sanghyuk Choi","Jeong-in Hwang","Hyungjong Noh","Yeonsoo Lee"],"182":["Qiang Sheng","Juan Cao","Xueyao Zhang","Xirong Li","Lei Zhong"],"183":["Chia-Yu Li","Ngoc Thang Vu"],"184":["Rodrigo Cu\u00e9llar-Hidalgo","Julio de Jes\u00fas Guerrero-Zambrano","Dominic Forest","Gerardo Reyes-Salgado","Juan-Manuel Torres-Moreno"],"185":["Arthur D. Sawadogo","Quentin Guimard","Tegawend\u00e9 F. Bissyand\u00e9","Abdoul Kader Kabor\u00e9","Jacques Klein","Naouel Moha"],"186":["Chia Yu Li","Ngoc Thang Vu"],"187":["Jingye Li","Hao Fei","Jiang Liu","Shengqiong Wu","Meishan Zhang","Chong Teng","Donghong Ji","Fei Li"],"188":["Gunjan Ansari","Muskan Garg","Chandni Saxena"],"189":["Qiuhao Lu","Thien Huu Nguyen","Dejing Dou"],"190":["Wenda Xu","Michael Saxon","Misha Sra","William Yang Wang"],"191":["Zixuan Ke","Bing Liu","Hao Wang","Lei Shu"],"192":["Zaki Mustafa Farooqi","Sreyan Ghosh","Rajiv Ratn Shah"],"193":["Jiangwei Liu","Jingshu Zhang","Xiaohong Huang","Liangyu Min"],"194":["Jinpeng Hu","Jianling Li","Zhihong Chen","Yaling Shen","Yan Song","Xiang Wan","Tsung-Hui Chang"],"195":["Aleksandra Piktus","Fabio Petroni","Vladimir Karpukhin","Dmytro Okhonko","Samuel Broscheit","Gautier Izacard","Patrick Lewis","Barlas O\u011fuz","Edouard Grave","Wen-tau Yih","Sebastian Riedel"],"196":["Joosung Lee","Kijong Han"],"197":["Hariom A. Pandya","Bhavik Ardeshna","Dr. Brijesh S. Bhatt"],"198":["Jatayu Baxi","Dr. Brijesh Bhatt"],"199":["Shaily Bhatt","Poonam Goyal","Sandipan Dandapat","Monojit Choudhury","Sunayana Sitaram"],"200":["Wenxin Hou","Han Zhu","Yidong Wang","Jindong Wang","Tao Qin","Renjun Xu","Takahiro Shinozaki"],"201":["Arafat Ahsan","Vandan Mujadia","Dipti Misra Sharma"],"202":["Shane Storks","Qiaozi Gao","Aishwarya Reganti","Govind Thattai"],"203":["Yifei Xu","Jingqiao Zhang","Ru He","Liangzhu Ge","Chao Yang","Cheng Yang","Ying Nian Wu"],"204":["Amir Zeldes"],"205":["Siddhant Arora","Danish Pruthi","Norman Sadeh","William W. Cohen","Zachary C. Lipton","Graham Neubig"],"206":["Denghui Zhang","Zixuan Yuan","Yanchi Liu","Fuzhen Zhuang","Haifeng Chen","Hui Xiong"],"207":["Jiayu Ding","Siyuan Wang","Qin Chen","Zhongyu Wei"],"208":["Jia Tracy Shen","Michiharu Yamashita","Ethan Prihar","Neil Heffernan","Xintao Wu","Ben Graff","Dongwon Lee"],"209":["Jheng-Hong Yang","Xueguang Ma","Jimmy Lin"],"210":["Sidney Evaldo Leal","Magali Sanches Duran","Carolina Evaristo Scarton","Nathan Siegle Hartmann","Sandra Maria Alu\u00edsio"],"211":["Dongxu Li","Chenchen Xu","Liu Liu","Yiran Zhong","Rong Wang","Lars Petersson","Hongdong Li"],"212":["Shini Renjith","Annie Abraham","Surya B. Jyothi","Lekshmi Chandran","Jincy Thomson"],"213":["Zhen Wang","Xu Shan","Xiangxie Zhang","Jie Yang"],"214":["Diptesh Kanojia","Pushpak Bhattacharyya","Malhar Kulkarni","Gholamreza Haffari"],"215":["Duc-Vu Nguyen","Linh-Bao Vo","Ngoc-Linh Tran","Kiet Van Nguyen","Ngan Luu-Thuy Nguyen"],"216":["P\u0131nar Baki"],"217":["Lukas Lange","Heike Adel","Jannik Str\u00f6tgen","Dietrich Klakow"],"218":["Timo Spinde","David Krieger","Manuel Plank","Bela Gipp"],"219":["Christoph Minixhofer","Ond\u0159ej Klejch","Peter Bell"],"220":["Songqiao Han","Hailiang Huang","Jiangwei Liu"],"221":["Omid Madani"],"222":["Yudong Zhu","Di Zhou","Jinghui Xiao","Xin Jiang","Xiao Chen","Qun Liu"],"223":["Yun-Cheng Wang","Xiou Ge","Bin Wang","C. -C. Jay Kuo"],"224":["Danish Pruthi","Rachit Bansal","Bhuwan Dhingra","Livio Baldini Soares","Michael Collins","Zachary C. Lipton","Graham Neubig","William W. Cohen"],"225":["Thomas Mandl","Sandip Modha","Gautam Kishore Shahi","Hiren Madhu","Shrey Satapara","Prasenjit Majumder","Johannes Schaefer","Tharindu Ranasinghe","Marcos Zampieri","Durgesh Nandini","Amit Kumar Jaiswal"],"226":["Vivek Iyer","Arvind Agarwal","Harshit Kumar"],"227":["Enrique Noriega-Atala","Peter M. Lovett","Clayton T. Morrison","Mihai Surdeanu"],"228":["Vinh Tong","Dai Quoc Nguyen","Dinh Phung","Dat Quoc Nguyen"],"229":["Di Jin","Zhijing Jin","Zhiting Hu","Olga Vechtomova","Rada Mihalcea"],"230":["Chang-You Tai","Ming-Yao Li","Lun-Wei Ku"],"231":["Yuqi Si","Kirk Roberts"],"232":["Mandy M. Greaves","Cass Dykeman"],"233":["Timo Spinde","Christina Kreuter","Wolfgang Gaissmaier","Felix Hamborg","Bela Gipp","Helge Giese"],"234":["Timo Spinde","Kanishka Sinha","Norman Meuschke","Bela Gipp"],"235":["Sanket Vaibhav Mehta","Darshan Patil","Sarath Chandar","Emma Strubell"],"236":["Gautier Izacard","Mathilde Caron","Lucas Hosseini","Sebastian Riedel","Piotr Bojanowski","Armand Joulin","Edouard Grave"],"237":["Jena D. Hwang","Chandra Bhagavatula","Ronan Le Bras","Jeff Da","Keisuke Sakaguchi","Antoine Bosselut","Yejin Choi"],"238":["Arun Babu","Changhan Wang","Andros Tjandra","Kushal Lakhotia","Qiantong Xu","Naman Goyal","Kritika Singh","Patrick von Platen","Yatharth Saraf","Juan Pino","Alexei Baevski","Alexis Conneau","Michael Auli"],"239":["Yichen Jiang","Mohit Bansal"],"240":["Dominic Widdows","Kirsty Kitto","Trevor Cohen"],"241":["Max Bartolo","Tristan Thrush","Sebastian Riedel","Pontus Stenetorp","Robin Jia","Douwe Kiela"],"242":["Kyle Richardson","Ashish Sabharwal"],"243":["Rinon Gal","Or Patashnik","Haggai Maron","Gal Chechik","Daniel Cohen-Or"],"244":["Rina Buoy","Nguonly Taing","Sovisal Chenda"],"245":["Prasanna Parasurama","Jo\u00e3o Sedoc"],"246":["Xiangyu Peng","Mark O. Riedl","Prithviraj Ammanabrolu"],"247":["Michael Henry Tessler","Jason Madeano","Pedro A. Tsividis","Brin Harper","Noah D. Goodman","Joshua B. Tenenbaum"],"248":["Johannes Stegm\u00fcller","Fabian Bauer-Marquart","Norman Meuschke","Terry Ruas","Moritz Schubotz","Bela Gipp"],"249":["David Thulke","Nico Daheim","Christian Dugast","Hermann Ney"],"250":["Hyunjae Kim","Jaehyo Yoo","Seunghyun Yoon","Jinhyuk Lee","Jaewoo Kang"],"251":["Tahmid Hasan","Abhik Bhattacharjee","Wasi Uddin Ahmad","Yuan-Fang Li","Yong-Bin Kang","Rifat Shahriyar"],"252":["Diptesh Kanojia","Raj Dabre","Shubham Dewangan","Pushpak Bhattacharyya","Gholamreza Haffari","Malhar Kulkarni"],"253":["Chengyi Wang","Yu Wu","Sanyuan Chen","Shujie Liu","Jinyu Li","Yao Qian","Zhenglu Yang"],"254":["Ori Ernst","Avi Caciularu","Ori Shapira","Ramakanth Pasunuru","Mohit Bansal","Jacob Goldberger","Ido Dagan"],"255":["Hazel Kim","Daecheol Woo","Seong Joon Oh","Jeong-Won Cha","Yo-Sub Han"],"256":["Yuntao Li","Hanchu Zhang","Yutian Li","Sirui Wang","Wei Wu","Yan Zhang"],"257":["Ximing Lu","Sean Welleck","Peter West","Liwei Jiang","Jungo Kasai","Daniel Khashabi","Ronan Le Bras","Lianhui Qin","Youngjae Yu","Rowan Zellers","Noah A. Smith","Yejin Choi"],"258":["Zekun Wang","Wenhui Wang","Haichao Zhu","Ming Liu","Bing Qin","Furu Wei"],"259":["Xiangru Tang","Arjun Nair","Borui Wang","Bingyao Wang","Jai Desai","Aaron Wade","Haoran Li","Asli Celikyilmaz","Yashar Mehdad","Dragomir Radev"],"260":["Richard Shin","Benjamin Van Durme"],"261":["Nikolai Vogler","Jonathan Parkes Allen","Matthew Thomas Miller","Taylor Berg-Kirkpatrick"],"262":["Akari Asai","Matt Gardner","Hannaneh Hajishirzi"],"263":["Richard Yuanzhe Pang","He He","Kyunghyun Cho"],"264":["Li Yang","Qifan Wang","Zac Yu","Anand Kulkarni","Sumit Sanghai","Bin Shu","Jon Elsas","Bhargav Kanagal"],"265":["Yadong Xi","Jiashu Pu","Xiaoxi Mao"],"266":["Davis Yoshida","Kevin Gimpel"],"267":["Yuanhao Xiong","Wei-Cheng Chang","Cho-Jui Hsieh","Hsiang-Fu Yu","Inderjit Dhillon"],"268":["Keshav Santhanam","Omar Khattab","Jon Saad-Falcon","Christopher Potts","Matei Zaharia"],"269":["Robert L. Logan IV","Alexandre Passos","Sameer Singh","Ming-Wei Chang"],"270":["Yuning Mao","Xiang Ren","Heng Ji","Jiawei Han"],"271":["Daniel Spokoyny","Ivan Lee","Zhao Jin","Taylor Berg-Kirkpatrick"],"272":["Hongyu Zhu","Yan Chen","Jing Yan","Jing Liu","Yu Hong","Ying Chen","Hua Wu","Haifeng Wang"],"273":["Richard Yuanzhe Pang","Alicia Parrish","Nitish Joshi","Nikita Nangia","Jason Phang","Angelica Chen","Vishakh Padmakumar","Johnny Ma","Jana Thompson","He He","Samuel R. Bowman"],"274":["Xiangyu Peng","Kaige Xie","Amal Alabdulkarim","Harshith Kayam","Samihan Dani","Mark O. Riedl"],"275":["Zhaofeng Wu","Hao Peng","Noah A. Smith"],"276":["Amal Alabdulkarim","Winston Li","Lara J. Martin","Mark O. Riedl"],"277":["Jianing Zhou","Ziheng Zeng","Hongyu Gong","Suma Bhat"],"278":["Ashis Kumer Biswas","Geeta Verma","Justin Otto Barber"],"279":["Zhecan Wang","Haoxuan You","Liunian Harold Li","Alireza Zareian","Suji Park","Yiqing Liang","Kai-Wei Chang","Shih-Fu Chang"],"280":["Ian Porada","Alessandro Sordoni","Jackie Chi Kit Cheung"],"281":["Swapnil Hingmire","Irene Li","Rena Kawamura","Benjamin Chen","Alexander Fabbri","Xiangru Tang","Yixin Liu","Thomas George","Tammy Liao","Wai Pan Wong","Vanessa Yan","Richard Zhou","Girish K. Palshikar","Dragomir Radev"],"282":["Sweta Agrawal","Julia Kreutzer","Colin Cherry"],"283":["Litian Zhang","Xiaoming Zhang","Junshu Pan","Feiran Huang"],"284":["Yue Guan","Zhengyi Li","Jingwen Leng","Zhouhan Lin","Minyi Guo","Yuhao Zhu"],"285":["Lalit Mohan Sanagavarapu","Vivek Iyer","Raghu Reddy"],"286":["Sheng Xu","Xiaojun Wan"],"287":["Derek Tam","Surafel M. Lakew","Yogesh Virkar","Prashant Mathur","Marcello Federico"],"288":["Mayank Kulkarni","Debanjan Mahata","Ravneet Arora","Rajarshi Bhowmik"],"289":["Nicholas Egan","Oleg Vasilyev","John Bohannon"],"290":["Xiaojie Guo","Shugen Wang","Hanqing Zhao","Shiliang Diao","Jiajia Chen","Zhuoye Ding","Zhen He","Yun Xiao","Bo Long","Han Yu","Lingfei Wu"],"291":["Qi He","Jo\u00e3o Sedoc","Jordan Rodu"],"292":["Seth Kulick","Neville Ryant","Beatrice Santorini"],"293":["Pedro Aceves","James A. Evans"],"294":["Zhengxiang Wang"],"295":["Melika Behjati","James Henderson"],"296":["Ant\u00f3nio G\u00f3is","Kyunghyun Cho","Andr\u00e9 Martins"],"297":["Mingyang Zhou","Mahasweta Chakraborti","Sijia Qian","Zhou Yu","Jingwen Zhang"],"298":["Witold Sosnowski","Anna Wroblewska","Piotr Gawrysiak"],"299":["Xueying Zhang","Yanyan Zou","Hainan Zhang","Jing Zhou","Shiliang Diao","Jiajia Chen","Zhuoye Ding","Zhen He","Xueqi He","Yun Xiao","Bo Long","Han Yu","Lingfei Wu"],"300":["Xueying Zhang","Yunjiang Jiang","Yue Shang","Zhaomeng Cheng","Chi Zhang","Xiaochuan Fan","Yun Xiao","Bo Long"],"301":["Sihao Chen","Siyi Liu","Xander Uyttendaele","Yi Zhang","William Bruno","Dan Roth"],"302":["Kun Qian","Ahmad Beirami","Satwik Kottur","Shahin Shayandeh","Paul Crook","Alborz Geramifard","Zhou Yu","Chinnadhurai Sankar"],"303":["Andrew Wang","Mohit Sudhakar","Yangfeng Ji"],"304":["Qingyang Wu","Song Feng","Derek Chen","Sachindra Joshi","Luis A. Lastras","Zhou Yu"],"305":["Linqing Liu","Patrick Lewis","Sebastian Riedel","Pontus Stenetorp"],"306":["Lei Zuo","Kun Qian","Bowen Yang","Zhou Yu"],"307":["Sai Muralidhar Jayanthi","Varsha Embar","Karthik Raghunathan"],"308":["Hyundong Cho","Chinnadhurai Sankar","Christopher Lin","Kaushik Ram Sadagopan","Shahin Shayandeh","Asli Celikyilmaz","Jonathan May","Ahmad Beirami"],"309":["Julia Rozanova","Deborah Ferreira","Marco Valentino","Mokanrarangan Thayaparan","Andre Freitas"],"310":["Xin Liu","Dayiheng Liu","Baosong Yang","Haibo Zhang","Junwei Ding","Wenqing Yao","Weihua Luo","Haiying Zhang","Jinsong Su"],"311":["Fardin Saad","Hasan Mahmud","Md. Alamin Shaheen","Md. Kamrul Hasan","Paresha Farastu","Mohammad Ridwan Kabir"],"312":["Juan Camilo Vasquez-Correa","Juan Carlos Guerrero-Sierra","Jose Luis Pemberty-Tamayo","Juan Esteban Jaramillo","Andres Felipe Tejada-Castro"],"313":["Arianna Falbo","Travis LaCroix"],"314":["Maxwell Nye","Michael Henry Tessler","Joshua B. Tenenbaum","Brenden M. Lake"],"315":["Andrea Di Sorbo","Sonia Laudanna","Anna Vacca","Corrado A. Visaggio","Gerardo Canfora"],"316":["Qinkai Chen","Christian-Yann Robert"],"317":["Asmelash Teka Hadgu","Abel Aregawi","Adam Beaudoin"],"318":["Romina Oji","Seyedeh Fatemeh Razavi","Sajjad Abdi Dehsorkh","Alireza Hariri","Hadi Asheri","Reshad Hosseini"],"319":["Manuel Senge","Timour Igamberdiev","Ivan Habernal"],"320":["Shuhe Wang","Jiwei Li","Yuxian Meng","Rongbin Ouyang","Guoyin Wang","Xiaoya Li","Tianwei Zhang","Shi Zong"],"321":["Bowen Yang","Cong Han","Yu Li","Lei Zuo","Zhou Yu"],"322":["Franziska Weeber","Felix Hamborg","Karsten Donnay","Bela Gipp"],"323":["Ahmed Izzidien","David Stillwell"],"324":["Ahmed Izzidien","David Stillwell"],"325":["Diptesh Kanojia","Prashant Sharma","Sayali Ghodekar","Pushpak Bhattacharyya","Gholamreza Haffari","Malhar Kulkarni"],"326":["Timo Lohrenz","Patrick Schwarz","Zhengyang Li","Tim Fingscheidt"],"327":["Tran Thi Hong Hanh","Antoine Doucet","Nicolas Sidere","Jose G. Moreno","Senja Pollak"],"328":["Dafei Yin","Jing Li","Gaosheng Wu"],"329":["Noor Ahmad Al Hindawi","Ismail Shahin","Ali Bou Nassif"],"330":["Emily Sheng","Josh Arnold","Zhou Yu","Kai-Wei Chang","Nanyun Peng"],"331":["Yu Li","Baolin Peng","Yelong Shen","Yi Mao","Lars Liden","Zhou Yu","Jianfeng Gao"],"332":["Tianyi Liu","Zuxuan Wu","Wenhan Xiong","Jingjing Chen","Yu-Gang Jiang"],"333":["Jianmo Ni","Chen Qu","Jing Lu","Zhuyun Dai","Gustavo Hern\u00e1ndez \u00c1brego","Ji Ma","Vincent Y. Zhao","Yi Luan","Keith B. Hall","Ming-Wei Chang","Yinfei Yang"],"334":["Xiaodong Yu","Wenpeng Yin","Nitish Gupta","Dan Roth"],"335":["Sheng Zhang","Hao Cheng","Shikhar Vashishth","Cliff Wong","Jinfeng Xiao","Xiaodong Liu","Tristan Naumann","Jianfeng Gao","Hoifung Poon"],"336":["Jaromir Savelka","Hannes Westermann","Karim Benyekhlef","Charlotte S. Alexander","Jayla C. Grant","David Restrepo Amariles","Rajaa El Hamdani","S\u00e9bastien Mee\u00f9s","Micha\u0142 Araszkiewicz","Kevin D. Ashley","Alexandra Ashley","Karl Branting","Mattia Falduti","Matthias Grabmair","Jakub Hara\u0161ta","Tereza Novotn\u00e1","Elizabeth Tippett","Shiwanni Johnson"],"337":["Mihaela Bornea","Ramon Fernandez Astudillo","Tahira Naseem","Nandana Mihindukulasooriya","Ibrahim Abdelaziz","Pavan Kapanipathi","Radu Florian","Salim Roukos"],"338":["Jakob Prange","Nathan Schneider","Lingpeng Kong"],"339":["Xi Yang","Jie Zhang","Kejiang Chen","Weiming Zhang","Zehua Ma","Feng Wang","Nenghai Yu"],"340":["Jaromir Savelka","Hannes Westermann","Karim Benyekhlef"],"341":["Robert Tinn","Hao Cheng","Yu Gu","Naoto Usuyama","Xiaodong Liu","Tristan Naumann","Jianfeng Gao","Hoifung Poon"],"342":["Tom De Smedt"],"343":["Zhe Gan","Yen-Chun Chen","Linjie Li","Tianlong Chen","Yu Cheng","Shuohang Wang","Jingjing Liu","Lijuan Wang","Zicheng Liu"],"344":["Sara Rosenthal","Mihaela Bornea","Avirup Sil","Radu Florian","Scott McCarley"],"345":["Patrick Lewis","Barlas O\u011fuz","Wenhan Xiong","Fabio Petroni","Wen-tau Yih","Sebastian Riedel"],"346":["Siddharth Sachdeva","Angel Hsu","Ian French","Elwin Lim"],"347":["Changsung Kang","Hongwei Shang","Jean-Marc Langlois"],"348":["David McDonald","James Pustejovsky"],"349":["Ori Ram","Gal Shachaf","Omer Levy","Jonathan Berant","Amir Globerson"],"350":["Udit Arora","William Huang","He He"],"351":["Zexuan Zhong","Dan Friedman","Danqi Chen"],"352":["Ankita Pasad","Felix Wu","Suwon Shon","Karen Livescu","Kyu J. Han"],"353":["Maartje ter Hoeve","Evgeny Kharitonov","Dieuwke Hupkes","Emmanuel Dupoux"],"354":["Pierre Beckmann","Mikolaj Kegler","Milos Cernak"],"355":["Guilherme Moraes Rosa","Luiz Henrique Bonifacio","Leandro Rodrigues de Souza","Roberto Lotufo","Rodrigo Nogueira"],"356":["Weijia Zhang","Svitlana Vakulenko","Thilina Rajapakse","Evangelos Kanoulas"],"357":["Vera Provatorova","Svitlana Vakulenko","Samarth Bhargav","Evangelos Kanoulas"],"358":["Jianjie Luo","Yehao Li","Yingwei Pan","Ting Yao","Hongyang Chao","Tao Mei"],"359":["Yuri Bizzoni","Telma Peura","Mads R. Thomsen","Kristoffer Nielbo"],"360":["Pieter Delobelle","Ewoenam Kwaku Tokpo","Toon Calders","Bettina Berendt"],"361":["Mar\u00eda Villota","C\u00e9sar Dom\u00ednguez","J\u00f3nathan Heras","Eloy Mata","Vico Pascual"],"362":["Vijit Malik","Ayush Kumar","Jithendra Veppa"],"363":["Timo Spinde","Lada Rudnitckaia","Felix Hamborg","Bela Gipp"],"364":["Haejun Lee","Akhil Kedia","Jongwon Lee","Ashwin Paranjape","Christopher D. Manning","Kyoung-Gu Woo"],"365":["Haritz Puerto","G\u00f6zde G\u00fcl \u015eahin","Iryna Gurevych"],"366":["Vishwajeet Kumar","Saneem Chemmengath","Yash Gupta","Jaydeep Sen","Samarth Bharadwaj","Soumen Chakrabarti"],"367":["Lei Li","Yankai Lin","Xuancheng Ren","Guangxiang Zhao","Peng Li","Jie Zhou","Xu Sun"],"368":["Yosi Mass","Doron Cohen","Asaf Yehudai","David Konopnicki"],"369":["Yazheng Yang","Boyuan Pan","Deng Cai","Huan Sun"],"370":["Keqi Deng","Songjun Cao","Yike Zhang","Long Ma"],"371":["Runxin Xu","Fuli Luo","Chengyu Wang","Baobao Chang","Jun Huang","Songfang Huang","Fei Huang"],"372":["Jianmo Ni","Gustavo Hern\u00e1ndez \u00c1brego","Noah Constant","Ji Ma","Keith B. Hall","Daniel Cer","Yinfei Yang"],"373":["Hongru Wang","Min Li","Zimo Zhou","Gabriel Pui Cheong Fung","Kam-Fai Wong"],"374":["Jaromir Savelka","Kevin D. Ashley"],"375":["Shusheng Xu","Yichen Liu","Xiaoyu Yi","Siyuan Zhou","Huizi Li","Yi Wu"],"376":["Dongqi Wang","Haoran Wei","Zhirui Zhang","Shujian Huang","Jun Xie","Jiajun Chen"],"377":["Pengfei Liu","Youzhang Ning","King Keung Wu","Kun Li","Helen Meng"],"378":["Jialin Wu","Jiasen Lu","Ashish Sabharwal","Roozbeh Mottaghi"],"379":["Nikhil Patel","James Hale","Kanika Jindal","Apoorva Sharma","Yichun Yu"],"380":["Pengfei Liu","Kun Li","Helen Meng"],"381":["Alejandro Rodriguez Pascual"],"382":["Csaba Veres"],"383":["Luis Rojas Rubio","Claudio Meneses Villegas"],"384":["Marco Rasetto","Juan P. Dominguez-Morales","Angel Jimenez-Fernandez","Ryad Benosman"],"385":["Alara Dirik","Hilal Donmez","Pinar Yanardag"],"386":["Nan Du","Yanping Huang","Andrew M. Dai","Simon Tong","Dmitry Lepikhin","Yuanzhong Xu","Maxim Krikun","Yanqi Zhou","Adams Wei Yu","Orhan Firat","Barret Zoph","Liam Fedus","Maarten Bosma","Zongwei Zhou","Tao Wang","Yu Emma Wang","Kellie Webster","Marie Pellat","Kevin Robinson","Kathy Meier-Hellstern","Toju Duke","Lucas Dixon","Kun Zhang","Quoc V Le","Yonghui Wu","Zhifeng Chen","Claire Cui"],"387":["Diego Garcia-Olano","Yasumasa Onoe","Joydeep Ghosh"],"388":["Sourya Dipta Das","Ayan Basak","Saikat Dutta"],"389":["Nicola De Cao","Leon Schmid","Dieuwke Hupkes","Ivan Titov"],"390":["Krishna Garg","Jishnu Ray Chowdhury","Cornelia Caragea"],"391":["Rina Buoy","Nguonly Taing","Sovisal Chenda"],"392":["Kai Wei","Thanh Tran","Feng-Ju Chang","Kanthashree Mysore Sathyendra","Thejaswi Muniyappa","Jing Liu","Anirudh Raju","Ross McGowan","Nathan Susanj","Ariya Rastrow","Grant P. Strimel"],"393":["Wei-Lin Liao","Wei-Yun Ma"],"394":["Shailza Jolly","Pepa Atanasova","Isabelle Augenstein"],"395":["Anastasia Zhukova","Felix Hamborg","Bela Gipp"],"396":["Seungju Han","Beomsu Kim","Seokjun Seo","Enkhbayar Erdenee","Buru Chang"],"397":["Chenxin An","Ming Zhong","Zhichao Geng","Jianqiang Yang","Xipeng Qiu"],"398":["Sebastian P. Bayerl","Aniruddha Tammewar","Korbinian Riedhammer","Giuseppe Riccardi"],"399":["Gilles Hacheme"],"400":["Carlos Lassance","Maroua Maachou","Joohee Park","St\u00e9phane Clinchant"],"401":["Hao Xue","Flora D. Salim","Yongli Ren","Charles L. A. Clarke"],"402":["Mrinal Rawat","Diptesh Kanojia"],"403":["Shengqiong Wu","Hao Fei","Fei Li","Donghong Ji","Meishan Zhang","Yijiang Liu","Chong Teng"],"404":["Thibault Formal","Benjamin Piwowarski","St\u00e9phane Clinchant"],"405":["Saeed Damadi"],"406":["Injy Hamed","Alia El Bolock","Nader Rizk","Cornelia Herbert","Slim Abdennadher","Ngoc Thang Vu"],"407":["Yu Cao"],"408":["Xiaodong Gu","Kang Min Yoo","Sang-Woo Lee"],"409":["Xiaodong Gu","Kang Min Yoo","Jung-Woo Ha"],"410":["Kehan Wang","Jiaxi Yang","Hongjun Wu"],"411":["Manas Gaur","Kalpa Gunaratna","Vijay Srinivasan","Hongxia Jin"],"412":["Yunyun Huang","Xiaoyu Shen","Chuanyi Li","Jidong Ge","Bin Luo"],"413":["Liang Qiu","Yizhou Zhao","Jinchao Li","Pan Lu","Baolin Peng","Jianfeng Gao","Song-Chun Zhu"],"414":["Islam Akef Ebeid","John R. Talburt","Md Abdus Salam Siddique"],"415":["Chia-Yu Li","Ngoc Thang Vu"],"416":["Nora Hollenstein","Marius Tr\u00f6ndle","Martyna Plomecka","Samuel Kiegeland","Yilmazcan \u00d6zyurt","Lena A. J\u00e4ger","Nicolas Langer"],"417":["Chia-Yu Li","Ngoc Thang Vu"],"418":["Zhisong Zhang","Yizhe Zhang","Bill Dolan"],"419":["Ao Liu","Congjian Luo","Naoaki Okazaki"],"420":["Yordan Yordanov","Vid Kocijan","Thomas Lukasiewicz","Oana-Maria Camburu"],"421":["Tejumade Afonja","Oladimeji Mudele","Iroro Orife","Kenechi Dukor","Lawrence Francis","Duru Goodness","Oluwafemi Azeez","Ademola Malomo","Clinton Mbataku"],"422":["Patrick Huber","Linzi Xing","Giuseppe Carenini"],"423":["Hang Jiang","Doug Beeferman","Weiquan Mao","Deb Roy"],"424":["Tanya Roosta","Peyman Passban","Ankit Chadha"],"425":["Yu Feng","Jing Zhang","Xiaokang Zhang","Lemao Liu","Cuiping Li","Hong Chen"],"426":["Bodhisattwa Prasad Majumder","Oana-Maria Camburu","Thomas Lukasiewicz","Julian McAuley"],"427":["Chongyang Bai","Haipeng Chen","Srijan Kumar","Jure Leskovec","V. S. Subrahmanian"],"428":["Adam Farris","Aryaman Arora"],"429":["Zein Shaheen","Gerhard Wohlgenannt","Dmitry Mouromtsev"],"430":["Tong Zhu","Xiaoye Qu","Wenliang Chen","Zhefeng Wang","Baoxing Huai","Nicholas Jing Yuan","Min Zhang"],"431":["Xiang Yue","Xinliang Frederick Zhang","Ziyu Yao","Simon Lin","Huan Sun"],"432":["Esha Banerjee","Atul Kr. Ojha","Girish Nath Jha"],"433":["Hannah Metzler","Hubert Baginski","Thomas Niederkrotenthaler","David Garcia"],"434":["Yongkang Li"],"435":["Nicholas Boucher","Ilia Shumailov","Ross Anderson","Nicolas Papernot"],"436":["Costas Mavromatis","Prasanna Lakkur Subramanyam","Vassilis N. Ioannidis","Soji Adeshina","Phillip R. Howard","Tetiana Grinberg","Nagib Hakim","George Karypis"],"437":["Kurt Shuster","Jack Urbanek","Arthur Szlam","Jason Weston"],"438":["Manaal Faruqui","Dilek Hakkani-T\u00fcr"],"439":["Piyawat Lertvittayakumjorn","Francesca Toni"],"440":["Kenichi Kumatani","Dimitrios Dimitriadis","Yashesh Gaur","Robert Gmyr","Sefik Emre Eskimez","Jinyu Li","Michael Zeng"],"441":["Vedangi Wagh","Geet Shingi"],"442":["Juan Ciro","Daniel Galvez","Tim Schlippe","David Kanter"],"443":["Hannes Westermann","Jaromir Savelka","Vern R. Walker","Kevin D. Ashley","Karim Benyekhlef"],"444":["Arvid Frydenlund","Gagandeep Singh","Frank Rudzicz"],"445":["Marjan Ghazvininejad","Vladimir Karpukhin","Asli Celikyilmaz"],"446":["Patrick Xia","Richard Shin"],"447":["Bryan Eikema","Germ\u00e1n Kruszewski","Hady Elsahar","Marc Dymetman"],"448":["Johann Frei","Frank Kramer"],"449":["Damien Sileo","Marie-Francine Moens"],"450":["Jetsun Whitton","Anthony Hunter"],"451":["Mathieu Bernard","Maxime Poli","Julien Karadayi","Emmanuel Dupoux"],"452":["Frederico Souza","Jo\u00e3o Filho"],"453":["Aleksandr Gashkov","Aleksandr Perevalov","Maria Eltsova","Andreas Both"],"454":["Thomas Palmeira Ferraz","Alexandre Alcoforado","Enzo Bustos","Andr\u00e9 Seidel Oliveira","Rodrigo Gerber","Na\u00edde M\u00fcller","Andr\u00e9 Corr\u00eaa d'Almeida","Bruno Miguel Veloso","Anna Helena Reali Costa"],"455":["Dusan Grujicic","Thierry Deruyttere","Marie-Francine Moens","Matthew Blaschko"],"456":["Raymond Li","Wen Xiao","Lanjun Wang","Giuseppe Carenini"],"457":["Yifan Chen","Qi Zeng","Dilek Hakkani-Tur","Di Jin","Heng Ji","Yun Yang"],"458":["Binyuan Hui","Xiang Shi","Ruiying Geng","Binhua Li","Yongbin Li","Jian Sun","Xiaodan Zhu"],"459":["Rongxin Zhu","Jey Han Lau","Jianzhong Qi"],"460":["Dave Schneider","Michael Witbrock"],"461":["Constantin Eichenberg","Sidney Black","Samuel Weinbach","Letitia Parcalabescu","Anette Frank"],"462":["Elise Jing","Kristiana Schneck","Dennis Egan","Scott A. Waterman"],"463":["David Gaddy","Alex Kouzemtchenko","Pavankumar Reddy Muddireddy","Prateek Kolhar","Rushin Shah"],"464":["Elizabeth Salesky","David Etter","Matt Post"],"465":["Amanda Askell","Yuntao Bai","Anna Chen","Dawn Drain","Deep Ganguli","Tom Henighan","Andy Jones","Nicholas Joseph","Ben Mann","Nova DasSarma","Nelson Elhage","Zac Hatfield-Dodds","Danny Hernandez","Jackson Kernion","Kamal Ndousse","Catherine Olsson","Dario Amodei","Tom Brown","Jack Clark","Sam McCandlish","Chris Olah","Jared Kaplan"],"466":["Saghar Hosseini","Ahmed Hassan Awadallah","Yu Su"],"467":["Luana Ruiz","Joshua Ainslie","Santiago Onta\u00f1\u00f3n"],"468":["Shuyang Li","Bodhisattwa Prasad Majumder","Julian McAuley"],"469":["Lei Ding","Dengdeng Yu","Jinhan Xie","Wenxing Guo","Shenggang Hu","Meichen Liu","Linglong Kong","Hongsheng Dai","Yanchun Bao","Bei Jiang"],"470":["Yining Hong","Li Yi","Joshua B. Tenenbaum","Antonio Torralba","Chuang Gan"],"471":["Andrei Manolache","Florin Brad","Elena Burceanu","Antonio Barbalau","Radu Ionescu","Marius Popescu"],"472":["Yucheng Liu","Tian Zhu"],"473":["Su Zhu","Lu Chen","Ruisheng Cao","Zhi Chen","Qingliang Miao","Kai Yu"],"474":["Max M\u00fcller-Eberstein","Rob van der Goot","Barbara Plank"],"475":["Anindya Sundar Das","Sriparna Saha"],"476":["Jia-Yan Wu","Alexander Te-Wei Shieh","Shih-Ju Hsu","Yun-Nung Chen"],"477":["Weijia Wu","Yuanqiang Cai","Debing Zhang","Sibo Wang","Zhuang Li","Jiahong Li","Yejun Tang","Hong Zhou"],"478":["Jenna Kanerva","Hanna Kitti","Li-Hsin Chang","Teemu Vahtola","Mathias Creutz","Filip Ginter"],"479":["Poorav Desai","Tanmoy Chakraborty","Md Shad Akhtar"],"480":["Wentao Xu","Zhiping Luo","Weiqing Liu","Jiang Bian","Jian Yin","Tie-Yan Liu"],"481":["Claudia Mart\u00ednez-deMiguel","Isabel Segura-Bedmar","Esteban Chac\u00f3n-Solano","Sara Guerrero-Aspizua"],"482":["Santiago Alonso-Bartolome","Isabel Segura-Bedmar"],"483":["Jiangjie Chen","Qiaoben Bao","Changzhi Sun","Xinbo Zhang","Jiaze Chen","Hao Zhou","Yanghua Xiao","Lei Li"],"484":["Chuhan Wu","Fangzhao Wu","Tao Qi","Yongfeng Huang"],"485":["Dominik Wunderlich","Daniel Bernau","Francesco Ald\u00e0","Javier Parra-Arnau","Thorsten Strufe"],"486":["Sherzod Hakimov","Ralph Ewerth"],"487":["Bin Li","Fei Xia","Yixuan Weng","Xiusheng Huang","Bin Sun","Shutao Li"],"488":["Bin Li","Fei Xia","Yixuan Weng","Xiusheng Huang","Bin Sun"],"489":["Valentin Vielzeuf","Grigory Antipov"],"490":["Huidong Liu","Shaoyuan Xu","Jinmiao Fu","Yang Liu","Ning Xie","Chien-Chih Wang","Bryan Wang","Yi Sun"],"491":["Yashank Singh","Niladri Chatterjee"],"492":["Xiwen Liang","Fengda Zhu","Yi Zhu","Bingqian Lin","Bing Wang","Xiaodan Liang"],"493":["Prasanna Parasurama"],"494":["Congbo Ma","Wei Emma Zhang","Mingyu Guo","Hu Wang","Quan Z. Sheng"],"495":["Yongmin Yoo","Dongjin Lim","Tak-Sung Heo"],"496":["Torsten Scholak","Jonathan Pilault","Joey Velez-Ginorio"],"497":["Nan Wu","Yuan Xie","Cong Hao"],"498":["Pengcheng He","Jianfeng Gao","Weizhu Chen"],"499":["Seoyeon Park","Jishnu Ray Chowdhury","Tuhin Kundu","Cornelia Caragea"],"500":["Jiaying Gong","Hoda Eldardiry"],"501":["Chen Ju","Tengda Han","Kunhao Zheng","Ya Zhang","Weidi Xie"],"502":["Yixin Nie","Linjie Li","Zhe Gan","Shuohang Wang","Chenguang Zhu","Michael Zeng","Zicheng Liu","Mohit Bansal","Lijuan Wang"],"503":["Nina Shvetsova","Brian Chen","Andrew Rouditchenko","Samuel Thomas","Brian Kingsbury","Rogerio Feris","David Harwath","James Glass","Hilde Kuehne"],"504":["Laura Weidinger","John Mellor","Maribeth Rauh","Conor Griffin","Jonathan Uesato","Po-Sen Huang","Myra Cheng","Mia Glaese","Borja Balle","Atoosa Kasirzadeh","Zac Kenton","Sasha Brown","Will Hawkins","Tom Stepleton","Courtney Biles","Abeba Birhane","Julia Haas","Laura Rimell","Lisa Anne Hendricks","William Isaac","Sean Legassick","Geoffrey Irving","Iason Gabriel"],"505":["Hanane Djeddal","Thomas Gerald","Laure Soulier","Karen Pinel-Sauvagnat","Lynda Tamine"],"506":["Francesco Sovrano","Fabio Vitali"],"507":["Jean N\u00e9raud"],"508":["Isabelle Augenstein"],"509":["Oier Mees","Lukas Hermann","Erick Rosete-Beas","Wolfram Burgard"],"510":["Ahmed Cheikh Rouhoua","Marwa Dhiaf","Yousri Kessentini","Sinda Ben Salem"],"511":["Cristiano Chesi"],"512":["Damien Sileo","Wout Vossen","Robbe Raymaekers"],"513":["Wenbo Gou","Wen Shi","Jian Lou","Lijie Huang","Pan Zhou","Ruixuan Li"],"514":["Abhayjeet Singh","Achuth Rao MV","Rakesh Vaideeswaran","Chiranjeevi Yarra","Prasanta Kumar Ghosh"],"515":["Jungo Kasai","Keisuke Sakaguchi","Ronan Le Bras","Lavinia Dunagan","Jacob Morrison","Alexander R. Fabbri","Yejin Choi","Noah A. Smith"],"516":["Qingnan Jiang","Mingxuan Wang","Jun Cao","Shanbo Cheng","Shujian Huang","Lei Li"],"517":["Chanjun Park","Yoonna Jang","Seolhwa Lee","Sungjin Park","Heuiseok Lim"],"518":["Jian Sun","Yu Zhou","Chengqing Zong"],"519":["Alexander Hanbo Li","Patrick Ng","Peng Xu","Henghui Zhu","Zhiguo Wang","Bing Xiang"],"520":["Spencer Braun","Oleg Vasilyev","Neslihan Iskender","John Bohannon"],"521":["Yanjun Gao","Dmitriy Dligach","Leslie Christensen","Samuel Tesch","Ryan Laffin","Dongfang Xu","Timothy Miller","Ozlem Uzuner","Matthew M Churpek","Majid Afshar"],"522":["Marouane Yassine","David Beauchemin","Fran\u00e7ois Laviolette","Luc Lamontagne"],"523":["Arpit Mittal","Jeel Tejaskumar Vaishnav","Aishwarya Kaliki","Nathan Johns","Wyatt Pease"],"524":["Sarah Wiegreffe","Ana Marasovi\u0107"],"525":["Domonkos Vamossy","Rolf Skog"],"526":["Darsh J Shah","Sinong Wang","Han Fang","Hao Ma","Luke Zettlemoyer"],"527":["Liunian Harold Li","Pengchuan Zhang","Haotian Zhang","Jianwei Yang","Chunyuan Li","Yiwu Zhong","Lijuan Wang","Lu Yuan","Lei Zhang","Jenq-Neng Hwang","Kai-Wei Chang","Jianfeng Gao"],"528":["Manas Jain","Sriparna Saha","Pushpak Bhattacharyya","Gladvin Chinnadurai","Manish Kumar Vatsa"],"529":["Louis Castricato","Spencer Frazier","Jonathan Balloch","Nitya Tarakad","Mark Riedl"],"530":["Yijia Xiao","Jiezhong Qiu","Ziang Li","Chang-Yu Hsieh","Jie Tang"],"531":["Samuel A. Barnett","Robert D. Hawkins","Thomas L. Griffiths"],"532":["Congcong Wang","David Lillis"],"533":["Sean Benhur","Kanchana Sivanraju"],"534":["Naman Paharia","Muhammad Syafiq Mohd Pozi","Adam Jatowt"],"535":["Rob van der Goot","Miryam de Lhoneux"],"536":["Geetanjali Bihani"],"537":["Fran\u00e7ois Charton","Amaury Hayat","Sean T. McQuade","Nathaniel J. Merrill","Benedetto Piccoli"],"538":["Dinesh Raghu","Shantanu Agarwal","Sachindra Joshi"," Mausam"],"539":["Hariom A. Pandya","Brijesh S. Bhatt"],"540":["Kun Yan","Chenbin Zhang","Jun Hou","Ping Wang","Zied Bouraoui","Shoaib Jameel","Steven Schockaert"],"541":["Sungjae Cho","Soo-Young Lee"],"542":["Chen Zhu","Wei Ping","Chaowei Xiao","Mohammad Shoeybi","Tom Goldstein","Anima Anandkumar","Bryan Catanzaro"],"543":["Kofi Arhin","Ioana Baldini","Dennis Wei","Karthikeyan Natesan Ramamurthy","Moninder Singh"],"544":["Yichen Huang","Yuchen Wang","Yik-Cheung Tam"],"545":["Liang Chen","Yanchun Liang","Xiaohu Shi","You Zhou","Chunguo Wu"],"546":["Prateek Chaudhry","Matthew Lease"],"547":["Thong Nguyen","Luu Anh Tuan"],"548":["Mohammad Alali","Shaayan Syed","Mohammed Alsayed","Smit Patel","Hemanth Bodala"],"549":["Kevin Alex Mathews","Michael Strube"],"550":["Meng Cao","Yue Dong","Jackie Chi Kit Cheung"],"551":["Oscar Michel","Roi Bar-On","Richard Liu","Sagie Benaim","Rana Hanocka"],"552":["Mayank Agarwal","Tathagata Chakraborti","Sachin Grover","Arunima Chaudhary"],"553":["Ruan Chaves Rodrigues","Marcelo Akira Inuzuka","Juliana Resplande Sant'Anna Gomes","Acquila Santos Rocha","Iacer Calixto","Hugo Alexandre Dantas do Nascimento"],"554":["Marco Valentino","Mokanarangan Thayaparan","Deborah Ferreira","Andr\u00e9 Freitas"],"555":["Guillaume Couairon","Matthieu Cord","Matthijs Douze","Holger Schwenk"],"556":["Haoran Xu","Sixing Lu","Zhongkai Sun","Chengyuan Ma","Chenlei Guo"],"557":["George Chrysostomou","Nikolaos Aletras"],"558":["Ehab A. AlBadawy","Andrew Gibiansky","Qing He","Jilong Wu","Ming-Ching Chang","Siwei Lyu"],"559":["Gregor Betz","Kyle Richardson"],"560":["Andrea Schioppa","Polina Zablotskaia","David Vilar","Artem Sokolov"],"561":["Sahand Sabour","Chujie Zheng","Minlie Huang"],"562":["Shilin Zhou","Qingrong Xia","Zhenghua Li","Yu Zhang","Min Zhang"],"563":["Ben Saunders","Necati Cihan Camgoz","Richard Bowden"],"564":["Philip M\u00fcller","Georgios Kaissis","Congyu Zou","Daniel R\u00fcckert"],"565":["Byunghyun Ban"],"566":["Kfir Bar","Nachum Dershowitz","Lena Dankin"],"567":["Shailza Jolly","Zi Xuan Zhang","Andreas Dengel","Lili Mou"],"568":["Zixuan Ke","Hu Xu","Bing Liu"],"569":["Atsuki Yamaguchi","Gaku Morio","Hiroaki Ozaki","Ken-ichi Yokote","Kenji Nagamatsu"],"570":["D. -S. Wang"],"571":["Kaustubh D. Dhole","Varun Gangal","Sebastian Gehrmann","Aadesh Gupta","Zhenhao Li","Saad Mahamood","Abinaya Mahendiran","Simon Mille","Ashish Srivastava","Samson Tan","Tongshuang Wu","Jascha Sohl-Dickstein","Jinho D. Choi","Eduard Hovy","Ondrej Dusek","Sebastian Ruder","Sajant Anand","Nagender Aneja","Rabin Banjade","Lisa Barthe","Hanna Behnke","Ian Berlot-Attwell","Connor Boyle","Caroline Brun","Marco Antonio Sobrevilla Cabezudo","Samuel Cahyawijaya","Emile Chapuis","Wanxiang Che","Mukund Choudhary","Christian Clauss","Pierre Colombo","Filip Cornell","Gautier Dagan","Mayukh Das","Tanay Dixit","Thomas Dopierre","Paul-Alexis Dray","Suchitra Dubey","Tatiana Ekeinhor","Marco Di Giovanni","Rishabh Gupta","Rishabh Gupta","Louanes Hamla","Sang Han","Fabrice Harel-Canada","Antoine Honore","Ishan Jindal","Przemyslaw K. Joniak","Denis Kleyko","Venelin Kovatchev","Kalpesh Krishna","Ashutosh Kumar","Stefan Langer","Seungjae Ryan Lee","Corey James Levinson","Hualou Liang","Kaizhao Liang","Zhexiong Liu","Andrey Lukyanenko","Vukosi Marivate","Gerard de Melo","Simon Meoni","Maxime Meyer","Afnan Mir","Nafise Sadat Moosavi","Niklas Muennighoff","Timothy Sum Hon Mun","Kenton Murray","Marcin Namysl","Maria Obedkova","Priti Oli","Nivranshu Pasricha","Jan Pfister","Richard Plant","Vinay Prabhu","Vasile Pais","Libo Qin","Shahab Raji","Pawan Kumar Rajpoot","Vikas Raunak","Roy Rinberg","Nicolas Roberts","Juan Diego Rodriguez","Claude Roux","Vasconcellos P. H. S.","Ananya B. Sai","Robin M. Schmidt","Thomas Scialom","Tshephisho Sefara","Saqib N. Shamsi","Xudong Shen","Haoyue Shi","Yiwen Shi","Anna Shvets","Nick Siegel","Damien Sileo","Jamie Simon","Chandan Singh","Roman Sitelew","Priyank Soni","Taylor Sorensen","William Soto","Aman Srivastava","KV Aditya Srivatsa","Tony Sun","Mukund Varma T","A Tabassum","Fiona Anting Tan","Ryan Teehan","Mo Tiwari","Marie Tolkiehn","Athena Wang","Zijian Wang","Gloria Wang","Zijie J. Wang","Fuxuan Wei","Bryan Wilie","Genta Indra Winata","Xinyi Wu","Witold Wydma\u0144ski","Tianbao Xie","Usama Yaseen","M. Yee","Jing Zhang","Yue Zhang"],"572":["Zixuan Ke","Bing Liu","Hu Xu","Lei Shu"],"573":["Zixuan Ke","Bing Liu","Nianzu Ma","Hu Xu","Lei Shu"],"574":["Xuanli He","Qiongkai Xu","Lingjuan Lyu","Fangzhao Wu","Chenguang Wang"],"575":["Jidong Ge","Yunyun huang","Xiaoyu Shen","Chuanyi Li","Wei Hu"],"576":["Qibin Chen","Jeremy Lacomis","Edward J. Schwartz","Graham Neubig","Bogdan Vasilescu","Claire Le Goues"],"577":["Payam Karisani","Negin Karisani","Li Xiong"],"578":["Jacob Turton","Ali Kabiri","David Tuckett","Robert Elliott Smith","David P. Vinson"],"579":["Adeep Hande","Ruba Priyadharshini","Anbukkarasi Sampath","Kingston Pal Thamburaj","Prabakaran Chandran","Bharathi Raja Chakravarthi"],"580":["Llu\u00eds Alemany-Puig","Juan Luis Esteban","Ramon Ferrer-i-Cancho"],"581":["Zhengxuan Wu","Atticus Geiger","Josh Rozner","Elisa Kreiss","Hanson Lu","Thomas Icard","Christopher Potts","Noah D. Goodman"],"582":["Aditya Kalyanpur","Tom Breloff","David Ferrucci"],"583":["Mesut Erhan Unal","Adriana Kovashka","Wen-Ting Chung","Yu-Ru Lin"],"584":["Aparup Khatua","Wolfgang Nejdl"],"585":["Devendra Singh Sachan","Siva Reddy","William Hamilton","Chris Dyer","Dani Yogatama"],"586":["Renrui Zhang","Longtian Qiu","Wei Zhang","Ziyao Zeng"],"587":["Ramon Ferrer-i-Cancho","Carlos G\u00f3mez-Rodr\u00edguez"],"588":["Elena Mikhalkova"],"589":["Huy Nghiem","Fred Morstatter"],"590":["Shachi H Kumar","Hsuan Su","Ramesh Manuvinakurike","Saurav Sahay","Lama Nachman"],"591":["Wei Yang","Peng Xu","Yanshuai Cao"],"592":["Shuwen Qiu","Sirui Xie","Lifeng Fan","Tao Gao","Song-Chun Zhu","Yixin Zhu"],"593":["Shahid Rabbani","Zahid Ahmed Qureshi"],"594":["Ye Jia","Michelle Tadmor Ramanovich","Tal Remez","Roi Pomerantz"],"595":["Amir Atapour-Abarghouei","Stephen Bonner","Andrew Stephen McGough"],"596":["Chen Xing","Wenhao Liu","Caiming Xiong"],"597":["Cedric M\u00f6ller","Jens Lehmann","Ricardo Usbeck"],"598":["Gabriel Recchia"],"599":["Ciara Blackledge","Amir Atapour-Abarghouei"],"600":["Andr\u00e9 Barbosa","Alan Godoy"],"601":["Harsh Agarwal","Keshav Bansal","Abhinav Joshi","Ashutosh Modi"],"602":["Leibo Liu","Oscar Perez-Concha","Anthony Nguyen","Vicki Bennett","Louisa Jorm"],"603":["Nauros Romim","Mosahed Ahmed","Md Saiful Islam","Arnab Sen Sharma","Hriteshwar Talukder","Mohammad Ruhul Amin"],"604":["Fran\u00e7ois Charton"],"605":["Markus Eberts","Adrian Ulges"],"606":["Carlos Rodriguez-Penagos","Carme Armentano-Oller","Marta Villegas","Maite Melero","Aitor Gonzalez","Ona de Gibert Bonet","Casimiro Carrino Pio"],"607":["Zizhao Hu","Ravikiran Chanumolu","Xingyu Lin","Nayela Ayaz","Vincent Chi"],"608":["K R Prajwal","Triantafyllos Afouras","Andrew Zisserman"],"609":["Vijit Malik","Rishabh Sanjay","Shouvik Kumar Guha","Shubham Kumar Nigam","Angshuman Hazarika","Arnab Bhattacharya","Ashutosh Modi"],"610":["Ritesh Kumar","Girish Nath Jha"],"611":["Mat\u011bj Koci\u00e1n","Jakub N\u00e1plava","Daniel \u0160tancl","Vladim\u00edr Kadlec"],"612":["Samy Benslimane","J\u00e9rome Az\u00e9","Sandra Bringay","Maximilien Servajean","Caroline Mollevi"],"613":["Wenliang Dai","Samuel Cahyawijaya","Zihan Liu","Pascale Fung"],"614":["Ritesh Kumar","Shiv Bhusan Kaushik","Pinkey Nainwani","Girish Nath Jha"],"615":["Shuwei Zhang","Maiqi Tang","Qingyang Zhang","Yucan Luo","Yuhui Zou"],"616":["Yuting Yang","Binbin Du","Yingxin Zhang","Wenxuan Wang","Yuke Li"],"617":["Nethra Gunti","Sathyanarayanan Ramamoorthy","Parth Patwa","Amitava Das"],"618":["Shaily Desai","Atharva Kshirsagar","Manisha Marathe"],"619":["Bernard Koch","Emily Denton","Alex Hanna","Jacob G. Foster"],"620":["Kuan-Yu Chiang","Shihao Lin","Joe Chen","Qian Yin","Qizhen Jin"],"621":["Xiaotian Lin","Nankai Lin","Kanoksak Wattanachote","Shengyi Jiang","Lianxi Wang"],"622":["Ziwang Fu","Feng Liu","Hanyang Wang","Siyuan Shen","Jiahao Zhang","Jiayin Qi","Xiangling Fu","Aimin Zhou"],"623":["Tuo Sun","Wanrong Zheng","Shufan Yu","Mengxun Li","Jiarui Ou"],"624":["Xinwei Du","Kailun Dong","Yuchen Zhang","Yongsheng Li","Ruei-Yu Tsay"],"625":["Chenxiao Liu","Guanzhi Deng","Tao Ji","Difei Tang","Silai Zheng"],"626":["Andr\u00e9 Seidel Oliveira","Anna Helena Reali Costa"],"627":["Giovanni Paolini","Ben Athiwaratkun","Jason Krone","Jie Ma","Alessandro Achille","Rishita Anubhai","Cicero Nogueira dos Santos","Bing Xiang","Stefano Soatto"],"628":["Xingchao Liu","Chengyue Gong","Lemeng Wu","Shujian Zhang","Hao Su","Qiang Liu"],"629":["Robert D. Hawkins","Michael Franke","Michael C. Frank","Adele E. Goldberg","Kenny Smith","Thomas L. Griffiths","Noah D. Goodman"],"630":["Ningyu Zhang","Hongbin Ye","Jiacheng Yang","Shumin Deng","Chuanqi Tan","Mosha Chen","Songfang Huang","Fei Huang","Huajun Chen"],"631":["Huaishao Luo","Lei Ji","Yanyong Huang","Bin Wang","Shenggong Ji","Tianrui Li"],"632":["Marco Valentino","Mokanarangan Thayaparan","Andr\u00e9 Freitas"],"633":["Shavrina Tatiana","Malykh Valentin"],"634":["Ze Tang","Chuanyi Li","Jidong Ge","Xiaoyu Shen","Zheling Zhu","Bin Luo"],"635":["Andrea Tagarelli","Andrea Simeri"],"636":["Deshui Miao","Jiaqi Zhang","Wenbo Xie","Jian Song","Xin Li","Lijuan Jia","Ning Guo"],"637":["Eugene Kharitonov","Marco Baroni","Dieuwke Hupkes"],"638":["Yitian Yuan","Lin Ma","Jingwen Wang","Wenwu Zhu"],"639":["Chong Zhou","Chen Change Loy","Bo Dai"],"640":["Yitian Yuan","Lin Ma","Wenwu Zhu"],"641":["Marco Anteghini","Jennifer D'Souza","Vitor A. P. Martins dos Santos","S\u00f6ren Auer"],"642":["Joshua Yee Kim","Tongliang Liu","Kalina Yacef"],"643":["Ipsita Mohanty","Ankit Goyal","Alex Dotterweich"],"644":["Wanli Li","Tieyun Qian"],"645":["Taolin Zhang","Chengyu Wang","Nan Hu","Minghui Qiu","Chengguang Tang","Xiaofeng He","Jun Huang"],"646":["Uladzislau Yorsh","Pavel Kord\u00edk","Alexander Kovalenko"],"647":["Guanglin Niu","Bo Li","Yongfei Zhang","Shiliang Pu"],"648":["Vishwanath Pratap Singh","Shakti P. Rath","Abhishek Pandey"],"649":["Ying-Hong Chan","Ho-Lam Chung","Yao-Chung Fan"],"650":["Bowen Ma","Chengzhi Zhang","Yuzhuo Wang","Sanhong Deng"],"651":["Zihang Meng","David Yang","Xuefei Cao","Ashish Shah","Ser-Nam Lim"],"652":["Wenqiao Zhang","Xin Eric Wang","Siliang Tang","Haizhou Shi","Haocheng Shi","Jun Xiao","Yueting Zhuang","William Yang Wang"],"653":["Athena Xiourouppa"],"654":["Bo-Ying Su","Shang-Ling Hsu","Kuan-Yin Lai","Jane Yung-jen Hsu"],"655":["Vikram Gupta","Haoyue Shi","Kevin Gimpel","Mrinmaya Sachan"],"656":["Steven Y. Feng","Varun Gangal","Jason Wei","Sarath Chandar","Soroush Vosoughi","Teruko Mitamura","Eduard Hovy"],"657":["Aaron W. Li","Veronica Jiang","Steven Y. Feng","Julia Sprague","Wei Zhou","Jesse Hoey"],"658":["Steven Y. Feng","Jessica Huynh","Chaitanya Narisetty","Eduard Hovy","Varun Gangal"],"659":["Teyun Kwon","Anandha Gopalan"],"660":["Christopher Clark","Jordi Salvador","Dustin Schwenk","Derrick Bonafilia","Mark Yatskar","Eric Kolve","Alvaro Herrasti","Jonghyun Choi","Sachin Mehta","Sam Skjonsberg","Carissa Schoenick","Aaron Sarnat","Hannaneh Hajishirzi","Aniruddha Kembhavi","Oren Etzioni","Ali Farhadi"],"661":["Tomasz Korbak","Hady Elsahar","German Kruszewski","Marc Dymetman"],"662":["Felix Grezes","Sergi Blanco-Cuaresma","Alberto Accomazzi","Michael J. Kurtz","Golnaz Shapurian","Edwin Henneken","Carolyn S. Grant","Donna M. Thompson","Roman Chyla","Stephen McDonald","Timothy W. Hostetler","Matthew R. Templeton","Kelly E. Lockhart","Nemanja Martinovic","Shinyi Chen","Chris Tanner","Pavlos Protopapas"],"663":["Leon Bergen","Timothy J. O'Donnell","Dzmitry Bahdanau"],"664":["Denghui Zhang","Zixuan Yuan","Yanchi Liu","Hao Liu","Fuzhen Zhuang","Hui Xiong","Haifeng Chen"],"665":["Arda Akdemir","Yeojoo Jeon"],"666":["Hadi Abdine","Yanzhu Guo","Moussa Kamal Eddine","Giannis Nikolentzos","Stamatis Outsios","Guokan Shang","Christos Xypolopoulos","Michalis Vazirgiannis"],"667":["Ali Bou Nassif","Abdollah Masoud Darya","Ashraf Elnagar"],"668":["Sagor Sarker"],"669":["Wei Wang","Junyu Gao","Changsheng Xu"],"670":["Vihanga Jayawickrama","Gihan Weeraprameshwara","Nisansa de Silva","Yudhanjaya Wijeratne"],"671":["Shengfei Lyu","Xingyu Wu","Jinlong Li","Qiuju Chen","Huanhuan Chen"],"672":["Zihan Liu","Feijun Jiang","Yuxiang Hu","Chen Shi","Pascale Fung"],"673":["Woncheol Shin","Gyubok Lee","Jiyoung Lee","Joonseok Lee","Edward Choi"],"674":["I-Fan Chen","Brian King","Jasha Droppo"],"675":["Linhao Li","Ming Xu","Yongfeng Dong","Xin Li","Ao Wang","Qinghua Hu"],"676":["Anmol Nayak","Hari Prasad Timmapathini"],"677":["Jialin Gao","Xin Sun","Mengmeng Xu","Xi Zhou","Bernard Ghanem"],"678":["Kaiji Lu","Zifan Wang","Piotr Mardziel","Anupam Datta"],"679":["Shiwen Ni","Jiawen Li","Hung-Yu Kao"],"680":["Weiran Wang","Ke Hu","Tara Sainath"],"681":["Michael F\u00e4rber","Anna Steyer"],"682":["Alexey Tikhonov","Max Ryabinin"],"683":["Matteo Stefanini","Marcella Cornia","Lorenzo Baraldi","Silvia Cascianelli","Giuseppe Fiameni","Rita Cucchiara"],"684":["Ronen Tamari","Kyle Richardson","Aviad Sar-Shalom","Noam Kahlon","Nelson Liu","Reut Tsarfaty","Dafna Shahaf"],"685":["Tuan-Phong Nguyen","Simon Razniewski","Julien Romero","Gerhard Weikum"],"686":["Jesus Perez-Martin","Benjamin Bustos","Silvio Jamil F. Guimar\u00e3es","Ivan Sipiran","Jorge P\u00e9rez","Grethel Coello Said"],"687":["Ignacio Arroyo-Fern\u00e1ndez","Jos\u00e9 Armando S\u00e1nchez-Rojas","Arturo Tellez-Vel\u00e1zquez","Flavio Ju\u00e1rez-Mart\u00ednez","Ra\u00fal Cruz-Barbosa","Enrique Guzm\u00e1n-Ram\u00edrez","Yalbi Itzel Balderas-Mart\u00ednez"],"688":["Tian Yan","Fang Liu"],"689":["Carol Anderson","Bo Liu","Anas Abidin","Hoo-Chang Shin","Virginia Adams"],"690":["Virginia Adams","Hoo-Chang Shin","Carol Anderson","Bo Liu","Anas Abidin"],"691":["Virginia Adams","Hoo-Chang Shin","Carol Anderson","Bo Liu","Anas Abidin"],"692":["Thomas Louf","David Sanchez","Jose J. Ramasco"],"693":["Betty van Aken","Sebastian Herrmann","Alexander L\u00f6ser"],"694":["Yu Qiao","Sourabh Zanwar","Rishab Bhattacharyya","Daniel Wiechmann","Wei Zhou","Elma Kerz","Ralf Schl\u00fcter"],"695":["Matej Martinc","Bla\u017e \u0160krlj","Senja Pollak"],"696":["Avi Chawla","Nidhi Mulay","Vikas Bishnoi","Gaurav Dhama"],"697":["Vesa Halava"],"698":["Avi Chawla","Nidhi Mulay","Vikas Bishnoi","Gaurav Dhama","Dr. Anil Kumar Singh"],"699":["Dmytro Kalpakchi","Johan Boye"],"700":["Jaime Sevilla"],"701":["Ritesh Kumar"],"702":["Shashank Kedia","Aditya Mantha","Sneha Gupta","Stephen Guo","Kannan Achan"],"703":["Georgios Balikas","Massih-Reza Amini","Marianne Clausel"],"704":["Muhammad Asif Ayub","Khubaib Ahmad","Kashif Ahmad","Nasir Ahmad","Ala Al-Fuqaha"],"705":["Ritesh Kumar"],"706":["Seyed Mousavi"],"707":["Jay Ahn","Hari Madhu","Viet Nguyen"],"708":["Pakhi Bamdev","Manraj Singh Grover","Yaman Kumar Singla","Payman Vafaee","Mika Hama","Rajiv Ratn Shah"],"709":["Xian Li","Hongyu Gong"],"710":["Chengzhi Zhang","Lei Zhao","Mengyuan Zhao","Yingyi Zhang"],"711":["Navdeep Jain"],"712":["Wangchunshu Zhou","Qifei Li","Chenle Li"],"713":["Mayank Soni","Brendan Spillane","Emer Gilmartin","Christian Saam","Benjamin R. Cowan","Vincent Wade"],"714":["Brian Yan","Chunlei Zhang","Meng Yu","Shi-Xiong Zhang","Siddharth Dalmia","Dan Berrebbi","Chao Weng","Shinji Watanabe","Dong Yu"],"715":["Azzam Alwan","Maayane Attias","Larry Rubin","Adnan El Bakri"],"716":["Ron Hochstenbach","Flavius Frasincar","Maria Mihaela Trusca"],"717":["Ali Khodadadi","Soroush Ghandiparsi","Chen-Nee Chuah"],"718":["Jie Lei","Tamara L. Berg","Mohit Bansal"],"719":["Dyah Adila","Dongyeop Kang"],"720":["Avinandan Bose","Soumendu Sundar Mukherjee"],"721":["Bang Tran","Youxiang Zhu","Xiaohui Liang","James W. Schwoebel","Lindsay A. Warrenburg"],"722":["Garry Kuwanto","Afra Feyza Aky\u00fcrek","Isidora Chara Tourni","Siyang Li","Alexander Gregory Jones","Derry Wijaya"],"723":["Marcelo Archanjo Jos\u00e9","Fabio Gagliardi Cozman"],"724":["Lasse Borgholt","Jakob Drachmann Havtorn","Mostafa Abdou","Joakim Edin","Lars Maal\u00f8e","Anders S\u00f8gaard","Christian Igel"],"725":["Qingyang Zhou","Rongpeng Li","Zhifeng Zhao","Chenghui Peng","Honggang Zhang"],"726":["Junhao Xu","Jianwei Yu","Shoukang Hu","Xunying Liu","Helen Meng"],"727":["Matt McVicar","Bruno Di Giorgi","Baris Dundar","Matthias Mauch"],"728":["Zheyu Ye","Jiangning Liu","Qian Yu","Jianxun Ju"],"729":["Junhao Xu","Shoukang Hu","Jianwei Yu","Xunying Liu","Helen Meng"],"730":["Yangkai Du","Tengfei Ma","Lingfei Wu","Fangli Xu","Xuhong Zhang","Bo Long","Shouling Ji"],"731":["Alex Xiao","Weiyi Zheng","Gil Keren","Duc Le","Frank Zhang","Christian Fuegen","Ozlem Kalinli","Yatharth Saraf","Abdelrahman Mohamed"],"732":["Xiaofei Sun","Jiwei Li","Xiaoya Li","Ziyao Wang","Tianwei Zhang","Han Qiu","Fei Wu","Chun Fan"],"733":["Charlotte Caucheteux","Alexandre Gramfort","Jean-Remi King"],"734":["Valts Blukis","Chris Paxton","Dieter Fox","Animesh Garg","Yoav Artzi"],"735":["Benjamin Meindl","Joana Mendon\u00e7a"],"736":["Libo Qin","Minheng Ni","Yue Zhang","Wanxiang Che","Yangming Li","Ting Liu"],"737":["Ilnar Salimzianov"],"738":["Ye Liu","Wolfgang Maier","Wolfgang Minker","Stefan Ultes"],"739":["Boseop Kim","HyoungSeok Kim","Sang-Woo Lee","Gichang Lee","Donghyun Kwak","Dong Hyeon Jeon","Sunghyun Park","Sungju Kim","Seonhoon Kim","Dongpil Seo","Heungsub Lee","Minyoung Jeong","Sungjae Lee","Minsub Kim","Suk Hyun Ko","Seokhun Kim","Taeyong Park","Jinuk Kim","Soyoung Kang","Na-Hyeon Ryu","Kang Min Yoo","Minsuk Chang","Soobin Suh","Sookyo In","Jinseong Park","Kyungduk Kim","Hiun Kim","Jisu Jeong","Yong Goo Yeo","Donghoon Ham","Dongju Park","Min Young Lee","Jaewook Kang","Inho Kang","Jung-Woo Ha","Woomyoung Park","Nako Sung"],"740":["Yicheng Zhu","Yiqiao Qiu","Yanghui Rao"],"741":["Varun Nair","Namit Katariya","Xavier Amatriain","Ilya Valmianski","Anitha Kannan"],"742":["Manraj Singh Grover","Pakhi Bamdev","Ratin Kumar Brala","Yaman Kumar","Mika Hama","Rajiv Ratn Shah"],"743":["Xinxin Yan","Ndapa Nakashole"],"744":["Manraj Singh Grover","Yaman Kumar","Sumit Sarin","Payman Vafaee","Mika Hama","Rajiv Ratn Shah"],"745":["Ndapa Nakashole"],"746":["Alexandros Haridis","Stella Rossikopoulou Pappa"],"747":["Bill Tuck Weng Pung","Alvin Chan"],"748":["Bill Tuck Weng Pung","Alvin Chan"],"749":["Helen Ngo","Cooper Raterink","Jo\u00e3o G. M. Ara\u00fajo","Ivan Zhang","Carol Chen","Adrien Morisot","Nicholas Frosst"],"750":["Anand A. Rajasekar","Nikesh Garera"],"751":["Vaishnavi Shrivastava","Radhika Gaonkar","Shashank Gupta","Abhishek Jha"],"752":["Fei-Tzin Lee","Chris Kedzie","Nakul Verma","Kathleen McKeown"],"753":["Agnieszka Mykowiecka","Agnieszka A. Mykowiecka","Piotr Rychlik"],"754":["Mithun Das","Somnath Banerjee","Punyajoy Saha"],"755":["Somnath Banerjee","Maulindu Sarkar","Nancy Agrawal","Punyajoy Saha","Mithun Das"],"756":["Siddhesh Pawar","Shyam Thombre","Anirudh Mittal","Girishkumar Ponkiya","Pushpak Bhattacharyya"],"757":["Mohammed M. Abdelgwad"],"758":["Tai-Danae Bradley","Yiannis Vlassopoulos"],"759":["Rabeeh Karimi Mahabadi","James Henderson","Sebastian Ruder"],"760":["Zhenhua Wang","Beike Zhang","Dong Gao"],"761":["Reza Khanmohammadi","Mitra Sadat Mirshafiee","Yazdan Rezaee Jouryabi","Seyed Abolghasem Mirroshandel"],"762":["Hongyuan Lu","Wai Lam","Hong Cheng","Helen M. Meng"],"763":["Babak Ravandi","Valentina Concu"],"764":["Dongfang Xu","Shan Chen","Timothy Miller"],"765":["Peter Hase","Mona Diab","Asli Celikyilmaz","Xian Li","Zornitsa Kozareva","Veselin Stoyanov","Mohit Bansal","Srinivasan Iyer"],"766":["Arijit Gupta","Rajaswa Patil","Veeky Baths"],"767":["Sneha Singhania","Simon Razniewski","Gerhard Weikum"],"768":["Rabab Alkhalifa","Arkaitz Zubiaga"],"769":["Ye Liu","Wolfgang Maier","Wolfgang Minker","Stefan Ultes"],"770":["Yucheng Wang","Bowen Yu","Hongsong Zhu","Tingwen Liu","Nan Yu","Limin Sun"],"771":["Ivica Kostric","Krisztian Balog","Filip Radlinski"],"772":["Timo Schick","Hinrich Sch\u00fctze"],"773":["Shirong Shen","Zhen Li","Guilin Qi"],"774":["Tae Jin Park","Naoyuki Kanda","Dimitrios Dimitriadis","Kyu J. Han","Shinji Watanabe","Shrikanth Narayanan"],"775":["Kimia Noorbakhsh","Modar Sulaiman","Mahdi Sharifi","Kallol Roy","Pooyan Jamshidi"],"776":["Jingjing Xu","Hao Zhou","Chun Gan","Zaixiang Zheng","Lei Li"],"777":["Amr Hendy","Esraa A. Gad","Mohamed Abdelghaffar","Jailan S. ElMosalami","Mohamed Afify","Ahmed Y. Tawfik","Hany Hassan Awadalla"],"778":["Pranav Narayanan Venkit","Shomir Wilson"],"779":["Sahisnu Mazumder","Bing Liu","Shuai Wang","Sepideh Esmaeilpour"],"780":["Andrew Kiruluta","Andreas Lemos","Eric Lundy"],"781":["Kichang Yang"],"782":["Abir Messaoudi","Ahmed Cheikhrouhou","Hatem Haddad","Nourchene Ferchichi","Moez BenHajhmida","Abir Korched","Malek Naski","Faten Ghriss","Amine Kerkeni"],"783":["Sanskar Soni","Dev Mehta","Vinush Vishwanath","Aditi Seetha","Satyendra Singh Chouhan"],"784":["Anfu Tang","Louise Del\u00e9ger","Robert Bossy","Pierre Zweigenbaum","Claire N\u00e9dellec"],"785":["Anfu Tang","Claire N\u00e9dellec","Pierre Zweigenbaum","Louise Del\u00e9ger","Robert Bossy"],"786":["Luoqiu Li","Xiang Chen","Zhen Bi","Xin Xie","Shumin Deng","Ningyu Zhang","Chuanqi Tan","Mosha Chen","Huajun Chen"],"787":["Anton Alekseev","Elena Tutubalina","Sejeong Kwon","Sergey Nikolenko"],"788":["Yiming Cui","Wanxiang Che","Ting Liu","Bing Qin","Ziqing Yang"],"789":["Aditi Chaudhary","Bhargavi Paranjape","Michiel de Jong"],"790":["Yuntao Li","Can Xu","Huang Hu","Lei Sha","Yan Zhang","Daxin Jiang"],"791":["Yifan Gao","Jingjing Li","Chien-Sheng Wu","Michael R. Lyu","Irwin King"],"792":["Lisai Zhang","Hongfa Wu","Qingcai Chen","Yimeng Deng","Zhonghua Li","Dejiang Kong","Zhao Cao","Joanna Siebert","Yunpeng Han"],"793":["Ru Peng","Nankai Lin","Yi Fang","Shengyi Jiang","Junbo Zhao"],"794":["Atefe Pakzad","Morteza Analoui"],"795":["Dongha Lee","Dongmin Hyun","Jiawei Han","Hwanjo Yu"],"796":["Oshin Agarwal","Ani Nenkova"],"797":["Sebastian Jaszczur","Aakanksha Chowdhery","Afroz Mohiuddin","\u0141ukasz Kaiser","Wojciech Gajewski","Henryk Michalewski","Jonni Kanerva"],"798":["Stanislaw Ambroszkiewicz","Waldemar Bartyna","Stanislaw Bylka"],"799":["Jingqing Zhang","Luis Bolanos","Ashwani Tanwar","Julia Ive","Vibhor Gupta","Yike Guo"],"800":["Diogo A. P. Nunes","David Martins de Matos","Fani Neto","Joana Ferreira Gomes"],"801":["Jiaan Wang","Zhixu Li","Tingyi Zhang","Duo Zheng","Jianfeng Qu","An Liu","Lei Zhao","Zhigang Chen"],"802":["Ilseyar Alimova","Elena Tutubalina"],"803":["Mario Graff","Daniela Moctezuma","Sabino Miranda-Jim\u00e9nez","Eric S. Tellez"],"804":["Martijn van der Klis","Jos Tellings"],"805":["Valerio La Gatta","Vincenzo Moscato","Marco Postiglione","Giancarlo Sperl\u00ec"],"806":["Maximilian Wich","Adrian Gorniak","Tobias Eder","Daniel Bartmann","Burak Enes \u00c7akici","Georg Groh"],"807":["Junlei Zhang","Zhenzhong lan"],"808":["Chen Zhu","Renkun Ni","Zheng Xu","Kezhi Kong","W. Ronny Huang","Tom Goldstein"],"809":["Sarang Shrivastava","Afreen Shaikh","Shivani Shrivastava","Chung Ming Ho","Pradeep Reddy","Vijay Saraswat"],"810":["Leilei Gan","Zhiyang Teng","Yue Zhang","Linchao Zhu","Fei Wu","Yi Yang"],"811":["Hyeonseok Moon","Chanjun Park","Sugyeong Eo","Jaehyung Seo","SeungJun Lee","Heuiseok Lim"],"812":["Seongmin Park","Jihwa Lee"],"813":["Olivier Ferret"],"814":["Alex Tamkin","Vincent Liu","Rongfei Lu","Daniel Fein","Colin Schultz","Noah Goodman"],"815":["Henri Kauhanen"],"816":["Ian Colbert","Jake Daly","Norm Rubin"],"817":["Andrei-Marius Avram","Vasile P\u0103i\u015f","Dan Tufi\u015f"],"818":["Irene Solaiman","Christy Dennison"],"819":["Hugh Perkins"],"820":["Chahat Raj","Priyanka Meel"],"821":["Judit \u00c1cs","D\u00e1niel L\u00e9vai","Andr\u00e1s Kornai"],"822":["Guy Feigenblat","Chulaka Gunasekara","Benjamin Sznajder","Sachindra Joshi","David Konopnicki","Ranit Aharonov"],"823":["Mohamad Yaser Jaradeh","Kuldeep Singh","Markus Stocker","S\u00f6ren Auer"],"824":["Zhao You","Shulin Feng","Dan Su","Dong Yu"],"825":["Akshara Prabhakar","Gouri Sankar Majumder","Ashish Anand"],"826":["Jonathan Davies","Miguel Arana-Catania","Rob Procter","Felix-Anselm van Lier","Yulan He"],"827":["Duy-Hung Nguyen","Bao-Sinh Nguyen","Nguyen Viet Dung Nghiem","Dung Tien Le","Mim Amina Khatun","Minh-Tien Nguyen","Hung Le"],"828":["Krishna Pillutla","Swabha Swayamdipta","Rowan Zellers","John Thickstun","Sean Welleck","Yejin Choi","Zaid Harchaoui"],"829":["Gongzheng Li","Yadong Xi","Jingzhen Ding","Duan Wang","Bai Liu","Changjie Fan","Xiaoxi Mao","Zeng Zhao"],"830":["Jay DeYoung","Iz Beltagy","Madeleine van Zuylen","Bailey Kuehl","Lucy Lu Wang"],"831":["Sanchit Agarwal","Jan Jezabek","Arijit Biswas","Emre Barut","Shuyang Gao","Tagyoung Chung"],"832":["Jun Qi","Chao-Han Huck Yang","Pin-Yu Chen"],"833":["Ondrej Klejch","Electra Wallington","Peter Bell"],"834":["Sia Gholami","Mehdi Noori"],"835":["Syed Zohaib Hassan","Kashif Ahmad","Michael A. Riegler","Steven Hicks","Nicola Conci","Paal Halvorsen","Ala Al-Fuqaha"],"836":["Karan Desai","Gaurav Kaul","Zubin Aysola","Justin Johnson"],"837":["Oleg Vasilyev","Aysu Altun","Nidhi Vyas","Vedant Dharnidharka","Erika Lam","John Bohannon"],"838":["Jing Yang Lee","Kong Aik Lee","Woon Seng Gan"],"839":["Lachlan McPheat","Hadi Wazni","Mehrnoosh Sadrzadeh"],"840":["Idris Abdulmumin","Bashir Shehu Galadanci","Abubakar Isa","Habeebah Adamu Kakudi","Ismaila Idris Sinan"],"841":["Vasile P\u0103i\u015f","Radu Ion","Andrei-Marius Avram","Elena Irimia","Verginica Barbu Mititelu","Maria Mitrofan"],"842":["Somya Khosla"],"843":["Shengcai Liu","Ning Lu","Cheng Chen","Ke Tang"],"844":["Judicael Poumay","Ashwin Ittoo"],"845":["SangHun Im","Gibaeg Kim","Heung-Seon Oh","Seongung Jo","Donghwan Kim"],"846":["Cheng Pengsen","Dai Jinqiao","Liu Jiayong"],"847":["Bahareh Harandizadeh","J. Hunter Priniski","Fred Morstatter"],"848":["Yiwen Shao","Shi-Xiong Zhang","Dong Yu"],"849":["Ahmed A. Metwally","Ariel K. Leong","Aman Desai","Anvith Nagarjuna","Dalia Perelman","Michael Snyder"],"850":["Zijian Zhang","Chenxin Zhang","Jiangfeng Li","Qinpei Zhao"],"851":["Iurii Mokrii","Leonid Boytsov","Pavel Braslavski"],"852":["Daria Bakshandaeva","Denis Dimitrov","Alex Shonenkov","Mark Potanin","Vladimir Arkhipkin","Denis Karachev","Vera Davydova","Anton Voronov","Mikhail Martynov","Natalia Semenova","Mikhail Stepnov","Elena Tutubalina","Andrey Chertok","Aleksandr Petiushko"],"853":["Linlin Liu","Xin Li","Ruidan He","Lidong Bing","Shafiq Joty","Luo Si"],"854":["Shota Orihashi","Yoshihiro Yamazaki","Naoki Makishima","Mana Ihori","Akihiko Takashima","Tomohiro Tanaka","Ryo Masumura"],"855":["Andrew Z. Flores","Jessica Montag","Jon Willits"],"856":["Yandi Zhu","Xiaoling Lu","Jingya Hong","Feifei Wang"],"857":["Sakshini Hangloo","Bhavna Arora"],"858":["Yukun Cao","Yijia Tang","Ziyue Wei","ChengKun Jin","Zeyu Miao","Yixin Fang","Haizhou Du","Feifei Xu"],"859":["Narges Farokhshad","Milad Molazadeh","Saman Jamalabbasi","Hamed Babaei Giglou","Saeed Bibak"],"860":["Keng Ji Chow","Samson Tan","Min-Yen Kan"],"861":["Vasile P\u0103i\u015f","Dan Tufi\u015f"],"862":["Vasile P\u0103i\u015f","Dan Tufi\u015f"],"863":["Aman Kumar","Swathi Dinakaran"],"864":["Carlo Lipizzi","Dario Borrelli","Fernanda de Oliveira Capela"],"865":["Bohan Li","Yutai Hou","Wanxiang Che"],"866":["Alexey Birshert","Ekaterina Artemova"],"867":["Hyunjae Kim","Mujeen Sung","Wonjin Yoon","Sungjoon Park","Jaewoo Kang"],"868":["Yukyung Lee","Jina Kim","Pilsung Kang"],"869":["Lintang Sutawika","Jan Christian Blaise Cruz"],"870":["Swati Padhee","Kimberly Swygert","Ian Micir"],"871":["Wenpeng Yin","Shelby Heinecke","Jia Li","Nitish Shirish Keskar","Michael Jones","Shouzhong Shi","Stanislav Georgiev","Kurt Milich","Joseph Esposito","Caiming Xiong"],"872":["Bing Wang","Yue Wang","Ximing Li","Jihong Ouyang"],"873":["Ritesh Kumar","Enakshi Nandi","Laishram Niranjana Devi","Shyam Ratan","Siddharth Singh","Akash Bhagat","Yogesh Dawer"],"874":["Mohammad Javad Saeedizade","Najmeh Torabian","Behrouz Minaei-Bidgoli"],"875":["Giannis Bekoulis","Christina Papagiannopoulou","Nikos Deligiannis"],"876":["Alexandros Xenos","John Pavlopoulos","Ion Androutsopoulos","Lucas Dixon","Jeffrey Sorensen","Leo Laugier"],"877":["Asier Guti\u00e9rrez-Fandi\u00f1o","Miquel Noguer i Alonso","Petter Kolm","Jordi Armengol-Estap\u00e9"],"878":["Alexandra Vioni","Myrsini Christidou","Nikolaos Ellinas","Georgios Vamvoukakis","Panos Kakoulidis","Taehoon Kim","June Sig Sung","Hyoungmin Park","Aimilios Chalamandaris","Pirros Tsiakoulis"],"879":["Sergey Slavnov"],"880":["Konstantinos Klapsas","Nikolaos Ellinas","June Sig Sung","Hyoungmin Park","Spyros Raptis"],"881":["Myrsini Christidou","Alexandra Vioni","Nikolaos Ellinas","Georgios Vamvoukakis","Konstantinos Markopoulos","Panos Kakoulidis","June Sig Sung","Hyoungmin Park","Aimilios Chalamandaris","Pirros Tsiakoulis"],"882":["Prabhat Pandey","Sergio Duarte Torres","Ali Orkan Bayer","Ankur Gandhe","Volker Leutnant"],"883":["Nico Blokker","Andr\u00e9 Blessing","Erenay Dayanik","Jonas Kuhn","Sebastian Pad\u00f3","Gabriella Lapesa"],"884":["Junqiu Wei","Xiaozhe Ren","Xiaoguang Li","Wenyong Huang","Yi Liao","Yasheng Wang","Jiashu Lin","Xin Jiang","Xiao Chen","Qun Liu"],"885":["Elena Razova","Sergey Vychegzhanin","Evgeny Kotelnikov"],"886":["Anastasia Kotelnikova","Danil Paschenko","Klavdiya Bochenina","Evgeny Kotelnikov"],"887":["Shashank Bujimalla","Mahesh Subedar","Omesh Tickoo"],"888":["Ming Yan","Haiyang Xu","Chenliang Li","Junfeng Tian","Bin Bi","Wei Wang","Weihua Chen","Xianzhe Xu","Fan Wang","Zheng Cao","Zhicheng Zhang","Qiyu Zhang","Ji Zhang","Songfang Huang","Fei Huang","Luo Si","Rong Jin"],"889":["Ajay Jaiswal","Liyan Tang","Meheli Ghosh","Justin Rousseau","Yifan Peng","Ying Ding"],"890":["Sosuke Kobayashi","Sho Yokoi","Jun Suzuki","Kentaro Inui"],"891":["Lin Ni","Qiming Bao","Xiaoxuan Li","Qianqian Qi","Paul Denny","Jim Warren","Michael Witbrock","Jiamou Liu"],"892":["Jiyeon Kim","Mehul Kumar","Dhananjaya Gowda","Abhinav Garg","Chanwoo Kim"],"893":["Gowtham Ramesh","Sumanth Doddapaneni","Aravinth Bheemaraj","Mayank Jobanputra","Raghavan AK","Ajitesh Sharma","Sujit Sahoo","Harshita Diddee","Mahalakshmi J","Divyanshu Kakwani","Navneet Kumar","Aswin Pradeep","Srihari Nagaraj","Kumar Deepak","Vivek Raghavan","Anoop Kunchukuttan","Pratyush Kumar","Mitesh Shantadevi Khapra"],"894":["Liu Xingguang","Cheng Zhenbo","Shen Zhengyuan","Zhang Haoxin","Meng Hangcheng","Xu Xuesong","Xiao Gang"],"895":["Pavel Podberezko","Vsevolod Mitskevich","Raman Makouski","Pavel Goncharov","Andrei Khobnia","Nikolay Bushkov","Marina Chernyshevich"],"896":["Jiaying Gong","Hoda Eldardiry"],"897":["Chengxi Li","Brent Harrison"],"898":["Pawan Kalyan Jada","Konthala Yasaswini","Karthik Puranik","Anbukkarasi Sampath","Sathiyaraj Thangasamy","Kingston Pal Thamburaj"],"899":["Bharathi Raja Chakravarthi","Ruba Priyadharshini","Sajeetha Thavareesan","Dhivya Chinnappa","Durairaj Thenmozhi","Elizabeth Sherly","John P. McCrae","Adeep Hande","Rahul Ponnusamy","Shubhanker Banerjee","Charangan Vasantharajan"],"900":["Aviad Rom","Kfir Bar"],"901":["Zhanpeng Zeng","Yunyang Xiong","Sathya N. Ravi","Shailesh Acharya","Glenn Fung","Vikas Singh"],"902":["Kosuke Nishida","Kyosuke Nishida","Itsumi Saito","Sen Yoshida"],"903":["Aparajita Dey-Plissonneau","Hyowon Lee","Michael Scriney","Alan F. Smeaton","Vincent Pradier","Hamza Riaz"],"904":["Mario Giulianelli","Jacqueline Harding","Florian Mohnert","Dieuwke Hupkes","Willem Zuidema"],"905":["Yan Pan","Mingyang Ma","Bernhard Pflugfelder","Georg Groh"],"906":["Arnaldo Candido Junior","Edresson Casanova","Anderson Soares","Frederico Santos de Oliveira","Lucas Oliveira","Ricardo Corso Fernandes Junior","Daniel Peixoto Pinto da Silva","Fernando Gorgulho Fayet","Bruno Baldissera Carlotto","Lucas Rafael Stefanel Gris","Sandra Maria Alu\u00edsio"],"907":["Shira Guskin","Moshe Wasserblat","Ke Ding","Gyuwan Kim"],"908":["Hongjiang Jing","Zuchao Li","Hai Zhao","Shu Jiang"],"909":["G\u00f6zde G\u00fcl \u015eahin"],"910":["Urja Khurana","Eric Nalisnick","Antske Fokkens"],"911":["Hamdy Mubarak","Ahmed Abdelali","Kareem Darwish","Younes Samih"],"912":["Maria Heitmeier","Yu-Ying Chuang","R. Harald Baayen"],"913":["Kang Min Yoo","Dongju Park","Jaewook Kang","Sang-Woo Lee","Woomyeong Park"],"914":["Natalia Tomashenko","Xin Wang","Emmanuel Vincent","Jose Patino","Brij Mohan Lal Srivastava","Paul-Gauthier No\u00e9","Andreas Nautsch","Nicholas Evans","Junichi Yamagishi","Benjamin O'Brien","Ana\u00efs Chanclu","Jean-Fran\u00e7ois Bonastre","Massimiliano Todisco","Mohamed Maouche"],"915":["Dong-Jin Kim","Jae Won Cho","Jinsoo Choi","Yunjae Jung","In So Kweon"],"916":["Philippe Laban","Tobias Schnabel","Paul N. Bennett","Marti A. Hearst"],"917":["R. Thomas McCoy","Paul Smolensky","Tal Linzen","Jianfeng Gao","Asli Celikyilmaz"],"918":["Pavel Dolin","Luc d'Hauthuille","Andrea Vattani"],"919":["Tai-Danae Bradley","John Terilla","Yiannis Vlassopoulos"],"920":["Karl Cobbe","Vineet Kosaraju","Mohammad Bavarian","Mark Chen","Heewoo Jun","Lukasz Kaiser","Matthias Plappert","Jerry Tworek","Jacob Hilton","Reiichiro Nakano","Christopher Hesse","John Schulman"],"921":["Rhys Compton","Ilya Valmianski","Li Deng","Costa Huang","Namit Katariya","Xavier Amatriain","Anitha Kannan"],"922":["Keyon Vafa","Yuntian Deng","David M. Blei","Alexander M. Rush"],"923":["Srinivas Ravishankar","June Thai","Ibrahim Abdelaziz","Nandana Mihidukulasooriya","Tahira Naseem","Pavan Kapanipathi","Gaetano Rossiello","Achille Fokoue"],"924":["David Samuel","Milan Straka"],"925":["Milan Straka","Jakub N\u00e1plava","Jana Strakov\u00e1"],"926":["Yue Yang","Joongwon Kim","Artemis Panagopoulou","Mark Yatskar","Chris Callison-Burch"],"927":["Jakub N\u00e1plava","Martin Popel","Milan Straka","Jana Strakov\u00e1"],"928":["Ananth Balashankar","Lakshminarayanan Subramanian","Samuel P. Fraiberger"],"929":["Liang Xu","Jiacheng Liu","Xiang Pan","Xiaojing Lu","Xiaofeng Hou"],"930":["Zhijiang Guo","Michael Schlichtkrull","Andreas Vlachos"],"931":["Sian Gooding","Yevgeni Berzak","Tony Mak","Matt Sharifi"],"932":["Archit Parnami","Rahul Singh","Tarun Joshi"],"933":["Konstantinos Markopoulos","Nikolaos Ellinas","Alexandra Vioni","Myrsini Christidou","Panos Kakoulidis","Georgios Vamvoukakis","Georgia Maniati","June Sig Sung","Hyoungmin Park","Pirros Tsiakoulis","Aimilios Chalamandaris"],"934":["Georgia Maniati","Nikolaos Ellinas","Konstantinos Markopoulos","Georgios Vamvoukakis","June Sig Sung","Hyoungmin Park","Aimilios Chalamandaris","Pirros Tsiakoulis"],"935":["Aleksandra Edwards","Asahi Ushio","Jose Camacho-Collados","H\u00e9l\u00e8ne de Ribaupierre","Alun Preece"],"936":["Nikolaos Ellinas","Georgios Vamvoukakis","Konstantinos Markopoulos","Aimilios Chalamandaris","Georgia Maniati","Panos Kakoulidis","Spyros Raptis","June Sig Sung","Hyoungmin Park","Pirros Tsiakoulis"],"937":["Lars Kl\u00f6ser","Philipp Kohl","Bodo Kraft","Albert Z\u00fcndorf"],"938":["Peiyi Wang","Tianyu Liu","Damai Dai","Runxin Xu","Baobao Chang","Zhifang Sui"],"939":["Jungo Kasai","Keisuke Sakaguchi","Lavinia Dunagan","Jacob Morrison","Ronan Le Bras","Yejin Choi","Noah A. Smith"],"940":["Yaman Kumar Singla","Sriram Krishna","Rajiv Ratn Shah","Changyou Chen"],"941":["Maxwell A. Weinzierl","Sanda M. Harabagiu"],"942":["Richard Shin","Christopher H. Lin","Sam Thomson","Charles Chen","Subhro Roy","Emmanouil Antonios Platanios","Adam Pauls","Dan Klein","Jason Eisner","Benjamin Van Durme"],"943":["Hayate Iso","Xiaolan Wang","Yoshihiko Suhara","Stefanos Angelidis","Wang-Chiew Tan"],"944":["Abhilash Mishra","Yash Gorana"],"945":["Elnaz Zafarani-Moattar","Mohammad Reza Kangavari","Amir Masoud Rahmani"],"946":["Sandeep Subramanian","Oleksii Hrinchuk","Virginia Adams","Oleksii Kuchaiev"],"947":["Yoon Kim"],"948":["Lei Cui","Yiheng Xu","Tengchao Lv","Furu Wei"],"949":["Amanda Buddemeyer","Erin Walker","Malihe Alikhani"],"950":["Vinitra Swamy","Angelika Romanou","Martin Jaggi"],"951":["Harsh Sakhrani","Saloni Parekh","Shubham Mahajan"],"952":["Cheng Hsu","Cheng-Te Li","Diego Saez-Trumper","Yi-Zhan Hsu"],"953":["Milad Moradi","Matthias Samwald"],"954":["Mustafizur Shahid","Herv\u00e9 Debar"],"955":["Qihao Zhu","Jianxi Luo"],"956":["Erich R. Round","Sacha Beniamine","Louise Esher"],"957":["Philipp Kohl","Oliver Schmidts","Lars Kl\u00f6ser","Henri Werth","Bodo Kraft","Albert Z\u00fcndorf"],"958":["Maximilian Mozes","Isabelle van der Vegt","Bennett Kleinberg"],"959":["Lifan Yuan","Yichi Zhang","Yangyi Chen","Wei Wei"],"960":["Yi-Chang Chen","Chun-Yen Cheng","Chien-An Chen","Ming-Chieh Sung","Yi-Ren Yeh"],"961":["Zhixian Yang","Pengxuan Xu","Xiaojun Wan"],"962":["Shinhyeok Oh","Sion Jang","Hu Xu","Shounan An","Insoo Oh"],"963":["Leonard Tang","Elizabeth Ke","Nikhil Singh","Nakul Verma","Iddo Drori"],"964":["Andras Huebner","Wei Ji","Xiang Xiao"],"965":["Takatomo Kano","Atsunori Ogawa","Marc Delcroix","Shinji Watanabe"],"966":["Nianzu Zheng","Liqun Deng","Wenyong Huang","Yu Ting Yeung","Baohua Xu","Yuanyuan Guo","Yasheng Wang","Xin Jiang","Qun Liu"],"967":["Jason Phang","Angelica Chen","William Huang","Samuel R. Bowman"],"968":["Iddo Drori","Nakul Verma"],"969":["Junwen Bai","Bo Li","Yu Zhang","Ankur Bapna","Nikhil Siddhartha","Khe Chai Sim","Tara N. Sainath"],"970":["Zhuohan Xie","Trevor Cohn","Jey Han Lau"],"971":["Robert Robinson"],"972":["Gabriel Skantze","Bram Willemsen"],"973":["Mihaela G\u0103man","Radu Tudor Ionescu"],"974":["Nihir Vedd","Zixu Wang","Marek Rei","Yishu Miao","Lucia Specia"],"975":["Daniel Deutsch","Dan Roth"],"976":["Karthik Puranik","Bharathi B","Senthil Kumar B"],"977":["Myssar Jabbar Hammood Al-Battbootti","Iuliana Marin","Nicolae Goga","Ramona Popa"],"978":["Sarah Schr\u00f6der","Alexander Schulz","Philip Kenneweg","Robert Feldhans","Fabian Hinder","Barbara Hammer"],"979":["Yifei Yuan","Wai Lam"],"980":["Carlos Mena","Andrea DeMarco","Claudia Borg","Lonneke van der Plas","Albert Gatt"],"981":["Thanh Vu","Dai Quoc Nguyen"],"982":["Lifeng Han","Irina Sorokina","Gleb Erofeev","Serge Gladkoff"],"983":["Serge Gladkoff","Irina Sorokina","Lifeng Han","Alexandra Alekseeva"],"984":["Jialin Yu","Laila Alrajhi","Anoushka Harit","Zhongtian Sun","Alexandra I. Cristea","Lei Shi"],"985":["Amane Sugiyama","Naoki Yoshinaga"],"986":["Fenglin Liu","Chenyu You","Xian Wu","Shen Ge","Sheng Wang","Xu Sun"],"987":["Niall Taylor","Lei Sha","Dan W Joyce","Thomas Lukasiewicz","Alejo Nevado-Holgado","Andrey Kormilitzin"],"988":["Xin Zhang","Guangwei Xu","Yueheng Sun","Meishan Zhang","Pengjun Xie"],"989":["Naveen Ram","Tanay Gummadi","Rahul Bhethanabotla","Richard J. Savery","Gil Weinberg"],"990":["Maxat Tezekbayev","Vassilina Nikoulina","Matthias Gall\u00e9","Zhenisbek Assylbekov"],"991":["Hongzhan Lin","Jing Ma","Mingfei Cheng","Zhiwei Yang","Liangliang Chen","Guang Chen"],"992":["Zhu Li","Yuqing Zhang","Mengxi Nie","Ming Yan","Mengnan He","Ruixiong Zhang","Caixia Gong"],"993":["Renrui Zhang","Rongyao Fang","Wei Zhang","Peng Gao","Kunchang Li","Jifeng Dai","Yu Qiao","Hongsheng Li"],"994":["Siyu Lei","Ruiying Yang","Chu-Ren Huang"],"995":["Junxian He","Graham Neubig","Taylor Berg-Kirkpatrick"],"996":["Youxiang Zhu","Bang Tran","Xiaohui Liang","John A. Batsis","Robert M. Roth"],"997":["Jared Mowery"],"998":["Ting-Rui Chiang","Yi-Ting Yeh"],"999":["Kelvin Luu","Daniel Khashabi","Suchin Gururangan","Karishma Mandyam","Noah A. Smith"],"1000":["Junjie Hu","Hiroaki Hayashi","Kyunghyun Cho","Graham Neubig"],"1001":["Francisco Caio Lima Paiva","Leonardo Kanashiro Felizardo","Reinaldo Augusto da Costa Bianchi","Anna Helena Reali Costa"],"1002":["Jasmijn Bastings","Sebastian Ebert","Polina Zablotskaia","Anders Sandholm","Katja Filippova"],"1003":["Anubha Kabra","Mehar Bhatia","Yaman Kumar","Junyi Jessy Li","Rajiv Ratn Shah"],"1004":["Lucas G. O. Lopes","Thales M. A. Vieira","William W. M. Lira"],"1005":["Sahan Jayasinghe","Lakith Rambukkanage","Ashan Silva","Nisansa de Silva","Amal Shehan Perera"],"1006":["Jiangwei Liu","Xiaohong Huang"],"1007":["Elena Mikhalkova","Timofei Protasov","Anastasiia Drozdova","Anastasiia Bashmakova","Polina Gavin"],"1008":["Seongsu Bae","Daeyoung Kim","Jiho Kim","Edward Choi"],"1009":["Jiwen Zhang","Zhongyu Wei","Jianqing Fan","Jiajie Peng"],"1010":["Songxiang Liu","Dan Su","Dong Yu"],"1011":["Yuchen Liang","Mohammed J. Zaki"],"1012":["Tom De Smedt","Pierre Vou\u00e9","Sylvia Jaki","Emily Duffy","Lydia El-Khouri"],"1013":["Yizhen Zhang","Minkyu Choi","Kuan Han","Zhongming Liu"],"1014":["Ilia Karpov","Nick Kartashev"],"1015":["Khubaib Ahmed Qureshi"],"1016":["Matej Klemen","Marko Robnik-\u0160ikonja"],"1017":["Divyansh Singh"],"1018":["Jiayou Zhang","Zhirui Wang","Shizhuo Zhang","Megh Manoj Bhalerao","Yucong Liu","Dawei Zhu","Sheng Wang"],"1019":["Yu Zhang","Yu Meng","Jiaxin Huang","Frank F. Xu","Xuan Wang","Jiawei Han"],"1020":["Tanish Tyagi","Colin G. Magdamo","Ayush Noori","Zhaozhi Li","Xiao Liu","Mayuresh Deodhar","Zhuoqiao Hong","Wendong Ge","Elissa M. Ye","Yi-han Sheu","Haitham Alabsi","Laura Brenner","Gregory K. Robbins","Sahar Zafar","Nicole Benson","Lidia Moura","John Hsu","Alberto Serrano-Pozo","Dimitry Prokopenko","Rudolph E. Tanzi","Bradley T. Hyman","Deborah Blacker","Shibani S. Mukerji","M. Brandon Westover","Sudeshna Das"],"1021":["I-Hung Hsu","Xiao Guo","Premkumar Natarajan","Nanyun Peng"],"1022":["HongSeok Choi","Hyunju Lee"],"1023":["Sujay Kumar Jauhar","Nirupama Chandrasekaran","Michael Gamon","Ryen W. White"],"1024":["Igor Melnyk","Payel Das","Vijil Chenthamarakshan","Aurelie Lozano"],"1025":["Eleftheria Briakou","Sida I. Wang","Luke Zettlemoyer","Marjan Ghazvininejad"],"1026":["Shirley Anugrah Hayati","Dongyeop Kang","Lyle Ungar"],"1027":["Igor Kulev","Berkay K\u00f6pr\u00fc","Raul Rodriguez-Esteban","Diego Saldana","Yi Huang","Alessandro La Torraca","Elif Ozkirimli"],"1028":["Ganeshan Malhotra","Abdul Waheed","Aseem Srivastava","Md Shad Akhtar","Tanmoy Chakraborty"],"1029":["Qinxuan Wu","Allyson Ettinger"],"1030":["Ovishake Sen"," Al-Mahmud","Pias Roy"],"1031":["Mohsin Ali","Kandukuri Sai Teja","Sumanth Manduru","Parth Patwa","Amitava Das"],"1032":["Moontae Lee","Sungjun Cho","Kun Dong","David Mimno","David Bindel"],"1033":["Qingli Man","Yuanhao Zhuo"],"1034":["Ilya Valmianski","Nave Frost","Navdeep Sood","Yang Wang","Baodong Liu","James J. Zhu","Sunil Karumuri","Ian M. Finn","Daniel S. Zisook"],"1035":["Yu Zhang","Wei Wei","Binxuan Huang","Kathleen M. Carley","Yan Zhang"],"1036":["\u0141ukasz Kuci\u0144ski","Tomasz Korbak","Pawe\u0142 Ko\u0142odziej","Piotr Mi\u0142o\u015b"],"1037":["Yu Zhang","Zhihong Shen","Yuxiao Dong","Kuansan Wang","Jiawei Han"],"1038":["Peru Bhardwaj","John Kelleher","Luca Costabello","Declan O'Sullivan"],"1039":["Tomer Wullach","Amir Adler","Einat Minkov"],"1040":["Sarthak Khanal","Maria Traskowsky","Doina Caragea"],"1041":["Aly Moustafa","Salah A. Aly"],"1042":["Zijian Yang","Yingbo Gao","Alexander Gerstenberger","Jintao Jiang","Ralf Schl\u00fcter","Hermann Ney"],"1043":["Mack Makgatho","Vukosi Marivate","Tshephisho Sefara","Valencia Wagner"],"1044":["Mehmet Efruz Karabulut","K. Vijay-Shanker","Yifan Peng"],"1045":["Isabel Segura-Bedmar","David Camino-Perdonas","Sara Guerrero-Aspizua"],"1046":["Vikram Gupta"],"1047":["A. Fronzetti Colladon","J. Saint-Charles","P. Mongeau"],"1048":["Zhao Zhang","Fuzhen Zhuang","Hengshu Zhu","Chao Li","Hui Xiong","Qing He","Yongjun Xu"],"1049":["Jianyun Zou","Min Yang","Lichao Zhang","Yechen Xu","Qifan Pan","Fengqing Jiang","Ran Qin","Shushu Wang","Yifan He","Songfang Huang","Zhou Zhao"],"1050":["Xuechun Li","Xueyao Sun","Zewei Xu","Yifan Zhou"],"1051":["Jan Christian Blaise Cruz","Charibeth Cheng"],"1052":["Mingyang Song","Liping Jing","Lin Xiao"],"1053":["Denis Jered McInerney","Luyang Kong","Kristjan Arumae","Byron Wallace","Parminder Bhatia"],"1054":["Edwin G. Ng","Bo Pang","Piyush Sharma","Radu Soricut"],"1055":["Petra Galu\u0161\u010d\u00e1kov\u00e1","Douglas W. Oard","Suraj Nair"],"1056":["Babak Hemmatian","Sheridan Feucht","Rachel Avram","Alexander Wey","Muskaan Garg","Kate Spitalnic","Carsten Eickhoff","Ellie Pavlick","Bjorn Sandstede","Steven Sloman"],"1057":["Krishanu Das Baksi"],"1058":["Bing He","Caleb Ziems","Sandeep Soni","Naren Ramakrishnan","Diyi Yang","Srijan Kumar"],"1059":["Yuesheng Luo","Mayank Kejriwal"],"1060":["Lo\u00efc Rakotoson","Charles Letaillieur","Sylvain Massip","Fr\u00e9jus Laleye"],"1061":["Qianying Liu","Fei Cheng","Sadao Kurohashi"],"1062":["Qianying Liu","Wenyu Guan","Sujian Li","Fei Cheng","Daisuke Kawahara","Sadao Kurohashi"],"1063":["Ofir Zafrir","Ariel Larey","Guy Boudoukh","Haihao Shen","Moshe Wasserblat"],"1064":["Lena Reed","Cecilia Li","Angela Ramirez","Liren Wu","Marilyn Walker"],"1065":["Kholoud Alsubhi","Amani Jamal","Areej Alhothali"],"1066":["Tadej \u0160kvorc","Polona Gantar","Marko Robnik-\u0160ikonja"],"1067":["Zijian Gao","Jingyu Liu","Sheng Chen","Dedan Chang","Hao Zhang","Jinwei Yuan"],"1068":["Stijn Schouten","Victor de Boer","Lodewijk Petram","Marieke van Erp"],"1069":["Enrica Troiano","Aswathy Velutharambath","Roman Klinger"],"1070":["Ali Balali","Masoud Asadpour","Seyed Hossein Jafari"],"1071":["Paul Pu Liang","Yiwei Lyu","Xiang Fan","Zetian Wu","Yun Cheng","Jason Wu","Leslie Chen","Peter Wu","Michelle A. Lee","Yuke Zhu","Ruslan Salakhutdinov","Louis-Philippe Morency"],"1072":["Takyoung Kim","Yukyung Lee","Hoonsang Yoon","Pilsung Kang","Junseong Bang","Misuk Kim"],"1073":["Jingjing Xu","Wangchunshu Zhou","Zhiyi Fu","Hao Zhou","Lei Li"],"1074":["Md Mustafizur Rahman","Dinesh Balakrishnan","Dhiraj Murthy","Mucahid Kutlu","Matthew Lease"],"1075":["Jieyan Zhu"],"1076":["Manuela Nayantara Jeyaraj","Dharshana Kasthurirathna"],"1077":["Dongyu Ru","Changzhi Sun","Jiangtao Feng","Lin Qiu","Hao Zhou","Weinan Zhang","Yong Yu","Lei Li"],"1078":["Fan Bai","Alan Ritter","Wei Xu"],"1079":["Ozan \u0130rsoy","Adrian Benton","Karl Stratos"],"1080":["Jessica Huynh","Jeffrey Bigham","Maxine Eskenazi"],"1081":["Leonard Adolphs","Kurt Shuster","Jack Urbanek","Arthur Szlam","Jason Weston"],"1082":["Alexandra Hotti","Riccardo Sven Risuleo","Stefan Magureanu","Aref Moradi","Jens Lagergren"],"1083":["Kritika Venkatachalam","Raghava Mutharaju","Sumit Bhatia"],"1084":["Safa Alsaidi","Amandine Decker","Esteban Marquer","Pierre-Alexandre Murena","Miguel Couceiro"],"1085":["Alexander Michael Daniel"],"1086":["G\u00e9rald Kembellec"],"1087":["Xu Zou","Da Yin","Qingyang Zhong","Ming Ding","Hongxia Yang","Zhilin Yang","Jie Tang"],"1088":["Wang Zhu","Peter Shaw","Tal Linzen","Fei Sha"],"1089":["Sabur Butt","Shakshi Sharma","Rajesh Sharma","Grigori Sidorov","Alexander Gelbukh"],"1090":["Andrew Shin","Masato Ishii","Takuya Narihira"],"1091":["Abu Kaisar Mohammad Masum","Sheikh Abujar","Sharmin Akter","Nushrat Jahan Ria","Syed Akhter Hossain"],"1092":["Songqiao Han","Hailiang Huang","Jiangwei Liu","Shengsheng Xiao"],"1093":["Bingkun Chen","Shaobing Dai","Shenghua Zheng","Lei Liao","Yang Li"],"1094":["Tatiana Likhomanenko","Qiantong Xu","Gabriel Synnaeve","Ronan Collobert","Alex Rogozhnikov"],"1095":["Dinh-Truong Do","Ha Thanh Nguyen","Thang Ngoc Bui","Dinh Hieu Vo"],"1096":["Hengameh Mirzaalian","Mohamed E. Hussein","Leonidas Spinoulas","Jonathan May","Wael Abd-Almageed"],"1097":["Dan Hendrycks","Collin Burns","Saurav Kadavath","Akul Arora","Steven Basart","Eric Tang","Dawn Song","Jacob Steinhardt"],"1098":["Dan Hendrycks","Collin Burns","Anya Chen","Spencer Ball"],"1099":["Dan Hendrycks","Steven Basart","Saurav Kadavath","Mantas Mazeika","Akul Arora","Ethan Guo","Collin Burns","Samir Puranik","Horace He","Dawn Song","Jacob Steinhardt"],"1100":["Andrew Rouditchenko","Angie Boggust","David Harwath","Samuel Thomas","Hilde Kuehne","Brian Chen","Rameswar Panda","Rogerio Feris","Brian Kingsbury","Michael Picheny","James Glass"],"1101":["Muralikrishnna G. Sethuraman","Ali Payani","Faramarz Fekri","J. Clayton Kerce"],"1102":["Jonathan Bragg","Arman Cohan","Kyle Lo","Iz Beltagy"],"1103":["Xinyu Zhang","Xueguang Ma","Peng Shi","Jimmy Lin"],"1104":["Mika H\u00e4m\u00e4l\u00e4inen","Pattama Patpong","Khalid Alnajjar","Niko Partanen","Jack Rueter"],"1105":["Angel Felipe Magnoss\u00e3o de Paula","Roberto Fray da Silva","Ipek Baris Schlicht"],"1106":["Angel Felipe Magnoss\u00e3o de Paula","Ipek Baris Schlicht"],"1107":["Sara Papi","Matteo Negri","Marco Turchi"],"1108":["Eric Stubley"],"1109":["Sergey Gorshkov","Constantin Kondratiev","Roman Shebalov"],"1110":["Yulin Li","Yuxi Qian","Yuchen Yu","Xiameng Qin","Chengquan Zhang","Yan Liu","Kun Yao","Junyu Han","Jingtuo Liu","Errui Ding"],"1111":["Alexandre Berard","Dain Lee","St\u00e9phane Clinchant","Kweonwoo Jung","Vassilina Nikoulina"],"1112":["Xingyu Chen","Zihan Zhao","Lu Chen","Danyang Zhang","Jiabao Ji","Ao Luo","Yuxuan Xiong","Kai Yu"],"1113":["Hao Zhang","Aixin Sun","Wei Jing","Joey Tianyi Zhou"],"1114":["Yuta Koreeda","Christopher D. Manning"],"1115":["Fei Cheng","Shuntaro Yada","Ribeka Tanaka","Eiji Aramaki","Sadao Kurohashi"],"1116":["Autumn Toney-Wails","Aylin Caliskan"],"1117":["Rajarshi Das","Manzil Zaheer","Dung Thai","Ameya Godbole","Ethan Perez","Jay-Yoon Lee","Lizhen Tan","Lazaros Polymenakos","Andrew McCallum"],"1118":["Siddhant Garg","Goutham Ramakrishnan","Varun Thumbe"],"1119":["Daisy Stanton","Matt Shannon","Soroosh Mariooryad","RJ Skerry-Ryan","Eric Battenberg","Tom Bagby","David Kao"],"1120":["Salima Mdhaffar","Jean-Fran\u00e7ois Bonastre","Marc Tommasi","Natalia Tomashenko","Yannick Est\u00e8ve"],"1121":["Zeerak Talat","Hagen Blix","Josef Valvoda","Maya Indira Ganesh","Ryan Cotterell","Adina Williams"],"1122":["Thomas Fel","Remi Cadene","Mathieu Chalvidal","Matthieu Cord","David Vigouroux","Thomas Serre"],"1123":["Xingcheng Yao","Yanan Zheng","Xiaocong Yang","Zhilin Yang"],"1124":["Sheshera Mysore","Tim O'Gorman","Andrew McCallum","Hamed Zamani"],"1125":["Attila Nagy"],"1126":["Runzhe Zhan","Xuebo Liu","Derek F. Wong","Lidia S. Chao"],"1127":["Barriere Valentin","Jacquet Guillaume"],"1128":["Ismail Oussaid","William Vanhuffel","Pirashanth Ratnamogan","Mhamed Hajaiej","Alexis Mathey","Thomas Gilles"],"1129":["Sung-Feng Huang","Chyi-Jiunn Lin","Hung-yi Lee"],"1130":["Wenhao Zhu","Shujian Huang","Tong Pu","Pingxuan Huang","Xu Zhang","Jian Yu","Wei Chen","Yanfeng Wang","Jiajun Chen"],"1131":["Tal Schuster","Ashwin Kalyan","Oleksandr Polozov","Adam Tauman Kalai"],"1132":["Sven Buechel","Luise Modersohn","Udo Hahn"],"1133":["Zhongkai Shangguan","Zihe Zheng","Lei Lin"],"1134":["Timo Kats","Peter van der Putten","Jasper Schelling"],"1135":["Xiaoya Li","Jiwei Li","Xiaofei Sun","Chun Fan","Tianwei Zhang","Fei Wu","Yuxian Meng","Jun Zhang"],"1136":["Renukswamy Chikkamath","Vishvapalsinhji Ramsinh Parmar","Christoph Hewel","Markus Endres"],"1137":["Ali Osman Berk Sapci","Oznur Tastan","Reyyan Yeniterzi"],"1138":["Aditya Mandke","Onkar Litake","Dipali Kadam"],"1139":["Mika H\u00e4m\u00e4l\u00e4inen","Khalid Alnajjar","Niko Partanen","Jack Rueter"],"1140":["Ruiyang Qin","Haozheng Luo","Zheheng Fan","Ziang Ren"],"1141":["Maude Nguyen-The","Guillaume-Alexandre Bilodeau","Jan Rockemann"],"1142":["Subhabrata Choudhury","Iro Laina","Christian Rupprecht","Andrea Vedaldi"],"1143":["Yu Gai","Paras Jain","Wendi Zhang","Joseph E. Gonzalez","Dawn Song","Ion Stoica"],"1144":["Michihiro Yasunaga","Hongyu Ren","Antoine Bosselut","Percy Liang","Jure Leskovec"],"1145":["Amikul Kalra","Arkaitz Zubiaga"],"1146":["Joshua Rozner","Christopher Potts","Kyle Mahowald"],"1147":["Aditya Kadam","Anmol Goel","Jivitesh Jain","Jushaan Singh Kalra","Mallika Subramanian","Manvith Reddy","Prashant Kodali","T. H. Arjun","Manish Shrivastava","Ponnurangam Kumaraguru"],"1148":["Jianping Mei","Yilun Zheng","Qianwei Zhou","Rui Yan"],"1149":["Rahul Mishra","Shuo Zhang"],"1150":["Yangtao Zhang","X. Jessie Yang","Feng Zhou"],"1151":["Cl\u00e9ment Christophe","Julien Velcin","Jairo Cugliari","Manel Boumghar","Philippe Suignard"],"1152":["Irena Spasic"],"1153":["Bharathi Raja Chakravarthi","Dhivya Chinnappa","Ruba Priyadharshini","Anand Kumar Madasamy","Sangeetha Sivanesan","Subalalitha Chinnaudayar Navaneethakrishnan","Sajeetha Thavareesan","Dhanalakshmi Vadivel","Rahul Ponnusamy","Prasanna Kumar Kumaresan"],"1154":["Masato Kikuchi","Mitsuo Yoshida","Kyoji Umemura","Tadachika Ozono"],"1155":["Zhihao Fan","Zhongyu Wei","Zejun Li","Siyuan Wang","Jianqing Fan"],"1156":["Emmanuel Paviot-Adet","Denis Poitrenaud","Etienne Renault","Yann Thierry-Mieg"],"1157":["Guanhua Chen","Shuming Ma","Yun Chen","Li Dong","Dongdong Zhang","Jia Pan","Wenping Wang","Furu Wei"],"1158":["Taichi Murayama"],"1159":["Zhaohong Wan","Xiaojun Wan"],"1160":["Leilei Gan","Yating Zhang","Kun Kuang","Lin Yuan","Shuo Li","Changlong Sun","Xiaozhong Liu","Fei Wu"],"1161":["Feng-Ju Chang","Jing Liu","Martin Radfar","Athanasios Mouchtaris","Maurizio Omologo","Ariya Rastrow","Siegfried Kunzmann"],"1162":["Bin Liu","Guosheng Yin","Wenbin Du"],"1163":["Zihao Wang","Hang Yin","Yangqiu Song"],"1164":["Chester Palen-Michel","Nolan Holley","Constantine Lignos"],"1165":["Chowdhury Rafeed Rahman","MD. Hasibur Rahman","Mohammad Rafsan","Samiha Zakir","Mohammed Eunus Ali","Rafsanjani Muhammod"],"1166":["Jiangwei Liu","Liangyu Min","Xiaohong Huang"],"1167":["Siddharth Karamcheti","Megha Srivastava","Percy Liang","Dorsa Sadigh"],"1168":["Liangming Pan","Wenhu Chen","Min-Yen Kan","William Yang Wang"],"1169":["Junha Roh","Karthik Desingh","Ali Farhadi","Dieter Fox"],"1170":["Peru Bhardwaj","John Kelleher","Luca Costabello","Declan O'Sullivan"],"1171":["Anthony Bau","Jacob Andreas"],"1172":["Mycal Tucker","Huao Li","Siddharth Agrawal","Dana Hughes","Katia Sycara","Michael Lewis","Julie Shah"],"1173":["Alessandro Suglia","Qiaozi Gao","Jesse Thomason","Govind Thattai","Gaurav Sukhatme"],"1174":["Manuel A. Borroto Santana","Francesco Ricca","Bernardo Cuteri"],"1175":["Ehsan Tavan","Ali Rahmati","Maryam Najafi","Saeed Bibak","Zahed Rahmati"],"1176":["Matthias Gall\u00e9","Jos Rozen","Germ\u00e1n Kruszewski","Hady Elsahar"],"1177":["Seolhwa Lee","Kisu Yang","Chanjun Park","Jo\u00e3o Sedoc","Heuiseok Lim"],"1178":["Tan Huang"],"1179":["Gerhard Hagerer","Wing Sheung Leung","Qiaoxi Liu","Hannah Danner","Georg Groh"],"1180":["Kevin Eloff","Arnu Pretorius","Okko R\u00e4s\u00e4nen","Herman A. Engelbrecht","Herman Kamper"],"1181":["Jes\u00fas Santamar\u00eda"],"1182":["Xingjian Shi","Jonas Mueller","Nick Erickson","Mu Li","Alexander J. Smola"],"1183":["Nikolaos Stylianou","Ioannis Vlahavas"],"1184":["Matthew Baas","Herman Kamper"],"1185":["Han Wu","Kun Xu","Linqi Song"],"1186":["Peng Fan","Dongyue Guo","Yi Lin","Bo Yang","Jianwei Zhang"],"1187":["Shi Zong","Ashutosh Baheti","Wei Xu","Alan Ritter"],"1188":["Shruti Rijhwani","Daisy Rosenblum","Antonios Anastasopoulos","Graham Neubig"],"1189":["Kanishka Misra"],"1190":["Mehrad Moradshahi","Victoria Tsai","Giovanni Campagna","Monica S. Lam"],"1191":["Subhabrata Mukherjee","Xiaodong Liu","Guoqing Zheng","Saghar Hosseini","Hao Cheng","Greg Yang","Christopher Meek","Ahmed Hassan Awadallah","Jianfeng Gao"],"1192":["Tanya Goyal","Nazneen Fatema Rajani","Wenhao Liu","Wojciech Kry\u015bci\u0144ski"],"1193":["Juraj Juraska","Kevin K. Bowden","Lena Reed","Vrindavan Harrison","Wen Cui","Omkar Patil","Rishi Rajasekaran","Angela Ramirez","Cecilia Li","Eduardo Zamora","Phillip Lee","Jeshwanth Bheemanpally","Rohan Pandey","Adwait Ratnaparkhi","Marilyn Walker"],"1194":["Pieter Floris Jacobs","Gideon Maillette de Buy Wenniger","Marco Wiering","Lambert Schomaker"],"1195":["Fanchao Qi","Yangyi Chen","Mukai Li","Yuan Yao","Zhiyuan Liu","Maosong Sun"],"1196":["Hamzeh Motahari Khansari","Mehrnoush Shamsfard"],"1197":["Wenhui Wang","Hangbo Bao","Li Dong","Furu Wei"],"1198":["Alex Kruckman","Lawrence S. Moss"],"1199":["Gerhard Hagerer","David Szabo","Andreas Koch","Maria Luisa Ripoll Dominguez","Christian Widmer","Maximilian Wich","Hannah Danner","Georg Groh"],"1200":["Qing Han","Shubo Tian","Jinfeng Zhang"],"1201":["Gilchan Park","Julia M. Taylor"],"1202":["Dylan R. Ashley","Vincent Herrmann","Zachary Friggstad","Kory W. Mathewson","J\u00fcrgen Schmidhuber"],"1203":["Zhengyan Li","Yicheng Zou","Chong Zhang","Qi Zhang","Zhongyu Wei"],"1204":["Ziwang Fu","Feng Liu","Hanyang Wang","Jiayin Qi","Xiangling Fu","Aimin Zhou","Zhibin Li"],"1205":["Jesse Cui","Tingdan Zhang","Kokil Jaidka","Dandan Pang","Garrick Sherman","Vinit Jakhetiya","Lyle Ungar","Sharath Chandra Guntuku"],"1206":["Melissa Ailem","Jinghsu Liu","Raheel Qader"],"1207":["Christoph Schuhmann","Richard Vencu","Romain Beaumont","Robert Kaczmarczyk","Clayton Mullis","Aarush Katta","Theo Coombes","Jenia Jitsev","Aran Komatsuzaki"],"1208":["David Dale","Anton Voronov","Daryna Dementieva","Varvara Logacheva","Olga Kozlova","Nikita Semenov","Alexander Panchenko"],"1209":["Jian Yang","Shuming Ma","Haoyang Huang","Dongdong Zhang","Li Dong","Shaohan Huang","Alexandre Muzio","Saksham Singhal","Hany Hassan Awadalla","Xia Song","Furu Wei"],"1210":["Dongyue Guo","Jianwei Zhang","Bo Yang","Yi Lin"],"1211":["Shining Liang","Wanli Zuo","Zhenkun Shi","Sen Wang","Junhu Wang","Xianglin Zuo"],"1212":["Pu-Chin Chen","Henry Tsai","Srinadh Bhojanapalli","Hyung Won Chung","Yin-Wen Chang","Chun-Sung Ferng"],"1213":["Shengjie Luo","Shanda Li","Tianle Cai","Di He","Dinglan Peng","Shuxin Zheng","Guolin Ke","Liwei Wang","Tie-Yan Liu"],"1214":["Ning Ding","Shengding Hu","Weilin Zhao","Yulin Chen","Zhiyuan Liu","Hai-Tao Zheng","Maosong Sun"],"1215":["Linlong Xu","Baosong Yang","Xiaoyu Lv","Tianchi Bi","Dayiheng Liu","Haibo Zhang"],"1216":["Juuso Eronen","Michal Ptaszynski","Fumito Masui","Aleksander Smywi\u0144ski-Pohl","Gniewosz Leliwa","Michal Wroczynski"],"1217":["Xuezhe Ma","Xiang Kong","Sinong Wang","Chunting Zhou","Jonathan May","Hao Ma","Luke Zettlemoyer"],"1218":["Bipasha Sen","Aditya Agarwal","Rudrabha Mukhopadhyay","Vinay Namboodiri","C V Jawahar"],"1219":["Archita Pathak","Rohini K. Srihari"],"1220":["Sungjoon Park","Jihyung Moon","Sungdong Kim","Won Ik Cho","Jiyoon Han","Jangwon Park","Chisung Song","Junseong Kim","Yongsook Song","Taehwan Oh","Joohong Lee","Juhyun Oh","Sungwon Lyu","Younghoon Jeong","Inkwon Lee","Sangwoo Seo","Dongjun Lee","Hyunwoo Kim","Myeonghwa Lee","Seongbo Jang","Seungwon Do","Sunkyoung Kim","Kyungtae Lim","Jongwon Lee","Kyumin Park","Jamin Shin","Seonghyun Kim","Lucy Park","Alice Oh","Jung-Woo Ha","Kyunghyun Cho"],"1221":["Hendrik Strobelt","Benjamin Hoover","Arvind Satyanarayan","Sebastian Gehrmann"],"1222":["Samreen Kazi","Shakeel Khoja"],"1223":["Hind Saleh","Areej Alhothali","Kawthar Moria"],"1224":["Eliya Nachmani","Shaked Dovrat"],"1225":["Ruixi Lin","Hwee Tou Ng"],"1226":["Atharv Singh Patlan","Shiven Tripathi","Shubham Korde"],"1227":["Hongru Wang","Huimin Wang","Zezhong Wang","Kam-Fai Wong"],"1228":["Thayer Alshaabi","Colin M. Van Oort","Mikaela Irene Fudolig","Michael V. Arnold","Christopher M. Danforth","Peter Sheridan Dodds"],"1229":["Chen Zhang","Luis Fernando D'Haro","Yiming Chen","Thomas Friedrichs","Haizhou Li"],"1230":["Aakanksha Naik","Jill Lehman","Carolyn Rose"],"1231":["Peter Wu","Jiatong Shi","Yifan Zhong","Shinji Watanabe","Alan W Black"],"1232":["Trapit Bansal","Karthick Gunasekaran","Tong Wang","Tsendsuren Munkhdalai","Andrew McCallum"],"1233":["Shaw-Hwa Lo","Yiqiao Yin"],"1234":["Jiaying Lu","Xiangjue Dong","Carl Yang"],"1235":["Bonan Min","Hayley Ross","Elior Sulem","Amir Pouran Ben Veyseh","Thien Huu Nguyen","Oscar Sainz","Eneko Agirre","Ilana Heinz","Dan Roth"],"1236":["Zhiyang Xu","Andrew Drozdov","Jay Yoon Lee","Tim O'Gorman","Subendhu Rongali","Dylan Finkbeiner","Shilpa Suresh","Mohit Iyyer","Andrew McCallum"],"1237":["Parul Chopra","Sai Krishna Rallabandi","Alan W Black","Khyathi Raghavi Chandu"],"1238":["Sailik Sengupta","Jason Krone","Saab Mansour"],"1239":["Soham Tiwari","Kshitiz Lakhotia","Manjunath Mulimani"],"1240":["Avia Efrat","Uri Shaham","Dan Kilman","Omer Levy"],"1241":["Matthew Matero","Nikita Soni","Niranjan Balasubramanian","H. Andrew Schwartz"],"1242":["Supriya Nagesh","Alexander Moreno","Stephanie M. Carpenter","Jamie Yap","Soujanya Chatterjee","Steven Lloyd Lizotte","Neng Wan","Santosh Kumar","Cho Lam","David W. Wetter","Inbal Nahum-Shani","James M. Rehg"],"1243":["Salah A. Aly","Abdelrahman Salah","Hesham M. Eraqi"],"1244":["Sam Shleifer","Jason Weston","Myle Ott"],"1245":["Yulei Niu","Hanwang Zhang"],"1246":["Ruijie Jiang","Julia Gouvea","Eric Miller","David Hammer","Shuchin Aeron"],"1247":["Abhishek Velankar","Hrushikesh Patil","Amol Gore","Shubham Salunke","Raviraj Joshi"],"1248":["Teodor Ti\u0163a","Arkaitz Zubiaga"],"1249":["Ravindra Nayak","Raviraj Joshi"],"1250":["Marcelo Sancinetti","Jazmin Vidal","Cyntia Bonomi","Luciana Ferrer"],"1251":["Yushi Hirose","Masashi Shimbo","Taro Watanabe"],"1252":["Pan Yang","Xin Cong","Zhenyun Sun","Xingwu Liu"],"1253":["Ridewaan Hanslo"],"1254":["Sharid Lo\u00e1iciga","Luca Bevacqua","Christian Hardmeier"],"1255":["Chi-Liang Liu","Tsung-Yuan Hsu","Yung-Sung Chuang","Chung-Yi Li","Hung-yi Lee"],"1256":["Marvin Kaster","Wei Zhao","Steffen Eger"],"1257":["Chi-Liang Liu","Hung-yi Lee"],"1258":["Sugyeong Eo","Chanjun Park","Jaehyung Seo","Hyeonseok Moon","Heuiseok Lim"],"1259":["Jochen Z\u00f6llner","Konrad Sperfeld","Christoph Wick","Roger Labahn"],"1260":["Lianzhe Huang","Peiyi Wang","Sujian Li","Tianyu Liu","Xiaodong Zhang","Zhicong Cheng","Dawei Yin","Houfeng Wang"],"1261":["Yongrui Chen","Huiying Li","Guilin Qi","Tianxing Wu","Tenggou Wang"],"1262":["Vedangi Wagh","Snehal Khandve","Isha Joshi","Apurva Wani","Geetanjali Kale","Raviraj Joshi"],"1263":["Mihalis Gongolidis","Jeremy Minton","Ronin Wu","Valentin Stauber","Jason Hoelscher-Obermaier","Viktor Botev"],"1264":["Rongsheng Zhang","Yinhe Zheng","Xiaoxi Mao","Minlie Huang"],"1265":["Jie Yang","Soyeon Caren Han","Josiah Poon"],"1266":["Jehad Aldahdooh","Ziaurrehman Tanoli","Jing Tang"],"1267":["Anurag Katakkar","Alan W Black"],"1268":["Sairamvinay Vijayaraghavan","Jinxiao Song","David Tomassi","Siddhartha Punj","Jailan Sabet"],"1269":["James D. Finch","Sarah E. Finch","Jinho D. Choi"],"1270":["Sarah E. Finch","James D. Finch","Daniil Huryn","William Hutsell","Xiaoyuan Huang","Han He","Jinho D. Choi"],"1271":["Paul Gu\u00e9lorget","Benjamin Icard","Guillaume Gadek","Souhir Gahbiche","Sylvain Gatepaille","Ghislain Atemezing","Paul \u00c9gr\u00e9"],"1272":["Trung Dang","Om Thakkar","Swaroop Ramaswamy","Rajiv Mathews","Peter Chin","Fran\u00e7oise Beaufays"],"1273":["Nathan Crone","Adam Power","John Weldon"],"1274":["Dheeraj Rajagopal","Vivek Khetan","Bogdan Sacaleanu","Anatole Gershman","Andrew Fano","Eduard Hovy"],"1275":["Maor Ivgi","Jonathan Berant"],"1276":["Gunjan Haldar","Aman Mittal","Pradyumna Gupta"],"1277":["Ziyang Ma","Xianjing Han","Xuemeng Song","Yiran Cui","Liqiang Nie"],"1278":["Aneesh Muppidi","Martin Radfar"],"1279":["Martin Radfar","Athanasios Mouchtaris","Siegfried Kunzmann","Ariya Rastrow"],"1280":["Olawale Onabola","Zhuang Ma","Yang Xie","Benjamin Akera","Abdulrahman Ibraheem","Jia Xue","Dianbo Liu","Yoshua Bengio"],"1281":["Sourya Dipta Das","Ayan Basak","Soumil Mandal","Dipankar Das"],"1282":["Emmanouil Zaranis","Georgios Paraskevopoulos","Athanasios Katsamanis","Alexandros Potamianos"],"1283":["Sofia Oliveira","Daniel Loureiro","Al\u00edpio Jorge"],"1284":["Nurudin Alvarez-Gonzalez","Andreas Kaltenbrunner","Vicen\u00e7 G\u00f3mez"],"1285":["Irene Li","Vanessa Yan","Dragomir Radev"],"1286":["Nurendra Choudhary","Nikhil Rao","Sumeet Katariya","Karthik Subbian","Chandan K. Reddy"],"1287":["Arman Malekzadeh","Amin Gheibi","Ali Mohades"],"1288":["Chengrui Zhu","Keyu An","Huahuan Zheng","Zhijian Ou"],"1289":["Xuanli He","Iman Keivanloo","Yi Xu","Xiang He","Belinda Zeng","Santosh Rajagopalan","Trishul Chilimbi"],"1290":["Suvir Mirchandani","Siddharth Karamcheti","Dorsa Sadigh"],"1291":["Lujia Shen","Shouling Ji","Xuhong Zhang","Jinfeng Li","Jing Chen","Jie Shi","Chengfang Fang","Jianwei Yin","Ting Wang"],"1292":["Jaehyung Seo","Chanjun Park","Sugyeong Eo","Hyeonseok Moon","Heuiseok Lim"],"1293":["Chanjun Park","Seolhwa Lee","Hyeonseok Moon","Sugyeong Eo","Jaehyung Seo","Heuiseok Lim"],"1294":["Guoshun Nan","Guoqing Luo","Sicong Leng","Yao Xiao","Wei Lu"],"1295":["Yaqing Wang","Song Wang","Quanming Yao","Dejing Dou"],"1296":["Xuxi Chen","Tianlong Chen","Yu Cheng","Weizhu Chen","Zhangyang Wang","Ahmed Hassan Awadallah"],"1297":["Yifan Chen","Qi Zeng","Heng Ji","Yun Yang"],"1298":["K R Prajwal","Liliane Momeni","Triantafyllos Afouras","Andrew Zisserman"],"1299":["Letian Peng","Zuchao Li","Hai Zhao"],"1300":["Lily Davies","Marta Baldracchi","Carlo Alessandro Borella","Konstantinos Perifanos"],"1301":["Thi Huyen Nguyen","Tu Nguyen","Tuan-Anh Hoang","Claudia Nieder\u00e9e"],"1302":["Hang Zhang","Yeyun Gong","Yelong Shen","Jiancheng Lv","Nan Duan","Weizhu Chen"],"1303":["Peng Qi","Haejun Lee","Oghenetegiri \"TG\" Sido","Christopher D. Manning"],"1304":["Lukas Lange","Jannik Str\u00f6tgen","Heike Adel","Dietrich Klakow"],"1305":["Lukas Lange","Heike Adel","Jannik Str\u00f6tgen","Dietrich Klakow"],"1306":["Arnav Bhakta","Yeunjoo Kim","Pamela Cole"],"1307":["Bo Yang","Lijun Wu"],"1308":["Flor Miriam Plaza-del-Arco","Sercan Halat","Sebastian Pad\u00f3","Roman Klinger"],"1309":["Elena \u00c1lvarez Mellado","Luis Espinosa Anke","Julio Gonzalo Arroyo","Constantine Lignos","Jordi Porta Zamorano"],"1310":["Xin Tian","Liankai Huang","Yingzhan Lin","Siqi Bao","Huang He","Yunyi Yang","Hua Wu","Fan Wang","Shuqi Sun"],"1311":["Guanglin Niu","Yang Li","Chengguang Tang","Zhongkai Hu","Shibin Yang","Peng Li","Chengyu Wang","Hao Wang","Jian Sun"],"1312":["Shaoxiong Ji","Tianlin Zhang","Luna Ansari","Jie Fu","Prayag Tiwari","Erik Cambria"],"1313":["Simmi Marina Joseph","Salvatore Citraro","Virginia Morini","Giulio Rossetti","Massimo Stella"],"1314":["Vivek Kalyan","Paul Tan","Shaun Tan","Martin Andrews"],"1315":["Yu Zhao","Jia Song","Huali Feng","Fuzhen Zhuang","Qing Li","Xiaojie Wang","Ji Liu"],"1316":["Keyur Faldu","Amit Sheth","Prashant Kikani","Manas Gaur","Aditi Avasthi"],"1317":["Pisit Nakjai","Tatpong Katanyukul"],"1318":["Jiawei Zhou","Tahira Naseem","Ram\u00f3n Fernandez Astudillo","Young-Suk Lee","Radu Florian","Salim Roukos"],"1319":["Liang He","Shizhuo Zhang","Lijun Wu","Huanhuan Xia","Fusong Ju","He Zhang","Siyuan Liu","Yingce Xia","Jianwei Zhu","Pan Deng","Bin Shao","Tao Qin","Tie-Yan Liu"],"1320":["Dmitry Soshnikov","Vickie Soshnikova"],"1321":["Heming Wang","Yao Qian","Xiaofei Wang","Yiming Wang","Chengyi Wang","Shujie Liu","Takuya Yoshioka","Jinyu Li","DeLiang Wang"],"1322":["Sam Wiseman","Arturs Backurs","Karl Stratos"],"1323":["Diwakar Mahajan","Jennifer J. Liang","Ching-Huei Tsou"],"1324":["Zhaozhen Xu","Amelia Howarth","Nicole Briggs","Nello Cristianini"],"1325":["Toru Lin","Minyoung Huh","Chris Stauffer","Ser-Nam Lim","Phillip Isola"],"1326":["Connor Holmes","Minjia Zhang","Yuxiong He","Bo Wu"],"1327":["Hadrien Lautraite","Nada Naji","Louis Marceau","Marc Queudot","Eric Charton"],"1328":["Li-Wei Chen","Alexander Rudnicky"],"1329":["Christopher Akiki","Martin Potthast"],"1330":["Wenjuan Han","Hwee Tou Ng"],"1331":["Debajyoti Datta","Shashwat Kumar","Laura Barnes","Tom Fletcher"],"1332":["Gerhard Hagerer","Laura Lahesoo","Miriam Ansch\u00fctz","Stephan Krusche","Georg Groh"],"1333":["Aneta Koleva","Martin Ringsquandl","Mitchell Joblin","Volker Tresp"],"1334":["Felix Soldner","Bennett Kleinberg","Shane Johnson"],"1335":["Lukas Stappen","Jason Thies","Gerhard Hagerer","Bj\u00f6rn W. Schuller","Georg Groh"],"1336":["Chanjun Park","Midan Shim","Sugyeong Eo","Seolhwa Lee","Jaehyung Seo","Hyeonseok Moon","Heuiseok Lim"],"1337":["Congqing He","Jie Zhang","Xiangyu Zhu","Huan Liu","Yukun Huang"],"1338":["Th\u00e9o Deschamps-Berger","Lori Lamel","Laurence Devillers"],"1339":["Alban Petit","Caio Corro"],"1340":["Hongyu Ren","Hanjun Dai","Zihang Dai","Mengjiao Yang","Jure Leskovec","Dale Schuurmans","Bo Dai"],"1341":["Zhengda Bian","Hongxin Liu","Boxiang Wang","Haichen Huang","Yongbin Li","Chuanrui Wang","Fan Cui","Yang You"],"1342":["Cheng-I Jeff Lai","Erica Cooper","Yang Zhang","Shiyu Chang","Kaizhi Qian","Yi-Lun Liao","Yung-Sung Chuang","Alexander H. Liu","Junichi Yamagishi","David Cox","James Glass"],"1343":["Praneeth Gubbala","Xuan Zhang"],"1344":["Aida Mostafazadeh Davani","Mohammad Atari","Brendan Kennedy","Morteza Dehghani"],"1345":["Gabriel Oliveira dos Santos","Esther Luna Colombini","Sandra Avila"],"1346":["Akari Asai","Xinyan Yu","Jungo Kasai","Hannaneh Hajishirzi"],"1347":["Wout S. Lamers","Kevin Boyack","Vincent Larivi\u00e8re","Cassidy R. Sugimoto","Nees Jan van Eck","Ludo Waltman","Dakota Murray"],"1348":["Alexander Hoyle","Pranav Goel","Denis Peskov","Andrew Hian-Cheong","Jordan Boyd-Graber","Philip Resnik"],"1349":["Peter Hase","Harry Xie","Mohit Bansal"],"1350":["Loukas Ilias","Dimitris Askounis","John Psarras"],"1351":["Hannah Kirk","Yennie Jun","Haider Iqbal","Elias Benussi","Filippo Volpin","Frederic A. Dreyer","Aleksandar Shtedritski","Yuki M. Asano"],"1352":["Zeyu You","Yichu Zhou","Tao Yang","Wei Fan"],"1353":["Baptiste Roziere","Marie-Anne Lachaux","Marc Szafraniec","Guillaume Lample"],"1354":["Justin Payan","Yuval Merhav","He Xie","Satyapriya Krishna","Anil Ramakrishna","Mukund Sridhar","Rahul Gupta"],"1355":["Rahmad Mahendra","Alham Fikri Aji","Samuel Louvan","Fahrurrozi Rahman","Clara Vania"],"1356":["Xuanlin Li","Brandon Trabucco","Dong Huk Park","Michael Luo","Sheng Shen","Trevor Darrell","Yang Gao"],"1357":["Vimal Manohar","Tatiana Likhomanenko","Qiantong Xu","Wei-Ning Hsu","Ronan Collobert","Yatharth Saraf","Geoffrey Zweig","Abdelrahman Mohamed"],"1358":["Hossein Hassani"],"1359":["Weizhe Yuan","Graham Neubig","Pengfei Liu"],"1360":["Mithilesh Vaidya","Kamini Sabu","Preeti Rao"],"1361":["Mattia Atzeni","Jasmina Bogojeska","Andreas Loukas"],"1362":["Abhinav Gupta","Marc Lanctot","Angeliki Lazaridou"],"1363":["Silvia Corbara","Alejandro Moreo","Fabrizio Sebastiani"],"1364":["Xiaohui Wang","Ying Xiong","Xian Qian","Yang Wei","Lei Li","Mingxuan Wang"],"1365":["Phil Chen","Masha Itkina","Ransalu Senanayake","Mykel J. Kochenderfer"],"1366":["Wei Tan","Lan Du","Wray Buntine"],"1367":["Yu Meng","Chenyan Xiong","Payal Bajaj","Saurabh Tiwary","Paul Bennett","Jiawei Han","Xia Song"],"1368":["Zhong Zhou","Alex Waibel"],"1369":["Wenlin Yao","Xiaoman Pan","Lifeng Jin","Jianshu Chen","Dian Yu","Dong Yu"],"1370":["Bailin Wang","Mirella Lapata","Ivan Titov"],"1371":["Izzat Alsmadi","Kashif Ahmad","Mahmoud Nazzal","Firoj Alam","Ala Al-Fuqaha","Abdallah Khreishah","Abdulelah Algosaibi"],"1372":["James Powell","Kari Sentz"],"1373":["Mo Yu","Yang Zhang","Shiyu Chang","Tommi S. Jaakkola"],"1374":["Elizabeth Salesky","Julian M\u00e4der","Severin Klinger"],"1375":["Cheng-I Jeff Lai","Yang Zhang","Alexander H. Liu","Shiyu Chang","Yi-Lun Liao","Yung-Sung Chuang","Kaizhi Qian","Sameer Khurana","David Cox","James Glass"],"1376":["Louis Castricato","Spencer Frazier","Jonathan Balloch","Mark Riedl"],"1377":["Shahbuland Matiana","JR Smith","Ryan Teehan","Louis Castricato","Stella Biderman","Leo Gao","Spencer Frazier"],"1378":["Bogdan \u0141obodzi\u0144ski"],"1379":["David Ding","Felix Hill","Adam Santoro","Malcolm Reynolds","Matt Botvinick"],"1380":["Angeliki Lazaridou","Adhiguna Kuncoro","Elena Gribovskaya","Devang Agrawal","Adam Liska","Tayfun Terzi","Mai Gimenez","Cyprien de Masson d'Autume","Tomas Kocisky","Sebastian Ruder","Dani Yogatama","Kris Cao","Susannah Young","Phil Blunsom"],"1381":["Arij Riabi","Beno\u00eet Sagot","Djam\u00e9 Seddah"],"1382":["Joel Jang","Seonghyeon Ye","Sohee Yang","Joongbo Shin","Janghoon Han","Gyeonghun Kim","Stanley Jungkyu Choi","Minjoon Seo"],"1383":["Shaoxiong Ji","Matti H\u00f6ltt\u00e4","Pekka Marttinen"],"1384":["Asra Fatima","Li Ying","Thomas Hills","Massimo Stella"],"1385":["Keshav Singh","Naoya Inoue","Farjana Sultana Mim","Shoichi Naitoh","Kentaro Inui"],"1386":["Han Liu","Feng Zhang","Xiaotong Zhang","Siyang Zhao","Xianchao Zhang"],"1387":["Jialun Wu","Yang Liu","Zeyu Gao","Tieliang Gong","Chunbao Wang","Chen Li"],"1388":["Hangbo Bao","Li Dong","Wenhui Wang","Nan Yang","Furu Wei"],"1389":["Yongwei Zhou","Junwei Bao","Haipeng Sun","Jiahui Liang","Youzheng Wu","Xiaodong He","Bowen Zhou","Tiejun Zhao"],"1390":["Kun Wu","Lijie Wang","Zhenghua Li","Ao Zhang","Xinyan Xiao","Hua Wu","Min Zhang","Haifeng Wang"],"1391":["Wanyun Cui","Xingran Chen"],"1392":["Thomas Searle","Zina Ibrahim","James Teo","Richard JB Dobson"],"1393":["Ye Ma","Zixun Lan","Lu Zong","Kaizhu Huang"],"1394":["Vinay Aggarwal","Aparna Garimella","Balaji Vasan Srinivasan","Anandhavelu N","Rajiv Jain"],"1395":["Lei Fang","Jian-Guang Lou"],"1396":["Timon Gurcke","Milad Alshomary","Henning Wachsmuth"],"1397":["Yasumasa Kano","Katsuhito Sudoh","Satoshi Nakamura"],"1398":["Ke-Han Lu","Bo-Han Fang","Kuan-Yu Chen"],"1399":["Ruiliu Fu","Han Wang","Xuejun Zhang","Jun Zhou","Yonghong Yan"],"1400":["Piji Li","Shuming Shi"],"1401":["Takuya Yoshioka","Xiaofei Wang","Dongmei Wang","Min Tang","Zirun Zhu","Zhuo Chen","Naoyuki Kanda"],"1402":["Jimin Hong","Taehee Kim","Hyesu Lim","Jaegul Choo"],"1403":["Xinyi Wang","Wenhu Chen","Michael Saxon","William Yang Wang"],"1404":["Chenchen Ding"],"1405":["Juhua Liu","Qihuang Zhong","Liang Ding","Hua Jin","Bo Du","Dacheng Tao"],"1406":["Chengwei Wei","Bin Wang","C. -C. Jay Kuo"],"1407":["Liyuan Liu","Haoming Jiang","Pengcheng He","Weizhu Chen","Xiaodong Liu","Jianfeng Gao","Jiawei Han"],"1408":["Jekaterina Novikova"],"1409":["Benjamin Meindl","Morgan R. Frank","Joana Mendon\u00e7a"],"1410":["Alvin Chan","Ali Madani","Ben Krause","Nikhil Naik"],"1411":["Daniel Cahn"],"1412":["Monisha Jegadeesan","Sachin Kumar","John Wieting","Yulia Tsvetkov"],"1413":["Matthieu Riou","Bassam Jabaian","St\u00e9phane Huet","Fabrice Lef\u00e8vre"],"1414":["Panayiotis Smeros","Carlos Castillo","Karl Aberer"],"1415":["Milan Gritta","Ignacio Iacobacci"],"1416":["Vincent Claveau","Antoine Chaffin","Ewa Kijak"],"1417":["Fengyi Tang","Lifan Zeng","Fei Wang","Jiayu Zhou"],"1418":["Mingjie Li","Hanzhou Wu","Xinpeng Zhang"],"1419":["Yinpei Dai","Huihua Yu","Yixuan Jiang","Chengguang Tang","Yongbin Li","Jian Sun"],"1420":["Leandro Rodrigues de Souza","Rodrigo Nogueira","Roberto Lotufo"],"1421":["Adam Tsakalidis","Pierpaolo Basile","Marya Bazzi","Mihai Cucuringu","Barbara McGillivray"],"1422":["Guilherme Moraes Rosa","Ruan Chaves Rodrigues","Roberto Lotufo","Rodrigo Nogueira"],"1423":["Anirudh Mittal","Pranav Jeevan","Prerak Gandhi","Diptesh Kanojia","Pushpak Bhattacharyya"],"1424":["Thong Nguyen","Anh Tuan Luu"],"1425":["Anna Glazkova","Michael Kadantsev","Maksim Glazkov"],"1426":["Lulu Zhao","Fujia Zheng","Keqing He","Weihao Zeng","Yuejie Lei","Huixing Jiang","Wei Wu","Weiran Xu","Jun Guo","Fanyu Meng"],"1427":["Junyang Lin","An Yang","Jinze Bai","Chang Zhou","Le Jiang","Xianyan Jia","Ang Wang","Jie Zhang","Yong Li","Wei Lin","Jingren Zhou","Hongxia Yang"],"1428":["Ta-Chung Chi","Alexander I. Rudnicky"],"1429":["Moye Chen","Wei Li","Jiachen Liu","Xinyan Xiao","Hua Wu","Haifeng Wang"],"1430":["Xiaofei Sun","Diyi Yang","Xiaoya Li","Tianwei Zhang","Yuxian Meng","Han Qiu","Guoyin Wang","Eduard Hovy","Jiwei Li"],"1431":["Ting-Yao Hsu","C. Lee Giles","Ting-Hao 'Kenneth' Huang"],"1432":["Xueyuan Lin","Haihong E","Wenyu Song","Haoran Luo"],"1433":["Helen Ngo","Jo\u00e3o G. M. Ara\u00fajo","Jeffrey Hui","Nicholas Frosst"],"1434":["Wenhu Chen","Xinyi Wang","William Yang Wang"],"1435":["Shujian Zhang","Xinjie Fan","Huangjie Zheng","Korawat Tanwisuth","Mingyuan Zhou"],"1436":["Jos\u00e9 Carlos Rosales N\u00fa\u00f1ez","Guillaume Wisniewski","Djam\u00e9 Seddah"],"1437":["Jos\u00e9 Carlos Rosales N\u00fa\u00f1ez","Djam\u00e9 Seddah","Guillaume Wisniewski"],"1438":["William Hogan","Molly Huang","Yannis Katsis","Tyler Baldwin","Ho-Cheol Kim","Yoshiki Vazquez Baeza","Andrew Bartko","Chun-Nan Hsu"],"1439":["Roxana Girju"],"1440":["Hong Huang","Junjie H. Xu","Xiaoling Ling","Pujana Paliyawan"],"1441":["Eyal Ben-David","Boaz Carmeli","Ateret Anaby-Tavor"],"1442":["Mohr Wenger","Tom Kalir","Noga Berger","Carmit Chalamish","Renana Keydar","Gabriel Stanovsky"],"1443":["Koren Lazar","Benny Saret","Asaf Yehudai","Wayne Horowitz","Nathan Wasserman","Gabriel Stanovsky"],"1444":["Hossein Hassani"],"1445":["Manav Nitin Kapadnis","Sohan Patnaik","Siba Smarak Panigrahi","Varun Madhavan","Abhilash Nandy"],"1446":["Jiale Han","Bo Cheng","Wei Lu"],"1447":["Aman Madaan","Niket Tandon","Dheeraj Rajagopal","Peter Clark","Yiming Yang","Eduard Hovy"],"1448":["Matthias Lalisse","Paul Smolensky"],"1449":["Matthias Lalisse","Eric Rosen","Paul Smolensky"],"1450":["Chenlei Bao","Lican Huang"],"1451":["Anurendra Kumar","Keval Morabia","Jingjin Wang","Kevin Chen-Chuan Chang","Alexander Schwing"],"1452":["Benjamin A. Spiegel","George Konidaris"],"1453":["Robert E. Wray, III","James R. Kirk","John E. Laird"],"1454":["Michael Kranzlein","Emma Manning","Siyao Peng","Shira Wein","Aryaman Arora","Bradford Salen","Nathan Schneider"],"1455":["Ross Gruetzemacher","David Paradice"],"1456":["Asier Guti\u00e9rrez-Fandi\u00f1o","Jordi Armengol-Estap\u00e9","Aitor Gonzalez-Agirre","Marta Villegas"],"1457":["Long Doan","Linh The Nguyen","Nguyen Luong Tran","Thai Hoang","Dat Quoc Nguyen"],"1458":["Vedant Parikh","Vidit Mathur","Parth Mehta","Namita Mittal","Prasenjit Majumder"],"1459":["Yidan Hu","Yong Liu","Chunyan Miao","Gongqi Lin","Yuan Miao"],"1460":["Saket Dingliwal","Ashish Shenoy","Sravan Bodapati","Ankur Gandhe","Ravi Teja Gadde","Katrin Kirchhoff"],"1461":["Zixu Wang","Yishu Miao","Lucia Specia"],"1462":["Ethan C. Chau","Noah A. Smith"],"1463":["Nicolas Webersinke","Mathias Kraus","Julia Anna Bingler","Markus Leippold"],"1464":["Santosh Kumar Barnwal"],"1465":["Allen Kim","Charuta Pethe","Naoya Inoue","Steve Skiena"],"1466":["Thang M. Pham","Trung Bui","Long Mai","Anh Nguyen"],"1467":["Pritish Sahu","Karan Sikka","Ajay Divakaran"],"1468":["Yusuf Tas","Piotr Koniusz"],"1469":["Katy Ilonka Gero","Chris Kedzie","Savvas Petridis","Lydia Chilton"],"1470":["Milad Alshomary","Timon Gurcke","Shahbaz Syed","Philipp Heinrich","Maximilian Splieth\u00f6ver","Philipp Cimiano","Martin Potthast","Henning Wachsmuth"],"1471":["Emiel Hoogeboom","Didrik Nielsen","Priyank Jaini","Patrick Forr\u00e9","Max Welling"],"1472":["Peng Cui","Dongyao Hu","Le Hu"],"1473":["Lukas Stappen","Alice Baird","Lukas Christ","Lea Schumann","Benjamin Sertolli","Eva-Maria Messner","Erik Cambria","Guoying Zhao","Bj\u00f6rn W. Schuller"],"1474":["Benjamin Clavi\u00e9","Marc Alphonsus"],"1475":["Fabio Calefato","Filippo Lanubile"],"1476":["Lucas Ondel","L\u00e9a-Marie Lam-Yee-Mui","Martin Kocour","Caio Filippo Corro","Luk\u00e1\u0161 Burget"],"1477":["Yiren Chen","Xiaoyu Kou","Jiangang Bai","Yunhai Tong"],"1478":["Quintin Pope","Xiaoli Z. Fern"],"1479":["Haoran Xu","Hainan Zhang","Yanyan Zou","Hongshen Chen","Zhuoye Ding","Yanyan Lan"],"1480":["Haitian Sun","William W. Cohen","Ruslan Salakhutdinov"],"1481":["Rowan Zellers","Ximing Lu","Jack Hessel","Youngjae Yu","Jae Sung Park","Jize Cao","Ali Farhadi","Yejin Choi"],"1482":["Baolin Peng","Chunyuan Li","Zhu Zhang","Jinchao Li","Chenguang Zhu","Jianfeng Gao"],"1483":["Jerret Ross","Brian Belgodere","Vijil Chenthamarakshan","Inkit Padhi","Youssef Mroueh","Payel Das"],"1484":["Fangyu Liu","Emanuele Bugliarello","Edoardo Maria Ponti","Siva Reddy","Nigel Collier","Desmond Elliott"],"1485":["Matheus Schmitz","Goran Muri\u0107","Keith Burghardt"],"1486":["Eric Mitchell","Charles Lin","Antoine Bosselut","Chelsea Finn","Christopher D. Manning"],"1487":["Peng Cui","Le Hu","Yuanchao Liu"],"1488":["Peng Cui","Le Hu"],"1489":["Xiaodong Cui","Wei Zhang","Abdullah Kayi","Mingrui Liu","Ulrich Finkler","Brian Kingsbury","George Saon","David Kung"],"1490":["Jian Wu","Rajal Nivargi","Sree Sai Teja Lanka","Arjun Manoj Menon","Sai Ajay Modukuri","Nishanth Nakshatri","Xin Wei","Zhuoer Wang","James Caverlee","Sarah M. Rajtmajer","C. Lee Giles"],"1491":["Marilyn Walker","Colin Harmon","James Graupera","Davan Harrison","Steve Whittaker"],"1492":["Ting Jiang","Shaohan Huang","Zihan Zhang","Deqing Wang","Fuzhen Zhuang","Furu Wei","Haizhen Huang","Liangjie Zhang","Qi Zhang"],"1493":["Julian Risch","Timo M\u00f6ller","Julian Gutsch","Malte Pietsch"],"1494":["Daiki Kimura","Subhajit Chaudhury","Masaki Ono","Michiaki Tatsubori","Don Joven Agravante","Asim Munawar","Akifumi Wachi","Ryosuke Kohita","Alexander Gray"],"1495":["Daiki Kimura","Masaki Ono","Subhajit Chaudhury","Ryosuke Kohita","Akifumi Wachi","Don Joven Agravante","Michiaki Tatsubori","Asim Munawar","Alexander Gray"],"1496":["Clara Meister","Afra Amini","Tim Viera","Ryan Cotterell"],"1497":["Danqing Wang","Jiaze Chen","Xianze Wu","Hao Zhou","Lei Li"],"1498":["Lingbing Guo","Zequn Sun","Mingyang Chen","Wei Hu","Qiang Zhang","Huajun Chen"],"1499":["Ashwin Paranjape","Omar Khattab","Christopher Potts","Matei Zaharia","Christopher D. Manning"],"1500":["Nandan Thakur","Nils Reimers","Andreas R\u00fcckl\u00e9","Abhishek Srivastava","Iryna Gurevych"],"1501":["Adyasha Maharana","Mohit Bansal"],"1502":["Satwik Kottur","Seungwhan Moon","Alborz Geramifard","Babak Damavandi"],"1503":["David Ardia","Keven Bluteau","Samuel Borms","Kris Boudt"],"1504":["Peng Xu","Xinchi Chen","Xiaofei Ma","Zhiheng Huang","Bing Xiang"],"1505":["Charlie Snell","Ruiqi Zhong","Dan Klein","Jacob Steinhardt"],"1506":["Hong Chen","Hiroya Takamura","Hideki Nakayama"],"1507":["Maxime Peyrard","Wei Zhao","Steffen Eger","Robert West"],"1508":["Prithviraj Ammanabrolu","Mark O. Riedl"],"1509":["Eleftheria Briakou","Sweta Agrawal","Joel Tetreault","Marine Carpuat"],"1510":["Roni Friedman","Lena Dankin","Yufang Hou","Ranit Aharonov","Yoav Katz","Noam Slonim"],"1511":["Gerhard Hagerer","Martin Kirchhoff","Hannah Danner","Robert Pesch","Mainak Ghosh","Archishman Roy","Jiaxi Zhao","Georg Groh"],"1512":["Biswesh Mohapatra","Gaurav Pandey","Danish Contractor","Sachindra Joshi"],"1513":["Yuncong Li","Zhe Yang","Cunxiang Yin","Xu Pan","Lunan Cui","Qiang Huang","Ting Wei"],"1514":["Lukas Stappen","Alice Baird","Lea Schumann","Bj\u00f6rn Schuller"],"1515":["Lukas Stappen","Lea Schumann","Benjamin Sertolli","Alice Baird","Benjamin Weigel","Erik Cambria","Bj\u00f6rn W. Schuller"],"1516":["Alexandre Berard"],"1517":["Ahmet \u00dcst\u00fcn","Alexandre B\u00e9rard","Laurent Besacier","Matthias Gall\u00e9"],"1518":["Houda Alberts","Teresa Huang","Yash Deshpande","Yibo Liu","Kyunghyun Cho","Clara Vania","Iacer Calixto"],"1519":["Daniel Fern\u00e1ndez-Gonz\u00e1lez","Carlos G\u00f3mez-Rodr\u00edguez"],"1520":["Mun-Hak Lee","Joon-Hyuk Chang"],"1521":["Zekeriya Anil Guven","Banu Diri","Tolgahan Cakaloglu"],"1522":["Dominik S. Meier","Rui Mata","Dirk U. Wulff"],"1523":["Tong Guo"],"1524":["Shilun Li","Renee Li","Carina Zhang"],"1525":["Rongyi Sun","Borun Chen","Qingyu Zhou","Yinghui Li","YunBo Cao","Hai-Tao Zheng"],"1526":["Kazuhiro Seki","Yusuke Ikuta","Yoichi Matsubayashi"],"1527":["Takashi Wada","Tomoharu Iwata","Yuji Matsumoto","Timothy Baldwin","Jey Han Lau"],"1528":["Ankur Bapna","Yu-an Chung","Nan Wu","Anmol Gulati","Ye Jia","Jonathan H. Clark","Melvin Johnson","Jason Riesa","Alexis Conneau","Yu Zhang"],"1529":["Yunbin Tu","Liang Li","Chenggang Yan","Shengxiang Gao","Zhengtao Yu"],"1530":["Vivek Kulkarni","Shubhanshu Mishra","Aria Haghighi"],"1531":["Shubhanshu Mishra","Aria Haghighi"],"1532":["Ye Liu","Jian-Guo Zhang","Yao Wan","Congying Xia","Lifang He","Philip S. Yu"],"1533":["Ali Can Kocabiyikoglu","Fran\u00e7ois Portet","Raheel Qader","Jean-Marc Babouchkine"],"1534":["Tounsi Achraf","Elkefi Safa"],"1535":["Weiyu Liu","Chris Paxton","Tucker Hermans","Dieter Fox"],"1536":["Hendrik Strobelt","Jambay Kinley","Robert Krueger","Johanna Beyer","Hanspeter Pfister","Alexander M. Rush"],"1537":["Zineng Tang","Jaemin Cho","Hao Tan","Mohit Bansal"],"1538":["Mohammad Abuzar Shaikh","Zhanghexuan Ji","Dana Moukheiber","Yan Shen","Sargur Srihari","Mingchen Gao"],"1539":["Ziheng Zeng","Suma Bhat"],"1540":["Fl\u00e1vio Nakasato Ca\u00e7\u00e3o","Marcos Menon Jos\u00e9","Andr\u00e9 Seidel Oliveira","Stefano Spindola","Anna Helena Reali Costa","F\u00e1bio Gagliardi Cozman"],"1541":["Nicholas Asher","Julie Hunter"],"1542":["Yue Zhang","Bo Zhang","Rui Wang","Junjie Cao","Chen Li","Zuyi Bao"],"1543":["Wei Xiao","Qian Hu","Thahir Mohamed","Zheng Gao","Xibin Gao","Radhika Arava","Mohamed AbdelHady"],"1544":["P. Rovelli","C. Benedetti","A. Fronzetti Colladon","A. De Massis"],"1545":["Bogdan Kosti\u0107","Julian Risch","Timo M\u00f6ller"],"1546":["Zhijing Jin","Julius von K\u00fcgelgen","Jingwei Ni","Tejas Vaidhya","Ayush Kaushal","Mrinmaya Sachan","Bernhard Sch\u00f6lkopf"],"1547":["Julia White","Gabriel Poesia","Robert Hawkins","Dorsa Sadigh","Noah Goodman"],"1548":["Yupan Huang","Bei Liu","Jianlong Fu","Yutong Lu"],"1549":["Yupan Huang","Hongwei Xue","Bei Liu","Yutong Lu"],"1550":["Yen-Ling Kuo","Boris Katz","Andrei Barbu"],"1551":["Dhruv Agarwal","Tanay Agrawal","Laura M. Ferrari","Fran\u00e7ois Bremond"],"1552":["Roxana Girju","David Peng"],"1553":["Roxana Girju","Charlotte Lambert"],"1554":["Michael Riera","Erfan Bank Tavakoli","Masudul Hassan Quraishi","Fengbo Ren"],"1555":["Cunxiang Wang","Boyuan Zheng","Yuchen Niu","Yue Zhang"],"1556":["Mutian He","Jingzhou Yang","Lei He","Frank K. Soong"],"1557":["Shilun Li","Renee Li","Veronica Peng"],"1558":["HyoJung Han","Seokchan Ahn","Yoonjung Choi","Insoo Chung","Sangha Kim","Kyunghyun Cho"],"1559":["Nathaniel Hoy","Theodora Koulouri"],"1560":["Vineel Pratap","Qiantong Xu","Tatiana Likhomanenko","Gabriel Synnaeve","Ronan Collobert"],"1561":["Asa Cooper Stickland","Alexandre B\u00e9rard","Vassilina Nikoulina"],"1562":["Shareefuddin Mohammed","Rusty Bealer","Jason Cohen"],"1563":["Arijit Nag","Bidisha Samanta","Animesh Mukherjee","Niloy Ganguly","Soumen Chakrabarti"],"1564":["Mor Geva","Tomer Wolfson","Jonathan Berant"],"1565":["Rishi Balakrishnan","Stephen Sloan","Anil Aswani"],"1566":["Sangamesh Kodge","Kaushik Roy"],"1567":["Jon Chun"],"1568":["L\u00e9o Hemamou","Arthur Guillon","Jean-Claude Martin","Chlo\u00e9 Clavel"],"1569":["Kathleen C. Fraser","Majid Komeili"],"1570":["Arushi Sharma","Anubha Kabra","Minni Jain"],"1571":["Swarnadeep Saha","Prateek Yadav","Lisa Bauer","Mohit Bansal"],"1572":["Felix Meyer","Wilfried Michel","Mohammad Zeineldeen","Ralf Schl\u00fcter","Hermann Ney"],"1573":["Bashar Alhafni","Nizar Habash","Houda Bouamor"],"1574":["\u0130lker Kesen","Ozan Arkan Can","Erkut Erdem","Aykut Erdem","Deniz Yuret"],"1575":["Pierre Berjon","Avishek Nag","Soumyabrata Dev"],"1576":["Haitong Zhang","Haoyue Zhan","Yang Zhang","Xinyuan Yu","Yue Lin"],"1577":["Thomas Scialom","Felix Hill"],"1578":["Wen-Chin Huang","Erica Cooper","Junichi Yamagishi","Tomoki Toda"],"1579":["Mostafa Dehghani","Alexey Gritsenko","Anurag Arnab","Matthias Minderer","Yi Tay"],"1580":["Ankit Patil","Ankush Chopra","Sohom Ghosh","Vamshi Vadla"],"1581":["Xie Chen","Zhong Meng","Sarangarajan Parthasarathy","Jinyu Li"],"1582":["Seonghyeon Ye","Jiseon Kim","Alice Oh"],"1583":["Yi-Chen Chen","Shu-wen Yang","Cheng-Kuang Lee","Simon See","Hung-yi Lee"],"1584":["Jennifer D'Souza","Isaiah Onando Mulang'","Soeren Auer"],"1585":["Yichong Leng","Xu Tan","Rui Wang","Linchen Zhu","Jin Xu","Wenjie Liu","Linquan Liu","Tao Qin","Xiang-Yang Li","Edward Lin","Tie-Yan Liu"],"1586":["Andros Tjandra","Diptanu Gon Choudhury","Frank Zhang","Kritika Singh","Alexis Conneau","Alexei Baevski","Assaf Sela","Yatharth Saraf","Michael Auli"],"1587":["Zining Zhu","Aparna Balagopalan","Marzyeh Ghassemi","Frank Rudzicz"],"1588":["Xin Huang","Wenbin Zhang","Xuejiao Tang","Mingli Zhang","Jayachander Surbiryala","Vasileios Iosifidis","Zhen Liu","Ji Zhang"],"1589":["Artur Kulmizev","Joakim Nivre"],"1590":["Anirudh Srinivasan","Sunayana Sitaram","Tanuja Ganu","Sandipan Dandapat","Kalika Bali","Monojit Choudhury"],"1591":["Bla\u017e \u0160krlj","Marko Juki\u010d","Nika Er\u017een","Senja Pollak","Nada Lavra\u010d"],"1592":["Suyu Ge","Jiaxin Huang","Yu Meng","Sharon Wang","Jiawei Han"],"1593":["Milad Vazan","Jafar Razmara"],"1594":["Han Wang","Ruiliu Fu","Chengzhang Li","Xuejun Zhang","Jun Zhou","Yonghong Yan"],"1595":["Wei Sun","Shaoxiong Ji","Erik Cambria","Pekka Marttinen"],"1596":["Tam Nguyen","Tan M. Nguyen","Dung Le","Khuong Nguyen","Anh Tran","Richard G. Baraniuk","Nhat Ho","Stanley J. Osher"],"1597":["Edward J. Hu","Yelong Shen","Phillip Wallis","Zeyuan Allen-Zhu","Yuanzhi Li","Shean Wang","Lu Wang","Weizhu Chen"],"1598":["Heng Yang","Biqing Zeng","Mayi Xu","Tianxing Wang"],"1599":["Morgane Riviere","Jade Copet","Gabriel Synnaeve"],"1600":["Wei Wei","Zanbo Wang","Xianling Mao","Guangyou Zhou","Pan Zhou","Sheng Jiang"],"1601":["Moussa Kamal Eddine","Guokan Shang","Antoine J. -P. Tixier","Michalis Vazirgiannis"],"1602":["Julien Launay","E. L. Tommasone","Baptiste Pannier","Fran\u00e7ois Boniface","Am\u00e9lie Chatelain","Alessandro Cappelli","Iacopo Poli","Djam\u00e9 Seddah"],"1603":["Chenhe Dong","Yaliang Li","Ying Shen","Minghui Qiu"],"1604":["Yingzhu Zhao","Chongjia Ni","Cheung-Chi Leung","Shafiq Joty","Eng Siong Chng","Bin Ma"],"1605":["Haoyue Shi","Kevin Gimpel","Karen Livescu"],"1606":["Qinyuan Ye","Madian Khabsa","Mike Lewis","Sinong Wang","Xiang Ren","Aaron Jaech"],"1607":["Xisen Jin","Dejiao Zhang","Henghui Zhu","Wei Xiao","Shang-Wen Li","Xiaokai Wei","Andrew Arnold","Xiang Ren"],"1608":["Mehdi Rezagholizadeh","Aref Jafari","Puneeth Salad","Pranav Sharma","Ali Saheb Pasand","Ali Ghodsi"],"1609":["Neha Nayak Kennard","Tim O'Gorman","Akshay Sharma","Chhandak Bagchi","Matthew Clinton","Pranay Kumar Yelugam","Rajarshi Das","Hamed Zamani","Andrew McCallum"],"1610":["Huy Quoc To","Kiet Van Nguyen","Ngan Luu-Thuy Nguyen","Anh Gia-Tuan Nguyen"],"1611":["Eric Wallace","Adina Williams","Robin Jia","Douwe Kiela"],"1612":["Yuwei Fang","Shuohang Wang","Yichong Xu","Ruochen Xu","Siqi Sun","Chenguang Zhu","Michael Zeng"],"1613":["Tianda Li","Yassir El Mesbahi","Ivan Kobyzev","Ahmad Rashid","Atif Mahmud","Nithin Anchuri","Habib Hajimolahoseini","Yang Liu","Mehdi Rezagholizadeh"],"1614":["Xiaokai Wei","Shen Wang","Dejiao Zhang","Parminder Bhatia","Andrew Arnold"],"1615":["Zhong Zhou","Alex Waibel"],"1616":["Ian Stewart","Rada Mihalcea"],"1617":["Simran Arora","Sen Wu","Enci Liu","Christopher Re"],"1618":["Frederick Liu","Siamak Shakeri","Hongkun Yu","Jing Li"],"1619":["Kawin Ethayarajh","Yejin Choi","Swabha Swayamdipta"],"1620":["Mengnan Du","Subhabrata Mukherjee","Yu Cheng","Milad Shokouhi","Xia Hu","Ahmed Hassan Awadallah"],"1621":["Maxime Peyrard","Sarvjeet Singh Ghotra","Martin Josifoski","Vidhan Agarwal","Barun Patra","Dean Carignan","Emre Kiciman","Robert West"],"1622":["Andreas Madsen","Nicholas Meade","Vaibhav Adlakha","Siva Reddy"],"1623":["Chia-Chien Hung","Anne Lauscher","Simone Paolo Ponzetto","Goran Glava\u0161"],"1624":["Shu-wen Yang","Po-Han Chi","Yung-Sung Chuang","Cheng-I Jeff Lai","Kushal Lakhotia","Yist Y. Lin","Andy T. Liu","Jiatong Shi","Xuankai Chang","Guan-Ting Lin","Tzu-Hsien Huang","Wei-Cheng Tseng","Ko-tik Lee","Da-Rong Liu","Zili Huang","Shuyan Dong","Shang-Wen Li","Shinji Watanabe","Abdelrahman Mohamed","Hung-yi Lee"],"1625":["Yen-Ting Lin","Alexandros Papangelis","Seokhwan Kim","Dilek Hakkani-Tur"],"1626":["Pengcheng Yin","John Wieting","Avirup Sil","Graham Neubig"],"1627":["Bingbing Li","Hongwu Peng","Rajat Sainju","Junhuan Yang","Lei Yang","Yueying Liang","Weiwen Jiang","Binghui Wang","Hang Liu","Caiwen Ding"],"1628":["Derek Chen","Zhou Yu","Samuel R. Bowman"],"1629":["Haichuan Yang","Yuan Shangguan","Dilin Wang","Meng Li","Pierce Chuang","Xiaohui Zhang","Ganesh Venkatesh","Ozlem Kalinli","Vikas Chandra"],"1630":["Sankalan Pal Chowdhury","Adamos Solomou","Avinava Dubey","Mrinmaya Sachan"],"1631":["Samuel R. Bowman","George E. Dahl"],"1632":["Somnath Roy"],"1633":["Sachin Kumar","Antonios Anastasopoulos","Shuly Wintner","Yulia Tsvetkov"],"1634":["Yi Huang","Buse Giledereli","Abdullatif K\u00f6ksal","Arzucan \u00d6zg\u00fcr","Elif Ozkirimli"],"1635":["Yangyi Chen","Fanchao Qi","Zhiyuan Liu","Maosong Sun"],"1636":["Dheeru Dua","Shruti Bhosale","Vedanuj Goswami","James Cross","Mike Lewis","Angela Fan"],"1637":["Hiun Kim","Jisu Jeong","Kyung-Min Kim","Dongjun Lee","Hyun Dong Lee","Dongpil Seo","Jeeseung Han","Dong Wook Park","Ji Ae Heo","Rak Yeong Kim"],"1638":["Maya Varma","Laurel Orr","Sen Wu","Megan Leszczynski","Xiao Ling","Christopher R\u00e9"],"1639":["Bettina Fazzinga","Andrea Galassi","Paolo Torroni"],"1640":["Wen-Chin Huang","Bence Mark Halpern","Lester Phillip Violeta","Odette Scharenborg","Tomoki Toda"],"1641":["Cory Paik","St\u00e9phane Aroca-Ouellette","Alessandro Roncone","Katharina Kann"],"1642":["Lidiya Murakhovs'ka","Chien-Sheng Wu","Tong Niu","Wenhao Liu","Caiming Xiong"],"1643":["Ali Edalati","Marzieh Tahaei","Ahmad Rashid","Vahid Partovi Nia","James J. Clark","Mehdi Rezagholizadeh"],"1644":["Andrea Madotto","Zhaojiang Lin","Genta Indra Winata","Pascale Fung"],"1645":["Kyoung-Rok Jang","Junmo Kang","Giwon Hong","Sung-Hyon Myaeng","Joohee Park","Taewon Yoon","Heecheol Seo"],"1646":["Tengfei Zhao","Zhaocheng Ge","Hanping Hu","Dingmeng Shi"],"1647":["Xinyan Zhao","Bin He","Yasheng Wang","Yitong Li","Fei Mi","Yajiao Liu","Xin Jiang","Qun Liu","Huanhuan Chen"],"1648":["Victor Pellegrain","Myriam Tami","Michel Batteux","C\u00e9line Hudelot"],"1649":["Fanfan Wang","Zixiang Ding","Rui Xia","Zhaoyu Li","Jianfei Yu"],"1650":["Congcong Wang","Paul Nulty","David Lillis"],"1651":["Kim Breitwieser","Allison Lahnala","Charles Welch","Lucie Flek","Martin Potthast"],"1652":["Congcong Wang","Paul Nulty","David Lillis"],"1653":["Junmo Kang","Jeonghwan Kim","Suwon Shin","Sung-Hyon Myaeng"],"1654":["Daniel Bermuth","Alexander Poeppel","Wolfgang Reif"],"1655":["Roberto Dess\u00ec","Eugene Kharitonov","Marco Baroni"],"1656":["Maria Glenski","Svitlana Volkova"],"1657":["Jennifer D'Souza","S\u00f6ren Auer","Ted Pedersen"],"1658":["Raoul Buurke","Hedwig Sekeres","Wilbert Heeringa","Remco Knooihuizen","Martijn Wieling"],"1659":["Rimita Lahiri","Kenichi Kumatani","Eric Sun","Yao Qian"],"1660":["Maneet Singh","Rishemjit Kaur","Akiko Matsuo","S. R. S. Iyengar","Kazutoshi Sasahara"],"1661":["Corinna Coupette","Dirk Hartung","Janis Beckedorf","Maximilian B\u00f6ther","Daniel Martin Katz"],"1662":["Yujia Qin","Xiaozhi Wang","Yusheng Su","Yankai Lin","Ning Ding","Zhiyuan Liu","Juanzi Li","Lei Hou","Peng Li","Maosong Sun","Jie Zhou"],"1663":["Yang Liu","Chenguang Zhu","Michael Zeng"],"1664":["Goonmeet Bajaj","Vinh Nguyen","Thilini Wijesiriwardene","Hong Yung Yip","Vishesh Javangula","Srinivasan Parthasarathy","Amit Sheth","Olivier Bodenreider"],"1665":["Logan Lebanoff","Bingqing Wang","Zhe Feng","Fei Liu"],"1666":["Tomoki Hayashi","Ryuichi Yamamoto","Takenori Yoshimura","Peter Wu","Jiatong Shi","Takaaki Saeki","Yooncheol Ju","Yusuke Yasuda","Shinnosuke Takamichi","Shinji Watanabe"],"1667":["Nila Selvaraj","Yasumasa Onoe","Greg Durrett"],"1668":["Kim Thi-Thanh Nguyen","Sieu Khai Huynh","Luong Luc Phan","Phuc Huynh Pham","Duc-Vu Nguyen","Kiet Van Nguyen"],"1669":["Wenkai Yang","Yankai Lin","Peng Li","Jie Zhou","Xu Sun"],"1670":["Cole Pearson","Naeem Seliya","Rushit Dave"],"1671":["Minh Van Nguyen","Viet Dac Lai","Amir Pouran Ben Veyseh","Thien Huu Nguyen"],"1672":["Yuanchi Zhang","Yang Liu"],"1673":["Toshiko Shibano","Xinyi Zhang","Mia Taige Li","Haejin Cho","Peter Sullivan","Muhammad Abdul-Mageed"],"1674":["Fahimeh Saleh","Wray Buntine","Gholamreza Haffari","Lan Du"],"1675":["Akhilesh Deepak Gotmare","Junnan Li","Shafiq Joty","Steven C. H. Hoi"],"1676":["Simeng Sun","Angela Fan","James Cross","Vishrav Chaudhary","Chau Tran","Philipp Koehn","Francisco Guzman"],"1677":["Sosuke Nishikawa","Ikuya Yamada","Yoshimasa Tsuruoka","Isao Echizen"],"1678":["Akhil Arora","Alberto Garc\u00eda-Dur\u00e1n","Robert West"],"1679":["Tiberiu Sosea","Chau Pham","Alexander Tekle","Cornelia Caragea","Junyi Jessy Li"],"1680":["Tianlu Wang","Diyi Yang","Xuezhi Wang"],"1681":["Dominik Schlechtweg","Nina Tahmasebi","Simon Hengchen","Haim Dubossarsky","Barbara McGillivray"],"1682":["Zihao Wang","Ming Jiang","Junli Wang"],"1683":["Dong-Ho Lee","Ravi Kiran Selvam","Sheikh Muhammad Sarwar","Bill Yuchen Lin","Mahak Agarwal","Fred Morstatter","Jay Pujara","Elizabeth Boschee","James Allan","Xiang Ren"],"1684":["Myrthe Reuver","Suzan Verberne","Roser Morante","Antske Fokkens"],"1685":["Jiangshu Du","Yingtong Dou","Congying Xia","Limeng Cui","Jing Ma","Philip S. Yu"],"1686":["Liyan Tang","Dhruv Rajan","Suyash Mohan","Abhijeet Pradhan","R. Nick Bryan","Greg Durrett"],"1687":["Davan Harrison"],"1688":["Chengkun Zeng","Guanyi Chen","Chenghua Lin","Ruizhe Li","Zhigang Chen"],"1689":["Katy Ilonka Gero","Vivian Liu","Lydia B. Chilton"],"1690":["Bla\u017e \u0160krlj","Matej Petkovi\u010d"],"1691":["Ji Xin","Chenyan Xiong","Ashwin Srinivasan","Ankita Sharma","Damien Jose","Paul N. Bennett"],"1692":["Ian Palmer","Andrew Rouditchenko","Andrei Barbu","Boris Katz","James Glass"],"1693":["Liwei Jiang","Jena D. Hwang","Chandra Bhagavatula","Ronan Le Bras","Maxwell Forbes","Jon Borchardt","Jenny Liang","Oren Etzioni","Maarten Sap","Yejin Choi"],"1694":["Dora Jambor","Dzmitry Bahdanau"],"1695":["Anurag Katakkar","Weiqin Wang","Clay H. Yoo","Zachary C. Lipton","Divyansh Kaushik"],"1696":["Alan Ansell","Edoardo Maria Ponti","Anna Korhonen","Ivan Vuli\u0107"],"1697":["Yiming Zheng","Serena Booth","Julie Shah","Yilun Zhou"],"1698":["Milan Straka","Jakub N\u00e1plava","Jana Strakov\u00e1","David Samuel"],"1699":["Chenyang Huang","Hao Zhou","Osmar R. Za\u00efane","Lili Mou","Lei Li"],"1700":["Yaman Kumar Singla","Swapnil Parekh","Somesh Singh","Junyi Jessy Li","Rajiv Ratn Shah","Changyou Chen"],"1701":["Lingzhi Wang","Huang Hu","Lei Sha","Can Xu","Kam-Fai Wong","Daxin Jiang"],"1702":["Maxime De Bruyn","Ehsan Lotfi","Jeska Buhmann","Walter Daelemans"],"1703":["Namrata Mukhija","Monojit Choudhury","Kalika Bali"],"1704":["Hao Jiang","Ke Zhan","Jianwei Qu","Yongkang Wu","Zhaoye Fei","Xinyu Zhang","Lei Chen","Zhicheng Dou","Xipeng Qiu","Zikai Guo","Ruofei Lai","Jiawen Wu","Enrui Hu","Yinxia Zhang","Yantao Jia","Fan Yu","Zhao Cao"],"1705":["Delfina Sol Martinez Pandiani","Valentina Presutti"],"1706":["Benno Weck","Xavier Favory","Konstantinos Drossos","Xavier Serra"],"1707":["Lan Zhang","Wray Buntine","Ehsan Shareghi"],"1708":["Mohammad Umair","Francis Ferraro"],"1709":["Jamshid Mozafari","Afsaneh Fatemi","Mohammad Ali Nematbakhsh"],"1710":["Ruiyang Ren","Yingqi Qu","Jing Liu","Wayne Xin Zhao","Qiaoqiao She","Hua Wu","Haifeng Wang","Ji-Rong Wen"],"1711":["Xin Zhou","Ruotian Ma","Tao Gui","Yiding Tan","Qi Zhang","Xuanjing Huang"],"1712":["Mikael Brunila","Jack LaViolette"],"1713":["Jian Liu","Zhiyang Teng","Leyang Cui","Hanmeng Liu","Yue Zhang"],"1714":["Federico Nanni","Goran Glavas","Ines Rehbein","Simone Paolo Ponzetto","Heiner Stuckenschmidt"],"1715":["Marco Gaido","Matteo Negri","Mauro Cettolo","Marco Turchi"],"1716":["Anoop Kunchukuttan"],"1717":["Fang Wang","Yuncong Li","Sheng-hua Zhong","Cunxiang Yin","Yancheng He"],"1718":["Arij Riabi","Thomas Scialom","Rachel Keraron","Beno\u00eet Sagot","Djam\u00e9 Seddah","Jacopo Staiano"],"1719":["Qiyuan Zhang","Lei Wang","Sicheng Yu","Shuohang Wang","Yang Wang","Jing Jiang","Ee-Peng Lim"],"1720":["Yair Lakretz","Th\u00e9o Desbordes","Dieuwke Hupkes","Stanislas Dehaene"],"1721":["Nankai Lin","Yingwen Fu","Chuwei Chen","Ziyu Yang","Shengyi Jiang"],"1722":["Zhuosheng Zhang","Hanqing Zhang","Keming Chen","Yuhang Guo","Jingyun Hua","Yulong Wang","Ming Zhou"],"1723":["Haitong Zhang","Yue Lin"],"1724":["Shen Liu","Meirong Ma","Hao Yuan","Jianchao Zhu","Yuanbin Wu","Man Lan"],"1725":["Mohamed Sana","Emilio Calvanese Strinati"],"1726":["Peter West","Chandra Bhagavatula","Jack Hessel","Jena D. Hwang","Liwei Jiang","Ronan Le Bras","Ximing Lu","Sean Welleck","Yejin Choi"],"1727":["Guan-Ting Lin","Manuel Giambi"],"1728":["Prafulla Kumar Choubey","Jesse Vig","Wenhao Liu","Nazneen Fatema Rajani"],"1729":["Yuan Jin","He Zhao","Ming Liu","Lan Du","Wray Buntine"],"1730":["Kelvin Lo","Yuan Jin","Weicong Tan","Ming Liu","Lan Du","Wray Buntine"],"1731":["Benjamin Muller","Luca Soldaini","Rik Koncel-Kedziorski","Eric Lind","Alessandro Moschitti"],"1732":["Cheng Chen","Yichun Yin","Lifeng Shang","Xin Jiang","Yujia Qin","Fengyu Wang","Zhi Wang","Xiao Chen","Zhiyuan Liu","Qun Liu"],"1733":["Fanchao Qi","Yangyi Chen","Xurui Zhang","Mukai Li","Zhiyuan Liu","Maosong Sun"],"1734":["Guohao Li","Feng He","Zhifan Feng"],"1735":["Deng Cai","Xin Li","Jackie Chun-Sing Ho","Lidong Bing","Wai Lam"],"1736":["Hossein Hadian","Arseniy Gorin"],"1737":["Kazutoshi Shinoda","Yuki Takezawa","Masahiro Suzuki","Yusuke Iwasawa","Yutaka Matsuo"],"1738":["Elise Jing","Yong-Yeol Ahn"],"1739":["Jeffrey Josanne Michael","Nagendra Kumar Goel","Navneeth K","Jonas Robertson","Shravan Mishra"],"1740":["Shufan Wang","Laure Thompson","Mohit Iyyer"],"1741":["Oana-Maria Camburu"],"1742":["Florian Mai","James Henderson"],"1743":["Yue Dong","Chandra Bhagavatula","Ximing Lu","Jena D. Hwang","Antoine Bosselut","Jackie Chi Kit Cheung","Yejin Choi"],"1744":["Julia Kreutzer","David Vilar","Artem Sokolov"],"1745":["Sharon Levy","Kevin Mo","Wenhan Xiong","William Yang Wang"],"1746":["Aviv Slobodkin","Leshem Choshen","Omri Abend"],"1747":["Yanai Elazar","Hongming Zhang","Yoav Goldberg","Dan Roth"],"1748":["Moya Chen","Paul A. Crook","Stephen Roller"],"1749":["Ankit P. Shah","Shijie Geng","Peng Gao","Anoop Cherian","Takaaki Hori","Tim K. Marks","Jonathan Le Roux","Chiori Hori"],"1750":["Haitian Sun","William W. Cohen","Ruslan Salakhutdinov"],"1751":["Sabrina Ludwig","Christian Mayer","Christopher Hansen","Kerstin Eilers","Steffen Brandt"],"1752":["Yu Zhang","Qingrong Xia","Shilin Zhou","Yong Jiang","Zhenghua Li","Guohong Fu","Min Zhang"],"1753":["Sylvain Carr\u00e9","Franck Gabriel","Cl\u00e9ment Hongler","Gustavo Lacerda","Gloria Capano"],"1754":["P. S. Dodds","T. Alshaabi","M. I. Fudolig","J. W. Zimmerman","J. Lovato","S. Beaulieu","J. R. Minot","M. V. Arnold","A. J. Reagan","C. M. Danforth"],"1755":["Srinadh Bhojanapalli","Ayan Chakrabarti","Andreas Veit","Michal Lukasik","Himanshu Jain","Frederick Liu","Yin-Wen Chang","Sanjiv Kumar"],"1756":["Zaid Alyafeai","Maraim Masoud","Mustafa Ghaleb","Maged S. Al-shaibani"],"1757":["Dami\u00e1n Blasi","Antonios Anastasopoulos","Graham Neubig"],"1758":["Owain Evans","Owen Cotton-Barratt","Lukas Finnveden","Adam Bales","Avital Balwit","Peter Wills","Luca Righetti","William Saunders"],"1759":[" Lo\u00efc","Kwate Dassi"],"1760":["Junmo Kang","Suwon Shin","Jeonghwan Kim","Jaeyoung Jo","Sung-Hyon Myaeng"],"1761":["David Tsurel","Michael Doron","Alexander Nus","Arnon Dagan","Ido Guy","Dafna Shahaf"],"1762":["Jing Zhao","Junwei Bao","Yifan Wang","Youzheng Wu","Xiaodong He","Bowen Zhou"],"1763":["Mohd Abbas Zaidi","Beomseok Lee","Nikhil Kumar Lakumarapu","Sangha Kim","Chanwoo Kim"],"1764":["Sheng Bi","Xiya Cheng","Yuan-Fang Li","Lizhen Qu","Shirong Shen","Guilin Qi","Lu Pan","Yinlin Jiang"],"1765":["Hongru Wang","Zhijing Jin","Jiarun Cao","Gabriel Pui Cheong Fung","Kam-Fai Wong"],"1766":["Hendrik Schuff","Hsiu-Yu Yang","Heike Adel","Ngoc Thang Vu"],"1767":["Claudia Schon","Sophie Siebert","Frieder Stolzenburg"],"1768":["Yucheng Zhou","Xiubo Geng","Tao Shen","Guodong Long","Daxin Jiang"],"1769":["Nigel P. Duffy","Sai Akhil Puranam","Sridhar Dasaratha","Karmvir Singh Phogat","Sunil Reddy Tiyyagura"],"1770":["Riccardo Di Sipio","Jia-Hong Huang","Samuel Yen-Chi Chen","Stefano Mangini","Marcel Worring"],"1771":["Anuj Saraswat","Mehar Bhatia","Yaman Kumar Singla","Changyou Chen","Rajiv Ratn Shah"],"1772":["Da Yu","Saurabh Naik","Arturs Backurs","Sivakanth Gopi","Huseyin A. Inan","Gautam Kamath","Janardhan Kulkarni","Yin Tat Lee","Andre Manoel","Lukas Wutschitz","Sergey Yekhanin","Huishuai Zhang"],"1773":["Fahim Shahriar Khan","Mueeze Al Mushabbir","Mohammad Sabik Irbaz","MD Abdullah Al Nasim"],"1774":["Digbalay Bose","Krishna Somandepalli","Souvik Kundu","Rimita Lahiri","Jonathan Gratch","Shrikanth Narayanan"],"1775":["Bing Liu","Harrisen Scells","Guido Zuccon","Wen Hua","Genghong Zhao"],"1776":["Kevin Mart\u00ednez-Gallego","Andr\u00e9s M. \u00c1lvarez-Ortiz","Juli\u00e1n D. Arias-Londo\u00f1o"],"1777":["Shaopeng Lai","Ante Wang","Fandong Meng","Jie Zhou","Yubin Ge","Jiali Zeng","Junfeng Yao","Degen Huang","Jinsong Su"],"1778":["Hoang-Quoc Nguyen-Son","Seira Hidano","Kazuhide Fukushima","Shinsaku Kiyomoto"],"1779":["Yujie Lu","Chao Huang","Huanli Zhan","Yong Zhuang"],"1780":["Zhihua Jin","Xin Jiang","Xingbo Wang","Qun Liu","Yong Wang","Xiaozhe Ren","Huamin Qu"],"1781":["Aakash Ahmad","Madhushi Bandara","Mahdi Fahmideh","Henderik A. Proper","Giancarlo Guizzardi","Jeffrey Soar"],"1782":["Peng Xu","Davis Liang","Zhiheng Huang","Bing Xiang"],"1783":["Pooja Sethi","Denis Savenkov","Forough Arabshahi","Jack Goetz","Micaela Tolliver","Nicolas Scheffer","Ilknur Kabul","Yue Liu","Ahmed Aly"],"1784":["Marianna Apidianaki","Aina Gar\u00ed Soler"],"1785":["Amy Pu","Hyung Won Chung","Ankur P. Parikh","Sebastian Gehrmann","Thibault Sellam"],"1786":["Felix Gervits","Gordon Briggs","Antonio Roque","Genki A. Kadomatsu","Dean Thurston","Matthias Scheutz","Matthew Marge"],"1787":["Wen-Chin Huang","Shu-Wen Yang","Tomoki Hayashi","Hung-Yi Lee","Shinji Watanabe","Tomoki Toda"],"1788":["Yaqing Wang","Subhabrata Mukherjee","Xiaodong Liu","Jing Gao","Ahmed Hassan Awadallah","Jianfeng Gao"],"1789":["Yangqiaoyu Zhou","Chenhao Tan"],"1790":["Jorge Martinez-Gil"],"1791":["Hamed Vahdat-Nejad","Fatemeh Salmani","Mahdi Hajiabadi","Faezeh Azizi","Sajedeh Abbasi","Mohadese Jamalian","Reyhane Mosafer","Hamideh Hajiabadi"],"1792":["Charlotte Caucheteux","Alexandre Gramfort","Jean-R\u00e9mi King"],"1793":["Omer Goldman","Reut Tsarfaty"],"1794":["Md Abul Bashar","Richi Nayak","Anjor Kothare","Vishal Sharma","Kesavan Kandadai"],"1795":["Haozhe Ji","Minlie Huang"],"1796":["Ana-Maria Bucur","Adrian Cosma","Liviu P. Dinu"],"1797":["Evgeniia Tokarchuk","David Thulke","Weiyue Wang","Christian Dugast","Hermann Ney"],"1798":["Prem Selvaraj","Gokul NC","Pratyush Kumar","Mitesh Khapra"],"1799":["Aiden Seungjoon Lee","Hanseok Oh","Minjoon Seo"],"1800":["Szu-Wei Fu","Cheng Yu","Kuo-Hsuan Hung","Mirco Ravanelli","Yu Tsao"],"1801":["Rami Aly","Zhijiang Guo","Michael Schlichtkrull","James Thorne","Andreas Vlachos","Christos Christodoulopoulos","Oana Cocarascu","Arpit Mittal"],"1802":["Benyou Wang","Qianqian Xie","Jiahuan Pei","Prayag Tiwari","Zhao Li","Jie fu"],"1803":["M. Arana-Catania","Rob Procter","Yulan He","Maria Liakata"],"1804":["Paul Michel","Sebastian Ruder","Dani Yogatama"],"1805":["Elizabeth Nielsen","Mark Steedman","Sharon Goldwater"],"1806":["Martin Fajcik","Josef Jon","Pavel Smrz"],"1807":["Ofer Lavi","Ella Rabinovich","Segev Shlomov","David Boaz","Inbal Ronen","Ateret Anaby-Tavor"],"1808":["David Francis","Ella Rabinovich","Farhan Samir","David Mortensen","Suzanne Stevenson"],"1809":["Zhuosheng Zhang","Hai Zhao"],"1810":["Zhuosheng Zhang","Hai Zhao"],"1811":["Sanyuan Chen","Yu Wu","Chengyi Wang","Zhengyang Chen","Zhuo Chen","Shujie Liu","Jian Wu","Yao Qian","Furu Wei","Jinyu Li","Xiangzhan Yu"],"1812":["Jiaan Wang","Zhixu Li","Qiang Yang","Jianfeng Qu","Zhigang Chen","Qingsheng Liu","Guoping Hu"],"1813":["Yilun Zhu","Sameer Pradhan","Amir Zeldes"],"1814":["Fenglei Gu","Duoji Jiang"],"1815":["Aida Mostafazadeh Davani","Mark D\u00edaz","Vinodkumar Prabhakaran"],"1816":["Rakesh Chada","Pradeep Natarajan"],"1817":["Vinodkumar Prabhakaran","Aida Mostafazadeh Davani","Mark D\u00edaz"],"1818":["Shaohua Wu","Xudong Zhao","Tong Yu","Rongguo Zhang","Chong Shen","Hongli Liu","Feng Li","Hong Zhu","Jiangang Luo","Liang Xu","Xuanwei Zhang"],"1819":["Weiting Tan","Shuoyang Ding","Huda Khayrallah","Philipp Koehn"],"1820":["Xuechen Li","Florian Tram\u00e8r","Percy Liang","Tatsunori Hashimoto"],"1821":["Ting-Rui Chiang","Yi-Ting Yeh","Ta-Chung Chi","Yau-Shian Wang"],"1822":["Aishwarya Kamath","Mannat Singh","Yann LeCun","Gabriel Synnaeve","Ishan Misra","Nicolas Carion"],"1823":["Jonathan Dunn","Harish Tayyar Madabushi"],"1824":["Mandar Sharma","John S. Brownstein","Naren Ramakrishnan"],"1825":["Kamil Raczycki","Marcin Szyma\u0144ski","Yahor Yeliseyenka","Piotr Szyma\u0144ski","Tomasz Kajdanowicz"],"1826":["Jing Pan","Tao Lei","Kwangyoun Kim","Kyu Han","Shinji Watanabe"],"1827":["Fredrik Olsson","Magnus Sahlgren"],"1828":["Sashank Santhanam","Behnam Hedayatnia","Spandana Gella","Aishwarya Padmakumar","Seokhwan Kim","Yang Liu","Dilek Hakkani-Tur"],"1829":["Jesse Michael Han","Igor Babuschkin","Harrison Edwards","Arvind Neelakantan","Tao Xu","Stanislas Polu","Alex Ray","Pranav Shyam","Aditya Ramesh","Alec Radford","Ilya Sutskever"],"1830":["Mayank Agarwal","Kartik Talamadupula","Fernando Martinez","Stephanie Houde","Michael Muller","John Richards","Steven I Ross","Justin D. Weisz"],"1831":["Rose E. Wang","Julia White","Jesse Mu","Noah D. Goodman"],"1832":["Aygul Zagidullina","Georgios Patoulidis","Jonas Bokstaller"],"1833":["Suyoun Kim","Duc Le","Weiyi Zheng","Tarun Singh","Abhinav Arora","Xiaoyu Zhai","Christian Fuegen","Ozlem Kalinli","Michael L. Seltzer"],"1834":["Jing Yang","Didier Vega-Oliveros","Ta\u00eds Seibt","Anderson Rocha"],"1835":["Zahra Fatemi","Chen Xing","Wenhao Liu","Caiming Xiong"],"1836":["William Held","Dan Iter","Dan Jurafsky"],"1837":["Tristan Karch","Laetitia Teodorescu","Katja Hofmann","Cl\u00e9ment Moulin-Frier","Pierre-Yves Oudeyer"],"1838":["Ting-Rui Chiang"],"1839":["Slim Gharbi","Heger Arfaoui","Hatem Haddad","Mayssa Kchaou"],"1840":["Yosuke Higuchi","Nanxin Chen","Yuya Fujita","Hirofumi Inaguma","Tatsuya Komatsu","Jaesong Lee","Jumon Nozaki","Tianzi Wang","Shinji Watanabe"],"1841":["Po-Nien Kung","Chung-Cheng Chang","Tse-Hsuan Yang","Hsin-Kai Hsu","Yu-Jia Liou","Yun-Nung Chen"],"1842":["Jinming Zhao","Philip Arthur","Gholamreza Haffari","Trevor Cohn","Ehsan Shareghi"],"1843":["Jounghee Kim","Pilsung Kang"],"1844":["Jieyu Zhang","Yue Yu","Yinghao Li","Yujing Wang","Yaming Yang","Mao Yang","Alexander Ratner"],"1845":["Alexander Robertson","Walid Magdy","Sharon Goldwater"],"1846":["Jasper Kyle Catapang","Jerome V. Cleofas"],"1847":["Andrea Galassi","Marco Lippi","Paolo Torroni"],"1848":["Peyman Alavi","Pouria Nikvand","Mehrnoush Shamsfard"],"1849":["Jiaxin Pei","David Jurgens"],"1850":["Judicael Poumay","Ashwin Ittoo"],"1851":["Yova Kementchedjhieva","Anders S\u00f8gaard"],"1852":["Marina Fomicheva","Shuo Sun","Erick Fonseca","Chrysoula Zerva","Fr\u00e9d\u00e9ric Blain","Vishrav Chaudhary","Francisco Guzm\u00e1n","Nina Lopatina","Lucia Specia","Andr\u00e9 F. T. Martins"],"1853":["Dong-Jin Kim","Tae-Hyun Oh","Jinsoo Choi","In So Kweon"],"1854":["Renliang Sun","Hanqi Jin","Xiaojun Wan"],"1855":["Abderrazek Azri","C\u00e9cile Favre","Nouria Harbi","J\u00e9r\u00f4me Darmont","Camille No\u00fbs"],"1856":["Sabyasachee Baruah","Krishna Somandepalli","Shrikanth Narayanan"],"1857":["Justin Olah","Sabyasachee Baruah","Digbalay Bose","Shrikanth Narayanan"],"1858":["Onyenwe Ikechukwu","Onyedikachukwu Ikechukwu-Onyenwe","Onyedinma Ebele"],"1859":["Dominic Flocco","Bryce Palmer-Toy","Ruixiao Wang","Hongyu Zhu","Rishi Sonthalia","Junyuan Lin","Andrea L. Bertozzi","P. Jeffrey Brantingham"],"1860":["Chen Zhao","Chenyan Xiong","Jordan Boyd-Graber","Hal Daum\u00e9 III"],"1861":["Simon Razniewski","Andrew Yates","Nora Kassner","Gerhard Weikum"],"1862":["Francielle Alves Vargas","Fabiana Rodrigues de G\u00f3es","Isabelle Carvalho","Fabr\u00edcio Benevenuto","Thiago Alexandre Salgueiro Pardo"],"1863":["Francielle Alves Vargas","Isabelle Carvalho","Fabiana Rodrigues de G\u00f3es"],"1864":["Benjamin Townsend","Eamon Ito-Fisher","Lily Zhang","Madison May"],"1865":["Jacqueline Comer","Sam Work","Kory W Mathewson","Lana Cuthbertson","Kasey Machin"],"1866":["Yuan-Ching Lin","Jinwen Ma"],"1867":["Matthew Wiesner","Desh Raj","Sanjeev Khudanpur"],"1868":["Anton Chernyavskiy","Dmitry Ilvovsky","Preslav Nakov"],"1869":["Anton Chernyavskiy","Dmitry Ilvovsky","Pavel Kalinin","Preslav Nakov"],"1870":["Mohamed Abdalla","Krishnapriya Vishnubhotla","Saif M. Mohammad"],"1871":["Tiezheng Yu","Wenliang Dai","Zihan Liu","Pascale Fung"],"1872":["Janarthanan Rajendran","Jonathan K. Kummerfeld","Satinder Singh"],"1873":["Kai-Po Chang","Wei-Yun Ma"],"1874":["Tuan Nguyen","Hanh Pham","Truong Bui","Tan Nguyen","Duc Luong","Phong Nguyen"],"1875":["Rajdeep Mukherjee","Tapas Nayak","Yash Butala","Sourangshu Bhattacharya","Pawan Goyal"],"1876":["Jiaxin Shi","Shulin Cao","Lei Hou","Juanzi Li","Hanwang Zhang"],"1877":["Cong Zhang","Huinan Zeng","Huang Liu","Jiewen Zheng"],"1878":["Chao Wang","Zhonghao Li","Benlai Tang","Xiang Yin","Yuan Wan","Yibiao Yu","Zejun Ma"],"1879":["Yan Liu","Yazheng Yang"],"1880":["Vinod Ganesan","Gowtham Ramesh","Pratyush Kumar"],"1881":["Xisen Jin","Bill Yuchen Lin","Mohammad Rostami","Xiang Ren"],"1882":["Vanya Cohen","Geraud Nangue Tasse","Nakul Gopalan","Steven James","Matthew Gombolay","Benjamin Rosman"],"1883":["Ofir Arviv","Dmitry Nikolaev","Taelin Karidi","Omri Abend"],"1884":["Sahana Ramnath","Preksha Nema","Deep Sahni","Mitesh M. Khapra"],"1885":["Jiashuo Wang","Wenjie LI","Peiqin Lin","Feiteng Mu"],"1886":["Jimmy Tobin","Katrin Tomanek"],"1887":["Samuel Cahyawijaya","Genta Indra Winata","Bryan Wilie","Karissa Vincentio","Xiaohong Li","Adhiguna Kuncoro","Sebastian Ruder","Zhi Yuan Lim","Syafri Bahar","Masayu Leylia Khodra","Ayu Purwarianti","Pascale Fung"],"1888":["Xuankai Chang","Takashi Maekaku","Pengcheng Guo","Jing Shi","Yen-Ju Lu","Aswin Shanmugam Subramanian","Tianzi Wang","Shu-wen Yang","Yu Tsao","Hung-yi Lee","Shinji Watanabe"],"1889":["Guolin Zheng","Yubei Xiao","Ke Gong","Pan Zhou","Xiaodan Liang","Liang Lin"],"1890":["Peng Gao","Shijie Geng","Renrui Zhang","Teli Ma","Rongyao Fang","Yongfeng Zhang","Hongsheng Li","Yu Qiao"],"1891":["Zhengyuan Liu","Nancy F. Chen"],"1892":["Jialun Cao","Meiziniu Li","Yeting Li","Ming Wen","Shing-Chi Cheung"],"1893":["Zhengyuan Liu","Ke Shi","Nancy F. Chen"],"1894":["Daniela Brook Weiss","Paul Roit","Ori Ernst","Ido Dagan"],"1895":["Han Zhu","Li Wang","Ying Hou","Jindong Wang","Gaofeng Cheng","Pengyuan Zhang","Yonghong Yan"],"1896":["Mu Yang","Shaojin Ding","Tianlong Chen","Tong Wang","Zhangyang Wang"],"1897":["Alexios Gidiotis","Grigorios Tsoumakas"],"1898":["Varun Madhavan","Aditya Girish Pawate","Shraman Pal","Abhranil Chandra"],"1899":["Qinglin Zhang","Qian Chen","Yali Li","Jiaqing Liu","Wen Wang"],"1900":["Jianlin Su","Yu Lu","Shengfeng Pan","Bo Wen","Yunfeng Liu"],"1901":["Seth Pate","Wei Xu","Ziyi Yang","Maxwell Love","Siddarth Ganguri","Lawson L. S. Wong"],"1902":["Yang Jiao","Zequn Jie","Weixin Luo","Jingjing Chen","Yu-Gang Jiang","Xiaolin Wei","Lin Ma"],"1903":["Ankita Pasad","Ju-Chieh Chou","Karen Livescu"],"1904":["Xinghua Zhang","Bowen Yu","Tingwen Liu","Zhenyu Zhang","Jiawei Sheng","Mengge Xue","Hongbo Xu"],"1905":["Chan Young Park","Julia Mendelsohn","Karthik Radhakrishnan","Kinjal Jain","Tushar Kanakagiri","David Jurgens","Yulia Tsvetkov"],"1906":["Iv\u00e1n Vall\u00e9s-P\u00e9rez","Juan G\u00f3mez-Sanchis","Marcelino Mart\u00ednez-Sober","Joan Vila-Franc\u00e9s","Antonio J. Serrano-L\u00f3pez","Emilio Soria-Olivas"],"1907":["Alan Lundgard","Arvind Satyanarayan"],"1908":["Hui Yin","Xiangyu Song","Shuiqiao Yang","Jianxin Li"],"1909":["Marina Fomicheva","Piyawat Lertvittayakumjorn","Wei Zhao","Steffen Eger","Yang Gao"],"1910":["Anna J\u00f8rgensen","Anders S\u00f8gaard"],"1911":["Yuval Kirstain","Patrick Lewis","Sebastian Riedel","Omer Levy"],"1912":["Odellia Boni","Guy Feigenblat","Guy Lev","Michal Shmueli-Scheuer","Benjamin Sznajder","David Konopnicki"],"1913":["Donghan Yu","Chenguang Zhu","Yuwei Fang","Wenhao Yu","Shuohang Wang","Yichong Xu","Xiang Ren","Yiming Yang","Michael Zeng"],"1914":["Paolo D'Alberto","Jiangsha Ma","Jintao Li","Yiming Hu","Manasa Bollavaram","Shaoxia Fang"],"1915":["Diogo Cortiz","Jefferson O. Silva","Newton Calegari","Ana Lu\u00edsa Freitas","Ana Ang\u00e9lica Soares","Carolina Botelho","Gabriel Gaudencio R\u00eago","Waldir Sampaio","Paulo Sergio Boggio"],"1916":["Ruskin Raj Manku","Aditya Jyoti Paul"],"1917":["Hieu Nguyen","Long Phan","James Anibal","Alec Peltekian","Hieu Tran"],"1918":["Dimitri Kartsaklis","Ian Fan","Richie Yeung","Anna Pearson","Robin Lorenz","Alexis Toumi","Giovanni de Felice","Konstantinos Meichanetzidis","Stephen Clark","Bob Coecke"],"1919":["Kento Kaku","Masato Kikuchi","Tadachika Ozono","Toramatsu Shintani"],"1920":["Ning Shi","Boxin Wang","Wei Wang","Xiangyu Liu","Rong Zhang","Hui Xue","Xinbing Wang","Zhouhan Lin"],"1921":["Ingo Marquart"],"1922":["Tim Steuer","Anna Filighera","Tobias Meuser","Christoph Rensing"],"1923":["Yunfan Shao","Zhichao Geng","Yitao Liu","Junqi Dai","Fei Yang","Li Zhe","Hujun Bao","Xipeng Qiu"],"1924":["Eyal Arviv","Oren Tsur"],"1925":["Michal R\u016f\u017ei\u010dka","Petr Sojka"],"1926":["Gjorgjina Cenikj","Barbara Korou\u0161i\u0107 Seljak","Tome Eftimov"],"1927":["Luis Miguel Botelho"],"1928":["Jumon Nozaki","Tatsuya Komatsu"],"1929":["Joan Plepi","Lucie Flek"],"1930":["Daria Dzendzik","Carl Vogel","Jennifer Foster"],"1931":["Yuan Yao","Ao Zhang","Zhengyan Zhang","Zhiyuan Liu","Tat-Seng Chua","Maosong Sun"],"1932":["Jiun-Hao Jhan","Chao-Peng Liu","Shyh-Kang Jeng","Hung-Yi Lee"],"1933":["Chengdong Liang","Menglong Xu","Xiao-Lei Zhang"],"1934":["Qinjin Jia","Jialin Cui","Yunkai Xiao","Chengyuan Liu","Parvez Rashid","Edward F. Gehringer"],"1935":["Yuanchao Wang","Wenji Du","Chenghao Cai","Yanyan Xu"],"1936":["Kemal Kurniawan","Lea Frermann","Philip Schulz","Trevor Cohn"],"1937":["Guangyan Zhang","Yichong Leng","Daxin Tan","Ying Qin","Kaitao Song","Xu Tan","Sheng Zhao","Tan Lee"],"1938":["Shuo Yang","Le Hou","Xiaodan Song","Qiang Liu","Denny Zhou"],"1939":["Surafel M. Lakew","Marcello Federico","Yue Wang","Cuong Hoang","Yogesh Virkar","Roberto Barra-Chicote","Robert Enyedi"],"1940":["Michihiro Yasunaga","Jure Leskovec","Percy Liang"],"1941":["Weijia Xu","Marine Carpuat"],"1942":["Yangyang Shi","Chunyang Wu","Dilin Wang","Alex Xiao","Jay Mahadeokar","Xiaohui Zhang","Chunxi Liu","Ke Li","Yuan Shangguan","Varun Nagaraja","Ozlem Kalinli","Mike Seltzer"],"1943":["Siva Uday Sampreeth Chebolu","Franck Dernoncourt","Nedim Lipka","Thamar Solorio"],"1944":["Charalambos Themistocleous","Valantis Fyndanis","Kyrana Tsapkini"],"1945":["Erik Yan","Harish Tayyar Madabushi"],"1946":["Nora Kassner","Oyvind Tafjord","Hinrich Schutze","Peter Clark"],"1947":["Liwen Wang","Xuefeng Li","Jiachi Liu","Keqing He","Yuanmeng Yan","Weiran Xu"],"1948":["Jessica L\u00f3pez Espejel","Ga\u00ebl de Chalendar","Jorge Garcia Flores","Thierry Charnois","Ivan Vladimir Meza Ruiz"],"1949":["Sameer Khurana","Antoine Laurent","James Glass"],"1950":["Liang-Hsuan Tseng","Yu-Kuan Fu","Heng-Jui Chang","Hung-yi Lee"],"1951":["Pierre Colombo","Chouchang Yang","Giovanna Varni","Chlo\u00e9 Clavel"],"1952":["Linlin Zhang"],"1953":["Kartikay Bagla","Ankit Kumar","Shivam Gupta","Anuj Gupta"],"1954":["Namkyu Jung","Geonmin Kim","Han-Gyu Kim"],"1955":["Ruizhe Li","Xutan Peng","Chenghua Lin"],"1956":["Sebastian Ruder","Noah Constant","Jan Botha","Aditya Siddhant","Orhan Firat","Jinlan Fu","Pengfei Liu","Junjie Hu","Dan Garrette","Graham Neubig","Melvin Johnson"],"1957":["Jia Huei Tan","Chee Seng Chan","Joon Huang Chuah"],"1958":["Vikram Ramesh","Rida Assaf"],"1959":["Yuchen He","Zhuosheng Zhang","Hai Zhao"],"1960":["Kyuhong Shim","Iksoo Choi","Wonyong Sung","Jungwook Choi"],"1961":["Xiaochuang Han","Yulia Tsvetkov"],"1962":["Kuan Wang","Yuyu Zhang","Diyi Yang","Le Song","Tao Qin"],"1963":["Sumit Shekhar","Bhanu Prakash Reddy Guda","Ashutosh Chaubey","Ishan Jindal","Avneet Jain"],"1964":["Kate Pearce","Tiffany Zhan","Aneesh Komanduri","Justin Zhan"],"1965":["Tsendsuren Munkhdalai","Khe Chai Sim","Angad Chandorkar","Fan Gao","Mason Chua","Trevor Strohman","Fran\u00e7oise Beaufays"],"1966":["Ife Adebara","Muhammad Abdul-Mageed"],"1967":["Mohammed M. Abdelgwad","Taysir Hassan A Soliman","Ahmed I. Taloba","Mohamed Fawzy Farghaly"],"1968":["Leo Gao"],"1969":["Mauricio Verano Merino","Jurgen Vinju","Mark van den Brand"],"1970":["Pengcheng He","Xiaodong Liu","Jianfeng Gao","Weizhu Chen"],"1971":["Rongqing Huang"],"1972":["Orevaoghene Ahia","Julia Kreutzer","Sara Hooker"],"1973":["Vibhav Agarwal","Sudeep Deepak Shivnikar","Sourav Ghosh","Himanshu Arora","Yashwant Saini"],"1974":["Fiona Anting Tan","See-Kiong Ng"],"1975":["Han Guo","Bowen Tan","Zhengzhong Liu","Eric P. Xing","Zhiting Hu"],"1976":["Sawsan Alqahtani","Garima Lalwani","Yi Zhang","Salvatore Romeo","Saab Mansour"],"1977":["James Powell","Kari Sentz","Martin Klein"],"1978":["Shubho Sengupta","Vineel Pratap","Awni Hannun"],"1979":["Yihong Chen","Pasquale Minervini","Sebastian Riedel","Pontus Stenetorp"],"1980":["Namkyu Jung","Geonmin Kim","Joon Son Chung"],"1981":["Biao Zhang","Ivan Titov","Rico Sennrich"],"1982":["Grzegorz Chrupa\u0142a"],"1983":["Amauri J Paula"],"1984":["Christian Kahmann","Andreas Niekler","Gregor Wiedemann"],"1985":["Yi Zhou","Danushka Bollegala"],"1986":["Lu Zhang","Jiandong Ding","Yi Xu","Yingyao Liu","Shuigeng Zhou"],"1987":["Anita L. Ver\u0151","Ann Copestake"],"1988":["Zongyi Li","Jianhan Xu","Jiehang Zeng","Linyang Li","Xiaoqing Zheng","Qi Zhang","Kai-Wei Chang","Cho-Jui Hsieh"],"1989":["Linyang Li","Demin Song","Ruotian Ma","Xipeng Qiu","Xuanjing Huang"],"1990":["Sanxing Chen","Xiaodong Liu","Jianfeng Gao","Jian Jiao","Ruofei Zhang","Yangfeng Ji"],"1991":["Hao Peng","Jungo Kasai","Nikolaos Pappas","Dani Yogatama","Zhaofeng Wu","Lingpeng Kong","Roy Schwartz","Noah A. Smith"],"1992":["Miriam Stern"],"1993":["Kangjie Chen","Yuxian Meng","Xiaofei Sun","Shangwei Guo","Tianwei Zhang","Jiwei Li","Chun Fan"],"1994":["Zhen Xu","David R. So","Andrew M. Dai"],"1995":["Fangda Han","Guoyao Hao","Ricardo Guerrero","Vladimir Pavlovic"],"1996":["Rishabh Bhardwaj","Tushar Vaidya","Soujanya Poria"],"1997":["Justin Wilson","Sunyeong Park","Seunghye J. Wilson","Ming C. Lin"],"1998":["Tyler A. Chang","Benjamin K. Bergen"],"1999":["Narsimha Chilkuri","Eric Hunsberger","Aaron Voelker","Gurshaant Malik","Chris Eliasmith"],"2000":["Kristine Mae Adlaon","Nelson Marcos"],"2001":["Karthikeyan K","Aalok Sathe","Somak Aditya","Monojit Choudhury"],"2002":["Xinying Song","Alex Salcianu","Yang Song","Dave Dopson","Denny Zhou"],"2003":["Christopher Michael Rytting","David Wingate"],"2004":["Rahul Aralikatte","Miryam de Lhoneux","Anoop Kunchukuttan","Anders S\u00f8gaard"],"2005":["Andreas R\u00fcckl\u00e9","Gregor Geigle","Max Glockner","Tilman Beck","Jonas Pfeiffer","Nils Reimers","Iryna Gurevych"],"2006":["Jacob Krantz","Aaron Gokaslan","Dhruv Batra","Stefan Lee","Oleksandr Maksymets"],"2007":["Natesh Reddy","Muktabh Mayank Srivastava"],"2008":["A. Emin Orhan"],"2009":["Fatemeh Salmani","Hamed Vahdat-Nejad","Hamideh Hajiabadi"],"2010":["Sajad Sotudeh","Hanieh Deilamsalehy","Franck Dernoncourt","Nazli Goharian"],"2011":["Frederike Zufall","Marius Hamacher","Katharina Kloppenborg","Torsten Zesch"],"2012":["Atanu Mandal","Santanu Pal","Indranil Dutta","Mahidas Bhattacharya","Sudip Kumar Naskar"],"2013":["Muhammad Khalifa","Aminul Islam"],"2014":["Ruijie Zhou","Soham Deshmukh","Jeremiah Greer","Charles Lee"],"2015":["Momchil Hardalov","Ivan Koychev","Preslav Nakov"],"2016":["Peter Vieting","Christoph L\u00fcscher","Wilfried Michel","Ralf Schl\u00fcter","Hermann Ney"],"2017":["Maxime De Bruyn","Ehsan Lotfi","Jeska Buhmann","Walter Daelemans"],"2018":["Ehsan Lotfi","Maxime De Bruyn","Jeska Buhmann","Walter Daelemans"],"2019":["Chong Zhang","Junran Wu","He Zhu","Ke Xu"],"2020":["Hoai Nam Tran","Udo Kruschwitz"],"2021":["David Amat Ol\u00f3ndriz","Pon\u00e7 Palau Puigdevall","Adri\u00e0 Salvador Palau"],"2022":["Ilya Gusev"],"2023":["Marco Di Giovanni","Marco Brambilla"],"2024":["Ishani Mondal","Procheta Sen","Debasis Ganguly"],"2025":["Mohamed Seghir Hadj Ameur","Hassina Aliane"],"2026":["Eryk Wdowiak"],"2027":["Hayato Futami","Hirofumi Inaguma","Masato Mimura","Shinsuke Sakai","Tatsuya Kawahara"],"2028":["Tanik Saikh","Sovan Kumar Sahoo","Asif Ekbal","Pushpak Bhattacharyya"],"2029":["Harsh Jhamtani","Taylor Berg-Kirkpatrick"],"2030":["Hadeel Saadany","Constantin Orasan","Emad Mohamed","Ashraf Tantawy"],"2031":["Felipe Maia Polo","Gabriel Caiaffa Floriano Mendon\u00e7a","Kau\u00ea Capellato J. Parreira","Lucka Gianvechio","Peterson Cordeiro","Jonathan Batista Ferreira","Leticia Maria Paz de Lima","Ant\u00f4nio Carlos do Amaral Maia","Renato Vicente"],"2032":["Xuebo Liu","Longyue Wang","Derek F. Wong","Liang Ding","Lidia S. Chao","Shuming Shi","Zhaopeng Tu"],"2033":["Erhan Sezerer","Selma Tekir"],"2034":["Yuta Koreeda","Christopher D. Manning"],"2035":["Nikolaos Flemotomos","Victor R. Martinez","Zhuohao Chen","Torrey A. Creed","David C. Atkins","Shrikanth Narayanan"],"2036":["Sohrab Ferdowsi","Nikolay Borissov","Julien Knafou","Poorya Amini","Douglas Teodoro"],"2037":["Yubo Xie","Pearl Pu"],"2038":["Ramon Ferrer-i-Cancho","Carlos G\u00f3mez-Rodr\u00edguez","Juan Luis Esteban","Llu\u00eds Alemany-Puig"],"2039":["Priyam Basu","Tiasa Singha Roy","Rakshit Naidu","Zumrut Muftuoglu"],"2040":["Minghan Li","Jimmy Lin"],"2041":["Feng Cheng"],"2042":["Manuel R. Ciosici","Joe Cecil","Alex Hedges","Dong-Ho Lee","Marjorie Freedman","Ralph Weischedel"],"2043":["John Xi Qiu","Adam Faulkner","Aysu Ezen Can"],"2044":["Prajjwal Bhargava","Aleksandr Drozd","Anna Rogers"],"2045":["Timo Schick","Hinrich Sch\u00fctze"],"2046":["Timo Schick","Hinrich Sch\u00fctze"],"2047":["Julio Cesar Duarte","S\u00e9rgio Colcher"],"2048":["Mimansa Jaiswal","Emily Mower Provost"],"2049":["Muskan Garg"],"2050":["Taelin Karidi","Yichu Zhou","Nathan Schneider","Omri Abend","Vivek Srikumar"],"2051":["Gulmira Tolegen","Alymzhan Toleu","Orken Mamyrbayev","Rustam Mussabayev"],"2052":["Weronika \u0141ajewska","Anna Wr\u00f3blewska"],"2053":["Thomas Hirsch","Birgit Hofer"],"2054":["Canwen Xu","Wangchunshu Zhou","Tao Ge","Ke Xu","Julian McAuley","Furu Wei"],"2055":["Nathaniel Berger","Stefan Riezler","Artem Sokolov","Sebastian Ebert"],"2056":["Ruben Kruiper","Ioannis Konstas","Alasdair Gray","Farhad Sadeghineko","Richard Watson","Bimal Kumar"],"2057":["Jiaxin Ju","Ming Liu","Huan Yee Koh","Yuan Jin","Lan Du","Shirui Pan"],"2058":["Enshuai Hou","Jie zhu"],"2059":["Yiming Chen","Yan Zhang","Chen Zhang","Grandee Lee","Ran Cheng","Haizhou Li"],"2060":["Muhammad Imran","Umair Qazi","Ferda Ofli"],"2061":["Ali-Reza Feizi-Derakhshi","Mohammad-Reza Feizi-Derakhshi","Majid Ramezani","Narjes Nikzad-Khasmakhi","Meysam Asgari-Chenaghlu","Taymaz Akan","Mehrdad Ranjbar-Khadivi","Elnaz Zafarni-Moattar","Zoleikha Jahanbakhsh-Naghadeh"],"2062":["Letian Peng","Zuchao Li","Hai Zhao"],"2063":["Adrian Caruana","Madhushi Bandara","Daniel Catchpoole","Paul J Kennedy"],"2064":["Kyle Gorman","Christo Kirov","Brian Roark","Richard Sproat"],"2065":["Shivin Thukral","Kunal Kukreja","Christian Kavouras"],"2066":["Wenqian Ye","Fei Xu","Yaojia Huang","Cassie Huang","Ji A"],"2067":["Yigeng Zhang","Mahsa Shafaei","Fabio Gonzalez","Thamar Solorio"],"2068":["Esin Durmus"],"2069":["Ori Shapira","Ramakanth Pasunuru","Ido Dagan","Yael Amsterdamer"]},"pdf_link":{"0":"http:\/\/export.arxiv.org\/pdf\/2201.00075v1","1":"http:\/\/export.arxiv.org\/pdf\/2201.02735v1","2":"http:\/\/export.arxiv.org\/pdf\/1907.09358v3","3":"http:\/\/export.arxiv.org\/pdf\/2103.10415v3","4":"http:\/\/export.arxiv.org\/pdf\/2112.15545v1","5":"http:\/\/export.arxiv.org\/pdf\/2103.12360v3","6":"http:\/\/export.arxiv.org\/pdf\/2112.15356v1","7":"http:\/\/export.arxiv.org\/pdf\/2105.04976v2","8":"http:\/\/export.arxiv.org\/pdf\/2112.15324v1","9":"http:\/\/export.arxiv.org\/pdf\/2112.15290v1","10":"http:\/\/export.arxiv.org\/pdf\/2112.15283v1","11":"http:\/\/export.arxiv.org\/pdf\/2112.15280v1","12":"http:\/\/export.arxiv.org\/pdf\/2112.11632v2","13":"http:\/\/export.arxiv.org\/pdf\/2112.15253v1","14":"http:\/\/export.arxiv.org\/pdf\/2112.15124v1","15":"http:\/\/export.arxiv.org\/pdf\/2112.15099v1","16":"http:\/\/export.arxiv.org\/pdf\/2112.15060v1","17":"http:\/\/export.arxiv.org\/pdf\/2112.15051v1","18":"http:\/\/export.arxiv.org\/pdf\/2112.15043v1","19":"http:\/\/export.arxiv.org\/pdf\/2112.15011v1","20":"http:\/\/export.arxiv.org\/pdf\/2112.15009v1","21":"http:\/\/export.arxiv.org\/pdf\/2112.14938v1","22":"http:\/\/export.arxiv.org\/pdf\/2112.14933v1","23":"http:\/\/export.arxiv.org\/pdf\/2112.02498v2","24":"http:\/\/export.arxiv.org\/pdf\/2105.01893v2","25":"http:\/\/export.arxiv.org\/pdf\/2112.14890v1","26":"http:\/\/export.arxiv.org\/pdf\/2106.05642v3","27":"http:\/\/export.arxiv.org\/pdf\/2112.14820v1","28":"http:\/\/export.arxiv.org\/pdf\/1907.00457v2","29":"http:\/\/export.arxiv.org\/pdf\/2112.14789v1","30":"http:\/\/export.arxiv.org\/pdf\/2112.14731v1","31":"http:\/\/export.arxiv.org\/pdf\/2103.15330v2","32":"http:\/\/export.arxiv.org\/pdf\/2111.10269v2","33":"http:\/\/export.arxiv.org\/pdf\/2109.02325v2","34":"http:\/\/export.arxiv.org\/pdf\/2112.14569v1","35":"http:\/\/export.arxiv.org\/pdf\/2009.09708v3","36":"http:\/\/export.arxiv.org\/pdf\/2012.05481v2","37":"http:\/\/export.arxiv.org\/pdf\/2102.01547v5","38":"http:\/\/export.arxiv.org\/pdf\/2112.14484v1","39":"http:\/\/export.arxiv.org\/pdf\/2110.00031v2","40":"http:\/\/export.arxiv.org\/pdf\/2201.02504v1","41":"http:\/\/export.arxiv.org\/pdf\/2112.14375v1","42":"http:\/\/export.arxiv.org\/pdf\/2110.00534v3","43":"http:\/\/export.arxiv.org\/pdf\/2112.14343v1","44":"http:\/\/export.arxiv.org\/pdf\/2112.14330v1","45":"http:\/\/export.arxiv.org\/pdf\/2112.14318v1","46":"http:\/\/export.arxiv.org\/pdf\/1809.04128v3","47":"http:\/\/export.arxiv.org\/pdf\/2104.08646v3","48":"http:\/\/export.arxiv.org\/pdf\/2112.13572v2","49":"http:\/\/export.arxiv.org\/pdf\/2110.01529v2","50":"http:\/\/export.arxiv.org\/pdf\/2109.00527v2","51":"http:\/\/export.arxiv.org\/pdf\/2112.14192v1","52":"http:\/\/export.arxiv.org\/pdf\/2112.14168v1","53":"http:\/\/export.arxiv.org\/pdf\/2112.14153v1","54":"http:\/\/export.arxiv.org\/pdf\/2201.02737v1","55":"http:\/\/export.arxiv.org\/pdf\/2109.05837v3","56":"http:\/\/export.arxiv.org\/pdf\/2112.13808v2","57":"http:\/\/export.arxiv.org\/pdf\/1906.08487v3","58":"http:\/\/export.arxiv.org\/pdf\/2112.13969v1","59":"http:\/\/export.arxiv.org\/pdf\/2112.13960v1","60":"http:\/\/export.arxiv.org\/pdf\/2112.13946v1","61":"http:\/\/export.arxiv.org\/pdf\/2112.13906v1","62":"http:\/\/export.arxiv.org\/pdf\/2112.13870v1","63":"http:\/\/export.arxiv.org\/pdf\/2112.13834v1","64":"http:\/\/export.arxiv.org\/pdf\/2112.13833v1","65":"http:\/\/export.arxiv.org\/pdf\/2112.13800v1","66":"http:\/\/export.arxiv.org\/pdf\/2008.00097v3","67":"http:\/\/export.arxiv.org\/pdf\/2112.13790v1","68":"http:\/\/export.arxiv.org\/pdf\/2112.13776v1","69":"http:\/\/export.arxiv.org\/pdf\/2112.13758v1","70":"http:\/\/export.arxiv.org\/pdf\/2112.13756v1","71":"http:\/\/export.arxiv.org\/pdf\/2112.13742v1","72":"http:\/\/export.arxiv.org\/pdf\/1911.01208v4","73":"http:\/\/export.arxiv.org\/pdf\/2112.13634v1","74":"http:\/\/export.arxiv.org\/pdf\/2112.13619v1","75":"http:\/\/export.arxiv.org\/pdf\/2112.13610v1","76":"http:\/\/export.arxiv.org\/pdf\/2008.11841v3","77":"http:\/\/export.arxiv.org\/pdf\/2112.13597v1","78":"http:\/\/export.arxiv.org\/pdf\/2112.13556v1","79":"http:\/\/export.arxiv.org\/pdf\/2112.13512v1","80":"http:\/\/export.arxiv.org\/pdf\/2112.13432v1","81":"http:\/\/export.arxiv.org\/pdf\/2112.13428v1","82":"http:\/\/export.arxiv.org\/pdf\/2111.03963v2","83":"http:\/\/export.arxiv.org\/pdf\/2105.10909v2","84":"http:\/\/export.arxiv.org\/pdf\/2109.06935v2","85":"http:\/\/export.arxiv.org\/pdf\/2105.07148v3","86":"http:\/\/export.arxiv.org\/pdf\/2106.01598v2","87":"http:\/\/export.arxiv.org\/pdf\/2112.13372v1","88":"http:\/\/export.arxiv.org\/pdf\/2112.13352v1","89":"http:\/\/export.arxiv.org\/pdf\/2112.03719v2","90":"http:\/\/export.arxiv.org\/pdf\/2112.13320v1","91":"http:\/\/export.arxiv.org\/pdf\/2112.13319v1","92":"http:\/\/export.arxiv.org\/pdf\/2104.07396v3","93":"http:\/\/export.arxiv.org\/pdf\/2108.12928v2","94":"http:\/\/export.arxiv.org\/pdf\/2112.13288v1","95":"http:\/\/export.arxiv.org\/pdf\/2112.13259v1","96":"http:\/\/export.arxiv.org\/pdf\/2112.13241v1","97":"http:\/\/export.arxiv.org\/pdf\/2112.13238v1","98":"http:\/\/export.arxiv.org\/pdf\/2112.13237v1","99":"http:\/\/export.arxiv.org\/pdf\/2009.06206v5","100":"http:\/\/export.arxiv.org\/pdf\/2112.13179v1","101":"http:\/\/export.arxiv.org\/pdf\/2010.08566v4","102":"http:\/\/export.arxiv.org\/pdf\/1909.13302v4","103":"http:\/\/export.arxiv.org\/pdf\/2112.12996v1","104":"http:\/\/export.arxiv.org\/pdf\/2112.12940v1","105":"http:\/\/export.arxiv.org\/pdf\/2112.12938v1","106":"http:\/\/export.arxiv.org\/pdf\/2112.12913v1","107":"http:\/\/export.arxiv.org\/pdf\/2111.02110v3","108":"http:\/\/export.arxiv.org\/pdf\/2112.12870v1","109":"http:\/\/export.arxiv.org\/pdf\/2112.12809v1","110":"http:\/\/export.arxiv.org\/pdf\/2112.12731v1","111":"http:\/\/export.arxiv.org\/pdf\/2112.12672v1","112":"http:\/\/export.arxiv.org\/pdf\/2112.12489v1","113":"http:\/\/export.arxiv.org\/pdf\/2112.12444v1","114":"http:\/\/export.arxiv.org\/pdf\/2112.12441v1","115":"http:\/\/export.arxiv.org\/pdf\/2112.12433v1","116":"http:\/\/export.arxiv.org\/pdf\/2107.00676v2","117":"http:\/\/export.arxiv.org\/pdf\/2107.08408v2","118":"http:\/\/export.arxiv.org\/pdf\/2112.12389v1","119":"http:\/\/export.arxiv.org\/pdf\/2201.02738v1","120":"http:\/\/export.arxiv.org\/pdf\/2112.12356v1","121":"http:\/\/export.arxiv.org\/pdf\/2112.12318v1","122":"http:\/\/export.arxiv.org\/pdf\/2106.00400v2","123":"http:\/\/export.arxiv.org\/pdf\/2112.12224v1","124":"http:\/\/export.arxiv.org\/pdf\/2112.12028v1","125":"http:\/\/export.arxiv.org\/pdf\/2201.02739v1","126":"http:\/\/export.arxiv.org\/pdf\/2112.12014v1","127":"http:\/\/export.arxiv.org\/pdf\/2107.11414v3","128":"http:\/\/export.arxiv.org\/pdf\/2112.08914v2","129":"http:\/\/export.arxiv.org\/pdf\/2112.11973v1","130":"http:\/\/export.arxiv.org\/pdf\/2112.11941v1","131":"http:\/\/export.arxiv.org\/pdf\/2112.11850v1","132":"http:\/\/export.arxiv.org\/pdf\/2008.00364v6","133":"http:\/\/export.arxiv.org\/pdf\/2106.12384v2","134":"http:\/\/export.arxiv.org\/pdf\/2112.11800v1","135":"http:\/\/export.arxiv.org\/pdf\/2112.11776v1","136":"http:\/\/export.arxiv.org\/pdf\/2106.02382v3","137":"http:\/\/export.arxiv.org\/pdf\/2112.11769v1","138":"http:\/\/export.arxiv.org\/pdf\/2107.02126v5","139":"http:\/\/export.arxiv.org\/pdf\/2112.11740v1","140":"http:\/\/export.arxiv.org\/pdf\/2112.11739v1","141":"http:\/\/export.arxiv.org\/pdf\/2110.13715v2","142":"http:\/\/export.arxiv.org\/pdf\/2106.08785v2","143":"http:\/\/export.arxiv.org\/pdf\/2111.03945v3","144":"http:\/\/export.arxiv.org\/pdf\/2112.11670v1","145":"http:\/\/export.arxiv.org\/pdf\/2112.11668v1","146":"http:\/\/export.arxiv.org\/pdf\/2112.11642v1","147":"http:\/\/export.arxiv.org\/pdf\/2112.11640v1","148":"http:\/\/export.arxiv.org\/pdf\/2004.14174v3","149":"http:\/\/export.arxiv.org\/pdf\/2105.10396v2","150":"http:\/\/export.arxiv.org\/pdf\/2112.11494v1","151":"http:\/\/export.arxiv.org\/pdf\/2112.11471v1","152":"http:\/\/export.arxiv.org\/pdf\/2112.11391v1","153":"http:\/\/export.arxiv.org\/pdf\/2112.11389v1","154":"http:\/\/export.arxiv.org\/pdf\/2112.12262v1","155":"http:\/\/export.arxiv.org\/pdf\/2010.08197v2","156":"http:\/\/export.arxiv.org\/pdf\/2201.00693v1","157":"http:\/\/export.arxiv.org\/pdf\/2110.04217v2","158":"http:\/\/export.arxiv.org\/pdf\/2112.11241v1","159":"http:\/\/export.arxiv.org\/pdf\/2112.11176v1","160":"http:\/\/export.arxiv.org\/pdf\/2112.11070v1","161":"http:\/\/export.arxiv.org\/pdf\/2109.06050v2","162":"http:\/\/export.arxiv.org\/pdf\/2112.11031v1","163":"http:\/\/export.arxiv.org\/pdf\/2112.10991v1","164":"http:\/\/export.arxiv.org\/pdf\/2110.04913v2","165":"http:\/\/export.arxiv.org\/pdf\/2104.03934v2","166":"http:\/\/export.arxiv.org\/pdf\/2112.10936v1","167":"http:\/\/export.arxiv.org\/pdf\/2110.14207v2","168":"http:\/\/export.arxiv.org\/pdf\/2112.10925v1","169":"http:\/\/export.arxiv.org\/pdf\/2105.02486v2","170":"http:\/\/export.arxiv.org\/pdf\/2112.10746v1","171":"http:\/\/export.arxiv.org\/pdf\/2112.10684v1","172":"http:\/\/export.arxiv.org\/pdf\/2112.10668v1","173":"http:\/\/export.arxiv.org\/pdf\/2112.00712v2","174":"http:\/\/export.arxiv.org\/pdf\/2012.07499v4","175":"http:\/\/export.arxiv.org\/pdf\/2109.13510v2","176":"http:\/\/export.arxiv.org\/pdf\/2112.10553v1","177":"http:\/\/export.arxiv.org\/pdf\/2112.10543v1","178":"http:\/\/export.arxiv.org\/pdf\/2112.10508v1","179":"http:\/\/export.arxiv.org\/pdf\/2008.09943v3","180":"http:\/\/export.arxiv.org\/pdf\/2112.10424v1","181":"http:\/\/export.arxiv.org\/pdf\/2112.10360v1","182":"http:\/\/export.arxiv.org\/pdf\/2112.10322v1","183":"http:\/\/export.arxiv.org\/pdf\/2112.10202v1","184":"http:\/\/export.arxiv.org\/pdf\/2112.10189v1","185":"http:\/\/export.arxiv.org\/pdf\/2112.10123v1","186":"http:\/\/export.arxiv.org\/pdf\/2112.10108v1","187":"http:\/\/export.arxiv.org\/pdf\/2112.10070v1","188":"http:\/\/export.arxiv.org\/pdf\/2112.10064v1","189":"http:\/\/export.arxiv.org\/pdf\/2201.02510v1","190":"http:\/\/export.arxiv.org\/pdf\/2110.02950v2","191":"http:\/\/export.arxiv.org\/pdf\/2112.10021v1","192":"http:\/\/export.arxiv.org\/pdf\/2112.09986v1","193":"http:\/\/export.arxiv.org\/pdf\/2112.09939v1","194":"http:\/\/export.arxiv.org\/pdf\/2112.09925v1","195":"http:\/\/export.arxiv.org\/pdf\/2112.09924v1","196":"http:\/\/export.arxiv.org\/pdf\/2112.05328v3","197":"http:\/\/export.arxiv.org\/pdf\/2112.09866v1","198":"http:\/\/export.arxiv.org\/pdf\/2112.09860v1","199":"http:\/\/export.arxiv.org\/pdf\/2109.07140v2","200":"http:\/\/export.arxiv.org\/pdf\/2105.11905v2","201":"http:\/\/export.arxiv.org\/pdf\/2112.09841v1","202":"http:\/\/export.arxiv.org\/pdf\/2201.02740v1","203":"http:\/\/export.arxiv.org\/pdf\/2106.07176v3","204":"http:\/\/export.arxiv.org\/pdf\/2112.09742v1","205":"http:\/\/export.arxiv.org\/pdf\/2112.09669v1","206":"http:\/\/export.arxiv.org\/pdf\/2009.02835v3","207":"http:\/\/export.arxiv.org\/pdf\/2112.09658v1","208":"http:\/\/export.arxiv.org\/pdf\/2106.07340v4","209":"http:\/\/export.arxiv.org\/pdf\/2112.09628v1","210":"http:\/\/export.arxiv.org\/pdf\/2201.03445v1","211":"http:\/\/export.arxiv.org\/pdf\/2112.09600v1","212":"http:\/\/export.arxiv.org\/pdf\/2112.10609v1","213":"http:\/\/export.arxiv.org\/pdf\/2108.13327v3","214":"http:\/\/export.arxiv.org\/pdf\/2112.09526v1","215":"http:\/\/export.arxiv.org\/pdf\/2112.09488v1","216":"http:\/\/export.arxiv.org\/pdf\/2112.09467v1","217":"http:\/\/export.arxiv.org\/pdf\/2112.08754v2","218":"http:\/\/export.arxiv.org\/pdf\/2112.07421v2","219":"http:\/\/export.arxiv.org\/pdf\/2112.08098v2","220":"http:\/\/export.arxiv.org\/pdf\/2111.05068v2","221":"http:\/\/export.arxiv.org\/pdf\/2112.09348v1","222":"http:\/\/export.arxiv.org\/pdf\/2010.16143v3","223":"http:\/\/export.arxiv.org\/pdf\/2112.09340v1","224":"http:\/\/export.arxiv.org\/pdf\/2012.00893v2","225":"http:\/\/export.arxiv.org\/pdf\/2112.09301v1","226":"http:\/\/export.arxiv.org\/pdf\/2102.04081v3","227":"http:\/\/export.arxiv.org\/pdf\/2112.09288v1","228":"http:\/\/export.arxiv.org\/pdf\/2112.09231v1","229":"http:\/\/export.arxiv.org\/pdf\/2011.00416v5","230":"http:\/\/export.arxiv.org\/pdf\/2112.09215v1","231":"http:\/\/export.arxiv.org\/pdf\/2104.08444v2","232":"http:\/\/export.arxiv.org\/pdf\/1902.06689v2","233":"http:\/\/export.arxiv.org\/pdf\/2112.07392v2","234":"http:\/\/export.arxiv.org\/pdf\/2112.07391v2","235":"http:\/\/export.arxiv.org\/pdf\/2112.09153v1","236":"http:\/\/export.arxiv.org\/pdf\/2112.09118v1","237":"http:\/\/export.arxiv.org\/pdf\/2010.05953v2","238":"http:\/\/export.arxiv.org\/pdf\/2111.09296v3","239":"http:\/\/export.arxiv.org\/pdf\/2112.09097v1","240":"http:\/\/export.arxiv.org\/pdf\/2101.04255v6","241":"http:\/\/export.arxiv.org\/pdf\/2112.09062v1","242":"http:\/\/export.arxiv.org\/pdf\/2112.09054v1","243":"http:\/\/export.arxiv.org\/pdf\/2108.00946v2","244":"http:\/\/export.arxiv.org\/pdf\/2112.08918v1","245":"http:\/\/export.arxiv.org\/pdf\/2112.08910v1","246":"http:\/\/export.arxiv.org\/pdf\/2112.08907v1","247":"http:\/\/export.arxiv.org\/pdf\/2107.13377v3","248":"http:\/\/export.arxiv.org\/pdf\/2111.09749v2","249":"http:\/\/export.arxiv.org\/pdf\/2112.08844v1","250":"http:\/\/export.arxiv.org\/pdf\/2112.08808v1","251":"http:\/\/export.arxiv.org\/pdf\/2112.08804v1","252":"http:\/\/export.arxiv.org\/pdf\/2112.08789v1","253":"http:\/\/export.arxiv.org\/pdf\/2112.08778v1","254":"http:\/\/export.arxiv.org\/pdf\/2112.08770v1","255":"http:\/\/export.arxiv.org\/pdf\/2112.11916v1","256":"http:\/\/export.arxiv.org\/pdf\/2112.08735v1","257":"http:\/\/export.arxiv.org\/pdf\/2112.08726v1","258":"http:\/\/export.arxiv.org\/pdf\/2112.08723v1","259":"http:\/\/export.arxiv.org\/pdf\/2112.08713v1","260":"http:\/\/export.arxiv.org\/pdf\/2112.08696v1","261":"http:\/\/export.arxiv.org\/pdf\/2112.08692v1","262":"http:\/\/export.arxiv.org\/pdf\/2112.08688v1","263":"http:\/\/export.arxiv.org\/pdf\/2112.08670v1","264":"http:\/\/export.arxiv.org\/pdf\/2112.08663v1","265":"http:\/\/export.arxiv.org\/pdf\/2112.08657v1","266":"http:\/\/export.arxiv.org\/pdf\/2112.08653v1","267":"http:\/\/export.arxiv.org\/pdf\/2112.08652v1","268":"http:\/\/export.arxiv.org\/pdf\/2112.01488v2","269":"http:\/\/export.arxiv.org\/pdf\/2112.08634v1","270":"http:\/\/export.arxiv.org\/pdf\/2010.12723v2","271":"http:\/\/export.arxiv.org\/pdf\/2112.08616v1","272":"http:\/\/export.arxiv.org\/pdf\/2112.08609v1","273":"http:\/\/export.arxiv.org\/pdf\/2112.08608v1","274":"http:\/\/export.arxiv.org\/pdf\/2112.08596v1","275":"http:\/\/export.arxiv.org\/pdf\/2012.05395v5","276":"http:\/\/export.arxiv.org\/pdf\/2112.08593v1","277":"http:\/\/export.arxiv.org\/pdf\/2112.08592v1","278":"http:\/\/export.arxiv.org\/pdf\/2112.09738v1","279":"http:\/\/export.arxiv.org\/pdf\/2112.08587v1","280":"http:\/\/export.arxiv.org\/pdf\/2112.08583v1","281":"http:\/\/export.arxiv.org\/pdf\/2112.08578v1","282":"http:\/\/export.arxiv.org\/pdf\/2112.08570v1","283":"http:\/\/export.arxiv.org\/pdf\/2112.12072v1","284":"http:\/\/export.arxiv.org\/pdf\/2112.08560v1","285":"http:\/\/export.arxiv.org\/pdf\/2112.08554v1","286":"http:\/\/export.arxiv.org\/pdf\/2112.08550v1","287":"http:\/\/export.arxiv.org\/pdf\/2112.08548v1","288":"http:\/\/export.arxiv.org\/pdf\/2112.08547v1","289":"http:\/\/export.arxiv.org\/pdf\/2103.10918v2","290":"http:\/\/export.arxiv.org\/pdf\/2112.10613v1","291":"http:\/\/export.arxiv.org\/pdf\/2112.11913v1","292":"http:\/\/export.arxiv.org\/pdf\/2112.08532v1","293":"http:\/\/export.arxiv.org\/pdf\/2112.08491v1","294":"http:\/\/export.arxiv.org\/pdf\/2111.14709v2","295":"http:\/\/export.arxiv.org\/pdf\/2102.01223v2","296":"http:\/\/export.arxiv.org\/pdf\/2004.14120v2","297":"http:\/\/export.arxiv.org\/pdf\/2112.08470v1","298":"http:\/\/export.arxiv.org\/pdf\/2112.08462v1","299":"http:\/\/export.arxiv.org\/pdf\/2112.11915v1","300":"http:\/\/export.arxiv.org\/pdf\/2112.08414v1","301":"http:\/\/export.arxiv.org\/pdf\/2112.08357v1","302":"http:\/\/export.arxiv.org\/pdf\/2112.08351v1","303":"http:\/\/export.arxiv.org\/pdf\/2112.08346v1","304":"http:\/\/export.arxiv.org\/pdf\/2112.08342v1","305":"http:\/\/export.arxiv.org\/pdf\/2109.01156v2","306":"http:\/\/export.arxiv.org\/pdf\/2112.08333v1","307":"http:\/\/export.arxiv.org\/pdf\/2112.08327v1","308":"http:\/\/export.arxiv.org\/pdf\/2112.08321v1","309":"http:\/\/export.arxiv.org\/pdf\/2112.08289v1","310":"http:\/\/export.arxiv.org\/pdf\/2112.08266v1","311":"http:\/\/export.arxiv.org\/pdf\/2111.10776v2","312":"http:\/\/export.arxiv.org\/pdf\/2112.08261v1","313":"http:\/\/export.arxiv.org\/pdf\/2112.08256v1","314":"http:\/\/export.arxiv.org\/pdf\/2107.02794v2","315":"http:\/\/export.arxiv.org\/pdf\/2008.05449v3","316":"http:\/\/export.arxiv.org\/pdf\/2107.10941v2","317":"http:\/\/export.arxiv.org\/pdf\/2112.08191v1","318":"http:\/\/export.arxiv.org\/pdf\/2111.03470v2","319":"http:\/\/export.arxiv.org\/pdf\/2112.08159v1","320":"http:\/\/export.arxiv.org\/pdf\/2112.08152v1","321":"http:\/\/export.arxiv.org\/pdf\/2112.08140v1","322":"http:\/\/export.arxiv.org\/pdf\/2112.11914v1","323":"http:\/\/export.arxiv.org\/pdf\/2111.00086v4","324":"http:\/\/export.arxiv.org\/pdf\/2111.00107v3","325":"http:\/\/export.arxiv.org\/pdf\/2112.08087v1","326":"http:\/\/export.arxiv.org\/pdf\/2107.01275v2","327":"http:\/\/export.arxiv.org\/pdf\/2112.08033v1","328":"http:\/\/export.arxiv.org\/pdf\/2112.07985v1","329":"http:\/\/export.arxiv.org\/pdf\/2112.07940v1","330":"http:\/\/export.arxiv.org\/pdf\/2104.08728v2","331":"http:\/\/export.arxiv.org\/pdf\/2112.07924v1","332":"http:\/\/export.arxiv.org\/pdf\/2112.05587v2","333":"http:\/\/export.arxiv.org\/pdf\/2112.07899v1","334":"http:\/\/export.arxiv.org\/pdf\/2112.07888v1","335":"http:\/\/export.arxiv.org\/pdf\/2112.07887v1","336":"http:\/\/export.arxiv.org\/pdf\/2112.07882v1","337":"http:\/\/export.arxiv.org\/pdf\/2112.07877v1","338":"http:\/\/export.arxiv.org\/pdf\/2112.07874v1","339":"http:\/\/export.arxiv.org\/pdf\/2112.07873v1","340":"http:\/\/export.arxiv.org\/pdf\/2112.07870v1","341":"http:\/\/export.arxiv.org\/pdf\/2112.07869v1","342":"http:\/\/export.arxiv.org\/pdf\/2112.07783v1","343":"http:\/\/export.arxiv.org\/pdf\/2104.11832v2","344":"http:\/\/export.arxiv.org\/pdf\/2112.07772v1","345":"http:\/\/export.arxiv.org\/pdf\/2112.07771v1","346":"http:\/\/export.arxiv.org\/pdf\/2112.11207v1","347":"http:\/\/export.arxiv.org\/pdf\/2112.07742v1","348":"http:\/\/export.arxiv.org\/pdf\/2112.07711v1","349":"http:\/\/export.arxiv.org\/pdf\/2112.07708v1","350":"http:\/\/export.arxiv.org\/pdf\/2109.06827v2","351":"http:\/\/export.arxiv.org\/pdf\/2104.05240v2","352":"http:\/\/export.arxiv.org\/pdf\/2112.07648v1","353":"http:\/\/export.arxiv.org\/pdf\/2112.11911v1","354":"http:\/\/export.arxiv.org\/pdf\/1910.09909v5","355":"http:\/\/export.arxiv.org\/pdf\/2105.06813v4","356":"http:\/\/export.arxiv.org\/pdf\/2112.07536v1","357":"http:\/\/export.arxiv.org\/pdf\/2108.10949v2","358":"http:\/\/export.arxiv.org\/pdf\/2112.07515v1","359":"http:\/\/export.arxiv.org\/pdf\/2112.07497v1","360":"http:\/\/export.arxiv.org\/pdf\/2112.07447v1","361":"http:\/\/export.arxiv.org\/pdf\/2112.07443v1","362":"http:\/\/export.arxiv.org\/pdf\/2112.07434v1","363":"http:\/\/export.arxiv.org\/pdf\/2112.07384v1","364":"http:\/\/export.arxiv.org\/pdf\/2112.07381v1","365":"http:\/\/export.arxiv.org\/pdf\/2112.01922v2","366":"http:\/\/export.arxiv.org\/pdf\/2112.07337v1","367":"http:\/\/export.arxiv.org\/pdf\/2112.07327v1","368":"http:\/\/export.arxiv.org\/pdf\/2112.07308v1","369":"http:\/\/export.arxiv.org\/pdf\/2112.07259v1","370":"http:\/\/export.arxiv.org\/pdf\/2112.07254v1","371":"http:\/\/export.arxiv.org\/pdf\/2112.07198v1","372":"http:\/\/export.arxiv.org\/pdf\/2108.08877v3","373":"http:\/\/export.arxiv.org\/pdf\/2011.08772v3","374":"http:\/\/export.arxiv.org\/pdf\/2112.07165v1","375":"http:\/\/export.arxiv.org\/pdf\/2112.06494v2","376":"http:\/\/export.arxiv.org\/pdf\/2109.11136v3","377":"http:\/\/export.arxiv.org\/pdf\/2104.12114v2","378":"http:\/\/export.arxiv.org\/pdf\/2103.12248v3","379":"http:\/\/export.arxiv.org\/pdf\/2112.07089v1","380":"http:\/\/export.arxiv.org\/pdf\/2104.14781v2","381":"http:\/\/export.arxiv.org\/pdf\/2112.11483v1","382":"http:\/\/export.arxiv.org\/pdf\/2112.07055v1","383":"http:\/\/export.arxiv.org\/pdf\/2112.07035v1","384":"http:\/\/export.arxiv.org\/pdf\/2112.07011v1","385":"http:\/\/export.arxiv.org\/pdf\/2112.06953v1","386":"http:\/\/export.arxiv.org\/pdf\/2112.06905v1","387":"http:\/\/export.arxiv.org\/pdf\/2112.06888v1","388":"http:\/\/export.arxiv.org\/pdf\/2104.01791v2","389":"http:\/\/export.arxiv.org\/pdf\/2112.06837v1","390":"http:\/\/export.arxiv.org\/pdf\/2112.06776v1","391":"http:\/\/export.arxiv.org\/pdf\/2112.06748v1","392":"http:\/\/export.arxiv.org\/pdf\/2112.06743v1","393":"http:\/\/export.arxiv.org\/pdf\/2112.06736v1","394":"http:\/\/export.arxiv.org\/pdf\/2112.06924v1","395":"http:\/\/export.arxiv.org\/pdf\/2112.06724v1","396":"http:\/\/export.arxiv.org\/pdf\/2112.06723v1","397":"http:\/\/export.arxiv.org\/pdf\/2109.07943v2","398":"http:\/\/export.arxiv.org\/pdf\/2112.06603v1","399":"http:\/\/export.arxiv.org\/pdf\/2112.11482v1","400":"http:\/\/export.arxiv.org\/pdf\/2112.06540v1","401":"http:\/\/export.arxiv.org\/pdf\/2112.11481v1","402":"http:\/\/export.arxiv.org\/pdf\/2112.06507v1","403":"http:\/\/export.arxiv.org\/pdf\/2110.02001v2","404":"http:\/\/export.arxiv.org\/pdf\/2112.05662v2","405":"http:\/\/export.arxiv.org\/pdf\/2112.11480v1","406":"http:\/\/export.arxiv.org\/pdf\/2112.06462v1","407":"http:\/\/export.arxiv.org\/pdf\/2112.06448v1","408":"http:\/\/export.arxiv.org\/pdf\/2111.02643v5","409":"http:\/\/export.arxiv.org\/pdf\/2012.01775v2","410":"http:\/\/export.arxiv.org\/pdf\/2112.06412v1","411":"http:\/\/export.arxiv.org\/pdf\/2112.07622v1","412":"http:\/\/export.arxiv.org\/pdf\/2112.06370v1","413":"http:\/\/export.arxiv.org\/pdf\/2112.06346v1","414":"http:\/\/export.arxiv.org\/pdf\/2112.06331v1","415":"http:\/\/export.arxiv.org\/pdf\/2112.06327v1","416":"http:\/\/export.arxiv.org\/pdf\/2112.06310v1","417":"http:\/\/export.arxiv.org\/pdf\/2112.06309v1","418":"http:\/\/export.arxiv.org\/pdf\/2112.06295v1","419":"http:\/\/export.arxiv.org\/pdf\/2112.06240v1","420":"http:\/\/export.arxiv.org\/pdf\/2112.06204v1","421":"http:\/\/export.arxiv.org\/pdf\/2112.06199v1","422":"http:\/\/export.arxiv.org\/pdf\/2112.06196v1","423":"http:\/\/export.arxiv.org\/pdf\/2112.06166v1","424":"http:\/\/export.arxiv.org\/pdf\/2112.06135v1","425":"http:\/\/export.arxiv.org\/pdf\/2112.06109v1","426":"http:\/\/export.arxiv.org\/pdf\/2106.13876v2","427":"http:\/\/export.arxiv.org\/pdf\/2006.11405v2","428":"http:\/\/export.arxiv.org\/pdf\/2111.12783v2","429":"http:\/\/export.arxiv.org\/pdf\/2111.14192v2","430":"http:\/\/export.arxiv.org\/pdf\/2112.06013v1","431":"http:\/\/export.arxiv.org\/pdf\/2010.16021v3","432":"http:\/\/export.arxiv.org\/pdf\/2112.05973v1","433":"http:\/\/export.arxiv.org\/pdf\/2112.04796v2","434":"http:\/\/export.arxiv.org\/pdf\/2112.05910v1","435":"http:\/\/export.arxiv.org\/pdf\/2106.09898v2","436":"http:\/\/export.arxiv.org\/pdf\/2112.05785v1","437":"http:\/\/export.arxiv.org\/pdf\/2112.05843v1","438":"http:\/\/export.arxiv.org\/pdf\/2112.05842v1","439":"http:\/\/export.arxiv.org\/pdf\/2104.15135v3","440":"http:\/\/export.arxiv.org\/pdf\/2112.05826v1","441":"http:\/\/export.arxiv.org\/pdf\/2112.11479v1","442":"http:\/\/export.arxiv.org\/pdf\/2112.11478v1","443":"http:\/\/export.arxiv.org\/pdf\/2112.05807v1","444":"http:\/\/export.arxiv.org\/pdf\/2110.06961v2","445":"http:\/\/export.arxiv.org\/pdf\/2112.05717v1","446":"http:\/\/export.arxiv.org\/pdf\/2112.05705v1","447":"http:\/\/export.arxiv.org\/pdf\/2112.05702v1","448":"http:\/\/export.arxiv.org\/pdf\/2109.12104v2","449":"http:\/\/export.arxiv.org\/pdf\/2112.05647v1","450":"http:\/\/export.arxiv.org\/pdf\/2112.05596v1","451":"http:\/\/export.arxiv.org\/pdf\/2112.05555v1","452":"http:\/\/export.arxiv.org\/pdf\/2112.05459v1","453":"http:\/\/export.arxiv.org\/pdf\/2112.05452v1","454":"http:\/\/export.arxiv.org\/pdf\/2112.05438v1","455":"http:\/\/export.arxiv.org\/pdf\/2112.05419v1","456":"http:\/\/export.arxiv.org\/pdf\/2112.05364v1","457":"http:\/\/export.arxiv.org\/pdf\/2112.05359v1","458":"http:\/\/export.arxiv.org\/pdf\/2103.04399v2","459":"http:\/\/export.arxiv.org\/pdf\/2112.05346v1","460":"http:\/\/export.arxiv.org\/pdf\/2112.05256v1","461":"http:\/\/export.arxiv.org\/pdf\/2112.05253v1","462":"http:\/\/export.arxiv.org\/pdf\/2110.07096v2","463":"http:\/\/export.arxiv.org\/pdf\/2010.12675v3","464":"http:\/\/export.arxiv.org\/pdf\/2104.08211v3","465":"http:\/\/export.arxiv.org\/pdf\/2112.00861v3","466":"http:\/\/export.arxiv.org\/pdf\/2112.05209v1","467":"http:\/\/export.arxiv.org\/pdf\/2110.04169v2","468":"http:\/\/export.arxiv.org\/pdf\/2112.05197v1","469":"http:\/\/export.arxiv.org\/pdf\/2112.05194v1","470":"http:\/\/export.arxiv.org\/pdf\/2112.05136v1","471":"http:\/\/export.arxiv.org\/pdf\/2112.05125v1","472":"http:\/\/export.arxiv.org\/pdf\/2112.05056v1","473":"http:\/\/export.arxiv.org\/pdf\/2112.04999v1","474":"http:\/\/export.arxiv.org\/pdf\/2112.04971v1","475":"http:\/\/export.arxiv.org\/pdf\/2112.04928v1","476":"http:\/\/export.arxiv.org\/pdf\/2112.01332v2","477":"http:\/\/export.arxiv.org\/pdf\/2112.04888v1","478":"http:\/\/export.arxiv.org\/pdf\/2112.04886v1","479":"http:\/\/export.arxiv.org\/pdf\/2112.04873v1","480":"http:\/\/export.arxiv.org\/pdf\/2112.04871v1","481":"http:\/\/export.arxiv.org\/pdf\/2108.01204v2","482":"http:\/\/export.arxiv.org\/pdf\/2112.04831v1","483":"http:\/\/export.arxiv.org\/pdf\/2012.13577v2","484":"http:\/\/export.arxiv.org\/pdf\/2106.01040v3","485":"http:\/\/export.arxiv.org\/pdf\/2103.02895v2","486":"http:\/\/export.arxiv.org\/pdf\/2112.04803v1","487":"http:\/\/export.arxiv.org\/pdf\/2111.14301v2","488":"http:\/\/export.arxiv.org\/pdf\/2111.14306v3","489":"http:\/\/export.arxiv.org\/pdf\/2112.12572v1","490":"http:\/\/export.arxiv.org\/pdf\/2112.03562v2","491":"http:\/\/export.arxiv.org\/pdf\/2008.12552v3","492":"http:\/\/export.arxiv.org\/pdf\/2112.04138v2","493":"http:\/\/export.arxiv.org\/pdf\/2112.03807v3","494":"http:\/\/export.arxiv.org\/pdf\/2011.04843v3","495":"http:\/\/export.arxiv.org\/pdf\/2109.08796v3","496":"http:\/\/export.arxiv.org\/pdf\/2112.04630v1","497":"http:\/\/export.arxiv.org\/pdf\/2102.08138v2","498":"http:\/\/export.arxiv.org\/pdf\/2111.09543v2","499":"http:\/\/export.arxiv.org\/pdf\/2112.01476v2","500":"http:\/\/export.arxiv.org\/pdf\/2112.04539v1","501":"http:\/\/export.arxiv.org\/pdf\/2112.04478v1","502":"http:\/\/export.arxiv.org\/pdf\/2112.04453v1","503":"http:\/\/export.arxiv.org\/pdf\/2112.04446v1","504":"http:\/\/export.arxiv.org\/pdf\/2112.04359v1","505":"http:\/\/export.arxiv.org\/pdf\/2112.04344v1","506":"http:\/\/export.arxiv.org\/pdf\/2109.05327v2","507":"http:\/\/export.arxiv.org\/pdf\/2108.13659v2","508":"http:\/\/export.arxiv.org\/pdf\/2108.10274v2","509":"http:\/\/export.arxiv.org\/pdf\/2112.03227v2","510":"http:\/\/export.arxiv.org\/pdf\/2112.04189v1","511":"http:\/\/export.arxiv.org\/pdf\/2109.13871v3","512":"http:\/\/export.arxiv.org\/pdf\/2112.04184v1","513":"http:\/\/export.arxiv.org\/pdf\/2112.04154v1","514":"http:\/\/export.arxiv.org\/pdf\/2112.04151v1","515":"http:\/\/export.arxiv.org\/pdf\/2112.04139v1","516":"http:\/\/export.arxiv.org\/pdf\/2109.09991v2","517":"http:\/\/export.arxiv.org\/pdf\/2112.04126v1","518":"http:\/\/export.arxiv.org\/pdf\/2112.04104v1","519":"http:\/\/export.arxiv.org\/pdf\/2108.02866v2","520":"http:\/\/export.arxiv.org\/pdf\/2109.08129v2","521":"http:\/\/export.arxiv.org\/pdf\/2112.05780v1","522":"http:\/\/export.arxiv.org\/pdf\/2112.04008v1","523":"http:\/\/export.arxiv.org\/pdf\/2112.03984v1","524":"http:\/\/export.arxiv.org\/pdf\/2102.12060v4","525":"http:\/\/export.arxiv.org\/pdf\/2112.03868v1","526":"http:\/\/export.arxiv.org\/pdf\/2112.03858v1","527":"http:\/\/export.arxiv.org\/pdf\/2112.03857v1","528":"http:\/\/export.arxiv.org\/pdf\/2112.03849v1","529":"http:\/\/export.arxiv.org\/pdf\/2112.03808v1","530":"http:\/\/export.arxiv.org\/pdf\/2108.07435v2","531":"http:\/\/export.arxiv.org\/pdf\/2112.03799v1","532":"http:\/\/export.arxiv.org\/pdf\/2112.03737v1","533":"http:\/\/export.arxiv.org\/pdf\/2110.02852v4","534":"http:\/\/export.arxiv.org\/pdf\/2112.03634v1","535":"http:\/\/export.arxiv.org\/pdf\/2112.03625v1","536":"http:\/\/export.arxiv.org\/pdf\/2112.02557v2","537":"http:\/\/export.arxiv.org\/pdf\/2112.03588v1","538":"http:\/\/export.arxiv.org\/pdf\/2109.07263v2","539":"http:\/\/export.arxiv.org\/pdf\/2112.03572v1","540":"http:\/\/export.arxiv.org\/pdf\/2112.01037v2","541":"http:\/\/export.arxiv.org\/pdf\/2112.03557v1","542":"http:\/\/export.arxiv.org\/pdf\/2107.02192v3","543":"http:\/\/export.arxiv.org\/pdf\/2112.03529v1","544":"http:\/\/export.arxiv.org\/pdf\/2112.03521v1","545":"http:\/\/export.arxiv.org\/pdf\/2006.00452v3","546":"http:\/\/export.arxiv.org\/pdf\/2012.09090v2","547":"http:\/\/export.arxiv.org\/pdf\/2112.03473v1","548":"http:\/\/export.arxiv.org\/pdf\/2112.03414v1","549":"http:\/\/export.arxiv.org\/pdf\/2112.03256v1","550":"http:\/\/export.arxiv.org\/pdf\/2109.09784v2","551":"http:\/\/export.arxiv.org\/pdf\/2112.03221v1","552":"http:\/\/export.arxiv.org\/pdf\/2110.02311v2","553":"http:\/\/export.arxiv.org\/pdf\/2112.03213v1","554":"http:\/\/export.arxiv.org\/pdf\/2107.11879v2","555":"http:\/\/export.arxiv.org\/pdf\/2112.03162v1","556":"http:\/\/export.arxiv.org\/pdf\/2112.03154v1","557":"http:\/\/export.arxiv.org\/pdf\/2104.08219v2","558":"http:\/\/export.arxiv.org\/pdf\/2112.03099v1","559":"http:\/\/export.arxiv.org\/pdf\/2110.01509v2","560":"http:\/\/export.arxiv.org\/pdf\/2112.03052v1","561":"http:\/\/export.arxiv.org\/pdf\/2109.05739v2","562":"http:\/\/export.arxiv.org\/pdf\/2112.02970v1","563":"http:\/\/export.arxiv.org\/pdf\/2112.05277v1","564":"http:\/\/export.arxiv.org\/pdf\/2112.02889v1","565":"http:\/\/export.arxiv.org\/pdf\/2112.01624v2","566":"http:\/\/export.arxiv.org\/pdf\/2010.02665v2","567":"http:\/\/export.arxiv.org\/pdf\/2112.02770v1","568":"http:\/\/export.arxiv.org\/pdf\/2112.03271v1","569":"http:\/\/export.arxiv.org\/pdf\/2112.02741v1","570":"http:\/\/export.arxiv.org\/pdf\/2108.07909v3","571":"http:\/\/export.arxiv.org\/pdf\/2112.02721v1","572":"http:\/\/export.arxiv.org\/pdf\/2112.02714v1","573":"http:\/\/export.arxiv.org\/pdf\/2112.02706v1","574":"http:\/\/export.arxiv.org\/pdf\/2112.02701v1","575":"http:\/\/export.arxiv.org\/pdf\/2104.10726v3","576":"http:\/\/export.arxiv.org\/pdf\/2112.02650v1","577":"http:\/\/export.arxiv.org\/pdf\/2112.02611v1","578":"http:\/\/export.arxiv.org\/pdf\/2112.02607v1","579":"http:\/\/export.arxiv.org\/pdf\/2108.04616v2","580":"http:\/\/export.arxiv.org\/pdf\/2112.02512v1","581":"http:\/\/export.arxiv.org\/pdf\/2112.02505v1","582":"http:\/\/export.arxiv.org\/pdf\/2011.13354v4","583":"http:\/\/export.arxiv.org\/pdf\/2112.13910v1","584":"http:\/\/export.arxiv.org\/pdf\/2112.06642v1","585":"http:\/\/export.arxiv.org\/pdf\/2106.05346v2","586":"http:\/\/export.arxiv.org\/pdf\/2112.02399v1","587":"http:\/\/export.arxiv.org\/pdf\/2109.08900v2","588":"http:\/\/export.arxiv.org\/pdf\/2112.02325v1","589":"http:\/\/export.arxiv.org\/pdf\/2112.02265v1","590":"http:\/\/export.arxiv.org\/pdf\/2112.02246v1","591":"http:\/\/export.arxiv.org\/pdf\/2112.02212v1","592":"http:\/\/export.arxiv.org\/pdf\/2111.14210v2","593":"http:\/\/export.arxiv.org\/pdf\/2112.02145v1","594":"http:\/\/export.arxiv.org\/pdf\/2107.08661v4","595":"http:\/\/export.arxiv.org\/pdf\/2009.05160v4","596":"http:\/\/export.arxiv.org\/pdf\/2012.08789v2","597":"http:\/\/export.arxiv.org\/pdf\/2112.01989v1","598":"http:\/\/export.arxiv.org\/pdf\/2109.02102v3","599":"http:\/\/export.arxiv.org\/pdf\/2109.09796v2","600":"http:\/\/export.arxiv.org\/pdf\/2112.01959v1","601":"http:\/\/export.arxiv.org\/pdf\/2112.01938v1","602":"http:\/\/export.arxiv.org\/pdf\/2101.00146v3","603":"http:\/\/export.arxiv.org\/pdf\/2112.01902v1","604":"http:\/\/export.arxiv.org\/pdf\/2112.01898v1","605":"http:\/\/export.arxiv.org\/pdf\/2102.05980v2","606":"http:\/\/export.arxiv.org\/pdf\/2112.01894v1","607":"http:\/\/export.arxiv.org\/pdf\/2112.01867v1","608":"http:\/\/export.arxiv.org\/pdf\/2110.07603v2","609":"http:\/\/export.arxiv.org\/pdf\/2112.01836v1","610":"http:\/\/export.arxiv.org\/pdf\/2112.01822v1","611":"http:\/\/export.arxiv.org\/pdf\/2112.01810v1","612":"http:\/\/export.arxiv.org\/pdf\/2112.11445v1","613":"http:\/\/export.arxiv.org\/pdf\/2103.09666v3","614":"http:\/\/export.arxiv.org\/pdf\/2112.01764v1","615":"http:\/\/export.arxiv.org\/pdf\/2112.01762v1","616":"http:\/\/export.arxiv.org\/pdf\/2112.01757v1","617":"http:\/\/export.arxiv.org\/pdf\/2111.07074v3","618":"http:\/\/export.arxiv.org\/pdf\/2112.01742v1","619":"http:\/\/export.arxiv.org\/pdf\/2112.01716v1","620":"http:\/\/export.arxiv.org\/pdf\/2112.01707v1","621":"http:\/\/export.arxiv.org\/pdf\/2112.01705v1","622":"http:\/\/export.arxiv.org\/pdf\/2112.01697v1","623":"http:\/\/export.arxiv.org\/pdf\/2112.11444v1","624":"http:\/\/export.arxiv.org\/pdf\/2112.01660v1","625":"http:\/\/export.arxiv.org\/pdf\/2112.01616v1","626":"http:\/\/export.arxiv.org\/pdf\/2112.01591v1","627":"http:\/\/export.arxiv.org\/pdf\/2101.05779v3","628":"http:\/\/export.arxiv.org\/pdf\/2112.01573v1","629":"http:\/\/export.arxiv.org\/pdf\/2104.05857v3","630":"http:\/\/export.arxiv.org\/pdf\/2112.01404v1","631":"http:\/\/export.arxiv.org\/pdf\/2112.01368v1","632":"http:\/\/export.arxiv.org\/pdf\/2009.14539v2","633":"http:\/\/export.arxiv.org\/pdf\/2112.01342v1","634":"http:\/\/export.arxiv.org\/pdf\/2112.01184v1","635":"http:\/\/export.arxiv.org\/pdf\/2112.03033v1","636":"http:\/\/export.arxiv.org\/pdf\/2111.13301v2","637":"http:\/\/export.arxiv.org\/pdf\/2110.02782v2","638":"http:\/\/export.arxiv.org\/pdf\/2112.01073v1","639":"http:\/\/export.arxiv.org\/pdf\/2112.01071v1","640":"http:\/\/export.arxiv.org\/pdf\/2112.01062v1","641":"http:\/\/export.arxiv.org\/pdf\/2111.15182v2","642":"http:\/\/export.arxiv.org\/pdf\/2112.03032v1","643":"http:\/\/export.arxiv.org\/pdf\/2112.01054v1","644":"http:\/\/export.arxiv.org\/pdf\/2112.01048v1","645":"http:\/\/export.arxiv.org\/pdf\/2112.01047v1","646":"http:\/\/export.arxiv.org\/pdf\/2111.15588v3","647":"http:\/\/export.arxiv.org\/pdf\/2112.01040v1","648":"http:\/\/export.arxiv.org\/pdf\/2112.01025v1","649":"http:\/\/export.arxiv.org\/pdf\/2112.01012v1","650":"http:\/\/export.arxiv.org\/pdf\/2111.14110v2","651":"http:\/\/export.arxiv.org\/pdf\/2112.00969v1","652":"http:\/\/export.arxiv.org\/pdf\/2112.00967v1","653":"http:\/\/export.arxiv.org\/pdf\/2112.03025v1","654":"http:\/\/export.arxiv.org\/pdf\/2112.00894v1","655":"http:\/\/export.arxiv.org\/pdf\/2010.12784v2","656":"http:\/\/export.arxiv.org\/pdf\/2105.03075v5","657":"http:\/\/export.arxiv.org\/pdf\/1910.08293v4","658":"http:\/\/export.arxiv.org\/pdf\/2108.06643v2","659":"http:\/\/export.arxiv.org\/pdf\/2112.00819v1","660":"http:\/\/export.arxiv.org\/pdf\/2112.00800v1","661":"http:\/\/export.arxiv.org\/pdf\/2112.00791v1","662":"http:\/\/export.arxiv.org\/pdf\/2112.00590v1","663":"http:\/\/export.arxiv.org\/pdf\/2112.00578v1","664":"http:\/\/export.arxiv.org\/pdf\/2112.03024v1","665":"http:\/\/export.arxiv.org\/pdf\/2112.00567v1","666":"http:\/\/export.arxiv.org\/pdf\/2112.00566v1","667":"http:\/\/export.arxiv.org\/pdf\/2112.00534v1","668":"http:\/\/export.arxiv.org\/pdf\/2102.00405v2","669":"http:\/\/export.arxiv.org\/pdf\/2112.00475v1","670":"http:\/\/export.arxiv.org\/pdf\/2112.00468v1","671":"http:\/\/export.arxiv.org\/pdf\/2105.09045v3","672":"http:\/\/export.arxiv.org\/pdf\/2112.00405v1","673":"http:\/\/export.arxiv.org\/pdf\/2112.00384v1","674":"http:\/\/export.arxiv.org\/pdf\/2112.00350v1","675":"http:\/\/export.arxiv.org\/pdf\/2112.00284v1","676":"http:\/\/export.arxiv.org\/pdf\/2112.00283v1","677":"http:\/\/export.arxiv.org\/pdf\/2110.05717v3","678":"http:\/\/export.arxiv.org\/pdf\/2011.00740v3","679":"http:\/\/export.arxiv.org\/pdf\/2112.00245v1","680":"http:\/\/export.arxiv.org\/pdf\/2112.11442v1","681":"http:\/\/export.arxiv.org\/pdf\/2112.00160v1","682":"http:\/\/export.arxiv.org\/pdf\/2106.12066v2","683":"http:\/\/export.arxiv.org\/pdf\/2107.06912v3","684":"http:\/\/export.arxiv.org\/pdf\/2112.00086v1","685":"http:\/\/export.arxiv.org\/pdf\/2112.04596v1","686":"http:\/\/export.arxiv.org\/pdf\/2103.14785v3","687":"http:\/\/export.arxiv.org\/pdf\/2111.13781v2","688":"http:\/\/export.arxiv.org\/pdf\/2112.04351v1","689":"http:\/\/export.arxiv.org\/pdf\/2111.15641v1","690":"http:\/\/export.arxiv.org\/pdf\/2111.15622v1","691":"http:\/\/export.arxiv.org\/pdf\/2111.15617v1","692":"http:\/\/export.arxiv.org\/pdf\/2105.02570v3","693":"http:\/\/export.arxiv.org\/pdf\/2111.15512v1","694":"http:\/\/export.arxiv.org\/pdf\/2111.07130v2","695":"http:\/\/export.arxiv.org\/pdf\/2003.09166v3","696":"http:\/\/export.arxiv.org\/pdf\/2111.15436v1","697":"http:\/\/export.arxiv.org\/pdf\/2111.15420v1","698":"http:\/\/export.arxiv.org\/pdf\/2111.15417v1","699":"http:\/\/export.arxiv.org\/pdf\/2111.15413v1","700":"http:\/\/export.arxiv.org\/pdf\/2112.00799v1","701":"http:\/\/export.arxiv.org\/pdf\/2111.15322v1","702":"http:\/\/export.arxiv.org\/pdf\/2111.15298v1","703":"http:\/\/export.arxiv.org\/pdf\/2111.15278v1","704":"http:\/\/export.arxiv.org\/pdf\/2112.11441v1","705":"http:\/\/export.arxiv.org\/pdf\/2111.15268v1","706":"http:\/\/export.arxiv.org\/pdf\/2112.00006v1","707":"http:\/\/export.arxiv.org\/pdf\/2111.15166v1","708":"http:\/\/export.arxiv.org\/pdf\/2111.15156v1","709":"http:\/\/export.arxiv.org\/pdf\/2104.07639v4","710":"http:\/\/export.arxiv.org\/pdf\/2111.14106v2","711":"http:\/\/export.arxiv.org\/pdf\/2111.14282v2","712":"http:\/\/export.arxiv.org\/pdf\/2111.15093v1","713":"http:\/\/export.arxiv.org\/pdf\/2111.14188v2","714":"http:\/\/export.arxiv.org\/pdf\/2111.15016v1","715":"http:\/\/export.arxiv.org\/pdf\/2112.11439v1","716":"http:\/\/export.arxiv.org\/pdf\/2111.14988v1","717":"http:\/\/export.arxiv.org\/pdf\/2111.14977v1","718":"http:\/\/export.arxiv.org\/pdf\/2107.09609v2","719":"http:\/\/export.arxiv.org\/pdf\/2111.14730v1","720":"http:\/\/export.arxiv.org\/pdf\/2112.00827v1","721":"http:\/\/export.arxiv.org\/pdf\/2111.14684v1","722":"http:\/\/export.arxiv.org\/pdf\/2103.13272v2","723":"http:\/\/export.arxiv.org\/pdf\/2110.03546v2","724":"http:\/\/export.arxiv.org\/pdf\/2111.14842v1","725":"http:\/\/export.arxiv.org\/pdf\/2108.09119v3","726":"http:\/\/export.arxiv.org\/pdf\/2112.11438v1","727":"http:\/\/export.arxiv.org\/pdf\/2112.11436v1","728":"http:\/\/export.arxiv.org\/pdf\/2111.14445v1","729":"http:\/\/export.arxiv.org\/pdf\/2112.11540v1","730":"http:\/\/export.arxiv.org\/pdf\/2104.05094v3","731":"http:\/\/export.arxiv.org\/pdf\/2111.05948v3","732":"http:\/\/export.arxiv.org\/pdf\/2111.14309v1","733":"http:\/\/export.arxiv.org\/pdf\/2111.14232v1","734":"http:\/\/export.arxiv.org\/pdf\/2107.05612v3","735":"http:\/\/export.arxiv.org\/pdf\/2111.14168v1","736":"http:\/\/export.arxiv.org\/pdf\/2004.14871v2","737":"http:\/\/export.arxiv.org\/pdf\/2107.10637v2","738":"http:\/\/export.arxiv.org\/pdf\/2111.14119v1","739":"http:\/\/export.arxiv.org\/pdf\/2109.04650v2","740":"http:\/\/export.arxiv.org\/pdf\/2111.14094v1","741":"http:\/\/export.arxiv.org\/pdf\/2111.07564v2","742":"http:\/\/export.arxiv.org\/pdf\/2006.05236v2","743":"http:\/\/export.arxiv.org\/pdf\/2111.14083v1","744":"http:\/\/export.arxiv.org\/pdf\/2005.08182v2","745":"http:\/\/export.arxiv.org\/pdf\/2103.12048v3","746":"http:\/\/export.arxiv.org\/pdf\/2111.14066v1","747":"http:\/\/export.arxiv.org\/pdf\/2111.14034v1","748":"http:\/\/export.arxiv.org\/pdf\/2111.14031v1","749":"http:\/\/export.arxiv.org\/pdf\/2108.07790v3","750":"http:\/\/export.arxiv.org\/pdf\/2111.14003v1","751":"http:\/\/export.arxiv.org\/pdf\/2111.13999v1","752":"http:\/\/export.arxiv.org\/pdf\/2111.13993v1","753":"http:\/\/export.arxiv.org\/pdf\/2111.13982v1","754":"http:\/\/export.arxiv.org\/pdf\/2111.14830v1","755":"http:\/\/export.arxiv.org\/pdf\/2111.13974v1","756":"http:\/\/export.arxiv.org\/pdf\/2111.13972v1","757":"http:\/\/export.arxiv.org\/pdf\/2107.13290v3","758":"http:\/\/export.arxiv.org\/pdf\/2007.03834v4","759":"http:\/\/export.arxiv.org\/pdf\/2106.04647v2","760":"http:\/\/export.arxiv.org\/pdf\/2111.13861v1","761":"http:\/\/export.arxiv.org\/pdf\/2109.14934v3","762":"http:\/\/export.arxiv.org\/pdf\/2111.13833v1","763":"http:\/\/export.arxiv.org\/pdf\/2112.05783v1","764":"http:\/\/export.arxiv.org\/pdf\/2111.13726v1","765":"http:\/\/export.arxiv.org\/pdf\/2111.13654v1","766":"http:\/\/export.arxiv.org\/pdf\/2105.05091v2","767":"http:\/\/export.arxiv.org\/pdf\/2111.13611v1","768":"http:\/\/export.arxiv.org\/pdf\/2109.00475v2","769":"http:\/\/export.arxiv.org\/pdf\/2109.02938v2","770":"http:\/\/export.arxiv.org\/pdf\/2106.00218v2","771":"http:\/\/export.arxiv.org\/pdf\/2111.13463v1","772":"http:\/\/export.arxiv.org\/pdf\/2111.13440v1","773":"http:\/\/export.arxiv.org\/pdf\/2112.03073v1","774":"http:\/\/export.arxiv.org\/pdf\/2101.09624v4","775":"http:\/\/export.arxiv.org\/pdf\/2110.03501v2","776":"http:\/\/export.arxiv.org\/pdf\/2012.15671v5","777":"http:\/\/export.arxiv.org\/pdf\/2111.13284v1","778":"http:\/\/export.arxiv.org\/pdf\/2111.13259v1","779":"http:\/\/export.arxiv.org\/pdf\/1910.14084v2","780":"http:\/\/export.arxiv.org\/pdf\/2111.15473v1","781":"http:\/\/export.arxiv.org\/pdf\/2112.03014v1","782":"http:\/\/export.arxiv.org\/pdf\/2111.13138v1","783":"http:\/\/export.arxiv.org\/pdf\/2111.15629v1","784":"http:\/\/export.arxiv.org\/pdf\/2112.02955v1","785":"http:\/\/export.arxiv.org\/pdf\/2112.02097v1","786":"http:\/\/export.arxiv.org\/pdf\/2104.00312v4","787":"http:\/\/export.arxiv.org\/pdf\/2111.12956v1","788":"http:\/\/export.arxiv.org\/pdf\/1906.08101v3","789":"http:\/\/export.arxiv.org\/pdf\/1812.02253v2","790":"http:\/\/export.arxiv.org\/pdf\/2111.10154v2","791":"http:\/\/export.arxiv.org\/pdf\/2102.08633v3","792":"http:\/\/export.arxiv.org\/pdf\/2110.11338v3","793":"http:\/\/export.arxiv.org\/pdf\/2111.11707v2","794":"http:\/\/export.arxiv.org\/pdf\/2111.12802v1","795":"http:\/\/export.arxiv.org\/pdf\/2111.12796v1","796":"http:\/\/export.arxiv.org\/pdf\/2111.12790v1","797":"http:\/\/export.arxiv.org\/pdf\/2111.12763v1","798":"http:\/\/export.arxiv.org\/pdf\/2105.10362v4","799":"http:\/\/export.arxiv.org\/pdf\/2107.11665v2","800":"http:\/\/export.arxiv.org\/pdf\/2108.10218v2","801":"http:\/\/export.arxiv.org\/pdf\/2111.12535v1","802":"http:\/\/export.arxiv.org\/pdf\/2111.12477v1","803":"http:\/\/export.arxiv.org\/pdf\/2009.01826v3","804":"http:\/\/export.arxiv.org\/pdf\/2012.04946v3","805":"http:\/\/export.arxiv.org\/pdf\/2111.12421v1","806":"http:\/\/export.arxiv.org\/pdf\/2109.07346v2","807":"http:\/\/export.arxiv.org\/pdf\/2111.11750v2","808":"http:\/\/export.arxiv.org\/pdf\/2102.08098v3","809":"http:\/\/export.arxiv.org\/pdf\/2111.12317v1","810":"http:\/\/export.arxiv.org\/pdf\/2012.15197v2","811":"http:\/\/export.arxiv.org\/pdf\/2111.12284v1","812":"http:\/\/export.arxiv.org\/pdf\/2108.02446v3","813":"http:\/\/export.arxiv.org\/pdf\/2111.12174v1","814":"http:\/\/export.arxiv.org\/pdf\/2111.12062v1","815":"http:\/\/export.arxiv.org\/pdf\/2111.12061v1","816":"http:\/\/export.arxiv.org\/pdf\/2111.12055v1","817":"http:\/\/export.arxiv.org\/pdf\/2111.12028v1","818":"http:\/\/export.arxiv.org\/pdf\/2106.10328v2","819":"http:\/\/export.arxiv.org\/pdf\/2103.04180v2","820":"http:\/\/export.arxiv.org\/pdf\/2112.00803v1","821":"http:\/\/export.arxiv.org\/pdf\/2109.06327v2","822":"http:\/\/export.arxiv.org\/pdf\/2111.11894v1","823":"http:\/\/export.arxiv.org\/pdf\/2111.11845v1","824":"http:\/\/export.arxiv.org\/pdf\/2111.11831v1","825":"http:\/\/export.arxiv.org\/pdf\/2111.11815v1","826":"http:\/\/export.arxiv.org\/pdf\/2111.11766v1","827":"http:\/\/export.arxiv.org\/pdf\/2111.07158v2","828":"http:\/\/export.arxiv.org\/pdf\/2102.01454v3","829":"http:\/\/export.arxiv.org\/pdf\/2104.12470v4","830":"http:\/\/export.arxiv.org\/pdf\/2104.06486v3","831":"http:\/\/export.arxiv.org\/pdf\/2111.11576v1","832":"http:\/\/export.arxiv.org\/pdf\/2110.03861v3","833":"http:\/\/export.arxiv.org\/pdf\/2111.06799v2","834":"http:\/\/export.arxiv.org\/pdf\/2111.11520v1","835":"http:\/\/export.arxiv.org\/pdf\/2111.11471v1","836":"http:\/\/export.arxiv.org\/pdf\/2111.11431v1","837":"http:\/\/export.arxiv.org\/pdf\/2111.11372v1","838":"http:\/\/export.arxiv.org\/pdf\/2111.11363v1","839":"http:\/\/export.arxiv.org\/pdf\/2111.11331v1","840":"http:\/\/export.arxiv.org\/pdf\/2011.07403v3","841":"http:\/\/export.arxiv.org\/pdf\/2111.11170v1","842":"http:\/\/export.arxiv.org\/pdf\/2111.11159v1","843":"http:\/\/export.arxiv.org\/pdf\/2109.02229v3","844":"http:\/\/export.arxiv.org\/pdf\/2112.03104v1","845":"http:\/\/export.arxiv.org\/pdf\/2111.11104v1","846":"http:\/\/export.arxiv.org\/pdf\/2111.11030v1","847":"http:\/\/export.arxiv.org\/pdf\/2112.03101v1","848":"http:\/\/export.arxiv.org\/pdf\/2111.11023v1","849":"http:\/\/export.arxiv.org\/pdf\/2110.15498v2","850":"http:\/\/export.arxiv.org\/pdf\/2108.05098v2","851":"http:\/\/export.arxiv.org\/pdf\/2103.03335v4","852":"http:\/\/export.arxiv.org\/pdf\/2111.10974v1","853":"http:\/\/export.arxiv.org\/pdf\/2111.10962v1","854":"http:\/\/export.arxiv.org\/pdf\/2111.10957v1","855":"http:\/\/export.arxiv.org\/pdf\/2009.06810v2","856":"http:\/\/export.arxiv.org\/pdf\/2111.10846v1","857":"http:\/\/export.arxiv.org\/pdf\/2112.11185v1","858":"http:\/\/export.arxiv.org\/pdf\/2112.03011v1","859":"http:\/\/export.arxiv.org\/pdf\/2110.09086v3","860":"http:\/\/export.arxiv.org\/pdf\/2111.10756v1","861":"http:\/\/export.arxiv.org\/pdf\/2111.10750v1","862":"http:\/\/export.arxiv.org\/pdf\/2111.10746v1","863":"http:\/\/export.arxiv.org\/pdf\/2111.10692v1","864":"http:\/\/export.arxiv.org\/pdf\/2005.06059v2","865":"http:\/\/export.arxiv.org\/pdf\/2110.01852v2","866":"http:\/\/export.arxiv.org\/pdf\/2109.14350v2","867":"http:\/\/export.arxiv.org\/pdf\/2111.10584v1","868":"http:\/\/export.arxiv.org\/pdf\/2111.09564v2","869":"http:\/\/export.arxiv.org\/pdf\/2111.10513v1","870":"http:\/\/export.arxiv.org\/pdf\/2111.10501v1","871":"http:\/\/export.arxiv.org\/pdf\/2111.10497v1","872":"http:\/\/export.arxiv.org\/pdf\/2112.03009v1","873":"http:\/\/export.arxiv.org\/pdf\/2111.10390v1","874":"http:\/\/export.arxiv.org\/pdf\/2106.14233v2","875":"http:\/\/export.arxiv.org\/pdf\/2010.03001v5","876":"http:\/\/export.arxiv.org\/pdf\/2111.10223v1","877":"http:\/\/export.arxiv.org\/pdf\/2111.00526v2","878":"http:\/\/export.arxiv.org\/pdf\/2111.10177v1","879":"http:\/\/export.arxiv.org\/pdf\/2005.10058v4","880":"http:\/\/export.arxiv.org\/pdf\/2111.10173v1","881":"http:\/\/export.arxiv.org\/pdf\/2111.10168v1","882":"http:\/\/export.arxiv.org\/pdf\/2111.10157v1","883":"http:\/\/export.arxiv.org\/pdf\/2111.10142v1","884":"http:\/\/export.arxiv.org\/pdf\/1909.00204v3","885":"http:\/\/export.arxiv.org\/pdf\/2111.10100v1","886":"http:\/\/export.arxiv.org\/pdf\/2111.10097v1","887":"http:\/\/export.arxiv.org\/pdf\/2109.05115v2","888":"http:\/\/export.arxiv.org\/pdf\/2111.08896v3","889":"http:\/\/export.arxiv.org\/pdf\/2110.15426v2","890":"http:\/\/export.arxiv.org\/pdf\/2012.04207v2","891":"http:\/\/export.arxiv.org\/pdf\/2111.10058v1","892":"http:\/\/export.arxiv.org\/pdf\/2111.10047v1","893":"http:\/\/export.arxiv.org\/pdf\/2104.05596v3","894":"http:\/\/export.arxiv.org\/pdf\/2111.10044v1","895":"http:\/\/export.arxiv.org\/pdf\/2111.09927v1","896":"http:\/\/export.arxiv.org\/pdf\/2011.07126v2","897":"http:\/\/export.arxiv.org\/pdf\/2110.10704v2","898":"http:\/\/export.arxiv.org\/pdf\/2111.09836v1","899":"http:\/\/export.arxiv.org\/pdf\/2111.09811v1","900":"http:\/\/export.arxiv.org\/pdf\/2111.09791v1","901":"http:\/\/export.arxiv.org\/pdf\/2111.09714v1","902":"http:\/\/export.arxiv.org\/pdf\/2111.09029v2","903":"http:\/\/export.arxiv.org\/pdf\/2111.08788v2","904":"http:\/\/export.arxiv.org\/pdf\/1808.08079v3","905":"http:\/\/export.arxiv.org\/pdf\/2112.03007v1","906":"http:\/\/export.arxiv.org\/pdf\/2110.15731v2","907":"http:\/\/export.arxiv.org\/pdf\/2111.09645v1","908":"http:\/\/export.arxiv.org\/pdf\/2111.09634v1","909":"http:\/\/export.arxiv.org\/pdf\/2111.09618v1","910":"http:\/\/export.arxiv.org\/pdf\/2111.09612v1","911":"http:\/\/export.arxiv.org\/pdf\/2111.09574v1","912":"http:\/\/export.arxiv.org\/pdf\/2106.07936v3","913":"http:\/\/export.arxiv.org\/pdf\/2104.08826v2","914":"http:\/\/export.arxiv.org\/pdf\/2109.00648v3","915":"http:\/\/export.arxiv.org\/pdf\/2110.10906v2","916":"http:\/\/export.arxiv.org\/pdf\/2111.09525v1","917":"http:\/\/export.arxiv.org\/pdf\/2111.09509v1","918":"http:\/\/export.arxiv.org\/pdf\/2108.08411v2","919":"http:\/\/export.arxiv.org\/pdf\/2106.07890v2","920":"http:\/\/export.arxiv.org\/pdf\/2110.14168v2","921":"http:\/\/export.arxiv.org\/pdf\/2111.09381v1","922":"http:\/\/export.arxiv.org\/pdf\/2109.06387v2","923":"http:\/\/export.arxiv.org\/pdf\/2111.05825v2","924":"http:\/\/export.arxiv.org\/pdf\/2110.15248v2","925":"http:\/\/export.arxiv.org\/pdf\/2111.09280v1","926":"http:\/\/export.arxiv.org\/pdf\/2111.09276v1","927":"http:\/\/export.arxiv.org\/pdf\/2110.07428v2","928":"http:\/\/export.arxiv.org\/pdf\/2111.15602v1","929":"http:\/\/export.arxiv.org\/pdf\/2111.08647v2","930":"http:\/\/export.arxiv.org\/pdf\/2108.11896v2","931":"http:\/\/export.arxiv.org\/pdf\/2105.06354v2","932":"http:\/\/export.arxiv.org\/pdf\/2110.15225v3","933":"http:\/\/export.arxiv.org\/pdf\/2111.09146v1","934":"http:\/\/export.arxiv.org\/pdf\/2111.09075v1","935":"http:\/\/export.arxiv.org\/pdf\/2111.09064v1","936":"http:\/\/export.arxiv.org\/pdf\/2111.09052v1","937":"http:\/\/export.arxiv.org\/pdf\/2111.09035v1","938":"http:\/\/export.arxiv.org\/pdf\/2106.11148v2","939":"http:\/\/export.arxiv.org\/pdf\/2111.08940v1","940":"http:\/\/export.arxiv.org\/pdf\/2111.08906v1","941":"http:\/\/export.arxiv.org\/pdf\/2108.02314v3","942":"http:\/\/export.arxiv.org\/pdf\/2104.08768v2","943":"http:\/\/export.arxiv.org\/pdf\/2104.01371v3","944":"http:\/\/export.arxiv.org\/pdf\/2111.08723v1","945":"http:\/\/export.arxiv.org\/pdf\/2111.08658v1","946":"http:\/\/export.arxiv.org\/pdf\/2111.08634v1","947":"http:\/\/export.arxiv.org\/pdf\/2109.01135v7","948":"http:\/\/export.arxiv.org\/pdf\/2111.08609v1","949":"http:\/\/export.arxiv.org\/pdf\/2111.08581v1","950":"http:\/\/export.arxiv.org\/pdf\/2111.08546v1","951":"http:\/\/export.arxiv.org\/pdf\/2111.08545v1","952":"http:\/\/export.arxiv.org\/pdf\/2111.08543v1","953":"http:\/\/export.arxiv.org\/pdf\/2111.08529v1","954":"http:\/\/export.arxiv.org\/pdf\/2111.08510v1","955":"http:\/\/export.arxiv.org\/pdf\/2111.08489v1","956":"http:\/\/export.arxiv.org\/pdf\/2111.08465v1","957":"http:\/\/export.arxiv.org\/pdf\/2111.08408v1","958":"http:\/\/export.arxiv.org\/pdf\/2107.03466v2","959":"http:\/\/export.arxiv.org\/pdf\/2110.15317v2","960":"http:\/\/export.arxiv.org\/pdf\/2111.08400v1","961":"http:\/\/export.arxiv.org\/pdf\/2105.03641v2","962":"http:\/\/export.arxiv.org\/pdf\/2109.06515v2","963":"http:\/\/export.arxiv.org\/pdf\/2111.08267v1","964":"http:\/\/export.arxiv.org\/pdf\/2111.08210v1","965":"http:\/\/export.arxiv.org\/pdf\/2111.08201v1","966":"http:\/\/export.arxiv.org\/pdf\/2111.08191v1","967":"http:\/\/export.arxiv.org\/pdf\/2111.08181v1","968":"http:\/\/export.arxiv.org\/pdf\/2111.08171v1","969":"http:\/\/export.arxiv.org\/pdf\/2111.08137v1","970":"http:\/\/export.arxiv.org\/pdf\/2111.08133v1","971":"http:\/\/export.arxiv.org\/pdf\/2111.08088v1","972":"http:\/\/export.arxiv.org\/pdf\/2111.07993v1","973":"http:\/\/export.arxiv.org\/pdf\/2007.15700v3","974":"http:\/\/export.arxiv.org\/pdf\/2110.08226v2","975":"http:\/\/export.arxiv.org\/pdf\/2111.07935v1","976":"http:\/\/export.arxiv.org\/pdf\/2111.07906v1","977":"http:\/\/export.arxiv.org\/pdf\/2111.09155v1","978":"http:\/\/export.arxiv.org\/pdf\/2111.07864v1","979":"http:\/\/export.arxiv.org\/pdf\/2111.07815v1","980":"http:\/\/export.arxiv.org\/pdf\/2111.07793v1","981":"http:\/\/export.arxiv.org\/pdf\/2104.12128v2","982":"http:\/\/export.arxiv.org\/pdf\/2108.09484v3","983":"http:\/\/export.arxiv.org\/pdf\/2111.07699v1","984":"http:\/\/export.arxiv.org\/pdf\/2104.12643v2","985":"http:\/\/export.arxiv.org\/pdf\/2010.12827v2","986":"http:\/\/export.arxiv.org\/pdf\/2111.04318v2","987":"http:\/\/export.arxiv.org\/pdf\/2111.07611v1","988":"http:\/\/export.arxiv.org\/pdf\/2105.14980v2","989":"http:\/\/export.arxiv.org\/pdf\/2111.07592v1","990":"http:\/\/export.arxiv.org\/pdf\/2111.06832v2","991":"http:\/\/export.arxiv.org\/pdf\/2110.04522v2","992":"http:\/\/export.arxiv.org\/pdf\/2111.07549v1","993":"http:\/\/export.arxiv.org\/pdf\/2111.03930v2","994":"http:\/\/export.arxiv.org\/pdf\/2111.07525v1","995":"http:\/\/export.arxiv.org\/pdf\/2109.04212v3","996":"http:\/\/export.arxiv.org\/pdf\/2111.07454v1","997":"http:\/\/export.arxiv.org\/pdf\/2111.07448v1","998":"http:\/\/export.arxiv.org\/pdf\/2109.14144v2","999":"http:\/\/export.arxiv.org\/pdf\/2111.07408v1","1000":"http:\/\/export.arxiv.org\/pdf\/2111.07393v1","1001":"http:\/\/export.arxiv.org\/pdf\/2112.02095v1","1002":"http:\/\/export.arxiv.org\/pdf\/2111.07367v1","1003":"http:\/\/export.arxiv.org\/pdf\/2007.06796v5","1004":"http:\/\/export.arxiv.org\/pdf\/2112.01842v1","1005":"http:\/\/export.arxiv.org\/pdf\/2111.05721v2","1006":"http:\/\/export.arxiv.org\/pdf\/2111.09111v1","1007":"http:\/\/export.arxiv.org\/pdf\/2111.07256v1","1008":"http:\/\/export.arxiv.org\/pdf\/2111.14703v1","1009":"http:\/\/export.arxiv.org\/pdf\/2111.07228v1","1010":"http:\/\/export.arxiv.org\/pdf\/2111.07218v1","1011":"http:\/\/export.arxiv.org\/pdf\/2111.07198v1","1012":"http:\/\/export.arxiv.org\/pdf\/2111.07188v1","1013":"http:\/\/export.arxiv.org\/pdf\/2111.07180v1","1014":"http:\/\/export.arxiv.org\/pdf\/2111.07148v1","1015":"http:\/\/export.arxiv.org\/pdf\/2112.03005v1","1016":"http:\/\/export.arxiv.org\/pdf\/2111.07119v1","1017":"http:\/\/export.arxiv.org\/pdf\/2105.09226v5","1018":"http:\/\/export.arxiv.org\/pdf\/2112.03002v1","1019":"http:\/\/export.arxiv.org\/pdf\/2005.00624v3","1020":"http:\/\/export.arxiv.org\/pdf\/2111.09115v1","1021":"http:\/\/export.arxiv.org\/pdf\/2101.00124v3","1022":"http:\/\/export.arxiv.org\/pdf\/2111.06971v1","1023":"http:\/\/export.arxiv.org\/pdf\/2111.06902v1","1024":"http:\/\/export.arxiv.org\/pdf\/2111.06801v1","1025":"http:\/\/export.arxiv.org\/pdf\/2111.06787v1","1026":"http:\/\/export.arxiv.org\/pdf\/2109.02738v2","1027":"http:\/\/export.arxiv.org\/pdf\/2111.06664v1","1028":"http:\/\/export.arxiv.org\/pdf\/2111.06647v1","1029":"http:\/\/export.arxiv.org\/pdf\/2111.06644v1","1030":"http:\/\/export.arxiv.org\/pdf\/2111.06625v1","1031":"http:\/\/export.arxiv.org\/pdf\/2111.06599v1","1032":"http:\/\/export.arxiv.org\/pdf\/2111.06580v1","1033":"http:\/\/export.arxiv.org\/pdf\/2010.14784v2","1034":"http:\/\/export.arxiv.org\/pdf\/2010.09905v3","1035":"http:\/\/export.arxiv.org\/pdf\/2111.06515v1","1036":"http:\/\/export.arxiv.org\/pdf\/2111.06464v1","1037":"http:\/\/export.arxiv.org\/pdf\/2102.07349v2","1038":"http:\/\/export.arxiv.org\/pdf\/2111.06345v1","1039":"http:\/\/export.arxiv.org\/pdf\/2111.06336v1","1040":"http:\/\/export.arxiv.org\/pdf\/2111.06334v1","1041":"http:\/\/export.arxiv.org\/pdf\/2111.06331v1","1042":"http:\/\/export.arxiv.org\/pdf\/2111.06310v1","1043":"http:\/\/export.arxiv.org\/pdf\/2111.06230v1","1044":"http:\/\/export.arxiv.org\/pdf\/2112.03004v1","1045":"http:\/\/export.arxiv.org\/pdf\/2109.00343v2","1046":"http:\/\/export.arxiv.org\/pdf\/2111.06181v1","1047":"http:\/\/export.arxiv.org\/pdf\/2111.06133v1","1048":"http:\/\/export.arxiv.org\/pdf\/2111.06103v1","1049":"http:\/\/export.arxiv.org\/pdf\/2111.06086v1","1050":"http:\/\/export.arxiv.org\/pdf\/2111.06070v1","1051":"http:\/\/export.arxiv.org\/pdf\/2111.06053v1","1052":"http:\/\/export.arxiv.org\/pdf\/2110.09749v4","1053":"http:\/\/export.arxiv.org\/pdf\/2111.06012v1","1054":"http:\/\/export.arxiv.org\/pdf\/2012.02339v3","1055":"http:\/\/export.arxiv.org\/pdf\/2111.05988v1","1056":"http:\/\/export.arxiv.org\/pdf\/2111.05940v1","1057":"http:\/\/export.arxiv.org\/pdf\/2111.05937v1","1058":"http:\/\/export.arxiv.org\/pdf\/2005.12423v2","1059":"http:\/\/export.arxiv.org\/pdf\/2111.05823v1","1060":"http:\/\/export.arxiv.org\/pdf\/2111.05808v1","1061":"http:\/\/export.arxiv.org\/pdf\/2111.05805v1","1062":"http:\/\/export.arxiv.org\/pdf\/2010.01556v2","1063":"http:\/\/export.arxiv.org\/pdf\/2111.05754v1","1064":"http:\/\/export.arxiv.org\/pdf\/2110.08094v2","1065":"http:\/\/export.arxiv.org\/pdf\/2111.05671v1","1066":"http:\/\/export.arxiv.org\/pdf\/2008.05759v2","1067":"http:\/\/export.arxiv.org\/pdf\/2111.05610v1","1068":"http:\/\/export.arxiv.org\/pdf\/2111.05605v1","1069":"http:\/\/export.arxiv.org\/pdf\/2110.15871v2","1070":"http:\/\/export.arxiv.org\/pdf\/2107.10326v3","1071":"http:\/\/export.arxiv.org\/pdf\/2107.07502v2","1072":"http:\/\/export.arxiv.org\/pdf\/2108.12637v2","1073":"http:\/\/export.arxiv.org\/pdf\/2111.05193v2","1074":"http:\/\/export.arxiv.org\/pdf\/2106.09775v3","1075":"http:\/\/export.arxiv.org\/pdf\/2111.05414v1","1076":"http:\/\/export.arxiv.org\/pdf\/2111.05412v1","1077":"http:\/\/export.arxiv.org\/pdf\/2111.05407v1","1078":"http:\/\/export.arxiv.org\/pdf\/2109.04711v2","1079":"http:\/\/export.arxiv.org\/pdf\/2012.15332v2","1080":"http:\/\/export.arxiv.org\/pdf\/2111.05241v1","1081":"http:\/\/export.arxiv.org\/pdf\/2111.05204v1","1082":"http:\/\/export.arxiv.org\/pdf\/2111.02168v2","1083":"http:\/\/export.arxiv.org\/pdf\/2111.02265v2","1084":"http:\/\/export.arxiv.org\/pdf\/2111.05147v1","1085":"http:\/\/export.arxiv.org\/pdf\/2111.05139v1","1086":"http:\/\/export.arxiv.org\/pdf\/2111.05039v1","1087":"http:\/\/export.arxiv.org\/pdf\/2103.10685v3","1088":"http:\/\/export.arxiv.org\/pdf\/2111.05013v1","1089":"http:\/\/export.arxiv.org\/pdf\/2112.03003v1","1090":"http:\/\/export.arxiv.org\/pdf\/2103.04037v2","1091":"http:\/\/export.arxiv.org\/pdf\/2111.03937v2","1092":"http:\/\/export.arxiv.org\/pdf\/2111.04951v1","1093":"http:\/\/export.arxiv.org\/pdf\/2111.04933v1","1094":"http:\/\/export.arxiv.org\/pdf\/2106.03143v3","1095":"http:\/\/export.arxiv.org\/pdf\/2111.00640v2","1096":"http:\/\/export.arxiv.org\/pdf\/2111.04862v1","1097":"http:\/\/export.arxiv.org\/pdf\/2103.03874v2","1098":"http:\/\/export.arxiv.org\/pdf\/2103.06268v2","1099":"http:\/\/export.arxiv.org\/pdf\/2105.09938v3","1100":"http:\/\/export.arxiv.org\/pdf\/2111.04823v1","1101":"http:\/\/export.arxiv.org\/pdf\/2111.04785v1","1102":"http:\/\/export.arxiv.org\/pdf\/2107.07170v2","1103":"http:\/\/export.arxiv.org\/pdf\/2108.08787v2","1104":"http:\/\/export.arxiv.org\/pdf\/2111.04574v1","1105":"http:\/\/export.arxiv.org\/pdf\/2111.04551v1","1106":"http:\/\/export.arxiv.org\/pdf\/2111.04530v1","1107":"http:\/\/export.arxiv.org\/pdf\/2111.00514v2","1108":"http:\/\/export.arxiv.org\/pdf\/2111.04517v1","1109":"http:\/\/export.arxiv.org\/pdf\/2111.04507v1","1110":"http:\/\/export.arxiv.org\/pdf\/2108.02923v3","1111":"http:\/\/export.arxiv.org\/pdf\/2109.06679v2","1112":"http:\/\/export.arxiv.org\/pdf\/2101.09465v2","1113":"http:\/\/export.arxiv.org\/pdf\/2111.04321v1","1114":"http:\/\/export.arxiv.org\/pdf\/2105.00150v2","1115":"http:\/\/export.arxiv.org\/pdf\/2111.04261v1","1116":"http:\/\/export.arxiv.org\/pdf\/2006.03950v5","1117":"http:\/\/export.arxiv.org\/pdf\/2104.08762v2","1118":"http:\/\/export.arxiv.org\/pdf\/2101.11214v3","1119":"http:\/\/export.arxiv.org\/pdf\/2111.05095v1","1120":"http:\/\/export.arxiv.org\/pdf\/2111.04194v1","1121":"http:\/\/export.arxiv.org\/pdf\/2111.04158v1","1122":"http:\/\/export.arxiv.org\/pdf\/2111.04138v1","1123":"http:\/\/export.arxiv.org\/pdf\/2111.04130v1","1124":"http:\/\/export.arxiv.org\/pdf\/2103.12906v3","1125":"http:\/\/export.arxiv.org\/pdf\/2111.04099v1","1126":"http:\/\/export.arxiv.org\/pdf\/2111.04079v1","1127":"http:\/\/export.arxiv.org\/pdf\/2111.04052v1","1128":"http:\/\/export.arxiv.org\/pdf\/2111.04045v1","1129":"http:\/\/export.arxiv.org\/pdf\/2111.04040v1","1130":"http:\/\/export.arxiv.org\/pdf\/2012.15717v2","1131":"http:\/\/export.arxiv.org\/pdf\/2106.05784v3","1132":"http:\/\/export.arxiv.org\/pdf\/2012.00190v2","1133":"http:\/\/export.arxiv.org\/pdf\/2111.14929v1","1134":"http:\/\/export.arxiv.org\/pdf\/2111.03916v1","1135":"http:\/\/export.arxiv.org\/pdf\/2108.12731v2","1136":"http:\/\/export.arxiv.org\/pdf\/2111.09741v1","1137":"http:\/\/export.arxiv.org\/pdf\/2111.03837v1","1138":"http:\/\/export.arxiv.org\/pdf\/2111.03813v1","1139":"http:\/\/export.arxiv.org\/pdf\/2111.03800v1","1140":"http:\/\/export.arxiv.org\/pdf\/2112.02994v1","1141":"http:\/\/export.arxiv.org\/pdf\/2111.03715v1","1142":"http:\/\/export.arxiv.org\/pdf\/2111.03651v1","1143":"http:\/\/export.arxiv.org\/pdf\/2111.03642v1","1144":"http:\/\/export.arxiv.org\/pdf\/2104.06378v4","1145":"http:\/\/export.arxiv.org\/pdf\/2111.03612v1","1146":"http:\/\/export.arxiv.org\/pdf\/2104.08620v3","1147":"http:\/\/export.arxiv.org\/pdf\/2110.12780v2","1148":"http:\/\/export.arxiv.org\/pdf\/2112.02995v1","1149":"http:\/\/export.arxiv.org\/pdf\/2111.03547v1","1150":"http:\/\/export.arxiv.org\/pdf\/2111.03511v1","1151":"http:\/\/export.arxiv.org\/pdf\/2111.03496v1","1152":"http:\/\/export.arxiv.org\/pdf\/2110.06981v2","1153":"http:\/\/export.arxiv.org\/pdf\/2111.03375v1","1154":"http:\/\/export.arxiv.org\/pdf\/2111.03350v1","1155":"http:\/\/export.arxiv.org\/pdf\/2111.03349v1","1156":"http:\/\/export.arxiv.org\/pdf\/2111.03342v1","1157":"http:\/\/export.arxiv.org\/pdf\/2104.08757v2","1158":"http:\/\/export.arxiv.org\/pdf\/2111.03299v1","1159":"http:\/\/export.arxiv.org\/pdf\/2111.03294v1","1160":"http:\/\/export.arxiv.org\/pdf\/2111.03284v1","1161":"http:\/\/export.arxiv.org\/pdf\/2111.03250v1","1162":"http:\/\/export.arxiv.org\/pdf\/1911.04115v3","1163":"http:\/\/export.arxiv.org\/pdf\/2109.08925v2","1164":"http:\/\/export.arxiv.org\/pdf\/2107.14154v3","1165":"http:\/\/export.arxiv.org\/pdf\/2110.13032v2","1166":"http:\/\/export.arxiv.org\/pdf\/2111.03212v1","1167":"http:\/\/export.arxiv.org\/pdf\/2111.03205v1","1168":"http:\/\/export.arxiv.org\/pdf\/2110.07803v2","1169":"http:\/\/export.arxiv.org\/pdf\/2107.03438v3","1170":"http:\/\/export.arxiv.org\/pdf\/2111.03120v1","1171":"http:\/\/export.arxiv.org\/pdf\/2111.03108v1","1172":"http:\/\/export.arxiv.org\/pdf\/2108.01828v3","1173":"http:\/\/export.arxiv.org\/pdf\/2108.04927v2","1174":"http:\/\/export.arxiv.org\/pdf\/2111.03000v1","1175":"http:\/\/export.arxiv.org\/pdf\/2111.02188v2","1176":"http:\/\/export.arxiv.org\/pdf\/2111.02878v1","1177":"http:\/\/export.arxiv.org\/pdf\/2109.14199v2","1178":"http:\/\/export.arxiv.org\/pdf\/2111.02844v1","1179":"http:\/\/export.arxiv.org\/pdf\/2111.02259v2","1180":"http:\/\/export.arxiv.org\/pdf\/2111.02827v1","1181":"http:\/\/export.arxiv.org\/pdf\/2111.02760v1","1182":"http:\/\/export.arxiv.org\/pdf\/2111.02705v1","1183":"http:\/\/export.arxiv.org\/pdf\/2111.02687v1","1184":"http:\/\/export.arxiv.org\/pdf\/2111.02674v1","1185":"http:\/\/export.arxiv.org\/pdf\/2109.11541v2","1186":"http:\/\/export.arxiv.org\/pdf\/2111.02654v1","1187":"http:\/\/export.arxiv.org\/pdf\/2006.02567v3","1188":"http:\/\/export.arxiv.org\/pdf\/2111.02622v1","1189":"http:\/\/export.arxiv.org\/pdf\/2111.02603v1","1190":"http:\/\/export.arxiv.org\/pdf\/2111.02574v1","1191":"http:\/\/export.arxiv.org\/pdf\/2111.02570v1","1192":"http:\/\/export.arxiv.org\/pdf\/2110.04400v3","1193":"http:\/\/export.arxiv.org\/pdf\/2111.02519v1","1194":"http:\/\/export.arxiv.org\/pdf\/2109.04847v2","1195":"http:\/\/export.arxiv.org\/pdf\/2011.10369v3","1196":"http:\/\/export.arxiv.org\/pdf\/2111.02362v1","1197":"http:\/\/export.arxiv.org\/pdf\/2111.02358v1","1198":"http:\/\/export.arxiv.org\/pdf\/1809.00656v2","1199":"http:\/\/export.arxiv.org\/pdf\/2111.02326v1","1200":"http:\/\/export.arxiv.org\/pdf\/2112.02998v1","1201":"http:\/\/export.arxiv.org\/pdf\/2111.01676v2","1202":"http:\/\/export.arxiv.org\/pdf\/2111.02216v1","1203":"http:\/\/export.arxiv.org\/pdf\/2111.02194v1","1204":"http:\/\/export.arxiv.org\/pdf\/2111.02172v1","1205":"http:\/\/export.arxiv.org\/pdf\/2110.15726v2","1206":"http:\/\/export.arxiv.org\/pdf\/2111.02120v1","1207":"http:\/\/export.arxiv.org\/pdf\/2111.02114v1","1208":"http:\/\/export.arxiv.org\/pdf\/2109.08914v2","1209":"http:\/\/export.arxiv.org\/pdf\/2111.02086v1","1210":"http:\/\/export.arxiv.org\/pdf\/2111.02041v1","1211":"http:\/\/export.arxiv.org\/pdf\/1908.07822v4","1212":"http:\/\/export.arxiv.org\/pdf\/2104.08698v2","1213":"http:\/\/export.arxiv.org\/pdf\/2106.12566v2","1214":"http:\/\/export.arxiv.org\/pdf\/2111.01998v1","1215":"http:\/\/export.arxiv.org\/pdf\/2111.01992v1","1216":"http:\/\/export.arxiv.org\/pdf\/2111.01689v2","1217":"http:\/\/export.arxiv.org\/pdf\/2106.01540v2","1218":"http:\/\/export.arxiv.org\/pdf\/2111.01740v1","1219":"http:\/\/export.arxiv.org\/pdf\/2111.01706v1","1220":"http:\/\/export.arxiv.org\/pdf\/2105.09680v4","1221":"http:\/\/export.arxiv.org\/pdf\/2111.01582v1","1222":"http:\/\/export.arxiv.org\/pdf\/2111.01543v1","1223":"http:\/\/export.arxiv.org\/pdf\/2111.01515v1","1224":"http:\/\/export.arxiv.org\/pdf\/2111.01471v1","1225":"http:\/\/export.arxiv.org\/pdf\/2111.01465v1","1226":"http:\/\/export.arxiv.org\/pdf\/2111.01414v1","1227":"http:\/\/export.arxiv.org\/pdf\/2111.01398v1","1228":"http:\/\/export.arxiv.org\/pdf\/2109.09010v2","1229":"http:\/\/export.arxiv.org\/pdf\/2110.01895v2","1230":"http:\/\/export.arxiv.org\/pdf\/2111.01340v1","1231":"http:\/\/export.arxiv.org\/pdf\/2111.01326v1","1232":"http:\/\/export.arxiv.org\/pdf\/2111.01322v1","1233":"http:\/\/export.arxiv.org\/pdf\/2112.02997v1","1234":"http:\/\/export.arxiv.org\/pdf\/2110.15720v2","1235":"http:\/\/export.arxiv.org\/pdf\/2111.01243v1","1236":"http:\/\/export.arxiv.org\/pdf\/2109.05112v2","1237":"http:\/\/export.arxiv.org\/pdf\/2111.01231v1","1238":"http:\/\/export.arxiv.org\/pdf\/2104.07149v2","1239":"http:\/\/export.arxiv.org\/pdf\/2111.01205v1","1240":"http:\/\/export.arxiv.org\/pdf\/2103.01242v2","1241":"http:\/\/export.arxiv.org\/pdf\/2109.08113v2","1242":"http:\/\/export.arxiv.org\/pdf\/2111.01193v1","1243":"http:\/\/export.arxiv.org\/pdf\/2111.01136v1","1244":"http:\/\/export.arxiv.org\/pdf\/2110.09456v2","1245":"http:\/\/export.arxiv.org\/pdf\/2111.01026v1","1246":"http:\/\/export.arxiv.org\/pdf\/2111.01023v1","1247":"http:\/\/export.arxiv.org\/pdf\/2110.12200v2","1248":"http:\/\/export.arxiv.org\/pdf\/2111.00981v1","1249":"http:\/\/export.arxiv.org\/pdf\/2110.09338v2","1250":"http:\/\/export.arxiv.org\/pdf\/2111.00976v1","1251":"http:\/\/export.arxiv.org\/pdf\/2111.00974v1","1252":"http:\/\/export.arxiv.org\/pdf\/2111.00884v1","1253":"http:\/\/export.arxiv.org\/pdf\/2111.00830v1","1254":"http:\/\/export.arxiv.org\/pdf\/2111.00808v1","1255":"http:\/\/export.arxiv.org\/pdf\/2010.10041v4","1256":"http:\/\/export.arxiv.org\/pdf\/2110.04399v2","1257":"http:\/\/export.arxiv.org\/pdf\/2010.11003v2","1258":"http:\/\/export.arxiv.org\/pdf\/2111.00767v1","1259":"http:\/\/export.arxiv.org\/pdf\/2104.11559v2","1260":"http:\/\/export.arxiv.org\/pdf\/2102.08549v3","1261":"http:\/\/export.arxiv.org\/pdf\/2111.00732v1","1262":"http:\/\/export.arxiv.org\/pdf\/2111.00702v1","1263":"http:\/\/export.arxiv.org\/pdf\/2111.00677v1","1264":"http:\/\/export.arxiv.org\/pdf\/2111.00667v1","1265":"http:\/\/export.arxiv.org\/pdf\/2101.06426v2","1266":"http:\/\/export.arxiv.org\/pdf\/2111.00611v1","1267":"http:\/\/export.arxiv.org\/pdf\/2111.00610v1","1268":"http:\/\/export.arxiv.org\/pdf\/2111.00580v1","1269":"http:\/\/export.arxiv.org\/pdf\/2111.00572v1","1270":"http:\/\/export.arxiv.org\/pdf\/2111.00570v1","1271":"http:\/\/export.arxiv.org\/pdf\/2110.14780v2","1272":"http:\/\/export.arxiv.org\/pdf\/2111.00556v1","1273":"http:\/\/export.arxiv.org\/pdf\/2111.00554v1","1274":"http:\/\/export.arxiv.org\/pdf\/2111.00539v1","1275":"http:\/\/export.arxiv.org\/pdf\/2104.05062v2","1276":"http:\/\/export.arxiv.org\/pdf\/2111.00490v1","1277":"http:\/\/export.arxiv.org\/pdf\/2111.00417v1","1278":"http:\/\/export.arxiv.org\/pdf\/2111.00404v1","1279":"http:\/\/export.arxiv.org\/pdf\/2111.00400v1","1280":"http:\/\/export.arxiv.org\/pdf\/2104.02242v3","1281":"http:\/\/export.arxiv.org\/pdf\/2111.00350v1","1282":"http:\/\/export.arxiv.org\/pdf\/2111.00310v1","1283":"http:\/\/export.arxiv.org\/pdf\/2101.01213v3","1284":"http:\/\/export.arxiv.org\/pdf\/2109.01900v2","1285":"http:\/\/export.arxiv.org\/pdf\/2109.08722v5","1286":"http:\/\/export.arxiv.org\/pdf\/2110.13522v2","1287":"http:\/\/export.arxiv.org\/pdf\/2105.00309v2","1288":"http:\/\/export.arxiv.org\/pdf\/2107.05038v2","1289":"http:\/\/export.arxiv.org\/pdf\/2111.00230v1","1290":"http:\/\/export.arxiv.org\/pdf\/2103.05825v2","1291":"http:\/\/export.arxiv.org\/pdf\/2111.00197v1","1292":"http:\/\/export.arxiv.org\/pdf\/2111.00192v1","1293":"http:\/\/export.arxiv.org\/pdf\/2111.00191v1","1294":"http:\/\/export.arxiv.org\/pdf\/2109.05182v2","1295":"http:\/\/export.arxiv.org\/pdf\/2111.00180v1","1296":"http:\/\/export.arxiv.org\/pdf\/2111.00160v1","1297":"http:\/\/export.arxiv.org\/pdf\/2111.00035v1","1298":"http:\/\/export.arxiv.org\/pdf\/2110.15957v1","1299":"http:\/\/export.arxiv.org\/pdf\/2110.15931v1","1300":"http:\/\/export.arxiv.org\/pdf\/2110.15905v1","1301":"http:\/\/export.arxiv.org\/pdf\/2110.15789v1","1302":"http:\/\/export.arxiv.org\/pdf\/2110.03611v3","1303":"http:\/\/export.arxiv.org\/pdf\/2010.12527v4","1304":"http:\/\/export.arxiv.org\/pdf\/2104.08078v2","1305":"http:\/\/export.arxiv.org\/pdf\/2010.12305v2","1306":"http:\/\/export.arxiv.org\/pdf\/2110.15778v1","1307":"http:\/\/export.arxiv.org\/pdf\/2110.15763v1","1308":"http:\/\/export.arxiv.org\/pdf\/2109.10255v3","1309":"http:\/\/export.arxiv.org\/pdf\/2110.15682v1","1310":"http:\/\/export.arxiv.org\/pdf\/2110.15659v1","1311":"http:\/\/export.arxiv.org\/pdf\/2110.15622v1","1312":"http:\/\/export.arxiv.org\/pdf\/2110.15621v1","1313":"http:\/\/export.arxiv.org\/pdf\/2110.15269v2","1314":"http:\/\/export.arxiv.org\/pdf\/2110.15599v1","1315":"http:\/\/export.arxiv.org\/pdf\/2111.01910v1","1316":"http:\/\/export.arxiv.org\/pdf\/2111.05364v1","1317":"http:\/\/export.arxiv.org\/pdf\/2110.15542v1","1318":"http:\/\/export.arxiv.org\/pdf\/2110.15534v1","1319":"http:\/\/export.arxiv.org\/pdf\/2110.15527v1","1320":"http:\/\/export.arxiv.org\/pdf\/2110.15453v1","1321":"http:\/\/export.arxiv.org\/pdf\/2110.15430v1","1322":"http:\/\/export.arxiv.org\/pdf\/2101.08248v4","1323":"http:\/\/export.arxiv.org\/pdf\/2005.10899v2","1324":"http:\/\/export.arxiv.org\/pdf\/2110.15409v1","1325":"http:\/\/export.arxiv.org\/pdf\/2110.15349v1","1326":"http:\/\/export.arxiv.org\/pdf\/2110.15766v1","1327":"http:\/\/export.arxiv.org\/pdf\/2110.15235v1","1328":"http:\/\/export.arxiv.org\/pdf\/2110.06309v2","1329":"http:\/\/export.arxiv.org\/pdf\/2110.15181v1","1330":"http:\/\/export.arxiv.org\/pdf\/2110.15149v1","1331":"http:\/\/export.arxiv.org\/pdf\/2010.07212v3","1332":"http:\/\/export.arxiv.org\/pdf\/2110.15134v1","1333":"http:\/\/export.arxiv.org\/pdf\/2110.15132v1","1334":"http:\/\/export.arxiv.org\/pdf\/2110.15130v1","1335":"http:\/\/export.arxiv.org\/pdf\/2105.01466v4","1336":"http:\/\/export.arxiv.org\/pdf\/2110.15023v1","1337":"http:\/\/export.arxiv.org\/pdf\/2110.15722v1","1338":"http:\/\/export.arxiv.org\/pdf\/2110.14957v1","1339":"http:\/\/export.arxiv.org\/pdf\/2110.14945v1","1340":"http:\/\/export.arxiv.org\/pdf\/2107.05768v2","1341":"http:\/\/export.arxiv.org\/pdf\/2110.14883v1","1342":"http:\/\/export.arxiv.org\/pdf\/2110.01147v2","1343":"http:\/\/export.arxiv.org\/pdf\/2110.14843v1","1344":"http:\/\/export.arxiv.org\/pdf\/2110.14839v1","1345":"http:\/\/export.arxiv.org\/pdf\/2103.11474v2","1346":"http:\/\/export.arxiv.org\/pdf\/2107.11976v2","1347":"http:\/\/export.arxiv.org\/pdf\/2107.14641v2","1348":"http:\/\/export.arxiv.org\/pdf\/2107.02173v3","1349":"http:\/\/export.arxiv.org\/pdf\/2106.00786v2","1350":"http:\/\/export.arxiv.org\/pdf\/2110.14769v1","1351":"http:\/\/export.arxiv.org\/pdf\/2102.04130v3","1352":"http:\/\/export.arxiv.org\/pdf\/2110.14729v1","1353":"http:\/\/export.arxiv.org\/pdf\/2102.07492v3","1354":"http:\/\/export.arxiv.org\/pdf\/2110.14694v1","1355":"http:\/\/export.arxiv.org\/pdf\/2110.14566v1","1356":"http:\/\/export.arxiv.org\/pdf\/2110.15797v1","1357":"http:\/\/export.arxiv.org\/pdf\/2106.07759v2","1358":"http:\/\/export.arxiv.org\/pdf\/2110.14398v1","1359":"http:\/\/export.arxiv.org\/pdf\/2106.11520v2","1360":"http:\/\/export.arxiv.org\/pdf\/2110.14273v1","1361":"http:\/\/export.arxiv.org\/pdf\/2110.14266v1","1362":"http:\/\/export.arxiv.org\/pdf\/2110.14241v1","1363":"http:\/\/export.arxiv.org\/pdf\/2110.14203v1","1364":"http:\/\/export.arxiv.org\/pdf\/2110.05722v2","1365":"http:\/\/export.arxiv.org\/pdf\/2110.14182v1","1366":"http:\/\/export.arxiv.org\/pdf\/2110.14171v1","1367":"http:\/\/export.arxiv.org\/pdf\/2102.08473v2","1368":"http:\/\/export.arxiv.org\/pdf\/2108.07127v3","1369":"http:\/\/export.arxiv.org\/pdf\/2110.14091v1","1370":"http:\/\/export.arxiv.org\/pdf\/2106.03257v3","1371":"http:\/\/export.arxiv.org\/pdf\/2110.13980v1","1372":"http:\/\/export.arxiv.org\/pdf\/2110.13971v1","1373":"http:\/\/export.arxiv.org\/pdf\/2110.13880v1","1374":"http:\/\/export.arxiv.org\/pdf\/2110.13877v1","1375":"http:\/\/export.arxiv.org\/pdf\/2106.05933v2","1376":"http:\/\/export.arxiv.org\/pdf\/2104.07472v2","1377":"http:\/\/export.arxiv.org\/pdf\/2110.03111v3","1378":"http:\/\/export.arxiv.org\/pdf\/2104.08642v2","1379":"http:\/\/export.arxiv.org\/pdf\/2012.08508v3","1380":"http:\/\/export.arxiv.org\/pdf\/2102.01951v2","1381":"http:\/\/export.arxiv.org\/pdf\/2110.13658v1","1382":"http:\/\/export.arxiv.org\/pdf\/2110.03215v3","1383":"http:\/\/export.arxiv.org\/pdf\/2103.06511v2","1384":"http:\/\/export.arxiv.org\/pdf\/2110.13710v1","1385":"http:\/\/export.arxiv.org\/pdf\/2110.13692v1","1386":"http:\/\/export.arxiv.org\/pdf\/2110.13691v1","1387":"http:\/\/export.arxiv.org\/pdf\/2110.13683v1","1388":"http:\/\/export.arxiv.org\/pdf\/2110.13640v1","1389":"http:\/\/export.arxiv.org\/pdf\/2108.07994v2","1390":"http:\/\/export.arxiv.org\/pdf\/2103.02227v3","1391":"http:\/\/export.arxiv.org\/pdf\/2110.13577v1","1392":"http:\/\/export.arxiv.org\/pdf\/2105.11832v2","1393":"http:\/\/export.arxiv.org\/pdf\/2009.06891v5","1394":"http:\/\/export.arxiv.org\/pdf\/2110.15794v1","1395":"http:\/\/export.arxiv.org\/pdf\/2110.13505v1","1396":"http:\/\/export.arxiv.org\/pdf\/2110.13495v1","1397":"http:\/\/export.arxiv.org\/pdf\/2110.13480v1","1398":"http:\/\/export.arxiv.org\/pdf\/2106.13033v2","1399":"http:\/\/export.arxiv.org\/pdf\/2110.13472v1","1400":"http:\/\/export.arxiv.org\/pdf\/2106.01609v3","1401":"http:\/\/export.arxiv.org\/pdf\/2110.05745v2","1402":"http:\/\/export.arxiv.org\/pdf\/2110.13434v1","1403":"http:\/\/export.arxiv.org\/pdf\/2106.03831v2","1404":"http:\/\/export.arxiv.org\/pdf\/2110.03163v2","1405":"http:\/\/export.arxiv.org\/pdf\/2110.13398v1","1406":"http:\/\/export.arxiv.org\/pdf\/2110.13376v1","1407":"http:\/\/export.arxiv.org\/pdf\/1908.03265v4","1408":"http:\/\/export.arxiv.org\/pdf\/2109.11888v2","1409":"http:\/\/export.arxiv.org\/pdf\/2110.13317v1","1410":"http:\/\/export.arxiv.org\/pdf\/2107.02968v2","1411":"http:\/\/export.arxiv.org\/pdf\/2110.13244v1","1412":"http:\/\/export.arxiv.org\/pdf\/2110.13231v1","1413":"http:\/\/export.arxiv.org\/pdf\/2110.13213v1","1414":"http:\/\/export.arxiv.org\/pdf\/2110.13090v1","1415":"http:\/\/export.arxiv.org\/pdf\/2105.02472v2","1416":"http:\/\/export.arxiv.org\/pdf\/2110.13016v1","1417":"http:\/\/export.arxiv.org\/pdf\/2110.12949v1","1418":"http:\/\/export.arxiv.org\/pdf\/2110.12948v1","1419":"http:\/\/export.arxiv.org\/pdf\/2005.02233v3","1420":"http:\/\/export.arxiv.org\/pdf\/2109.01942v2","1421":"http:\/\/export.arxiv.org\/pdf\/2107.01076v2","1422":"http:\/\/export.arxiv.org\/pdf\/2105.05686v2","1423":"http:\/\/export.arxiv.org\/pdf\/2110.12765v1","1424":"http:\/\/export.arxiv.org\/pdf\/2110.12764v1","1425":"http:\/\/export.arxiv.org\/pdf\/2110.12687v1","1426":"http:\/\/export.arxiv.org\/pdf\/2110.12680v1","1427":"http:\/\/export.arxiv.org\/pdf\/2110.03888v3","1428":"http:\/\/export.arxiv.org\/pdf\/2110.12646v1","1429":"http:\/\/export.arxiv.org\/pdf\/2110.12645v1","1430":"http:\/\/export.arxiv.org\/pdf\/2110.10470v2","1431":"http:\/\/export.arxiv.org\/pdf\/2110.11624v2","1432":"http:\/\/export.arxiv.org\/pdf\/2107.03054v2","1433":"http:\/\/export.arxiv.org\/pdf\/2110.12609v1","1434":"http:\/\/export.arxiv.org\/pdf\/2108.06314v5","1435":"http:\/\/export.arxiv.org\/pdf\/2110.12567v1","1436":"http:\/\/export.arxiv.org\/pdf\/2110.12552v1","1437":"http:\/\/export.arxiv.org\/pdf\/2110.12551v1","1438":"http:\/\/export.arxiv.org\/pdf\/2110.12501v1","1439":"http:\/\/export.arxiv.org\/pdf\/2110.15054v1","1440":"http:\/\/export.arxiv.org\/pdf\/2110.12416v1","1441":"http:\/\/export.arxiv.org\/pdf\/2110.12412v1","1442":"http:\/\/export.arxiv.org\/pdf\/2110.12383v1","1443":"http:\/\/export.arxiv.org\/pdf\/2109.04513v2","1444":"http:\/\/export.arxiv.org\/pdf\/2110.12374v1","1445":"http:\/\/export.arxiv.org\/pdf\/2110.12370v1","1446":"http:\/\/export.arxiv.org\/pdf\/2109.05473v3","1447":"http:\/\/export.arxiv.org\/pdf\/2110.12349v1","1448":"http:\/\/export.arxiv.org\/pdf\/2110.12342v1","1449":"http:\/\/export.arxiv.org\/pdf\/2110.12341v1","1450":"http:\/\/export.arxiv.org\/pdf\/2110.12335v1","1451":"http:\/\/export.arxiv.org\/pdf\/2110.12320v1","1452":"http:\/\/export.arxiv.org\/pdf\/2110.15799v1","1453":"http:\/\/export.arxiv.org\/pdf\/2109.08270v3","1454":"http:\/\/export.arxiv.org\/pdf\/2110.12243v1","1455":"http:\/\/export.arxiv.org\/pdf\/2110.08975v2","1456":"http:\/\/export.arxiv.org\/pdf\/2110.12201v1","1457":"http:\/\/export.arxiv.org\/pdf\/2110.12199v1","1458":"http:\/\/export.arxiv.org\/pdf\/2110.01188v3","1459":"http:\/\/export.arxiv.org\/pdf\/2110.10358v2","1460":"http:\/\/export.arxiv.org\/pdf\/2110.06502v2","1461":"http:\/\/export.arxiv.org\/pdf\/2105.04780v2","1462":"http:\/\/export.arxiv.org\/pdf\/2106.09063v3","1463":"http:\/\/export.arxiv.org\/pdf\/2110.12010v1","1464":"http:\/\/export.arxiv.org\/pdf\/2110.11938v1","1465":"http:\/\/export.arxiv.org\/pdf\/2110.11934v1","1466":"http:\/\/export.arxiv.org\/pdf\/2110.11929v1","1467":"http:\/\/export.arxiv.org\/pdf\/2110.11899v1","1468":"http:\/\/export.arxiv.org\/pdf\/2110.11881v1","1469":"http:\/\/export.arxiv.org\/pdf\/2110.11850v1","1470":"http:\/\/export.arxiv.org\/pdf\/2109.15086v2","1471":"http:\/\/export.arxiv.org\/pdf\/2102.05379v3","1472":"http:\/\/export.arxiv.org\/pdf\/2110.11692v1","1473":"http:\/\/export.arxiv.org\/pdf\/2104.07123v2","1474":"http:\/\/export.arxiv.org\/pdf\/2109.07234v2","1475":"http:\/\/export.arxiv.org\/pdf\/2110.05035v2","1476":"http:\/\/export.arxiv.org\/pdf\/2112.00709v1","1477":"http:\/\/export.arxiv.org\/pdf\/2004.03808v4","1478":"http:\/\/export.arxiv.org\/pdf\/2110.11589v1","1479":"http:\/\/export.arxiv.org\/pdf\/2110.11560v1","1480":"http:\/\/export.arxiv.org\/pdf\/2106.00200v2","1481":"http:\/\/export.arxiv.org\/pdf\/2106.02636v3","1482":"http:\/\/export.arxiv.org\/pdf\/2110.11514v1","1483":"http:\/\/export.arxiv.org\/pdf\/2106.09553v2","1484":"http:\/\/export.arxiv.org\/pdf\/2109.13238v2","1485":"http:\/\/export.arxiv.org\/pdf\/2110.11333v1","1486":"http:\/\/export.arxiv.org\/pdf\/2110.11309v1","1487":"http:\/\/export.arxiv.org\/pdf\/2010.07668v2","1488":"http:\/\/export.arxiv.org\/pdf\/2110.11207v1","1489":"http:\/\/export.arxiv.org\/pdf\/2110.11199v1","1490":"http:\/\/export.arxiv.org\/pdf\/2104.04580v2","1491":"http:\/\/export.arxiv.org\/pdf\/2110.11164v1","1492":"http:\/\/export.arxiv.org\/pdf\/2110.11115v1","1493":"http:\/\/export.arxiv.org\/pdf\/2108.06130v3","1494":"http:\/\/export.arxiv.org\/pdf\/2110.10973v1","1495":"http:\/\/export.arxiv.org\/pdf\/2110.10963v1","1496":"http:\/\/export.arxiv.org\/pdf\/2109.11034v2","1497":"http:\/\/export.arxiv.org\/pdf\/2110.10874v1","1498":"http:\/\/export.arxiv.org\/pdf\/2110.10871v1","1499":"http:\/\/export.arxiv.org\/pdf\/2110.07752v2","1500":"http:\/\/export.arxiv.org\/pdf\/2104.08663v4","1501":"http:\/\/export.arxiv.org\/pdf\/2110.10834v1","1502":"http:\/\/export.arxiv.org\/pdf\/2104.08667v2","1503":"http:\/\/export.arxiv.org\/pdf\/2110.10817v1","1504":"http:\/\/export.arxiv.org\/pdf\/2110.10778v1","1505":"http:\/\/export.arxiv.org\/pdf\/2103.07601v3","1506":"http:\/\/export.arxiv.org\/pdf\/2110.10774v1","1507":"http:\/\/export.arxiv.org\/pdf\/2110.10746v1","1508":"http:\/\/export.arxiv.org\/pdf\/2106.09608v2","1509":"http:\/\/export.arxiv.org\/pdf\/2110.10668v1","1510":"http:\/\/export.arxiv.org\/pdf\/2110.10577v1","1511":"http:\/\/export.arxiv.org\/pdf\/2110.10575v1","1512":"http:\/\/export.arxiv.org\/pdf\/2010.10216v4","1513":"http:\/\/export.arxiv.org\/pdf\/1908.11017v4","1514":"http:\/\/export.arxiv.org\/pdf\/2101.06053v2","1515":"http:\/\/export.arxiv.org\/pdf\/2107.11757v2","1516":"http:\/\/export.arxiv.org\/pdf\/2110.10478v1","1517":"http:\/\/export.arxiv.org\/pdf\/2110.10472v1","1518":"http:\/\/export.arxiv.org\/pdf\/2008.09150v2","1519":"http:\/\/export.arxiv.org\/pdf\/2110.10431v1","1520":"http:\/\/export.arxiv.org\/pdf\/2110.10429v1","1521":"http:\/\/export.arxiv.org\/pdf\/2110.08591v2","1522":"http:\/\/export.arxiv.org\/pdf\/2110.05856v2","1523":"http:\/\/export.arxiv.org\/pdf\/2106.11483v3","1524":"http:\/\/export.arxiv.org\/pdf\/2110.10372v1","1525":"http:\/\/export.arxiv.org\/pdf\/2110.09702v2","1526":"http:\/\/export.arxiv.org\/pdf\/2110.10340v1","1527":"http:\/\/export.arxiv.org\/pdf\/2010.14649v2","1528":"http:\/\/export.arxiv.org\/pdf\/2110.10329v1","1529":"http:\/\/export.arxiv.org\/pdf\/2110.10328v1","1530":"http:\/\/export.arxiv.org\/pdf\/2110.10319v1","1531":"http:\/\/export.arxiv.org\/pdf\/2110.10318v1","1532":"http:\/\/export.arxiv.org\/pdf\/2110.06388v2","1533":"http:\/\/export.arxiv.org\/pdf\/2110.10213v1","1534":"http:\/\/export.arxiv.org\/pdf\/2110.15801v1","1535":"http:\/\/export.arxiv.org\/pdf\/2110.10189v1","1536":"http:\/\/export.arxiv.org\/pdf\/2110.10185v1","1537":"http:\/\/export.arxiv.org\/pdf\/2107.02681v2","1538":"http:\/\/export.arxiv.org\/pdf\/2109.04993v2","1539":"http:\/\/export.arxiv.org\/pdf\/2110.10064v1","1540":"http:\/\/export.arxiv.org\/pdf\/2110.10015v1","1541":"http:\/\/export.arxiv.org\/pdf\/2111.00867v1","1542":"http:\/\/export.arxiv.org\/pdf\/2110.09915v1","1543":"http:\/\/export.arxiv.org\/pdf\/2110.09877v1","1544":"http:\/\/export.arxiv.org\/pdf\/2110.13815v1","1545":"http:\/\/export.arxiv.org\/pdf\/2108.04049v2","1546":"http:\/\/export.arxiv.org\/pdf\/2110.03618v2","1547":"http:\/\/export.arxiv.org\/pdf\/2110.09779v1","1548":"http:\/\/export.arxiv.org\/pdf\/2110.09756v1","1549":"http:\/\/export.arxiv.org\/pdf\/2110.09753v1","1550":"http:\/\/export.arxiv.org\/pdf\/2008.02742v3","1551":"http:\/\/export.arxiv.org\/pdf\/2110.08270v2","1552":"http:\/\/export.arxiv.org\/pdf\/2110.09721v1","1553":"http:\/\/export.arxiv.org\/pdf\/2110.09710v1","1554":"http:\/\/export.arxiv.org\/pdf\/2011.10896v4","1555":"http:\/\/export.arxiv.org\/pdf\/2108.06743v2","1556":"http:\/\/export.arxiv.org\/pdf\/2110.09698v1","1557":"http:\/\/export.arxiv.org\/pdf\/2110.09665v1","1558":"http:\/\/export.arxiv.org\/pdf\/2110.09646v1","1559":"http:\/\/export.arxiv.org\/pdf\/2110.11240v1","1560":"http:\/\/export.arxiv.org\/pdf\/2110.05994v2","1561":"http:\/\/export.arxiv.org\/pdf\/2110.09574v1","1562":"http:\/\/export.arxiv.org\/pdf\/2110.12003v1","1563":"http:\/\/export.arxiv.org\/pdf\/2110.09570v1","1564":"http:\/\/export.arxiv.org\/pdf\/2107.13935v2","1565":"http:\/\/export.arxiv.org\/pdf\/2110.09495v1","1566":"http:\/\/export.arxiv.org\/pdf\/2110.15802v1","1567":"http:\/\/export.arxiv.org\/pdf\/2110.09454v1","1568":"http:\/\/export.arxiv.org\/pdf\/2110.09424v1","1569":"http:\/\/export.arxiv.org\/pdf\/2110.09421v1","1570":"http:\/\/export.arxiv.org\/pdf\/2110.09393v1","1571":"http:\/\/export.arxiv.org\/pdf\/2104.07644v3","1572":"http:\/\/export.arxiv.org\/pdf\/2110.09324v1","1573":"http:\/\/export.arxiv.org\/pdf\/2110.09216v1","1574":"http:\/\/export.arxiv.org\/pdf\/2003.12739v2","1575":"http:\/\/export.arxiv.org\/pdf\/2110.09179v1","1576":"http:\/\/export.arxiv.org\/pdf\/2110.07187v2","1577":"http:\/\/export.arxiv.org\/pdf\/2110.09147v1","1578":"http:\/\/export.arxiv.org\/pdf\/2110.09103v1","1579":"http:\/\/export.arxiv.org\/pdf\/2110.11403v1","1580":"http:\/\/export.arxiv.org\/pdf\/2110.09094v1","1581":"http:\/\/export.arxiv.org\/pdf\/2110.01500v5","1582":"http:\/\/export.arxiv.org\/pdf\/2109.05941v2","1583":"http:\/\/export.arxiv.org\/pdf\/2110.09930v1","1584":"http:\/\/export.arxiv.org\/pdf\/2110.09036v1","1585":"http:\/\/export.arxiv.org\/pdf\/2109.14420v3","1586":"http:\/\/export.arxiv.org\/pdf\/2107.04082v4","1587":"http:\/\/export.arxiv.org\/pdf\/2110.08931v1","1588":"http:\/\/export.arxiv.org\/pdf\/2103.14804v4","1589":"http:\/\/export.arxiv.org\/pdf\/2110.08887v1","1590":"http:\/\/export.arxiv.org\/pdf\/2110.08875v1","1591":"http:\/\/export.arxiv.org\/pdf\/2110.08874v1","1592":"http:\/\/export.arxiv.org\/pdf\/2110.08845v1","1593":"http:\/\/export.arxiv.org\/pdf\/2109.07680v3","1594":"http:\/\/export.arxiv.org\/pdf\/2110.08745v1","1595":"http:\/\/export.arxiv.org\/pdf\/2109.02418v2","1596":"http:\/\/export.arxiv.org\/pdf\/2110.08678v1","1597":"http:\/\/export.arxiv.org\/pdf\/2106.09685v2","1598":"http:\/\/export.arxiv.org\/pdf\/2110.08604v1","1599":"http:\/\/export.arxiv.org\/pdf\/2110.08583v1","1600":"http:\/\/export.arxiv.org\/pdf\/1908.09128v2","1601":"http:\/\/export.arxiv.org\/pdf\/2110.08559v1","1602":"http:\/\/export.arxiv.org\/pdf\/2110.08554v1","1603":"http:\/\/export.arxiv.org\/pdf\/2110.08551v1","1604":"http:\/\/export.arxiv.org\/pdf\/2110.08545v1","1605":"http:\/\/export.arxiv.org\/pdf\/2110.08538v1","1606":"http:\/\/export.arxiv.org\/pdf\/2110.08536v1","1607":"http:\/\/export.arxiv.org\/pdf\/2110.08534v1","1608":"http:\/\/export.arxiv.org\/pdf\/2110.08532v1","1609":"http:\/\/export.arxiv.org\/pdf\/2110.08520v1","1610":"http:\/\/export.arxiv.org\/pdf\/2108.13741v3","1611":"http:\/\/export.arxiv.org\/pdf\/2110.08514v1","1612":"http:\/\/export.arxiv.org\/pdf\/2110.08462v1","1613":"http:\/\/export.arxiv.org\/pdf\/2110.08460v1","1614":"http:\/\/export.arxiv.org\/pdf\/2110.08455v1","1615":"http:\/\/export.arxiv.org\/pdf\/2104.05848v7","1616":"http:\/\/export.arxiv.org\/pdf\/2110.08445v1","1617":"http:\/\/export.arxiv.org\/pdf\/2110.08430v1","1618":"http:\/\/export.arxiv.org\/pdf\/2110.08426v1","1619":"http:\/\/export.arxiv.org\/pdf\/2110.08420v1","1620":"http:\/\/export.arxiv.org\/pdf\/2110.08419v1","1621":"http:\/\/export.arxiv.org\/pdf\/2110.08413v1","1622":"http:\/\/export.arxiv.org\/pdf\/2110.08412v1","1623":"http:\/\/export.arxiv.org\/pdf\/2110.08395v1","1624":"http:\/\/export.arxiv.org\/pdf\/2105.01051v4","1625":"http:\/\/export.arxiv.org\/pdf\/2110.08383v1","1626":"http:\/\/export.arxiv.org\/pdf\/2110.08381v1","1627":"http:\/\/export.arxiv.org\/pdf\/2110.15733v1","1628":"http:\/\/export.arxiv.org\/pdf\/2110.08355v1","1629":"http:\/\/export.arxiv.org\/pdf\/2110.08352v1","1630":"http:\/\/export.arxiv.org\/pdf\/2110.08323v1","1631":"http:\/\/export.arxiv.org\/pdf\/2104.02145v3","1632":"http:\/\/export.arxiv.org\/pdf\/2106.02016v2","1633":"http:\/\/export.arxiv.org\/pdf\/2106.06797v2","1634":"http:\/\/export.arxiv.org\/pdf\/2109.04712v2","1635":"http:\/\/export.arxiv.org\/pdf\/2110.08247v1","1636":"http:\/\/export.arxiv.org\/pdf\/2110.08246v1","1637":"http:\/\/export.arxiv.org\/pdf\/2110.08241v1","1638":"http:\/\/export.arxiv.org\/pdf\/2110.08228v1","1639":"http:\/\/export.arxiv.org\/pdf\/2107.12079v3","1640":"http:\/\/export.arxiv.org\/pdf\/2110.08213v1","1641":"http:\/\/export.arxiv.org\/pdf\/2110.08182v1","1642":"http:\/\/export.arxiv.org\/pdf\/2110.08175v1","1643":"http:\/\/export.arxiv.org\/pdf\/2110.08152v1","1644":"http:\/\/export.arxiv.org\/pdf\/2110.08118v1","1645":"http:\/\/export.arxiv.org\/pdf\/2104.07198v2","1646":"http:\/\/export.arxiv.org\/pdf\/2110.08036v1","1647":"http:\/\/export.arxiv.org\/pdf\/2110.08032v1","1648":"http:\/\/export.arxiv.org\/pdf\/2110.08021v1","1649":"http:\/\/export.arxiv.org\/pdf\/2110.08020v1","1650":"http:\/\/export.arxiv.org\/pdf\/2110.08015v1","1651":"http:\/\/export.arxiv.org\/pdf\/2110.08011v1","1652":"http:\/\/export.arxiv.org\/pdf\/2110.08010v1","1653":"http:\/\/export.arxiv.org\/pdf\/2012.02957v2","1654":"http:\/\/export.arxiv.org\/pdf\/2110.07982v1","1655":"http:\/\/export.arxiv.org\/pdf\/2106.04258v3","1656":"http:\/\/export.arxiv.org\/pdf\/2110.07938v1","1657":"http:\/\/export.arxiv.org\/pdf\/2106.07385v3","1658":"http:\/\/export.arxiv.org\/pdf\/2110.07918v1","1659":"http:\/\/export.arxiv.org\/pdf\/2110.07909v1","1660":"http:\/\/export.arxiv.org\/pdf\/2108.10643v2","1661":"http:\/\/export.arxiv.org\/pdf\/2110.11984v1","1662":"http:\/\/export.arxiv.org\/pdf\/2110.07867v1","1663":"http:\/\/export.arxiv.org\/pdf\/2110.07850v1","1664":"http:\/\/export.arxiv.org\/pdf\/2109.13348v2","1665":"http:\/\/export.arxiv.org\/pdf\/2110.07844v1","1666":"http:\/\/export.arxiv.org\/pdf\/2110.07840v1","1667":"http:\/\/export.arxiv.org\/pdf\/2110.07837v1","1668":"http:\/\/export.arxiv.org\/pdf\/2110.07833v1","1669":"http:\/\/export.arxiv.org\/pdf\/2110.07831v1","1670":"http:\/\/export.arxiv.org\/pdf\/2110.15732v1","1671":"http:\/\/export.arxiv.org\/pdf\/2101.03289v5","1672":"http:\/\/export.arxiv.org\/pdf\/2110.07827v1","1673":"http:\/\/export.arxiv.org\/pdf\/2110.00678v3","1674":"http:\/\/export.arxiv.org\/pdf\/2110.07816v1","1675":"http:\/\/export.arxiv.org\/pdf\/2110.07811v1","1676":"http:\/\/export.arxiv.org\/pdf\/2110.07804v1","1677":"http:\/\/export.arxiv.org\/pdf\/2110.07792v1","1678":"http:\/\/export.arxiv.org\/pdf\/2104.08737v2","1679":"http:\/\/export.arxiv.org\/pdf\/2107.11020v2","1680":"http:\/\/export.arxiv.org\/pdf\/2110.07736v1","1681":"http:\/\/export.arxiv.org\/pdf\/2104.08540v2","1682":"http:\/\/export.arxiv.org\/pdf\/2110.06823v2","1683":"http:\/\/export.arxiv.org\/pdf\/2109.04726v2","1684":"http:\/\/export.arxiv.org\/pdf\/2110.07693v1","1685":"http:\/\/export.arxiv.org\/pdf\/2110.06495v2","1686":"http:\/\/export.arxiv.org\/pdf\/2110.07686v1","1687":"http:\/\/export.arxiv.org\/pdf\/2110.06209v2","1688":"http:\/\/export.arxiv.org\/pdf\/2108.08102v3","1689":"http:\/\/export.arxiv.org\/pdf\/2110.07640v1","1690":"http:\/\/export.arxiv.org\/pdf\/2110.07595v1","1691":"http:\/\/export.arxiv.org\/pdf\/2110.07581v1","1692":"http:\/\/export.arxiv.org\/pdf\/2110.07575v1","1693":"http:\/\/export.arxiv.org\/pdf\/2110.07574v1","1694":"http:\/\/export.arxiv.org\/pdf\/2110.07572v1","1695":"http:\/\/export.arxiv.org\/pdf\/2110.07566v1","1696":"http:\/\/export.arxiv.org\/pdf\/2110.07560v1","1697":"http:\/\/export.arxiv.org\/pdf\/2110.07550v1","1698":"http:\/\/export.arxiv.org\/pdf\/2105.11314v2","1699":"http:\/\/export.arxiv.org\/pdf\/2110.07515v1","1700":"http:\/\/export.arxiv.org\/pdf\/2109.11728v3","1701":"http:\/\/export.arxiv.org\/pdf\/2110.07477v1","1702":"http:\/\/export.arxiv.org\/pdf\/2108.00719v3","1703":"http:\/\/export.arxiv.org\/pdf\/2110.07444v1","1704":"http:\/\/export.arxiv.org\/pdf\/2110.07431v1","1705":"http:\/\/export.arxiv.org\/pdf\/2110.07420v1","1706":"http:\/\/export.arxiv.org\/pdf\/2110.07410v1","1707":"http:\/\/export.arxiv.org\/pdf\/2110.07383v1","1708":"http:\/\/export.arxiv.org\/pdf\/2110.07382v1","1709":"http:\/\/export.arxiv.org\/pdf\/1911.01528v4","1710":"http:\/\/export.arxiv.org\/pdf\/2110.07367v1","1711":"http:\/\/export.arxiv.org\/pdf\/2110.07331v1","1712":"http:\/\/export.arxiv.org\/pdf\/2110.07330v1","1713":"http:\/\/export.arxiv.org\/pdf\/2110.07310v1","1714":"http:\/\/export.arxiv.org\/pdf\/1904.06217v3","1715":"http:\/\/export.arxiv.org\/pdf\/2104.11710v2","1716":"http:\/\/export.arxiv.org\/pdf\/2110.07304v1","1717":"http:\/\/export.arxiv.org\/pdf\/2110.07303v1","1718":"http:\/\/export.arxiv.org\/pdf\/2010.12643v2","1719":"http:\/\/export.arxiv.org\/pdf\/2109.10604v2","1720":"http:\/\/export.arxiv.org\/pdf\/2110.07240v1","1721":"http:\/\/export.arxiv.org\/pdf\/2110.05896v3","1722":"http:\/\/export.arxiv.org\/pdf\/2110.06696v2","1723":"http:\/\/export.arxiv.org\/pdf\/2110.07210v1","1724":"http:\/\/export.arxiv.org\/pdf\/2110.07209v1","1725":"http:\/\/export.arxiv.org\/pdf\/2110.08049v1","1726":"http:\/\/export.arxiv.org\/pdf\/2110.07178v1","1727":"http:\/\/export.arxiv.org\/pdf\/2110.07174v1","1728":"http:\/\/export.arxiv.org\/pdf\/2110.07166v1","1729":"http:\/\/export.arxiv.org\/pdf\/2110.07161v1","1730":"http:\/\/export.arxiv.org\/pdf\/2110.07160v1","1731":"http:\/\/export.arxiv.org\/pdf\/2110.07150v1","1732":"http:\/\/export.arxiv.org\/pdf\/2110.07143v1","1733":"http:\/\/export.arxiv.org\/pdf\/2110.07139v1","1734":"http:\/\/export.arxiv.org\/pdf\/2110.07137v1","1735":"http:\/\/export.arxiv.org\/pdf\/2109.15196v2","1736":"http:\/\/export.arxiv.org\/pdf\/2110.07055v1","1737":"http:\/\/export.arxiv.org\/pdf\/2110.07031v1","1738":"http:\/\/export.arxiv.org\/pdf\/2103.06960v2","1739":"http:\/\/export.arxiv.org\/pdf\/2110.07027v1","1740":"http:\/\/export.arxiv.org\/pdf\/2109.06304v2","1741":"http:\/\/export.arxiv.org\/pdf\/2010.01496v2","1742":"http:\/\/export.arxiv.org\/pdf\/2110.07002v1","1743":"http:\/\/export.arxiv.org\/pdf\/2101.00371v2","1744":"http:\/\/export.arxiv.org\/pdf\/2110.06997v1","1745":"http:\/\/export.arxiv.org\/pdf\/2110.06962v1","1746":"http:\/\/export.arxiv.org\/pdf\/2110.06920v1","1747":"http:\/\/export.arxiv.org\/pdf\/2104.08161v2","1748":"http:\/\/export.arxiv.org\/pdf\/2110.06905v1","1749":"http:\/\/export.arxiv.org\/pdf\/2110.06894v1","1750":"http:\/\/export.arxiv.org\/pdf\/2110.06884v1","1751":"http:\/\/export.arxiv.org\/pdf\/2110.06874v1","1752":"http:\/\/export.arxiv.org\/pdf\/2110.06865v1","1753":"http:\/\/export.arxiv.org\/pdf\/2102.03044v4","1754":"http:\/\/export.arxiv.org\/pdf\/2110.06847v1","1755":"http:\/\/export.arxiv.org\/pdf\/2110.06821v1","1756":"http:\/\/export.arxiv.org\/pdf\/2110.06744v1","1757":"http:\/\/export.arxiv.org\/pdf\/2110.06733v1","1758":"http:\/\/export.arxiv.org\/pdf\/2110.06674v1","1759":"http:\/\/export.arxiv.org\/pdf\/2108.12026v2","1760":"http:\/\/export.arxiv.org\/pdf\/2110.06620v1","1761":"http:\/\/export.arxiv.org\/pdf\/2110.15730v1","1762":"http:\/\/export.arxiv.org\/pdf\/2105.02544v2","1763":"http:\/\/export.arxiv.org\/pdf\/2110.15729v1","1764":"http:\/\/export.arxiv.org\/pdf\/2110.06560v1","1765":"http:\/\/export.arxiv.org\/pdf\/2110.08254v1","1766":"http:\/\/export.arxiv.org\/pdf\/2109.07833v2","1767":"http:\/\/export.arxiv.org\/pdf\/2012.12641v3","1768":"http:\/\/export.arxiv.org\/pdf\/2110.06533v1","1769":"http:\/\/export.arxiv.org\/pdf\/2109.13662v3","1770":"http:\/\/export.arxiv.org\/pdf\/2110.06510v1","1771":"http:\/\/export.arxiv.org\/pdf\/2110.06507v1","1772":"http:\/\/export.arxiv.org\/pdf\/2110.06500v1","1773":"http:\/\/export.arxiv.org\/pdf\/2107.05541v6","1774":"http:\/\/export.arxiv.org\/pdf\/2110.06486v1","1775":"http:\/\/export.arxiv.org\/pdf\/2110.06474v1","1776":"http:\/\/export.arxiv.org\/pdf\/2110.06461v1","1777":"http:\/\/export.arxiv.org\/pdf\/2110.06446v1","1778":"http:\/\/export.arxiv.org\/pdf\/2110.05748v2","1779":"http:\/\/export.arxiv.org\/pdf\/2110.06419v1","1780":"http:\/\/export.arxiv.org\/pdf\/2109.03137v2","1781":"http:\/\/export.arxiv.org\/pdf\/2110.06397v1","1782":"http:\/\/export.arxiv.org\/pdf\/2110.06393v1","1783":"http:\/\/export.arxiv.org\/pdf\/2110.06384v1","1784":"http:\/\/export.arxiv.org\/pdf\/2110.06376v1","1785":"http:\/\/export.arxiv.org\/pdf\/2110.06341v1","1786":"http:\/\/export.arxiv.org\/pdf\/2110.06288v1","1787":"http:\/\/export.arxiv.org\/pdf\/2110.06280v1","1788":"http:\/\/export.arxiv.org\/pdf\/2110.06274v1","1789":"http:\/\/export.arxiv.org\/pdf\/2110.06223v1","1790":"http:\/\/export.arxiv.org\/pdf\/2110.07333v1","1791":"http:\/\/export.arxiv.org\/pdf\/2110.06151v1","1792":"http:\/\/export.arxiv.org\/pdf\/2110.06078v1","1793":"http:\/\/export.arxiv.org\/pdf\/2104.08512v2","1794":"http:\/\/export.arxiv.org\/pdf\/2110.15728v1","1795":"http:\/\/export.arxiv.org\/pdf\/2110.05999v1","1796":"http:\/\/export.arxiv.org\/pdf\/2110.02869v3","1797":"http:\/\/export.arxiv.org\/pdf\/2110.05892v1","1798":"http:\/\/export.arxiv.org\/pdf\/2110.05877v1","1799":"http:\/\/export.arxiv.org\/pdf\/2110.05146v2","1800":"http:\/\/export.arxiv.org\/pdf\/2110.05866v1","1801":"http:\/\/export.arxiv.org\/pdf\/2106.05707v3","1802":"http:\/\/export.arxiv.org\/pdf\/2110.05006v2","1803":"http:\/\/export.arxiv.org\/pdf\/2110.05847v1","1804":"http:\/\/export.arxiv.org\/pdf\/2110.05838v1","1805":"http:\/\/export.arxiv.org\/pdf\/2105.12667v2","1806":"http:\/\/export.arxiv.org\/pdf\/2008.12804v4","1807":"http:\/\/export.arxiv.org\/pdf\/2110.05780v1","1808":"http:\/\/export.arxiv.org\/pdf\/2110.05775v1","1809":"http:\/\/export.arxiv.org\/pdf\/2103.03125v2","1810":"http:\/\/export.arxiv.org\/pdf\/2110.04984v2","1811":"http:\/\/export.arxiv.org\/pdf\/2110.05752v1","1812":"http:\/\/export.arxiv.org\/pdf\/2110.05750v1","1813":"http:\/\/export.arxiv.org\/pdf\/2110.05727v1","1814":"http:\/\/export.arxiv.org\/pdf\/2110.05723v1","1815":"http:\/\/export.arxiv.org\/pdf\/2110.05719v1","1816":"http:\/\/export.arxiv.org\/pdf\/2109.01951v3","1817":"http:\/\/export.arxiv.org\/pdf\/2110.05699v1","1818":"http:\/\/export.arxiv.org\/pdf\/2110.04725v2","1819":"http:\/\/export.arxiv.org\/pdf\/2110.05691v1","1820":"http:\/\/export.arxiv.org\/pdf\/2110.05679v1","1821":"http:\/\/export.arxiv.org\/pdf\/2110.05665v1","1822":"http:\/\/export.arxiv.org\/pdf\/2104.12763v2","1823":"http:\/\/export.arxiv.org\/pdf\/2110.05663v1","1824":"http:\/\/export.arxiv.org\/pdf\/2110.05633v1","1825":"http:\/\/export.arxiv.org\/pdf\/2110.05573v1","1826":"http:\/\/export.arxiv.org\/pdf\/2110.05571v1","1827":"http:\/\/export.arxiv.org\/pdf\/2110.05464v1","1828":"http:\/\/export.arxiv.org\/pdf\/2110.05456v1","1829":"http:\/\/export.arxiv.org\/pdf\/2110.05448v1","1830":"http:\/\/export.arxiv.org\/pdf\/2110.05423v1","1831":"http:\/\/export.arxiv.org\/pdf\/2110.05422v1","1832":"http:\/\/export.arxiv.org\/pdf\/2109.09725v4","1833":"http:\/\/export.arxiv.org\/pdf\/2110.05376v1","1834":"http:\/\/export.arxiv.org\/pdf\/2110.05369v1","1835":"http:\/\/export.arxiv.org\/pdf\/2110.05367v1","1836":"http:\/\/export.arxiv.org\/pdf\/2110.05362v1","1837":"http:\/\/export.arxiv.org\/pdf\/2106.08858v2","1838":"http:\/\/export.arxiv.org\/pdf\/2110.05301v1","1839":"http:\/\/export.arxiv.org\/pdf\/2110.05287v1","1840":"http:\/\/export.arxiv.org\/pdf\/2110.05249v1","1841":"http:\/\/export.arxiv.org\/pdf\/2110.05221v1","1842":"http:\/\/export.arxiv.org\/pdf\/2110.05213v1","1843":"http:\/\/export.arxiv.org\/pdf\/2110.05172v1","1844":"http:\/\/export.arxiv.org\/pdf\/2109.11377v2","1845":"http:\/\/export.arxiv.org\/pdf\/2105.05887v2","1846":"http:\/\/export.arxiv.org\/pdf\/2111.04416v1","1847":"http:\/\/export.arxiv.org\/pdf\/1902.02181v4","1848":"http:\/\/export.arxiv.org\/pdf\/2110.05133v1","1849":"http:\/\/export.arxiv.org\/pdf\/2109.14776v2","1850":"http:\/\/export.arxiv.org\/pdf\/2110.05115v1","1851":"http:\/\/export.arxiv.org\/pdf\/2110.05111v1","1852":"http:\/\/export.arxiv.org\/pdf\/2010.04480v3","1853":"http:\/\/export.arxiv.org\/pdf\/2010.03855v3","1854":"http:\/\/export.arxiv.org\/pdf\/2110.05071v1","1855":"http:\/\/export.arxiv.org\/pdf\/2110.15727v1","1856":"http:\/\/export.arxiv.org\/pdf\/2110.03873v2","1857":"http:\/\/export.arxiv.org\/pdf\/2110.05021v1","1858":"http:\/\/export.arxiv.org\/pdf\/2110.04977v1","1859":"http:\/\/export.arxiv.org\/pdf\/2110.04932v1","1860":"http:\/\/export.arxiv.org\/pdf\/2110.04889v1","1861":"http:\/\/export.arxiv.org\/pdf\/2110.04888v1","1862":"http:\/\/export.arxiv.org\/pdf\/2104.12265v5","1863":"http:\/\/export.arxiv.org\/pdf\/2104.12227v5","1864":"http:\/\/export.arxiv.org\/pdf\/2105.07510v2","1865":"http:\/\/export.arxiv.org\/pdf\/2110.00116v2","1866":"http:\/\/export.arxiv.org\/pdf\/2110.04878v1","1867":"http:\/\/export.arxiv.org\/pdf\/2110.04863v1","1868":"http:\/\/export.arxiv.org\/pdf\/2105.00826v2","1869":"http:\/\/export.arxiv.org\/pdf\/2110.15725v1","1870":"http:\/\/export.arxiv.org\/pdf\/2110.04845v1","1871":"http:\/\/export.arxiv.org\/pdf\/2109.02401v4","1872":"http:\/\/export.arxiv.org\/pdf\/2110.15724v1","1873":"http:\/\/export.arxiv.org\/pdf\/2110.04821v1","1874":"http:\/\/export.arxiv.org\/pdf\/2110.15723v1","1875":"http:\/\/export.arxiv.org\/pdf\/2110.04794v1","1876":"http:\/\/export.arxiv.org\/pdf\/2104.07302v2","1877":"http:\/\/export.arxiv.org\/pdf\/2110.03609v2","1878":"http:\/\/export.arxiv.org\/pdf\/2110.04754v1","1879":"http:\/\/export.arxiv.org\/pdf\/2110.04741v1","1880":"http:\/\/export.arxiv.org\/pdf\/2110.04711v1","1881":"http:\/\/export.arxiv.org\/pdf\/2104.08808v3","1882":"http:\/\/export.arxiv.org\/pdf\/2110.04647v1","1883":"http:\/\/export.arxiv.org\/pdf\/2110.04644v1","1884":"http:\/\/export.arxiv.org\/pdf\/2110.04620v1","1885":"http:\/\/export.arxiv.org\/pdf\/2110.04614v1","1886":"http:\/\/export.arxiv.org\/pdf\/2110.04612v1","1887":"http:\/\/export.arxiv.org\/pdf\/2104.08200v3","1888":"http:\/\/export.arxiv.org\/pdf\/2110.04590v1","1889":"http:\/\/export.arxiv.org\/pdf\/2109.09161v2","1890":"http:\/\/export.arxiv.org\/pdf\/2110.04544v1","1891":"http:\/\/export.arxiv.org\/pdf\/2110.04526v1","1892":"http:\/\/export.arxiv.org\/pdf\/2012.01815v2","1893":"http:\/\/export.arxiv.org\/pdf\/2110.04518v1","1894":"http:\/\/export.arxiv.org\/pdf\/2110.04517v1","1895":"http:\/\/export.arxiv.org\/pdf\/2110.04484v1","1896":"http:\/\/export.arxiv.org\/pdf\/2110.04482v1","1897":"http:\/\/export.arxiv.org\/pdf\/2110.04480v1","1898":"http:\/\/export.arxiv.org\/pdf\/2110.04475v1","1899":"http:\/\/export.arxiv.org\/pdf\/2107.09278v2","1900":"http:\/\/export.arxiv.org\/pdf\/2104.09864v2","1901":"http:\/\/export.arxiv.org\/pdf\/2110.04441v1","1902":"http:\/\/export.arxiv.org\/pdf\/2110.04435v1","1903":"http:\/\/export.arxiv.org\/pdf\/2107.04734v2","1904":"http:\/\/export.arxiv.org\/pdf\/2110.04429v1","1905":"http:\/\/export.arxiv.org\/pdf\/2110.04419v1","1906":"http:\/\/export.arxiv.org\/pdf\/2110.07498v1","1907":"http:\/\/export.arxiv.org\/pdf\/2110.04406v1","1908":"http:\/\/export.arxiv.org\/pdf\/2111.04415v1","1909":"http:\/\/export.arxiv.org\/pdf\/2110.04392v1","1910":"http:\/\/export.arxiv.org\/pdf\/2110.04384v1","1911":"http:\/\/export.arxiv.org\/pdf\/2110.04374v1","1912":"http:\/\/export.arxiv.org\/pdf\/2110.03179v2","1913":"http:\/\/export.arxiv.org\/pdf\/2110.04330v1","1914":"http:\/\/export.arxiv.org\/pdf\/2110.04327v1","1915":"http:\/\/export.arxiv.org\/pdf\/2108.07638v2","1916":"http:\/\/export.arxiv.org\/pdf\/2110.04291v1","1917":"http:\/\/export.arxiv.org\/pdf\/2110.04257v1","1918":"http:\/\/export.arxiv.org\/pdf\/2110.04236v1","1919":"http:\/\/export.arxiv.org\/pdf\/2110.04204v1","1920":"http:\/\/export.arxiv.org\/pdf\/2003.06658v4","1921":"http:\/\/export.arxiv.org\/pdf\/2110.04151v1","1922":"http:\/\/export.arxiv.org\/pdf\/2110.04123v1","1923":"http:\/\/export.arxiv.org\/pdf\/2109.05729v3","1924":"http:\/\/export.arxiv.org\/pdf\/2110.04093v1","1925":"http:\/\/export.arxiv.org\/pdf\/2110.04040v1","1926":"http:\/\/export.arxiv.org\/pdf\/2110.02019v2","1927":"http:\/\/export.arxiv.org\/pdf\/2110.11167v1","1928":"http:\/\/export.arxiv.org\/pdf\/2104.02724v2","1929":"http:\/\/export.arxiv.org\/pdf\/2110.04001v1","1930":"http:\/\/export.arxiv.org\/pdf\/2101.10421v2","1931":"http:\/\/export.arxiv.org\/pdf\/2109.11797v2","1932":"http:\/\/export.arxiv.org\/pdf\/2110.03949v1","1933":"http:\/\/export.arxiv.org\/pdf\/2103.15722v4","1934":"http:\/\/export.arxiv.org\/pdf\/2110.03895v1","1935":"http:\/\/export.arxiv.org\/pdf\/2110.03879v1","1936":"http:\/\/export.arxiv.org\/pdf\/2110.03866v1","1937":"http:\/\/export.arxiv.org\/pdf\/2110.03857v1","1938":"http:\/\/export.arxiv.org\/pdf\/2110.03848v1","1939":"http:\/\/export.arxiv.org\/pdf\/2110.03847v1","1940":"http:\/\/export.arxiv.org\/pdf\/2109.06822v2","1941":"http:\/\/export.arxiv.org\/pdf\/2109.04620v2","1942":"http:\/\/export.arxiv.org\/pdf\/2110.05241v1","1943":"http:\/\/export.arxiv.org\/pdf\/2110.02334v2","1944":"http:\/\/export.arxiv.org\/pdf\/2110.03756v1","1945":"http:\/\/export.arxiv.org\/pdf\/2110.03730v1","1946":"http:\/\/export.arxiv.org\/pdf\/2104.08401v2","1947":"http:\/\/export.arxiv.org\/pdf\/2110.03572v1","1948":"http:\/\/export.arxiv.org\/pdf\/2110.03567v1","1949":"http:\/\/export.arxiv.org\/pdf\/2110.03560v1","1950":"http:\/\/export.arxiv.org\/pdf\/2110.03504v1","1951":"http:\/\/export.arxiv.org\/pdf\/2110.03389v1","1952":"http:\/\/export.arxiv.org\/pdf\/2104.08259v2","1953":"http:\/\/export.arxiv.org\/pdf\/2110.03353v1","1954":"http:\/\/export.arxiv.org\/pdf\/2110.03326v1","1955":"http:\/\/export.arxiv.org\/pdf\/2110.03318v1","1956":"http:\/\/export.arxiv.org\/pdf\/2104.07412v2","1957":"http:\/\/export.arxiv.org\/pdf\/2110.03298v1","1958":"http:\/\/export.arxiv.org\/pdf\/2110.03281v1","1959":"http:\/\/export.arxiv.org\/pdf\/2110.03269v1","1960":"http:\/\/export.arxiv.org\/pdf\/2110.03252v1","1961":"http:\/\/export.arxiv.org\/pdf\/2110.03212v1","1962":"http:\/\/export.arxiv.org\/pdf\/2110.03192v1","1963":"http:\/\/export.arxiv.org\/pdf\/2110.02069v2","1964":"http:\/\/export.arxiv.org\/pdf\/2110.03142v1","1965":"http:\/\/export.arxiv.org\/pdf\/2110.02220v2","1966":"http:\/\/export.arxiv.org\/pdf\/2108.03533v3","1967":"http:\/\/export.arxiv.org\/pdf\/2101.10539v4","1968":"http:\/\/export.arxiv.org\/pdf\/2109.00698v2","1969":"http:\/\/export.arxiv.org\/pdf\/2110.03073v1","1970":"http:\/\/export.arxiv.org\/pdf\/2006.03654v6","1971":"http:\/\/export.arxiv.org\/pdf\/2110.03047v1","1972":"http:\/\/export.arxiv.org\/pdf\/2110.03036v1","1973":"http:\/\/export.arxiv.org\/pdf\/2110.15717v1","1974":"http:\/\/export.arxiv.org\/pdf\/2110.02991v1","1975":"http:\/\/export.arxiv.org\/pdf\/2106.07704v3","1976":"http:\/\/export.arxiv.org\/pdf\/2110.02887v1","1977":"http:\/\/export.arxiv.org\/pdf\/2110.02884v1","1978":"http:\/\/export.arxiv.org\/pdf\/2110.02848v1","1979":"http:\/\/export.arxiv.org\/pdf\/2110.02834v1","1980":"http:\/\/export.arxiv.org\/pdf\/2110.02791v1","1981":"http:\/\/export.arxiv.org\/pdf\/2104.07012v2","1982":"http:\/\/export.arxiv.org\/pdf\/2104.13225v3","1983":"http:\/\/export.arxiv.org\/pdf\/2107.14638v4","1984":"http:\/\/export.arxiv.org\/pdf\/2110.02708v1","1985":"http:\/\/export.arxiv.org\/pdf\/2110.02204v2","1986":"http:\/\/export.arxiv.org\/pdf\/2110.02591v1","1987":"http:\/\/export.arxiv.org\/pdf\/2110.02577v1","1988":"http:\/\/export.arxiv.org\/pdf\/2108.12777v2","1989":"http:\/\/export.arxiv.org\/pdf\/2110.02523v1","1990":"http:\/\/export.arxiv.org\/pdf\/2008.12813v2","1991":"http:\/\/export.arxiv.org\/pdf\/2110.02488v1","1992":"http:\/\/export.arxiv.org\/pdf\/2109.14788v2","1993":"http:\/\/export.arxiv.org\/pdf\/2110.02467v1","1994":"http:\/\/export.arxiv.org\/pdf\/2102.02340v2","1995":"http:\/\/export.arxiv.org\/pdf\/2012.02821v2","1996":"http:\/\/export.arxiv.org\/pdf\/2110.02432v1","1997":"http:\/\/export.arxiv.org\/pdf\/2110.02411v1","1998":"http:\/\/export.arxiv.org\/pdf\/2110.02406v1","1999":"http:\/\/export.arxiv.org\/pdf\/2110.02402v1","2000":"http:\/\/export.arxiv.org\/pdf\/2110.15716v1","2001":"http:\/\/export.arxiv.org\/pdf\/2110.02386v1","2002":"http:\/\/export.arxiv.org\/pdf\/2012.15524v3","2003":"http:\/\/export.arxiv.org\/pdf\/2110.02370v1","2004":"http:\/\/export.arxiv.org\/pdf\/2106.03269v3","2005":"http:\/\/export.arxiv.org\/pdf\/2010.11918v2","2006":"http:\/\/export.arxiv.org\/pdf\/2110.02207v1","2007":"http:\/\/export.arxiv.org\/pdf\/2110.02200v1","2008":"http:\/\/export.arxiv.org\/pdf\/2109.15101v2","2009":"http:\/\/export.arxiv.org\/pdf\/2110.02198v1","2010":"http:\/\/export.arxiv.org\/pdf\/2110.01159v2","2011":"http:\/\/export.arxiv.org\/pdf\/2004.03422v3","2012":"http:\/\/export.arxiv.org\/pdf\/2110.03427v1","2013":"http:\/\/export.arxiv.org\/pdf\/2007.11073v2","2014":"http:\/\/export.arxiv.org\/pdf\/2110.02148v1","2015":"http:\/\/export.arxiv.org\/pdf\/2004.14848v2","2016":"http:\/\/export.arxiv.org\/pdf\/2104.04298v3","2017":"http:\/\/export.arxiv.org\/pdf\/2109.12870v2","2018":"http:\/\/export.arxiv.org\/pdf\/2110.02067v1","2019":"http:\/\/export.arxiv.org\/pdf\/2110.02047v1","2020":"http:\/\/export.arxiv.org\/pdf\/2110.02042v1","2021":"http:\/\/export.arxiv.org\/pdf\/2110.02035v1","2022":"http:\/\/export.arxiv.org\/pdf\/2006.11063v4","2023":"http:\/\/export.arxiv.org\/pdf\/2110.02030v1","2024":"http:\/\/export.arxiv.org\/pdf\/2110.01951v1","2025":"http:\/\/export.arxiv.org\/pdf\/2110.01948v1","2026":"http:\/\/export.arxiv.org\/pdf\/2110.01938v1","2027":"http:\/\/export.arxiv.org\/pdf\/2110.01857v1","2028":"http:\/\/export.arxiv.org\/pdf\/2110.09321v1","2029":"http:\/\/export.arxiv.org\/pdf\/2110.01839v1","2030":"http:\/\/export.arxiv.org\/pdf\/2109.14895v2","2031":"http:\/\/export.arxiv.org\/pdf\/2110.15709v1","2032":"http:\/\/export.arxiv.org\/pdf\/2110.01811v1","2033":"http:\/\/export.arxiv.org\/pdf\/2110.01804v1","2034":"http:\/\/export.arxiv.org\/pdf\/2110.01799v1","2035":"http:\/\/export.arxiv.org\/pdf\/2102.11573v2","2036":"http:\/\/export.arxiv.org\/pdf\/2110.15710v1","2037":"http:\/\/export.arxiv.org\/pdf\/2105.06829v2","2038":"http:\/\/export.arxiv.org\/pdf\/2007.15342v4","2039":"http:\/\/export.arxiv.org\/pdf\/2110.01643v1","2040":"http:\/\/export.arxiv.org\/pdf\/2110.01599v1","2041":"http:\/\/export.arxiv.org\/pdf\/2110.03529v1","2042":"http:\/\/export.arxiv.org\/pdf\/2110.01552v1","2043":"http:\/\/export.arxiv.org\/pdf\/2110.01550v1","2044":"http:\/\/export.arxiv.org\/pdf\/2110.01518v1","2045":"http:\/\/export.arxiv.org\/pdf\/2104.07540v3","2046":"http:\/\/export.arxiv.org\/pdf\/2012.11926v2","2047":"http:\/\/export.arxiv.org\/pdf\/2110.01425v1","2048":"http:\/\/export.arxiv.org\/pdf\/2104.08792v2","2049":"http:\/\/export.arxiv.org\/pdf\/2110.03663v1","2050":"http:\/\/export.arxiv.org\/pdf\/2109.11491v2","2051":"http:\/\/export.arxiv.org\/pdf\/2007.13626v2","2052":"http:\/\/export.arxiv.org\/pdf\/2110.01349v1","2053":"http:\/\/export.arxiv.org\/pdf\/2110.01336v1","2054":"http:\/\/export.arxiv.org\/pdf\/2109.03228v2","2055":"http:\/\/export.arxiv.org\/pdf\/2109.07926v2","2056":"http:\/\/export.arxiv.org\/pdf\/2110.01295v1","2057":"http:\/\/export.arxiv.org\/pdf\/2110.01280v1","2058":"http:\/\/export.arxiv.org\/pdf\/2110.01258v1","2059":"http:\/\/export.arxiv.org\/pdf\/2110.01256v1","2060":"http:\/\/export.arxiv.org\/pdf\/2110.03664v1","2061":"http:\/\/export.arxiv.org\/pdf\/2110.01186v1","2062":"http:\/\/export.arxiv.org\/pdf\/2110.01176v1","2063":"http:\/\/export.arxiv.org\/pdf\/2110.01160v1","2064":"http:\/\/export.arxiv.org\/pdf\/2110.01140v1","2065":"http:\/\/export.arxiv.org\/pdf\/2110.01113v1","2066":"http:\/\/export.arxiv.org\/pdf\/2110.01094v1","2067":"http:\/\/export.arxiv.org\/pdf\/2109.09276v2","2068":"http:\/\/export.arxiv.org\/pdf\/2110.01078v1","2069":"http:\/\/export.arxiv.org\/pdf\/2110.01073v1"},"category":{"0":["cs.CL","cs.LG"],"1":["cs.CL","cs.LG"],"2":["cs.CV","cs.CL","cs.LG"],"3":["cs.CL","cs.LG"],"4":["cs.LG","cs.CL"],"5":["cs.CL"],"6":["cs.CL"],"7":["cs.CL"],"8":["cs.CV","cs.CL"],"9":["cs.CL","cs.LG"],"10":["cs.CV","cs.CL"],"11":["cs.LG","cs.AI","cs.CL"],"12":["cs.CL","cs.AI"],"13":["cs.CL"],"14":["cs.CL"],"15":["cs.CL"],"16":["cs.CL","cs.AI"],"17":["cs.CL","cs.AI"],"18":["cs.CL"],"19":["eess.IV","cs.CL","cs.CV"],"20":["eess.IV","cs.CL","cs.CV"],"21":["cs.CL","cs.AI"],"22":["cs.CL","cs.AI","cs.LG"],"23":["cs.AI","cs.CL"],"24":["cs.CL","cs.AI"],"25":["cs.CL"],"26":["cs.SD","cs.CL","eess.AS"],"27":["cs.CL","cs.LG"],"28":["cs.CL","cs.LG","cs.SD","eess.AS"],"29":["cs.CL"],"30":["cs.CL","I.2.1; I.2.7"],"31":["cs.CL","cs.LG"],"32":["cs.CL","cs.LG"],"33":["cs.CL"],"34":["cs.CL","cs.AI","cs.LG","68T50, 91F20","I.2.7"],"35":["cs.CL"],"36":["cs.SD","cs.CL","eess.AS"],"37":["cs.SD","cs.CL","eess.AS"],"38":["cs.CL"],"39":["cs.CL"],"40":["cs.CL","cs.AI","cs.CR"],"41":["cs.LG","cs.CL"],"42":["cs.CV","cs.AI","cs.CL","cs.RO"],"43":["cs.CL","cs.AI"],"44":["cs.CL"],"45":["cs.IR","cs.CL"],"46":["cs.CL"],"47":["cs.CL"],"48":["cs.CL","cs.HC"],"49":["cs.IR","cs.CL"],"50":["cs.CL","cs.AI","cs.IR","cs.LG"],"51":["cs.IT","cs.CL","math.IT"],"52":["cs.CL","cs.CY"],"53":["cs.CL"],"54":["cs.CL","cs.LG"],"55":["cs.LO","cs.CL"],"56":["cs.CL"],"57":["cs.CL","cs.AI"],"58":["cs.CL","cs.LG"],"59":["cs.CL"],"60":["cs.CL","cs.IR"],"61":["cs.CV","cs.AI","cs.CL","cs.LG"],"62":["cs.CL"],"63":["cs.CL"],"64":["cs.CL","cs.AI"],"65":["cs.CL"],"66":["eess.SY","cs.CL","cs.LO","cs.SY"],"67":["cs.CL","cs.LG"],"68":["cs.CL","cs.AI"],"69":["cs.CL","cs.AI","cs.LG","cs.RO"],"70":["cs.CL"],"71":["cs.CL","cs.IR","cs.LG"],"72":["cs.CL","cs.LG","stat.CO","stat.ML","62G, 62P","J.5"],"73":["cs.CL"],"74":["cs.CL"],"75":["cs.CL"],"76":["cs.CL","91F20, 62C10, 94-10, 94A17, 68T37"],"77":["cs.CL","cs.AI"],"78":["cs.CL","cs.IR"],"79":["cs.CL"],"80":["cs.CL","cs.LG"],"81":["cs.CL","cs.AI"],"82":["cs.CL","cs.AI"],"83":["cs.CR","cs.CL","cs.LG"],"84":["cs.CL","cs.NE"],"85":["cs.CL"],"86":["cs.CL"],"87":["cs.CL","cs.AI","cs.CV","I.2.1; I.2.7; I.4.9"],"88":["cs.CL"],"89":["cs.CL"],"90":["cs.CL","cs.AI"],"91":["quant-ph","cs.CL","cs.DS"],"92":["cs.CL","cs.LG"],"93":["cs.CL"],"94":["cs.CL"],"95":["cs.CL","cs.AI","cs.LG","I.2.7; I.2.4; I.2.11"],"96":["cs.CL","cs.AI"],"97":["cs.CL"],"98":["cs.CL","cs.AI","cs.IR"],"99":["cs.CL"],"100":["cs.CL"],"101":["cs.CL"],"102":["cs.CL"],"103":["cs.CL","cs.IR"],"104":["cs.CL","cs.AI"],"105":["cs.CL","cs.AI","cs.LG"],"106":["cs.CL","cs.LG","68T50, 68T07","I.2.7"],"107":["cs.CL","cs.HC"],"108":["cs.CL"],"109":["cs.CL","cs.LG"],"110":["cs.CL"],"111":["cs.CL"],"112":["cs.CL"],"113":["cs.CL"],"114":["cs.CL"],"115":["cs.LG","cs.CL"],"116":["cs.CL"],"117":["cs.CL","cs.AI","cs.MA","cs.RO"],"118":["cs.CL","cs.SD","eess.AS"],"119":["cs.CL"],"120":["cs.CL"],"121":["cs.CL","cs.AI"],"122":["cs.CL"],"123":["cs.CL","J.5"],"124":["cs.CL","cs.AI"],"125":["cs.CL"],"126":["cs.CL","cs.CY"],"127":["cs.CL"],"128":["cs.LG","cs.CL"],"129":["cs.CL","I.2.7; K.3.1"],"130":["cs.CL"],"131":["cs.CL","cs.AI","cs.CV"],"132":["cs.CL"],"133":["cs.CL"],"134":["cs.DL","cs.CL","cs.IR"],"135":["cs.CL","cs.LG"],"136":["cs.CL"],"137":["cs.CC","cs.CL"],"138":["cs.CL"],"139":["cs.CL"],"140":["cs.CL","cs.AI","cs.LG"],"141":["cs.AI","cs.CL"],"142":["cs.CL","cs.AI"],"143":["cs.CL","cs.SD","eess.AS"],"144":["cs.CL","cs.AI","cs.LG"],"145":["cs.CL","cs.LG"],"146":["cs.CL","cs.AI"],"147":["cs.CL","cs.AI"],"148":["cs.CL","cs.AI","cs.CR","cs.LG"],"149":["cs.RO","cs.CL"],"150":["cs.CL","cs.AI","cs.LG"],"151":["cs.AI","cs.CL","cs.CY","cs.HC","cs.LG"],"152":["cs.CL","cs.LG","cs.SD","eess.AS"],"153":["cs.CL","cs.LG"],"154":["cs.LG","cs.CL"],"155":["cs.CL"],"156":["cs.IR","cs.AI","cs.CL","cs.CV"],"157":["cs.CL","cs.IR"],"158":["cs.CL","cs.LO","cs.SC"],"159":["cs.CL","cs.AI"],"160":["cs.LG","cs.CL"],"161":["cs.CL","cs.LG"],"162":["cs.CL","cs.IR","H.3.3; I.2.7"],"163":["cs.CL","cs.SD","eess.AS"],"164":["q-bio.NC","cs.CL","quant-ph"],"165":["cs.CL","eess.SP"],"166":["cs.CV","cs.AI","cs.CL","cs.CR","cs.MM"],"167":["cs.CL","cs.AI"],"168":["cs.DB","cs.AI","cs.CL"],"169":["cs.CL"],"170":["cs.CL","cs.IR","cs.LG"],"171":["cs.CL","cs.AI","cs.LG"],"172":["cs.CL","cs.AI"],"173":["cs.CL","cs.AI","cs.SI"],"174":["cs.CL","cs.AI","stat.ML"],"175":["cs.LG","cs.CL","cs.SD","eess.AS"],"176":["cs.CL"],"177":["cs.CL","cs.AI"],"178":["cs.CL","cs.LG"],"179":["cs.CL","cs.AI","quant-ph"],"180":["cs.CL","cs.AI"],"181":["cs.CL"],"182":["cs.CL","cs.IR"],"183":["cs.CL","cs.SD","eess.AS"],"184":["cs.CL","cs.IR"],"185":["cs.SE","cs.CL","cs.LG"],"186":["cs.CL","cs.LG","eess.AS"],"187":["cs.CL"],"188":["cs.CL"],"189":["cs.CL","cs.AI"],"190":["cs.CL","cs.CY","cs.LG"],"191":["cs.CL","cs.AI","cs.LG","cs.NE"],"192":["cs.CL","cs.AI","cs.LG"],"193":["cs.CL","cs.AI","cs.IR","stat.AP"],"194":["cs.CL"],"195":["cs.CL","cs.AI","cs.IR","cs.LG"],"196":["cs.CL","cs.AI"],"197":["cs.CL","cs.AI","cs.HC","cs.IR","cs.LG"],"198":["cs.CL","cs.AI","cs.LG","cs.PF"],"199":["cs.CL"],"200":["cs.CL","cs.SD","eess.AS"],"201":["cs.CL"],"202":["cs.CL","cs.AI"],"203":["cs.CL","cs.AI"],"204":["cs.CL"],"205":["cs.CL"],"206":["cs.CL","cs.AI","cs.LG"],"207":["cs.CL"],"208":["cs.CL","cs.AI"],"209":["cs.IR","cs.CL"],"210":["cs.CL"],"211":["cs.CL"],"212":["cs.IR","cs.CL","cs.LG","cs.SI"],"213":["cs.CL"],"214":["cs.CL"],"215":["cs.CL"],"216":["cs.CL","cs.LG"],"217":["cs.CL","cs.LG"],"218":["cs.CL"],"219":["cs.CL","cs.LG"],"220":["cs.IR","cs.AI","cs.CL"],"221":["cs.LG","cs.CL"],"222":["cs.CL","cs.LG"],"223":["cs.LG","cs.CL"],"224":["cs.CL","cs.LG"],"225":["cs.CL","cs.AI","cs.SI"],"226":["cs.CL"],"227":["cs.CL","cs.AI"],"228":["cs.CL","cs.AI","cs.LG"],"229":["cs.CL","cs.AI","cs.LG"],"230":["cs.CL","cs.AI"],"231":["cs.CL"],"232":["cs.CY","cs.CL","62G10","J.4"],"233":["cs.CL"],"234":["cs.CL"],"235":["cs.LG","cs.AI","cs.CL","cs.CV"],"236":["cs.IR","cs.AI","cs.CL"],"237":["cs.CL"],"238":["cs.CL","cs.SD","eess.AS"],"239":["cs.CL","cs.AI","cs.LG"],"240":["cs.AI","cs.CL","cs.IR"],"241":["cs.CL"],"242":["cs.CL"],"243":["cs.CV","cs.CL","cs.GR","cs.LG"],"244":["cs.CL"],"245":["cs.CL","cs.CY"],"246":["cs.HC","cs.AI","cs.CL"],"247":["cs.CL","cs.AI"],"248":["cs.CL","cs.DL"],"249":["cs.CL","cs.AI","cs.LG"],"250":["cs.CL"],"251":["cs.CL"],"252":["cs.CL"],"253":["eess.AS","cs.CL"],"254":["cs.CL","cs.LG"],"255":["cs.CL","cs.AI","cs.LG"],"256":["cs.CL","cs.AI"],"257":["cs.CL"],"258":["cs.CL","cs.CV"],"259":["cs.CL"],"260":["cs.CL"],"261":["cs.CV","cs.CL","cs.LG"],"262":["cs.CL"],"263":["cs.CL","cs.LG"],"264":["cs.CL","cs.IR"],"265":["cs.CL"],"266":["cs.CL"],"267":["cs.LG","cs.CL"],"268":["cs.IR","cs.CL"],"269":["cs.CL"],"270":["cs.CL"],"271":["cs.CL","cs.LG"],"272":["cs.CL"],"273":["cs.CL"],"274":["cs.CL"],"275":["cs.CL"],"276":["cs.CL","cs.AI"],"277":["cs.CL"],"278":["cs.CL","cs.AI","cs.CY","cs.LG"],"279":["cs.CV","cs.AI","cs.CL","cs.LG","cs.MM"],"280":["cs.CL"],"281":["cs.CL"],"282":["cs.CL"],"283":["cs.CV","cs.AI","cs.CL"],"284":["cs.CL"],"285":["cs.CL"],"286":["cs.CL"],"287":["cs.CL"],"288":["cs.CL","cs.IR","cs.LG"],"289":["cs.CL","cs.LG"],"290":["cs.IR","cs.AI","cs.CL"],"291":["cs.CL","cs.LG"],"292":["cs.CL"],"293":["cs.CL"],"294":["cs.CL"],"295":["cs.CL","cs.LG"],"296":["cs.CL","cs.AI","cs.LG"],"297":["cs.CL","cs.CV"],"298":["cs.CL"],"299":["cs.CL","cs.AI"],"300":["cs.CL","cs.AI"],"301":["cs.CL","cs.IR"],"302":["cs.CL"],"303":["cs.CL","cs.LG"],"304":["cs.CL"],"305":["cs.CL","cs.AI"],"306":["cs.CL"],"307":["cs.CL"],"308":["cs.CL"],"309":["cs.CL"],"310":["cs.CL"],"311":["cs.CL","cs.HC","cs.LG"],"312":["cs.HC","cs.CL"],"313":["cs.CY","cs.AI","cs.CL"],"314":["cs.AI","cs.CL","cs.LG"],"315":["cs.SE","cs.CL","cs.CR"],"316":["cs.CL","q-fin.ST","91-08","I.2.7"],"317":["cs.CL","I.2.7; I.2.1"],"318":["eess.AS","cs.CL","cs.LG"],"319":["cs.CL"],"320":["cs.CL"],"321":["cs.CL","cs.AI","cs.IR"],"322":["cs.DL","cs.AI","cs.CL"],"323":["cs.AI","cs.CL","cs.CY","I.2.7"],"324":["cs.CL","cs.AI","I.2.7"],"325":["cs.CL","cs.AI"],"326":["eess.AS","cs.CL","cs.LG","cs.SD"],"327":["cs.CL"],"328":["cs.LG","cs.CL","econ.EM"],"329":["cs.SD","cs.CL","eess.AS"],"330":["cs.CL"],"331":["cs.CL"],"332":["cs.CV","cs.CL","cs.LG"],"333":["cs.IR","cs.CL"],"334":["cs.CL"],"335":["cs.CL"],"336":["cs.CL"],"337":["cs.CL"],"338":["cs.CL"],"339":["cs.CR","cs.CL"],"340":["cs.CL"],"341":["cs.CL","cs.LG"],"342":["cs.CL"],"343":["cs.CV","cs.CL","cs.LG"],"344":["cs.CL"],"345":["cs.CL","cs.IR"],"346":["cs.CY","cs.CL","cs.LG","stat.AP"],"347":["cs.CL","cs.LG"],"348":["cs.CL","I.2.7"],"349":["cs.CL","cs.IR"],"350":["cs.CL","cs.LG"],"351":["cs.CL"],"352":["cs.CL","cs.LG","cs.SD","eess.AS"],"353":["cs.CL","cs.AI"],"354":["cs.CL","cs.SD","eess.AS"],"355":["cs.CL","cs.IR","cs.LG"],"356":["cs.CL","cs.IR"],"357":["cs.CL"],"358":["cs.CV","cs.AI","cs.CL","cs.MM"],"359":["cs.CL"],"360":["cs.CL","cs.CY","cs.LG"],"361":["cs.CL","cs.CV"],"362":["cs.CL","cs.LG"],"363":["cs.CL","cs.IR"],"364":["cs.CL","cs.AI"],"365":["cs.CL","cs.LG"],"366":["cs.CL","cs.AI"],"367":["cs.CL","cs.AI"],"368":["cs.CL"],"369":["cs.LG","cs.CL"],"370":["eess.AS","cs.CL","cs.SD"],"371":["cs.CL","cs.AI"],"372":["cs.CL"],"373":["cs.CL","cs.AI"],"374":["cs.CL","cs.IR"],"375":["cs.CL"],"376":["cs.CL"],"377":["cs.CL"],"378":["cs.CV","cs.CL"],"379":["cs.CL","cs.AI"],"380":["cs.CL"],"381":["cs.CL","cs.LG"],"382":["cs.CL","cs.LG"],"383":["cs.CL","cs.SI"],"384":["cs.CL","cs.SD","eess.AS"],"385":["cs.CL","cs.AI","cs.LG"],"386":["cs.CL"],"387":["cs.CL","cs.CV","cs.LG"],"388":["cs.CL","cs.AI"],"389":["cs.CL","cs.LG"],"390":["cs.CL"],"391":["cs.CL"],"392":["cs.CL","cs.AI"],"393":["cs.CL"],"394":["cs.CL","cs.LG"],"395":["cs.CL"],"396":["cs.CL","cs.AI"],"397":["cs.CL"],"398":["cs.CL","cs.AI","cs.SD","eess.AS"],"399":["cs.CL","I.2.7"],"400":["cs.IR","cs.CL"],"401":["cs.CL","cs.AI"],"402":["cs.CL"],"403":["cs.CL"],"404":["cs.IR","cs.CL"],"405":["cs.CL","cs.LG"],"406":["cs.CL"],"407":["cs.CL"],"408":["cs.CL"],"409":["cs.CL","cs.AI","cs.LG"],"410":["cs.CL","cs.AI"],"411":["cs.IR","cs.AI","cs.CL"],"412":["cs.CL","cs.AI","cs.LG"],"413":["cs.CL","cs.AI"],"414":["cs.DB","cs.CL"],"415":["cs.CL"],"416":["cs.CL"],"417":["cs.CL","cs.SD","eess.AS"],"418":["cs.CL"],"419":["cs.CL"],"420":["cs.CL","I.2.7"],"421":["cs.CL","cs.SD","eess.AS"],"422":["cs.CL","cs.AI"],"423":["cs.CL"],"424":["cs.CL"],"425":["cs.CL"],"426":["cs.CL","cs.AI","cs.LG"],"427":["cs.CV","cs.CL","cs.LG","cs.MM","cs.SD","eess.AS"],"428":["cs.CL","68T50","I.2.7"],"429":["cs.CL","cs.AI"],"430":["cs.CL"],"431":["cs.CL"],"432":["cs.CL"],"433":["cs.CL","cs.LG"],"434":["cs.CL","cs.LG"],"435":["cs.CL","cs.CR","cs.LG"],"436":["cs.CL","cs.AI","cs.LG"],"437":["cs.CL"],"438":["cs.CL","cs.LG","eess.AS"],"439":["cs.CL","cs.AI","cs.HC","cs.LG"],"440":["cs.CL","cs.AI","cs.LG","eess.AS"],"441":["cs.CL","cs.LG"],"442":["cs.CL","cs.IR","cs.LG"],"443":["cs.LG","cs.AI","cs.CL"],"444":["cs.CL","cs.LG","I.2.7; I.2.6"],"445":["cs.CL","cs.LG","stat.ML"],"446":["cs.CL","cs.LG"],"447":["cs.LG","cs.CL","cs.NE"],"448":["cs.CL","cs.AI","cs.IR","cs.LG"],"449":["cs.CL","I.2.7; I.2.6"],"450":["cs.CL","cs.AI"],"451":["cs.CL","cs.SD","eess.AS"],"452":["cs.CL"],"453":["cs.IR","cs.CL"],"454":["cs.AI","cs.CL","cs.LG"],"455":["cs.AI","cs.CL","cs.CV","cs.HC","cs.LG"],"456":["cs.CL","cs.AI"],"457":["cs.LG","cs.CL","stat.ML"],"458":["cs.CL"],"459":["cs.CL"],"460":["cs.CL","cs.AI"],"461":["cs.CV","cs.CL","I.2.7; I.4.8; I.5.1"],"462":["cs.CL"],"463":["cs.CL","cs.LG"],"464":["cs.CL"],"465":["cs.CL","cs.LG"],"466":["cs.CL"],"467":["cs.LG","cs.CL"],"468":["cs.CL","cs.IR"],"469":["cs.CL","cs.CY"],"470":["cs.CV","cs.AI","cs.CL","cs.LG"],"471":["cs.CL"],"472":["cs.CL","cs.LG"],"473":["cs.CL"],"474":["cs.CL"],"475":["cs.CV","cs.CL","cs.LG"],"476":["cs.CL"],"477":["cs.CV","cs.CL"],"478":["cs.CL"],"479":["cs.CL"],"480":["cs.AI","cs.CL","cs.LG"],"481":["cs.CL","cs.LG"],"482":["cs.CL"],"483":["cs.CL","cs.AI"],"484":["cs.CL"],"485":["cs.CR","cs.CL","cs.LG"],"486":["cs.CL","cs.LG"],"487":["cs.CL","cs.AI"],"488":["cs.CL","cs.AI"],"489":["eess.AS","cs.CL","cs.SD"],"490":["cs.CV","cs.CL","cs.LG"],"491":["cs.LG","cs.CL"],"492":["cs.CV","cs.CL","cs.LG"],"493":["cs.CL","cs.LG","68U01"],"494":["cs.CL","cs.LG"],"495":["cs.IR","cs.CL"],"496":["cs.CL","cs.PL"],"497":["cs.AR","cs.CL","cs.LG"],"498":["cs.CL","cs.LG","cs.CL, cs.GL","I.2; I.7"],"499":["cs.CL"],"500":["cs.CL"],"501":["cs.CV","cs.CL"],"502":["cs.CV","cs.CL","cs.LG"],"503":["cs.CV","cs.CL","cs.SD","eess.AS"],"504":["cs.CL","cs.AI","cs.CY"],"505":["cs.CL","cs.IR","cs.LG"],"506":["cs.AI","cs.CL"],"507":["cs.CL","cs.DM"],"508":["cs.CL","stat.ML"],"509":["cs.RO","cs.AI","cs.CL","cs.CV","cs.LG"],"510":["cs.CV","cs.CL"],"511":["cs.CL","cs.CC"],"512":["cs.CL","cs.IR","I.2.7; H.3.3; I.2.6"],"513":["cs.CV","cs.AI","cs.CL"],"514":["eess.AS","cs.CL","cs.SD"],"515":["cs.CL"],"516":["cs.CL"],"517":["cs.CL","cs.CY"],"518":["cs.CL"],"519":["cs.CL"],"520":["cs.CL"],"521":["cs.CL","cs.AI"],"522":["cs.CL","cs.LG"],"523":["cs.CL","cs.AI"],"524":["cs.CL","cs.AI","cs.LG"],"525":["q-fin.PR","cs.CL"],"526":["cs.CL"],"527":["cs.CV","cs.AI","cs.CL","cs.LG","cs.MM"],"528":["cs.CL","cs.AI"],"529":["cs.CL"],"530":["cs.LG","cs.CL","q-bio.BM"],"531":["cs.CL"],"532":["cs.CL"],"533":["cs.CL"],"534":["cs.DL","cs.CL"],"535":["cs.CL"],"536":["cs.CL","cs.AI"],"537":["cs.LG","cs.CL"],"538":["cs.CL","cs.LG"],"539":["cs.CL","cs.AI","cs.HC","cs.IR","cs.LG"],"540":["cs.CV","cs.CL"],"541":["cs.CL","cs.AI","cs.NE"],"542":["cs.CV","cs.CL","cs.LG","cs.MM"],"543":["cs.CL"],"544":["cs.CL","cs.AI"],"545":["eess.AS","cs.AI","cs.CL","cs.SD"],"546":["cs.CL","cs.AI","cs.LG"],"547":["cs.CL"],"548":["cs.CL","cs.AI"],"549":["cs.CL"],"550":["cs.CL"],"551":["cs.CV","cs.CL","cs.GR"],"552":["cs.CL"],"553":["cs.CL","I.2.7"],"554":["cs.CL","cs.AI","cs.IR"],"555":["cs.CV","cs.CL"],"556":["cs.CL"],"557":["cs.CL","cs.AI"],"558":["cs.SD","cs.CL","eess.AS"],"559":["cs.CL","cs.AI"],"560":["cs.LG","cs.CL","cs.CV"],"561":["cs.CL","cs.AI"],"562":["cs.CL"],"563":["cs.CV","cs.CL"],"564":["cs.CV","cs.CL","cs.LG","eess.IV"],"565":["cs.CL","cs.LG"],"566":["cs.CL"],"567":["cs.CL"],"568":["cs.CL","cs.AI","cs.LG","cs.NE"],"569":["cs.CL","cs.AI","cs.IR","cs.LG"],"570":["quant-ph","cond-mat.str-el","cs.CL"],"571":["cs.CL","cs.AI","cs.LG"],"572":["cs.CL","cs.AI","cs.LG","cs.NE"],"573":["cs.CL","cs.AI","cs.LG","cs.NE"],"574":["cs.CR","cs.CL"],"575":["cs.CL","cs.AI"],"576":["cs.SE","cs.CL","cs.LG","cs.PL"],"577":["cs.CL","cs.LG"],"578":["cs.CL","econ.GN","q-fin.EC"],"579":["cs.CL"],"580":["cs.CL","cs.DM"],"581":["cs.CL","cs.LG"],"582":["cs.CL"],"583":["cs.CL","cs.AI","cs.CV"],"584":["cs.LG","cs.CL","cs.CY","cs.SI"],"585":["cs.CL","cs.AI","cs.IR"],"586":["cs.CV","cs.CL"],"587":["cs.CL","q-bio.NC"],"588":["cs.CL"],"589":["cs.CL","cs.SI"],"590":["cs.CL"],"591":["cs.CL"],"592":["cs.CL","cs.CV"],"593":["cs.CL"],"594":["cs.CL","cs.LG","cs.SD","eess.AS"],"595":["cs.CL","cs.LG"],"596":["cs.CL"],"597":["cs.CL","cs.AI","cs.LG"],"598":["cs.CL","cs.AI","I.2.0; I.2.6"],"599":["cs.CL"],"600":["cs.CL"],"601":["cs.CL","cs.AI","cs.LG"],"602":["cs.CL","cs.IR"],"603":["cs.CL"],"604":["cs.LG","cs.CL"],"605":["cs.CL"],"606":["cs.CL","cs.AI","91F20","I.2.7"],"607":["cs.CL"],"608":["cs.CV","cs.CL"],"609":["cs.CL","cs.AI","cs.LG"],"610":["cs.CL"],"611":["cs.IR","cs.CL"],"612":["cs.CL","cs.LG","cs.NE","cs.SI"],"613":["cs.CL"],"614":["cs.CL"],"615":["cs.IR","cs.CL"],"616":["cs.CL","cs.SD","eess.AS"],"617":["cs.LG","cs.AI","cs.CL","cs.CV"],"618":["cs.CL"],"619":["cs.LG","cs.CL","cs.CV","cs.CY","stat.ML"],"620":["cs.CL","cs.AI"],"621":["cs.CL"],"622":["cs.CV","cs.CL","cs.LG","cs.SD","eess.AS"],"623":["cs.AI","cs.CL"],"624":["cs.CL","cs.AI"],"625":["cs.CL","cs.AI"],"626":["cs.CL","cs.LG"],"627":["cs.LG","cs.CL"],"628":["cs.CV","cs.CL","cs.LG"],"629":["cs.CL","cs.AI"],"630":["cs.CL","cs.AI"],"631":["cs.CL","cs.AI","cs.LG"],"632":["cs.AI","cs.CL"],"633":["cs.CL","cs.AI","68-06, 68T50, 68T01","G.3; I.2.7"],"634":["cs.CL","cs.SE"],"635":["cs.CL","cs.AI","cs.IR","physics.soc-ph"],"636":["cs.CL"],"637":["cs.CL"],"638":["cs.CV","cs.CL"],"639":["cs.CV","cs.CL"],"640":["cs.CV","cs.CL"],"641":["cs.AI","cs.CL","cs.DL","cs.LG"],"642":["cs.CL","cs.LG","I.2.6"],"643":["cs.CL"],"644":["cs.CL"],"645":["cs.CL"],"646":["cs.CL"],"647":["cs.AI","cs.CL"],"648":["eess.AS","cs.CL","cs.SD"],"649":["cs.CL","cs.AI","cs.LG"],"650":["cs.CL"],"651":["cs.CV","cs.AI","cs.CL"],"652":["cs.CV","cs.AI","cs.CL"],"653":["cs.CL","68T50 (Primary) 03B65, 91F20 (Secondary)","I.7"],"654":["cs.CL"],"655":["cs.CL"],"656":["cs.CL","cs.AI","cs.LG"],"657":["cs.CL","cs.AI","cs.LG"],"658":["cs.CL","cs.AI","cs.LG"],"659":["cs.CL"],"660":["cs.CL","cs.AI"],"661":["cs.LG","cs.CL"],"662":["cs.CL","astro-ph.IM"],"663":["cs.CL","cs.LG"],"664":["cs.CL"],"665":["cs.CL","cs.LG"],"666":["cs.CL"],"667":["cs.CL","cs.LG","I.2.7; I.5"],"668":["cs.CL"],"669":["cs.CV","cs.CL"],"670":["cs.LG","cs.CL"],"671":["cs.CL"],"672":["cs.CL","cs.AI"],"673":["cs.CV","cs.CL","cs.LG"],"674":["cs.CL","cs.LG","cs.SD","eess.AS"],"675":["cs.CL","cs.AI"],"676":["cs.CL"],"677":["cs.CV","cs.CL"],"678":["cs.CL"],"679":["cs.CL"],"680":["cs.CL","cs.LG","eess.AS"],"681":["cs.CL","cs.IR"],"682":["cs.CL","cs.LG"],"683":["cs.CV","cs.CL"],"684":["cs.CL","cs.AI"],"685":["cs.CL","cs.AI"],"686":["cs.CV","cs.CL"],"687":["cs.CL","cs.AI"],"688":["cs.CL","cs.CY","cs.LG"],"689":["cs.CL"],"690":["cs.CL"],"691":["cs.CL"],"692":["physics.soc-ph","cs.CL","cs.SI"],"693":["cs.CL","cs.LG"],"694":["cs.CL"],"695":["cs.CL"],"696":["cs.CL"],"697":["cs.FL","cs.CL","cs.DM","68Q45, 03D35,"],"698":["cs.CL"],"699":["cs.CL"],"700":["cs.AI","cs.CL","stat.AP","stat.CO"],"701":["cs.CL"],"702":["cs.CL","cs.LG"],"703":["cs.CL"],"704":["cs.CL","cs.SI"],"705":["cs.CL"],"706":["cs.CC","cs.CL"],"707":["cs.CL"],"708":["cs.CL","cs.SD","eess.AS"],"709":["cs.CL","cs.AI","cs.LG"],"710":["cs.IR","cs.CL","cs.DL"],"711":["cs.CL","cs.AI","cs.LG"],"712":["cs.CL"],"713":["cs.CL"],"714":["cs.CL","cs.SD","eess.AS"],"715":["cs.CL","cs.AI","cs.IR","cs.LG"],"716":["cs.CL"],"717":["eess.SY","cs.CL","cs.SY","eess.SP"],"718":["cs.CV","cs.AI","cs.CL"],"719":["cs.CL","cs.AI","cs.LG"],"720":["cs.CL","cs.IR","cs.LG","stat.ME","stat.ML"],"721":["cs.CL"],"722":["cs.CL"],"723":["cs.CL","cs.AI","68T07, 68T50","I.2.7; H.3.3"],"724":["eess.AS","cs.CL","cs.LG"],"725":["cs.CL","eess.SP"],"726":["cs.CL","cs.SD","eess.AS"],"727":["cs.CL"],"728":["cs.CL"],"729":["cs.CL","cs.SD","eess.AS"],"730":["cs.CL","cs.LG"],"731":["cs.CL","cs.SD","eess.AS"],"732":["cs.LG","cs.AI","cs.CL","cs.CV"],"733":["q-bio.NC","cs.AI","cs.CL","cs.LG","cs.NE"],"734":["cs.RO","cs.AI","cs.CL","cs.CV","cs.LG"],"735":["cs.CL","cs.CY"],"736":["cs.CL"],"737":["eess.AS","cs.CL","cs.LG","cs.SD"],"738":["cs.CL"],"739":["cs.CL"],"740":["cs.CL","cs.AI"],"741":["cs.CL","cs.AI","cs.LG"],"742":["cs.SD","cs.CL","eess.AS"],"743":["cs.CL"],"744":["cs.CL","cs.SD","eess.AS"],"745":["cs.CL","math.HO"],"746":["cs.CL","I.2.7; I.2.4; J.6"],"747":["cs.CL","cs.AI","cs.LG"],"748":["cs.CL","cs.LG"],"749":["cs.CL","cs.LG"],"750":["cs.CL","cs.LG"],"751":["cs.CL"],"752":["cs.CL"],"753":["cs.CL","cs.AI"],"754":["cs.CL"],"755":["cs.CL"],"756":["cs.CL","I.2.7"],"757":["cs.CL"],"758":["cs.CL","cs.LG","math.CT","quant-ph"],"759":["cs.CL"],"760":["cs.LG","cs.CL","cs.NE"],"761":["cs.CL"],"762":["cs.CL"],"763":["cs.CL","nlin.AO"],"764":["cs.CL","cs.LG"],"765":["cs.CL","cs.AI","cs.LG"],"766":["cs.CL"],"767":["cs.CL","cs.AI"],"768":["cs.CL"],"769":["cs.CL","cs.AI"],"770":["cs.CL"],"771":["cs.IR","cs.AI","cs.CL"],"772":["cs.CL"],"773":["cs.CL","cs.AI"],"774":["eess.AS","cs.CL","cs.SD"],"775":["stat.ML","cs.CL","cs.LG"],"776":["cs.CL"],"777":["cs.CL"],"778":["cs.CL","cs.AI"],"779":["cs.CL","cs.HC","cs.IR"],"780":["cs.CL","cs.LG"],"781":["cs.CL"],"782":["cs.CL","cs.LG"],"783":["cs.SI","cs.CL","cs.IR","cs.LG"],"784":["cs.CL","cs.AI","cs.LG","q-bio.QM"],"785":["q-bio.OT","cs.CL","cs.LG","q-bio.QM"],"786":["cs.CL","cs.AI"],"787":["cs.CL"],"788":["cs.CL","cs.LG"],"789":["cs.CL"],"790":["cs.CL","cs.IR"],"791":["cs.CL","cs.AI","cs.LG"],"792":["cs.CV","cs.CL","cs.IR"],"793":["cs.CL"],"794":["cs.CL","math.OC"],"795":["cs.IR","cs.CL","cs.LG"],"796":["cs.CL"],"797":["cs.LG","cs.CL"],"798":["cs.CL","cs.LO","68M14","F.4.3; F.1.1"],"799":["cs.CL"],"800":["cs.CL","cs.IR","cs.SI","q-bio.QM","I.2.7; I.5.3; I.5.4; J.3; J.4"],"801":["cs.CL","cs.AI"],"802":["cs.CL","cs.LG"],"803":["cs.CL"],"804":["cs.CL"],"805":["cs.CL","cs.AI","cs.IR"],"806":["cs.CL"],"807":["cs.CL"],"808":["cs.LG","cs.CL","cs.CV"],"809":["cs.CL"],"810":["cs.CL","cs.AI"],"811":["cs.CL"],"812":["cs.CL","cs.AI"],"813":["cs.CL"],"814":["cs.LG","cs.CL","cs.CV"],"815":["cs.CL","physics.soc-ph"],"816":["cs.LG","cs.AI","cs.CL"],"817":["cs.CL","cs.SD","eess.AS"],"818":["cs.CL","cs.CY"],"819":["cs.CL"],"820":["cs.CL"],"821":["cs.CL"],"822":["cs.CL"],"823":["cs.CL","cs.DL"],"824":["eess.AS","cs.CL","cs.SD"],"825":["cs.CL"],"826":["cs.CL","cs.CY"],"827":["cs.CL","cs.AI"],"828":["cs.CL"],"829":["cs.CL"],"830":["cs.CL","cs.AI","cs.LG"],"831":["cs.LG","cs.CL","cs.CV"],"832":["quant-ph","cs.AI","cs.CL","cs.CV","cs.LG","cs.NE"],"833":["cs.CL","eess.AS"],"834":["cs.CL","cs.IR","cs.LG"],"835":["cs.CL"],"836":["cs.CV","cs.CL"],"837":["cs.CL"],"838":["cs.CL","cs.AI"],"839":["cs.LO","cs.CL"],"840":["cs.CL","cs.LG"],"841":["cs.CL"],"842":["cs.CL","I.2.7"],"843":["cs.CL","cs.NE"],"844":["cs.IR","cs.CL","cs.LG"],"845":["cs.CL","cs.AI"],"846":["cs.CL"],"847":["cs.IR","cs.CL","cs.LG"],"848":["cs.SD","cs.CL","cs.HC","cs.LG","eess.AS"],"849":["cs.CL","cs.LG"],"850":["cs.CL"],"851":["cs.IR","cs.CL"],"852":["cs.CV","cs.AI","cs.CL"],"853":["cs.CL","cs.AI"],"854":["cs.CL","cs.LG"],"855":["cs.CL","stat.OT"],"856":["cs.CL","stat.ME","stat.ML"],"857":["cs.CY","cs.CL","cs.SI"],"858":["cs.CL","cs.AI","68T50","I.2.7"],"859":["cs.CL"],"860":["cs.CL","cs.CV","cs.LG"],"861":["cs.CL"],"862":["cs.CL"],"863":["cs.CL"],"864":["cs.CL","cs.LG","stat.ML"],"865":["cs.CL","cs.AI","cs.LG"],"866":["cs.CL"],"867":["cs.CL","cs.IR"],"868":["cs.LG","cs.CL"],"869":["cs.CL"],"870":["cs.CL","cs.AI","cs.IR","cs.LG"],"871":["cs.CL"],"872":["cs.CL","cs.AI"],"873":["cs.CL"],"874":["cs.CL"],"875":["cs.CL"],"876":["cs.CL"],"877":["cs.CL","q-fin.CP","q-fin.PM"],"878":["cs.SD","cs.CL","cs.LG","eess.AS"],"879":["math.LO","cs.CL","cs.LO"],"880":["cs.SD","cs.CL","cs.LG","eess.AS"],"881":["cs.SD","cs.CL","cs.LG","eess.AS"],"882":["cs.CL","cs.SD","eess.AS","I.2.7"],"883":["cs.CL"],"884":["cs.CL"],"885":["cs.CL"],"886":["cs.CL"],"887":["cs.CV","cs.CL"],"888":["cs.CL","cs.CV"],"889":["cs.LG","cs.CL"],"890":["cs.LG","cs.CL","cs.CV"],"891":["cs.CL","cs.AI","cs.LG"],"892":["eess.AS","cs.CL","cs.SD"],"893":["cs.CL"],"894":["cs.CL","cs.AI"],"895":["cs.IR","cs.CL"],"896":["cs.CL","cs.LG"],"897":["cs.CL"],"898":["cs.CL"],"899":["cs.CL"],"900":["cs.CL","cs.LG"],"901":["cs.LG","cs.CL"],"902":["cs.CL"],"903":["cs.CL","cs.HC"],"904":["cs.CL","cs.AI"],"905":["cs.CL","cs.AI"],"906":["cs.CL","cs.SD","eess.AS"],"907":["cs.CL","cs.LG"],"908":["cs.CL"],"909":["cs.CL","cs.AI"],"910":["cs.CL","cs.LG"],"911":["cs.CL"],"912":["cs.CL"],"913":["cs.CL","cs.AI"],"914":["cs.CL","cs.SD","eess.AS"],"915":["cs.CV","cs.AI","cs.CL","cs.LG"],"916":["cs.CL"],"917":["cs.CL"],"918":["cs.CL","cs.LG"],"919":["math.CT","cs.CL"],"920":["cs.LG","cs.CL"],"921":["cs.CL","cs.AI","cs.LG"],"922":["cs.CL","cs.LG"],"923":["cs.CL","cs.AI"],"924":["cs.CL"],"925":["cs.CL"],"926":["cs.CV","cs.CL"],"927":["cs.CL"],"928":["cs.CL","cs.LG"],"929":["cs.CL","cs.LG"],"930":["cs.CL"],"931":["cs.CL","cs.HC"],"932":["cs.CL","cs.LG"],"933":["cs.SD","cs.CL","cs.LG","eess.AS"],"934":["cs.SD","cs.CL","cs.LG","eess.AS"],"935":["cs.CL"],"936":["cs.SD","cs.CL","cs.LG","eess.AS"],"937":["cs.CL","cs.AI","cs.IR","cs.LG"],"938":["cs.CL"],"939":["cs.CL","cs.CV"],"940":["cs.CL","stat.AP"],"941":["cs.CL"],"942":["cs.CL"],"943":["cs.CL"],"944":["cs.CL","cs.AI","cs.HC","cs.LG"],"945":["cs.CL","cs.LG"],"946":["cs.CL","cs.LG"],"947":["cs.CL","cs.LG"],"948":["cs.CL"],"949":["cs.HC","cs.AI","cs.CL","cs.CY"],"950":["cs.LG","cs.CL"],"951":["cs.CL"],"952":["cs.CL","cs.IR","cs.LG"],"953":["cs.CL","cs.AI"],"954":["cs.CL","cs.AI","cs.LG"],"955":["cs.CL","cs.LG"],"956":["cs.CL","J.5"],"957":["cs.CL","cs.AI"],"958":["cs.CL","cs.SI"],"959":["cs.CL","cs.CR","cs.LG"],"960":["cs.CL","cs.SD","eess.AS"],"961":["cs.CL","cs.AI"],"962":["cs.CL","cs.AI","I.2.7"],"963":["cs.LG","cs.AI","cs.CL","cs.PL"],"964":["cs.CL"],"965":["eess.AS","cs.CL"],"966":["cs.CL","cs.SD","eess.AS"],"967":["cs.CL"],"968":["cs.LG","cs.AI","cs.CL"],"969":["cs.CL","cs.LG","cs.SD","eess.AS"],"970":["cs.CL","cs.LG"],"971":["cs.CL","cs.CY"],"972":["cs.CL"],"973":["cs.CL"],"974":["cs.LG","cs.CL","cs.CV"],"975":["cs.CL"],"976":["cs.CL"],"977":["cs.CV","cs.CL","cs.CY"],"978":["cs.CL"],"979":["cs.CL","cs.IR"],"980":["cs.CL"],"981":["cs.CL"],"982":["cs.CL","cs.AI","cs.LG"],"983":["cs.CL","cs.NA","math.NA","stat.AP"],"984":["cs.CL","cs.AI"],"985":["cs.CL"],"986":["cs.LG","cs.AI","cs.CL","cs.CV"],"987":["cs.CL","cs.AI"],"988":["cs.CL","cs.HC","cs.LG"],"989":["cs.CL","cs.HC","cs.LG","I.2.7"],"990":["cs.CL","cs.LG"],"991":["cs.CL"],"992":["cs.CL","cs.SD","eess.AS"],"993":["cs.CV","cs.CL"],"994":["cs.CL"],"995":["cs.CL"],"996":["cs.CL","cs.SD","eess.AS"],"997":["cs.CL","cs.AI","I.2.7"],"998":["cs.CL","cs.LG"],"999":["cs.CL"],"1000":["cs.CL","cs.AI"],"1001":["q-fin.TR","cs.AI","cs.CL","cs.LG","cs.NE"],"1002":["cs.CL"],"1003":["cs.CL","cs.AI"],"1004":["cs.CL","cs.LG","62M10","I.2.7"],"1005":["cs.CL","cs.AI","cs.LG"],"1006":["cs.LG","cs.AI","cs.CL","econ.GN","q-fin.EC","stat.AP"],"1007":["cs.CL"],"1008":["cs.CL","cs.AI","cs.LG"],"1009":["cs.LG","cs.AI","cs.CL","cs.CV"],"1010":["eess.AS","cs.CL","cs.SD"],"1011":["cs.CL","cs.IR","cs.LG"],"1012":["cs.CL"],"1013":["cs.CL","cs.LG"],"1014":["cs.CL","cs.AI","cs.SI"],"1015":["cs.CL","cs.SI"],"1016":["cs.CL"],"1017":["cs.CL"],"1018":["cs.CL","cs.AI"],"1019":["cs.CL","cs.IR"],"1020":["cs.CL","cs.LG"],"1021":["cs.CL","cs.AI","cs.LG"],"1022":["cs.CL"],"1023":["cs.CL","cs.AI"],"1024":["q-bio.BM","cs.CL"],"1025":["cs.CL"],"1026":["cs.CL"],"1027":["cs.CL","cs.LG"],"1028":["cs.CL"],"1029":["cs.CL"],"1030":["cs.SD","cs.AI","cs.CL","cs.LG"],"1031":["cs.CL","cs.AI","cs.LG"],"1032":["cs.CL","cs.AI","cs.LG"],"1033":["cs.CL","cs.LG"],"1034":["cs.CL","J.3; I.2.7"],"1035":["cs.CL"],"1036":["cs.LG","cs.AI","cs.CL"],"1037":["cs.CL"],"1038":["cs.LG","cs.AI","cs.CL","cs.NE"],"1039":["cs.CL"],"1040":["cs.CL","cs.LG"],"1041":["cs.SD","cs.AI","cs.CL","cs.LG","eess.AS"],"1042":["cs.CL","cs.SD","eess.AS"],"1043":["cs.CL","stat.AP"],"1044":["cs.CL","cs.AI"],"1045":["cs.CL","cs.LG","cs.NE"],"1046":["cs.CL"],"1047":["cs.SI","cs.CL","physics.soc-ph","I.2.7; H.0; J.4; H.4.0"],"1048":["cs.CL","cs.AI"],"1049":["cs.CL","cs.AI","cs.DB"],"1050":["cs.CL","cs.AI"],"1051":["cs.CL"],"1052":["cs.CL","cs.IR"],"1053":["cs.CL","cs.LG"],"1054":["cs.CV","cs.CL"],"1055":["cs.IR","cs.AI","cs.CL"],"1056":["cs.CL"],"1057":["cs.AI","cs.CL","cs.IR"],"1058":["cs.SI","cs.CL","cs.CY","cs.IR","physics.soc-ph"],"1059":["cs.SI","cs.CL"],"1060":["cs.CL","cs.AI","cs.LG"],"1061":["cs.CL"],"1062":["cs.CL"],"1063":["cs.CL","cs.AI","cs.LG"],"1064":["cs.CL"],"1065":["cs.CL"],"1066":["cs.CL","cs.LG"],"1067":["cs.CV","cs.CL"],"1068":["cs.DL","cs.CL"],"1069":["cs.CL"],"1070":["cs.CL","cs.LG"],"1071":["cs.LG","cs.AI","cs.CL","cs.CV","cs.MM"],"1072":["cs.CL"],"1073":["cs.LG","cs.CL"],"1074":["cs.CL","cs.IR"],"1075":["cs.CL","cs.DL"],"1076":["cs.LG","cs.CL"],"1077":["cs.CL"],"1078":["cs.CL"],"1079":["cs.CL","stat.ML"],"1080":["cs.CL"],"1081":["cs.CL","cs.AI","cs.LG"],"1082":["cs.LG","cs.CL","cs.CV","cs.HC","cs.IR","68T07"],"1083":["cs.CL"],"1084":["cs.CL","cs.NE"],"1085":["cs.CL","cs.CY","cs.LG"],"1086":["cs.CL","cs.IR","cs.IT","cs.SI","math.IT"],"1087":["cs.CL","cs.AI","cs.LG"],"1088":["cs.CL","cs.LG"],"1089":["cs.CL","cs.SI"],"1090":["cs.CV","cs.CL"],"1091":["cs.CL","cs.AI"],"1092":["cs.CL","cs.AI","econ.GN","q-fin.EC","stat.AP"],"1093":["cs.CL","cs.AI"],"1094":["cs.LG","cs.CL","cs.CV"],"1095":["cs.CL"],"1096":["cs.CV","cs.AI","cs.CL","cs.CR"],"1097":["cs.LG","cs.AI","cs.CL"],"1098":["cs.CL","cs.LG"],"1099":["cs.SE","cs.CL","cs.LG"],"1100":["cs.CL","cs.CV","cs.MM","cs.SD","eess.AS","eess.IV"],"1101":["cs.CV","cs.AI","cs.CL"],"1102":["cs.CL","cs.LG","I.2.7"],"1103":["cs.CL","cs.IR"],"1104":["cs.CL"],"1105":["cs.CL","cs.AI","cs.CY","cs.LG"],"1106":["cs.CL","cs.CY","cs.LG"],"1107":["cs.CL"],"1108":["math.GR","cs.CL"],"1109":["cs.SE","cs.CL"],"1110":["cs.CV","cs.CL"],"1111":["cs.CL"],"1112":["cs.CL"],"1113":["cs.CV","cs.CL"],"1114":["cs.CL","cs.CV","cs.IR"],"1115":["cs.CL","cs.AI"],"1116":["cs.CY","cs.AI","cs.CL","cs.LG"],"1117":["cs.CL","cs.AI","cs.LG"],"1118":["cs.CL","cs.LG"],"1119":["cs.SD","cs.CL","cs.LG","eess.AS","I.2.7; G.3"],"1120":["cs.CL","cs.SD","eess.AS"],"1121":["cs.CL","cs.AI"],"1122":["cs.CV","cs.AI","cs.CL","cs.LG"],"1123":["cs.CL","cs.LG"],"1124":["cs.IR","cs.CL"],"1125":["cs.CL","cs.LG"],"1126":["cs.CL"],"1127":["cs.CL"],"1128":["cs.CL","cs.CV"],"1129":["cs.SD","cs.CL","eess.AS"],"1130":["cs.CL"],"1131":["cs.LG","cs.AI","cs.CL","cs.PL","cs.SE"],"1132":["cs.CL","cs.AI","cs.LG"],"1133":["cs.CL"],"1134":["cs.CL"],"1135":["cs.CL"],"1136":["cs.LG","cs.CL","cs.IR"],"1137":["cs.CL","cs.IR","cs.LG"],"1138":["cs.CL"],"1139":["cs.CL"],"1140":["cs.CL","cs.AI"],"1141":["cs.CL","cs.LG"],"1142":["cs.CV","cs.CL"],"1143":["cs.CL","cs.LG"],"1144":["cs.CL","cs.LG"],"1145":["cs.CL","cs.LG"],"1146":["cs.CL","cs.AI"],"1147":["cs.CL"],"1148":["cs.CL","cs.AI"],"1149":["cs.CL","cs.AI","cs.IR"],"1150":["cs.HC","cs.CL","cs.RO"],"1151":["cs.CL","cs.LG"],"1152":["cs.CL","I.2.7; H.3.1"],"1153":["cs.CL"],"1154":["cs.CL"],"1155":["cs.CV","cs.CL","cs.IR"],"1156":["cs.CL","cs.FL"],"1157":["cs.CL"],"1158":["cs.LG","cs.CL","cs.CY"],"1159":["cs.CL"],"1160":["cs.CL","cs.AI"],"1161":["cs.CL","cs.LG","cs.SD","eess.AS"],"1162":["cs.CL"],"1163":["cs.CL"],"1164":["cs.CL"],"1165":["cs.CL"],"1166":["cs.CL","cs.AI","cs.LG"],"1167":["cs.RO","cs.AI","cs.CL","cs.HC","cs.LG"],"1168":["cs.CL","cs.AI"],"1169":["cs.RO","cs.CL","cs.CV"],"1170":["cs.LG","cs.AI","cs.CL","cs.NE"],"1171":["cs.CL"],"1172":["cs.LG","cs.CL","cs.MA","cs.RO"],"1173":["cs.CV","cs.AI","cs.CL","cs.LG"],"1174":["cs.CL","cs.IR","cs.LG"],"1175":["cs.CL"],"1176":["cs.CL","cs.IR"],"1177":["cs.CL"],"1178":["cs.CL","cs.AI"],"1179":["cs.CL","cs.IR"],"1180":["cs.CL","cs.LG"],"1181":["cs.CL"],"1182":["cs.LG","cs.CL","stat.ML"],"1183":["cs.CL","cs.AI","cs.LG"],"1184":["eess.AS","cs.CL","cs.SD"],"1185":["cs.CL","cs.AI","cs.LG"],"1186":["cs.SD","cs.CL","eess.AS"],"1187":["cs.CL","cs.SI"],"1188":["cs.CL"],"1189":["cs.CL","cs.AI"],"1190":["cs.CL","cs.LG"],"1191":["cs.CL","cs.LG"],"1192":["cs.CL"],"1193":["cs.CL"],"1194":["cs.CL","cs.LG","I.2.7"],"1195":["cs.CL","cs.CY"],"1196":["cs.CL"],"1197":["cs.CV","cs.CL","cs.LG"],"1198":["math.LO","cs.CL","cs.LO","03B20, 03B65"],"1199":["cs.CL","cs.HC","cs.LG"],"1200":["cs.CL","cs.LG"],"1201":["cs.CL"],"1202":["cs.CL","cs.LG","cs.MM","cs.SD","eess.AS","H.5.5; I.2.6; J.5"],"1203":["cs.CL","cs.AI"],"1204":["cs.CV","cs.CL","cs.MM"],"1205":["cs.CL","cs.AI","cs.CY","cs.SI"],"1206":["cs.CL","cs.AI"],"1207":["cs.CV","cs.CL","cs.LG"],"1208":["cs.CL","cs.LG"],"1209":["cs.CL"],"1210":["cs.SD","cs.CL","eess.AS"],"1211":["cs.CL","cs.AI","cs.LG"],"1212":["cs.CL","cs.LG"],"1213":["cs.LG","cs.CL","stat.ML"],"1214":["cs.CL","cs.AI","cs.LG"],"1215":["cs.CL"],"1216":["cs.CL","cs.AI","cs.CY"],"1217":["cs.LG","cs.CL"],"1218":["cs.CV","cs.CL"],"1219":["cs.CL","cs.AI","cs.IR"],"1220":["cs.CL"],"1221":["cs.CL","cs.HC"],"1222":["cs.CL","cs.AI"],"1223":["cs.CL"],"1224":["cs.CL","cs.LG"],"1225":["cs.CL"],"1226":["cs.CL","cs.AI"],"1227":["cs.CL","cs.AI"],"1228":["cs.CL","cs.LG","cs.SI","physics.soc-ph"],"1229":["cs.CL"],"1230":["cs.CL"],"1231":["eess.AS","cs.CL","cs.SD"],"1232":["cs.CL","cs.LG"],"1233":["cs.CL","cs.LG"],"1234":["cs.CL","cs.AI"],"1235":["cs.CL","cs.AI","cs.LG"],"1236":["cs.CL"],"1237":["cs.CL"],"1238":["cs.CL","cs.AI"],"1239":["cs.SD","cs.CL","eess.AS"],"1240":["cs.CL","cs.AI","cs.LG","stat.ML"],"1241":["cs.CL"],"1242":["cs.CL","cs.LG"],"1243":["cs.CL","cs.AI","cs.LG","cs.NI"],"1244":["cs.CL","cs.AI"],"1245":["cs.CV","cs.AI","cs.CL"],"1246":["cs.CL","cs.LG"],"1247":["cs.CL","cs.LG"],"1248":["cs.CL"],"1249":["cs.CL","cs.LG"],"1250":["cs.CL","cs.SD","eess.AS"],"1251":["cs.LG","cs.CL","cs.IR"],"1252":["cs.CL"],"1253":["cs.CL","cs.AI","I.2.7"],"1254":["cs.CL"],"1255":["cs.CL","cs.AI"],"1256":["cs.CL"],"1257":["cs.CL","cs.AI"],"1258":["cs.CL"],"1259":["cs.CL","cs.AI"],"1260":["cs.CL"],"1261":["cs.AI","cs.CL"],"1262":["cs.CL","cs.LG"],"1263":["cs.CL"],"1264":["cs.CL"],"1265":["cs.IR","cs.CL"],"1266":["cs.CL","cs.AI","cs.IR"],"1267":["cs.CL","cs.LG","cs.SD","eess.AS"],"1268":["cs.SE","cs.CL","cs.LG"],"1269":["cs.CL","cs.AI"],"1270":["cs.CL","cs.AI"],"1271":["cs.CL","cs.LG","68T07, 68T50"],"1272":["cs.LG","cs.CL","cs.CR"],"1273":["cs.CL","cs.LG"],"1274":["cs.CL","cs.AI"],"1275":["cs.LG","cs.CL"],"1276":["cs.CL","cs.AI","68T50 (Primary), 91F20 (Secondary)","I.2.7"],"1277":["cs.MM","cs.CL","cs.CV","cs.IR"],"1278":["cs.SD","cs.CL","eess.AS"],"1279":["cs.CL","cs.SD","eess.AS"],"1280":["cs.CL"],"1281":["cs.CL","cs.LG"],"1282":["cs.CL","cs.AI"],"1283":["cs.CL"],"1284":["cs.CL","cs.LG"],"1285":["cs.LG","cs.CL"],"1286":["cs.LG","cs.CL","cs.IR"],"1287":["cs.CL","cs.IR"],"1288":["cs.CL","cs.SD","eess.AS"],"1289":["cs.CL"],"1290":["cs.CL","cs.AI","cs.LG","cs.RO"],"1291":["cs.CL","cs.CR","cs.LG"],"1292":["cs.CL"],"1293":["cs.CL","cs.AI"],"1294":["cs.CL"],"1295":["cs.CL","cs.AI"],"1296":["cs.LG","cs.CL"],"1297":["cs.LG","cs.AI","cs.CL","stat.ML"],"1298":["cs.CV","cs.CL"],"1299":["cs.CL"],"1300":["cs.CL"],"1301":["cs.IR","cs.CL","cs.LG"],"1302":["cs.CL"],"1303":["cs.CL"],"1304":["cs.CL","cs.LG"],"1305":["cs.CL","cs.LG"],"1306":["cs.CL","cs.LG"],"1307":["cs.CL"],"1308":["cs.CL"],"1309":["cs.CL"],"1310":["cs.CL"],"1311":["cs.CL","cs.AI","cs.LG"],"1312":["cs.CL"],"1313":["cs.CL","cs.CY"],"1314":["cs.CL","cs.AI"],"1315":["cs.IR","cs.CL"],"1316":["cs.CL","cs.AI"],"1317":["cs.CL","cs.LG"],"1318":["cs.CL"],"1319":["cs.CL","cs.AI"],"1320":["cs.CL","cs.DL","cs.IR"],"1321":["cs.SD","cs.CL","eess.AS"],"1322":["cs.CL","cs.LG"],"1323":["cs.CL","cs.IR"],"1324":["cs.CL","cs.AI","cs.LG"],"1325":["cs.LG","cs.AI","cs.CL","cs.MA"],"1326":["cs.CL","cs.AI"],"1327":["cs.CL"],"1328":["eess.AS","cs.CL","cs.LG","cs.SD"],"1329":["cs.CL"],"1330":["cs.CL"],"1331":["cs.CL","stat.ML","F.2.0; I.2.7"],"1332":["cs.HC","cs.CL","cs.CY"],"1333":["cs.LG","cs.CL"],"1334":["cs.CL"],"1335":["cs.CL","cs.MM"],"1336":["cs.CL"],"1337":["cs.CL","cs.AI"],"1338":["cs.AI","cs.CL","cs.SD","eess.AS","stat.ML"],"1339":["cs.LG","cs.CL"],"1340":["cs.LG","cs.CL","cs.CV"],"1341":["cs.LG","cs.AI","cs.CL","cs.CV","cs.DC"],"1342":["cs.SD","cs.CL","eess.AS"],"1343":["cs.CL","cs.LG"],"1344":["cs.CL","cs.CY"],"1345":["cs.CV","cs.CL"],"1346":["cs.CL"],"1347":["cs.DL","cs.CL"],"1348":["cs.CL","cs.LG"],"1349":["cs.LG","cs.AI","cs.CL"],"1350":["cs.CL","cs.CV"],"1351":["cs.CL","cs.AI"],"1352":["cs.CL","cs.LG"],"1353":["cs.CL"],"1354":["cs.CL","cs.AI","cs.LG"],"1355":["cs.CL"],"1356":["cs.CL","cs.AI","cs.LG"],"1357":["eess.AS","cs.CL"],"1358":["cs.CL"],"1359":["cs.CL"],"1360":["cs.CL","cs.SD","eess.AS"],"1361":["cs.LG","cs.AI","cs.CL","cs.IR"],"1362":["cs.LG","cs.AI","cs.CL","cs.MA"],"1363":["cs.CL","cs.LG"],"1364":["cs.CL","cs.MS"],"1365":["cs.LG","cs.AI","cs.CL","cs.CV","stat.ML"],"1366":["cs.LG","cs.AI","cs.CL"],"1367":["cs.CL","cs.LG"],"1368":["cs.CL"],"1369":["cs.CL","cs.AI"],"1370":["cs.CL","cs.LG"],"1371":["cs.CL"],"1372":["cs.CL","cs.IR","q-bio.OT"],"1373":["cs.LG","cs.AI","cs.CL"],"1374":["cs.CL","cs.SD","eess.AS"],"1375":["cs.CL","cs.LG","cs.SD","eess.AS"],"1376":["cs.CL"],"1377":["cs.CL"],"1378":["cs.CL"],"1379":["cs.CV","cs.AI","cs.CL","cs.LG"],"1380":["cs.CL","cs.AI"],"1381":["cs.CL","cs.LG"],"1382":["cs.CL","cs.LG"],"1383":["cs.CL"],"1384":["cs.CY","cs.AI","cs.CL","cs.SI","physics.soc-ph"],"1385":["cs.CL"],"1386":["cs.CL","cs.AI"],"1387":["cs.CV","cs.AI","cs.CL"],"1388":["cs.CL"],"1389":["cs.CL"],"1390":["cs.CL"],"1391":["cs.CL"],"1392":["cs.CL"],"1393":["cs.CL"],"1394":["cs.CL","cs.AI"],"1395":["cs.CL"],"1396":["cs.CL"],"1397":["cs.CL"],"1398":["cs.CV","cs.CL"],"1399":["cs.CL"],"1400":["cs.CL","cs.AI"],"1401":["eess.AS","cs.CL","cs.LG","cs.SD"],"1402":["cs.CL"],"1403":["cs.LG","cs.CL","stat.ML"],"1404":["cs.CL"],"1405":["cs.CL","cs.AI"],"1406":["cs.CL"],"1407":["cs.LG","cs.CL","stat.ML"],"1408":["cs.CL"],"1409":["cs.CY","cs.CL","econ.GN","q-fin.EC"],"1410":["cs.LG","cs.CL","q-bio.QM"],"1411":["cs.LG","cs.CL"],"1412":["cs.CL"],"1413":["cs.CL","cs.HC"],"1414":["cs.CL","cs.CY","cs.IR","H.3.1; I.2.7"],"1415":["cs.CL"],"1416":["cs.CL","cs.IR"],"1417":["cs.CL","cs.LG"],"1418":["cs.CR","cs.CL"],"1419":["cs.CL"],"1420":["cs.CL"],"1421":["cs.CL","cs.DL","cs.LG"],"1422":["cs.IR","cs.CL","cs.LG"],"1423":["cs.CL","cs.AI"],"1424":["cs.CL"],"1425":["cs.CL","cs.AI","cs.LG","68T50","I.2.7; I.7.m; H.3.3"],"1426":["cs.CL","cs.AI"],"1427":["cs.LG","cs.CL"],"1428":["cs.CL"],"1429":["cs.CL"],"1430":["cs.CL"],"1431":["cs.CL","cs.AI","cs.CV"],"1432":["cs.CL","cs.AI"],"1433":["cs.CL","cs.LG"],"1434":["cs.CL","cs.AI"],"1435":["cs.LG","cs.CL","stat.ML"],"1436":["cs.CL"],"1437":["cs.CL"],"1438":["cs.CL","cs.LG"],"1439":["cs.HC","cs.CL","cs.CY"],"1440":["cs.CL","cs.MM"],"1441":["cs.CL","cs.AI","cs.LG"],"1442":["cs.CL"],"1443":["cs.CL"],"1444":["cs.CL"],"1445":["cs.CL"],"1446":["cs.CL"],"1447":["cs.AI","cs.CL"],"1448":["cs.CL"],"1449":["cs.CL"],"1450":["cs.CL","cs.AI"],"1451":["cs.CV","cs.AI","cs.CL","cs.HC","cs.IR"],"1452":["cs.AI","cs.CL","cs.HC","cs.RO","68T20","I.2.6; I.2.7"],"1453":["cs.AI","cs.CL","I.2.7; I.2.11"],"1454":["cs.CL"],"1455":["cs.CL","cs.AI"],"1456":["cs.CL","cs.AI"],"1457":["cs.CL"],"1458":["cs.CL","cs.AI","cs.IR"],"1459":["cs.CL"],"1460":["cs.CL"],"1461":["cs.CV","cs.CL"],"1462":["cs.CL"],"1463":["cs.CL"],"1464":["cs.CL"],"1465":["cs.CL"],"1466":["cs.CL","cs.AI"],"1467":["cs.CV","cs.CL"],"1468":["cs.CV","cs.CL"],"1469":["cs.CL"],"1470":["cs.CL"],"1471":["stat.ML","cs.CL","cs.LG"],"1472":["cs.CL"],"1473":["cs.CL","cs.AI"],"1474":["cs.CL"],"1475":["cs.SE","cs.AI","cs.CL","cs.LG"],"1476":["cs.DC","cs.CL"],"1477":["cs.CL","cs.LG"],"1478":["cs.CL"],"1479":["cs.CL","cs.HC"],"1480":["cs.CL","cs.AI"],"1481":["cs.CV","cs.CL","cs.LG"],"1482":["cs.CL","cs.AI"],"1483":["cs.LG","cs.CL","q-bio.BM"],"1484":["cs.CL","cs.AI","cs.CV"],"1485":["cs.SI","cs.CL"],"1486":["cs.LG","cs.AI","cs.CL"],"1487":["cs.CL","cs.AI"],"1488":["cs.CL","cs.AI"],"1489":["cs.CL"],"1490":["cs.DL","cs.AI","cs.CL","cs.LG"],"1491":["cs.CL","cs.AI"],"1492":["cs.CL"],"1493":["cs.CL","cs.IR"],"1494":["cs.AI","cs.CL","cs.LG","cs.RO"],"1495":["cs.AI","cs.CL","cs.LG","cs.RO"],"1496":["cs.CL","cs.LG"],"1497":["cs.CL"],"1498":["cs.CL","cs.AI"],"1499":["cs.CL","cs.IR"],"1500":["cs.IR","cs.AI","cs.CL"],"1501":["cs.CL","cs.AI","cs.CV","cs.LG"],"1502":["cs.CL","cs.AI"],"1503":["stat.ML","cs.CL","cs.LG","stat.AP"],"1504":["cs.CL"],"1505":["cs.CL","cs.AI"],"1506":["cs.CL"],"1507":["cs.CL","cs.AI"],"1508":["cs.LG","cs.AI","cs.CL"],"1509":["cs.CL"],"1510":["cs.CL"],"1511":["cs.CL"],"1512":["cs.CL","cs.AI"],"1513":["cs.CL"],"1514":["cs.MM","cs.CL"],"1515":["cs.CL"],"1516":["cs.CL"],"1517":["cs.CL"],"1518":["cs.CL","cs.AI","cs.CV","E.0; E.2"],"1519":["cs.CL","68T50","I.2.7"],"1520":["cs.LG","cs.CL","cs.SD","eess.AS"],"1521":["cs.CL","cs.IR","H.3.3; I.2.7; I.7.0"],"1522":["cs.CL"],"1523":["cs.CL"],"1524":["cs.CL","cs.AI","I.2.7"],"1525":["cs.CL"],"1526":["cs.CL"],"1527":["cs.CL","cs.AI","cs.LG"],"1528":["cs.CL","cs.LG"],"1529":["cs.CL","cs.CV"],"1530":["cs.CL","cs.CY","cs.IR","cs.LG","68T50, 68T07","I.2.7"],"1531":["cs.CL","cs.LG","68T50, 68T07","I.2.7"],"1532":["cs.CL","cs.AI","cs.LG"],"1533":["cs.CL"],"1534":["cs.CL","cs.AI","cs.LG"],"1535":["cs.RO","cs.AI","cs.CL","cs.CV","cs.LG"],"1536":["cs.CL","cs.AI","cs.HC","I.2.7; H.5.2"],"1537":["cs.CL","cs.AI","cs.CV","cs.LG"],"1538":["cs.CV","cs.AI","cs.CL"],"1539":["cs.CL"],"1540":["cs.CL","cs.LG"],"1541":["cs.AI","cs.CL"],"1542":["cs.CL","cs.AI","cs.LG"],"1543":["cs.LG","cs.CL","cs.IR"],"1544":["econ.GN","cs.CL","cs.SI","physics.soc-ph","q-fin.EC","I.2.7; H.0; J.4"],"1545":["cs.CL","cs.IR"],"1546":["cs.CL","cs.AI","cs.LG"],"1547":["cs.CL"],"1548":["cs.CV","cs.CL","cs.MM"],"1549":["cs.CV","cs.CL","cs.MM"],"1550":["cs.CL","cs.AI","cs.RO"],"1551":["cs.LG","cs.CL"],"1552":["cs.CL"],"1553":["cs.CL"],"1554":["cs.DC","cs.CL","cs.PF"],"1555":["cs.CL","cs.AI"],"1556":["cs.SD","cs.CL","eess.AS"],"1557":["cs.CL","cs.AI","I.2.7"],"1558":["cs.CL","cs.AI","cs.LG"],"1559":["cs.CL","cs.AI","cs.LG"],"1560":["eess.AS","cs.CL","cs.SD"],"1561":["cs.CL"],"1562":["q-fin.ST","cs.AI","cs.CL","cs.LG"],"1563":["cs.CL"],"1564":["cs.CL"],"1565":["cs.LG","cs.CL","cs.CR"],"1566":["cs.CL","cs.LG"],"1567":["cs.CL","cs.LG"],"1568":["cs.CV","cs.CL","cs.HC","cs.LG"],"1569":["cs.CL","cs.AI","cs.CY"],"1570":["cs.CL","cs.AI"],"1571":["cs.CL","cs.AI"],"1572":["cs.CL","cs.SD","eess.AS"],"1573":["cs.CL"],"1574":["cs.CV","cs.CL","cs.LG"],"1575":["cs.CL"],"1576":["cs.CL","cs.SD","eess.AS"],"1577":["cs.CL","cs.AI","cs.LG"],"1578":["cs.SD","cs.CL","eess.AS"],"1579":["cs.CV","cs.AI","cs.CL","cs.LG"],"1580":["cs.CL"],"1581":["cs.CL","eess.AS"],"1582":["cs.CL","cs.LG"],"1583":["eess.AS","cs.AI","cs.CL","cs.LG","cs.SD"],"1584":["cs.CL","cs.AI","cs.IR","cs.SC"],"1585":["cs.CL","cs.LG","cs.SD","eess.AS"],"1586":["cs.CL","cs.SD","eess.AS"],"1587":["cs.CL"],"1588":["cs.CL","cs.AI"],"1589":["cs.CL"],"1590":["cs.CL","cs.LG"],"1591":["cs.IR","cs.CL","cs.DL"],"1592":["cs.CL"],"1593":["cs.CL","cs.AI"],"1594":["cs.CL","cs.AI","cs.LG"],"1595":["cs.CL"],"1596":["cs.LG","cs.CL","stat.ML"],"1597":["cs.CL","cs.AI","cs.LG"],"1598":["cs.CL"],"1599":["eess.AS","cs.AI","cs.CL","cs.LG","cs.SD"],"1600":["cs.CL","cs.LG"],"1601":["cs.CL"],"1602":["cs.CL"],"1603":["cs.CL","cs.AI","cs.LG"],"1604":["eess.AS","cs.CL","cs.LG","cs.SD"],"1605":["cs.CL"],"1606":["cs.CL","cs.LG"],"1607":["cs.CL"],"1608":["cs.CL"],"1609":["cs.CL"],"1610":["cs.CL","cs.AI"],"1611":["cs.CL","cs.LG"],"1612":["cs.CL"],"1613":["cs.CL"],"1614":["cs.CL"],"1615":["cs.CL","cs.AI"],"1616":["cs.CL","I.7"],"1617":["cs.CL","cs.LG"],"1618":["cs.CL"],"1619":["cs.CL","cs.AI","cs.LG"],"1620":["cs.CL","cs.LG"],"1621":["cs.CL","cs.LG"],"1622":["cs.CL","cs.AI","cs.LG"],"1623":["cs.CL"],"1624":["cs.CL","cs.SD","eess.AS"],"1625":["cs.CL"],"1626":["cs.CL"],"1627":["cs.CL","cs.LG","I.2; I.7; H.0"],"1628":["cs.CL"],"1629":["cs.SD","cs.CL","eess.AS"],"1630":["cs.LG","cs.CL"],"1631":["cs.CL"],"1632":["cs.CL","cs.SD","eess.AS"],"1633":["cs.CL"],"1634":["cs.CL"],"1635":["cs.CR","cs.AI","cs.CL"],"1636":["cs.CL"],"1637":["cs.IR","cs.CL"],"1638":["cs.CL","cs.AI"],"1639":["cs.CL","cs.AI","cs.IR","cs.LG","I.2.1; I.2.4"],"1640":["cs.SD","cs.CL","eess.AS","q-bio.QM"],"1641":["cs.CL","cs.CV"],"1642":["cs.CL"],"1643":["cs.CL"],"1644":["cs.CL","cs.AI"],"1645":["cs.CL","cs.IR"],"1646":["cs.CL","cs.AI"],"1647":["cs.CL"],"1648":["cs.LG","cs.CL","cs.MM"],"1649":["cs.CL"],"1650":["cs.CL"],"1651":["cs.CL"],"1652":["cs.CL"],"1653":["cs.CL","cs.IR"],"1654":["cs.CL","cs.SD","eess.AS"],"1655":["cs.CL","cs.AI","cs.LG","cs.MA"],"1656":["cs.CL","cs.CY"],"1657":["cs.CL","cs.AI","cs.DL","cs.IR","cs.LG"],"1658":["cs.CL"],"1659":["cs.CL","eess.AS"],"1660":["cs.CL","cs.AI","J.4; I.2.7"],"1661":["cs.IR","cs.CL","cs.CY","cs.SE","cs.SI"],"1662":["cs.CL","cs.AI"],"1663":["cs.CL"],"1664":["cs.CL"],"1665":["cs.CL"],"1666":["cs.CL","cs.SD","eess.AS"],"1667":["cs.CL","cs.LG"],"1668":["cs.CL"],"1669":["cs.CL","cs.LG"],"1670":["cs.CL"],"1671":["cs.CL"],"1672":["cs.CL"],"1673":["eess.AS","cs.CL","cs.LG"],"1674":["cs.CL","cs.AI"],"1675":["cs.CL","cs.PL"],"1676":["cs.CL"],"1677":["cs.CL"],"1678":["cs.CL","cs.IR","cs.LG"],"1679":["cs.CL","cs.CY"],"1680":["cs.CL"],"1681":["cs.CL"],"1682":["cs.CL","cs.AI"],"1683":["cs.CL","cs.IR"],"1684":["cs.CL"],"1685":["cs.CL"],"1686":["cs.CL","cs.AI"],"1687":["cs.LG","cs.CL","cs.MS","cs.PL"],"1688":["cs.CL"],"1689":["cs.HC","cs.CL"],"1690":["cs.CL","cs.AI","cs.LG"],"1691":["cs.IR","cs.CL","cs.LG"],"1692":["cs.CL","cs.CV","cs.MM","eess.AS"],"1693":["cs.CL"],"1694":["cs.CL","cs.AI"],"1695":["cs.CL","cs.AI","cs.LG"],"1696":["cs.CL"],"1697":["cs.CL"],"1698":["cs.CL"],"1699":["cs.CL"],"1700":["cs.CL","cs.AI","cs.CY"],"1701":["cs.CL"],"1702":["cs.CL"],"1703":["cs.CL"],"1704":["cs.CL"],"1705":["cs.CV","cs.CL","cs.DL","cs.SI"],"1706":["cs.LG","cs.CL","cs.SD","eess.AS"],"1707":["cs.LG","cs.CL"],"1708":["cs.CL"],"1709":["cs.CL"],"1710":["cs.CL"],"1711":["cs.CL","cs.AI"],"1712":["cs.CL","I.2.7"],"1713":["cs.CL"],"1714":["cs.CL"],"1715":["cs.SD","cs.CL","eess.AS"],"1716":["cs.CL"],"1717":["cs.CL"],"1718":["cs.CL"],"1719":["cs.CL"],"1720":["cs.CL"],"1721":["cs.CL"],"1722":["cs.CL","cs.AI"],"1723":["cs.SD","cs.CL","eess.AS"],"1724":["cs.CL","cs.AI"],"1725":["cs.IT","cs.AI","cs.CL","cs.LO","math.IT"],"1726":["cs.CL"],"1727":["cs.CL","cs.LG"],"1728":["cs.CL"],"1729":["cs.CL","cs.LG"],"1730":["cs.CL"],"1731":["cs.CL"],"1732":["cs.CL"],"1733":["cs.CL","cs.AI","cs.CR"],"1734":["cs.CV","cs.CL"],"1735":["cs.CL","cs.AI"],"1736":["eess.AS","cs.CL"],"1737":["cs.AI","cs.CL","cs.HC"],"1738":["cs.CL","cs.SI"],"1739":["cs.SD","cs.CL","eess.AS"],"1740":["cs.CL"],"1741":["cs.CL","cs.AI"],"1742":["cs.CL","cs.AI","cs.LG"],"1743":["cs.CL"],"1744":["cs.CL","cs.AI"],"1745":["cs.CL","cs.IR"],"1746":["cs.CL"],"1747":["cs.CL"],"1748":["cs.CL"],"1749":["cs.CL"],"1750":["cs.CL","cs.AI"],"1751":["cs.CL"],"1752":["cs.CL"],"1753":["cs.GT","cs.CL","cs.LO","cs.SI","03F07, 03F20, 91A05, 91A06, 91A07, 91A10, 91A11, 91A24, 91A26,\n  91A27, 91A28, 91A80, 68N17, 68P05, 68V15, 68V20, 68V30","F.4"],"1754":["cs.CL","cs.CY","cs.SI","physics.soc-ph"],"1755":["cs.LG","cs.CL","cs.CV"],"1756":["cs.CL"],"1757":["cs.CL"],"1758":["cs.CY","cs.AI","cs.CL","I.2.0"],"1759":["cs.CL","cs.AI"],"1760":["cs.CL","cs.LG"],"1761":["cs.CL","cs.AI"],"1762":["cs.CL","cs.AI"],"1763":["cs.SD","cs.CL","eess.AS"],"1764":["cs.CL"],"1765":["cs.LG","cs.CL"],"1766":["cs.CL","cs.HC"],"1767":["cs.CL"],"1768":["cs.CL"],"1769":["eess.SY","cs.AI","cs.CL","cs.LG","cs.SY"],"1770":["cs.CL","cs.AI","cs.CV","cs.LG","quant-ph"],"1771":["cs.CL"],"1772":["cs.LG","cs.CL","cs.CR","stat.ML"],"1773":["cs.CL","cs.AI","cs.LG"],"1774":["cs.CV","cs.CL"],"1775":["cs.CL","cs.AI"],"1776":["cs.CL","cs.AI","cs.LG"],"1777":["cs.CL"],"1778":["cs.CL"],"1779":["cs.CL","cs.AI"],"1780":["cs.CL","cs.LG"],"1781":["cs.SE","cs.CL","cs.SC"],"1782":["cs.CL","cs.IR"],"1783":["cs.CL","cs.LG","I.2.7"],"1784":["cs.CL"],"1785":["cs.CL"],"1786":["cs.CL","I.2.6; J.4"],"1787":["cs.SD","cs.CL","cs.LG","eess.AS"],"1788":["cs.CL"],"1789":["cs.CL","cs.AI"],"1790":["cs.IR","cs.AI","cs.CL"],"1791":["cs.SI","cs.CL"],"1792":["q-bio.NC","cs.AI","cs.CL","cs.LG"],"1793":["cs.CL"],"1794":["cs.CL","cs.AI","cs.LG","cs.NE","cs.SI"],"1795":["cs.CL"],"1796":["cs.CL"],"1797":["cs.CL","cs.LG"],"1798":["cs.CL","cs.AI","cs.CV","cs.LG","I.2.7"],"1799":["cs.CV","cs.AI","cs.CL"],"1800":["cs.SD","cs.CL","eess.AS"],"1801":["cs.CL"],"1802":["cs.CL"],"1803":["cs.CL","cs.CY","cs.LG"],"1804":["cs.LG","cs.AI","cs.CL"],"1805":["cs.CL"],"1806":["cs.CL","cs.AI","cs.LG"],"1807":["cs.CL"],"1808":["cs.CL"],"1809":["cs.CL","cs.AI","cs.HC"],"1810":["cs.CL","cs.AI","cs.HC","cs.IR"],"1811":["cs.CL","cs.SD","eess.AS"],"1812":["cs.CL"],"1813":["cs.CL"],"1814":["cs.CY","cs.AI","cs.CL","68T50","I.2.7; J.4"],"1815":["cs.CL","cs.CY"],"1816":["cs.CL","cs.AI","cs.LG"],"1817":["cs.CL","cs.CY"],"1818":["cs.CL","cs.AI"],"1819":["cs.CL"],"1820":["cs.LG","cs.CL"],"1821":["cs.CL"],"1822":["cs.CV","cs.CL","cs.LG"],"1823":["cs.CL"],"1824":["cs.CL","cs.AI"],"1825":["cs.SI","cs.CL","cs.LG"],"1826":["eess.AS","cs.CL"],"1827":["cs.CL","cs.AI","cs.CY","cs.LG"],"1828":["cs.CL","cs.AI"],"1829":["cs.CL","cs.AI"],"1830":["cs.CL"],"1831":["cs.CL","cs.AI","cs.LG","cs.MA"],"1832":["cs.CL","cs.AI"],"1833":["cs.CL"],"1834":["cs.CL","cs.LG"],"1835":["cs.CL","cs.CY","cs.LG"],"1836":["cs.CL","cs.LG"],"1837":["cs.AI","cs.CL","cs.LG"],"1838":["cs.CL"],"1839":["cs.CL","cs.AI"],"1840":["eess.AS","cs.CL","cs.SD"],"1841":["cs.CL","cs.AI"],"1842":["cs.CL","cs.LG"],"1843":["cs.CL"],"1844":["cs.LG","cs.AI","cs.CL","stat.ML"],"1845":["cs.CL"],"1846":["cs.CY","cs.CL"],"1847":["cs.CL","cs.AI","cs.LG","stat.ML","68T50, 68T05, 68T07","I.2; I.7"],"1848":["cs.CL","cs.AI"],"1849":["cs.CL","cs.CY","cs.SI"],"1850":["cs.CL","cs.LG"],"1851":["cs.CL"],"1852":["cs.CL"],"1853":["cs.CV","cs.AI","cs.CL"],"1854":["cs.CL"],"1855":["cs.CL","cs.AI"],"1856":["cs.CL","cs.CY","cs.LG"],"1857":["cs.CL","cs.LG"],"1858":["cs.CL","cs.LG"],"1859":["cs.SI","cs.CL"],"1860":["cs.CL"],"1861":["cs.CL","cs.AI","cs.DB"],"1862":["cs.CL"],"1863":["cs.CL"],"1864":["cs.CL","cs.AI","cs.LG"],"1865":["cs.SI","cs.CL","cs.LG"],"1866":["cs.CL"],"1867":["eess.AS","cs.CL"],"1868":["cs.CL","cs.IR","68T50","F.2.2; I.2.7"],"1869":["cs.CL","cs.AI","cs.IR","cs.LG","cs.NE","68T50","F.2.2; I.2.7"],"1870":["cs.CL"],"1871":["cs.CL"],"1872":["cs.CL","cs.LG"],"1873":["cs.CL"],"1874":["cs.CL","cs.AI","cs.LG"],"1875":["cs.CL","I.2.7"],"1876":["cs.CL"],"1877":["cs.CL","cs.LG","cs.SD","eess.AS"],"1878":["cs.SD","cs.CL","eess.AS"],"1879":["cs.CL"],"1880":["cs.LG","cs.CL"],"1881":["cs.CL"],"1882":["cs.LG","cs.CL"],"1883":["cs.CL","cs.LG"],"1884":["cs.CL","cs.AI"],"1885":["cs.CL"],"1886":["eess.AS","cs.CL","cs.LG","cs.SD"],"1887":["cs.CL"],"1888":["cs.CL","cs.SD","eess.AS"],"1889":["cs.CL","eess.AS"],"1890":["cs.CV","cs.CL"],"1891":["cs.CL"],"1892":["cs.SE","cs.CL"],"1893":["cs.CL"],"1894":["cs.CL"],"1895":["eess.AS","cs.CL","cs.SD"],"1896":["eess.AS","cs.CL","cs.SD"],"1897":["cs.CL"],"1898":["cs.CL"],"1899":["cs.CL"],"1900":["cs.CL","cs.AI","cs.LG"],"1901":["cs.AI","cs.CL","cs.RO"],"1902":["cs.CV","cs.CL"],"1903":["cs.CL","cs.LG","eess.AS"],"1904":["cs.CL"],"1905":["cs.CL"],"1906":["cs.CL"],"1907":["cs.HC","cs.CL"],"1908":["cs.CY","cs.CL"],"1909":["cs.CL"],"1910":["cs.CL"],"1911":["cs.CL"],"1912":["cs.CL"],"1913":["cs.CL","cs.LG"],"1914":["cs.CL"],"1915":["cs.CL"],"1916":["cs.CL","cs.AI","cs.IR","cs.LG","cs.LO"],"1917":["cs.CL"],"1918":["cs.CL","cs.AI","quant-ph"],"1919":["cs.CL"],"1920":["cs.CL","cs.AI","cs.LG"],"1921":["cs.CL","cs.SI","I.2.7; I.5.4; J.4"],"1922":["cs.CL"],"1923":["cs.CL"],"1924":["cs.CL"],"1925":["cs.IR","cs.AI","cs.CL","97E40 (Primary) 00Axx, 68T50, 97-XX (Secondary)","H.3; H.4; I.2; I.7; I.1"],"1926":["cs.CL","cs.LG"],"1927":["cs.CL","cs.AI"],"1928":["eess.AS","cs.CL","cs.SD"],"1929":["cs.CL"],"1930":["cs.CL"],"1931":["cs.CV","cs.CL"],"1932":["cs.CL"],"1933":["cs.SD","cs.CL","cs.LG","eess.AS"],"1934":["cs.CL","cs.AI"],"1935":["cs.CL","cs.LG","cs.SD","eess.AS"],"1936":["cs.CL"],"1937":["eess.AS","cs.CL","cs.SD"],"1938":["cs.LG","cs.CL"],"1939":["cs.CL","cs.SD","eess.AS"],"1940":["cs.CL","cs.LG"],"1941":["cs.CL"],"1942":["eess.AS","cs.CL","cs.LG"],"1943":["cs.CL","cs.AI","cs.LG"],"1944":["cs.CL","cs.SD","eess.AS"],"1945":["cs.CL"],"1946":["cs.CL","cs.AI"],"1947":["cs.CL"],"1948":["cs.CL","cs.IR"],"1949":["cs.CL","cs.SD","eess.AS"],"1950":["cs.CL","eess.AS"],"1951":["cs.CL","cs.AI"],"1952":["cs.CL"],"1953":["cs.CL","cs.AI","cs.LG"],"1954":["cs.CL","cs.SD","eess.AS"],"1955":["cs.LG","cs.AI","cs.CL"],"1956":["cs.CL","cs.AI"],"1957":["cs.CV","cs.CL","cs.LG"],"1958":["cs.LG","cs.CL","cs.SD","eess.AS"],"1959":["cs.CL"],"1960":["cs.CL"],"1961":["cs.CL"],"1962":["cs.AI","cs.CL"],"1963":["cs.IR","cs.CL"],"1964":["cs.CL"],"1965":["eess.AS","cs.AI","cs.CL","cs.LG","cs.NE"],"1966":["cs.AI","cs.CL"],"1967":["cs.CL"],"1968":["cs.CL"],"1969":["cs.SE","cs.CL","cs.HC"],"1970":["cs.CL","cs.LG","cs.CL, cs.GL","I.2; I.7"],"1971":["cs.CL","cs.SD","eess.AS"],"1972":["cs.CL","cs.AI"],"1973":["cs.CL","cs.LG"],"1974":["cs.CL"],"1975":["cs.CL","cs.LG"],"1976":["cs.CL"],"1977":["cs.CL","cs.LG"],"1978":["cs.CL"],"1979":["cs.CL","cs.AI"],"1980":["cs.SD","cs.CL","eess.AS"],"1981":["cs.CL","cs.LG"],"1982":["cs.AI","cs.CL","cs.LG","cs.SD","eess.AS"],"1983":["cs.CL"],"1984":["cs.CL"],"1985":["cs.CL"],"1986":["cs.CL","I.7.0"],"1987":["cs.CL","cs.CV"],"1988":["cs.CL"],"1989":["cs.CL"],"1990":["cs.CL","cs.LG"],"1991":["cs.CL"],"1992":["cs.CL"],"1993":["cs.CL","cs.AI"],"1994":["cs.LG","cs.AI","cs.CL"],"1995":["cs.CV","cs.CL"],"1996":["cs.CL","cs.AI","cs.LG"],"1997":["cs.SD","cs.CL","cs.LG","eess.AS"],"1998":["cs.CL"],"1999":["cs.LG","cs.CL"],"2000":["cs.CL","A.2"],"2001":["cs.CL","cs.AI"],"2002":["cs.CL"],"2003":["cs.CL","cs.AI"],"2004":["cs.CL"],"2005":["cs.LG","cs.CL"],"2006":["cs.CV","cs.CL","cs.RO"],"2007":["cs.CL","cs.LG"],"2008":["cs.CL","cs.LG","cs.NE"],"2009":["cs.CL","cs.SI"],"2010":["cs.CL"],"2011":["cs.CL","I.2.7"],"2012":["cs.LG","cs.CL","cs.SD","eess.AS","eess.SP"],"2013":["cs.CL","cs.AI"],"2014":["cs.CL","cs.LG"],"2015":["cs.CL"],"2016":["eess.AS","cs.CL","cs.LG","cs.SD"],"2017":["cs.CL"],"2018":["cs.CL"],"2019":["cs.CL","cs.AI"],"2020":["cs.CL","cs.AI"],"2021":["cs.CV","cs.CL","cs.LG"],"2022":["cs.CL"],"2023":["cs.CL"],"2024":["cs.LG","cs.CL"],"2025":["cs.CL","cs.AI"],"2026":["cs.CL","I.2.7"],"2027":["cs.CL","eess.AS"],"2028":["cs.CL","cs.AI"],"2029":["cs.CL","cs.LG"],"2030":["cs.CL"],"2031":["cs.CL","cs.LG"],"2032":["cs.CL","cs.LG"],"2033":["cs.CL","cs.AI","cs.LG","cs.NE"],"2034":["cs.CL","cs.AI","cs.LG"],"2035":["cs.CL"],"2036":["cs.CL","cs.LG"],"2037":["cs.CL"],"2038":["cs.CL","cs.DM","physics.soc-ph"],"2039":["cs.CL","cs.CR"],"2040":["cs.IR","cs.CL"],"2041":["q-bio.NC","cs.CL"],"2042":["cs.CL","cs.AI","cs.LG"],"2043":["cs.CL"],"2044":["cs.CL"],"2045":["cs.CL","cs.LG"],"2046":["cs.CL","cs.LG"],"2047":["cs.SD","cs.CL","eess.AS"],"2048":["cs.CL","cs.HC"],"2049":["cs.SI","cs.CL","cs.IR"],"2050":["cs.CL"],"2051":["cs.IR","cs.CL"],"2052":["cs.CL"],"2053":["cs.SE","cs.CL"],"2054":["cs.CL","cs.AI","cs.LG"],"2055":["cs.CL"],"2056":["cs.CL"],"2057":["cs.CL"],"2058":["cs.CL"],"2059":["cs.CL"],"2060":["cs.SI","cs.CL"],"2061":["cs.CL","cs.AI"],"2062":["cs.CL"],"2063":["cs.LG","cs.AI","cs.CL"],"2064":["cs.CL"],"2065":["cs.CL"],"2066":["cs.CL"],"2067":["cs.CL"],"2068":["cs.CL"],"2069":["cs.CL"]}}