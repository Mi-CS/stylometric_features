{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load scripts\n",
    "from text_cleaning import clean_text\n",
    "from clustering import KMeansAuthors, ModHausdorffDocument\n",
    "from style_point_cloud import style_point_cloud\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/csCL_sample.json\")\n",
    "\n",
    "# Text cleaning\n",
    "df.text_body = df.text_body.progress_apply(clean_text)\n",
    "\n",
    "# Generate point cloud for each text. Since this is shorter, we must\n",
    "# take less tokens\n",
    "df[\"point_cloud\"] = df.text_body.progress_apply(lambda text: style_point_cloud(text, window_size=600, window_overlap=300, max_tokens=15_000))\n",
    "\n",
    "# Remove documents with no points\n",
    "df = df[df.point_cloud.apply(len) > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This subsample was taking by considering if Diptesh Kanojia, Hannes Westermann, or Bing Liu\n",
    "# were among the first 2 authors, so let just first use them as sole authors. \n",
    "author_list = [\"Diptesh Kanojia\", \"Hannes Westermann\", \"Bing Liu\"]\n",
    "df[\"author_single\"] = df.authors.apply(lambda x: set(x).intersection(author_list).pop())\n",
    "\n",
    "# Create an author label for each point\n",
    "auth_labels = [[author]*n_chunks for author, n_chunks in \n",
    "                zip(df.author_single, df.point_cloud.apply(len))]\n",
    "\n",
    "# Flatten\n",
    "auth_labels = [x for y in auth_labels for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = StandardScaler().fit_transform(np.vstack(df.point_cloud))\n",
    "X = PCA(n_components=5).fit_transform(data)\n",
    "\n",
    "cl = KMeansAuthors(n_authors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4467005076142132"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.fit(X, auth_labels)\n",
    "cl.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document accuracy\n",
    "(df.author_single == cl.predict_document(X, df.point_cloud.apply(len).to_numpy())).sum() / df.author_single.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cl.predict(X, author_labels=True)\n",
    "auth_idx = dict(zip(set(predictions), range(len(set(predictions)))))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "for label in set(predictions): \n",
    "    mask_pred = [True if pr == label else False for pr in predictions]\n",
    "    mask_true = [True if pr == label else False for pr in auth_labels]\n",
    "    ax1.scatter(X[:, 0][mask_pred], X[:, 1][mask_pred], label=label)\n",
    "    ax2.scatter(X[:, 0][mask_true], X[:, 1][mask_true], label=label)\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    ax1.set_title(\"KMeans Predicted\")\n",
    "    ax2.set_title(\"True labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhcl = ModHausdorffDocument(n_authors=3)\n",
    "mhcl.fit(X, doc_lengths=df.point_cloud.apply(len).to_numpy(), author_labels=df.author_single)\n",
    "mhcl.best_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "936a5b082d031c3f84051317a1cecdb9fa62954e636831d12ecae1cf9c53cca8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
